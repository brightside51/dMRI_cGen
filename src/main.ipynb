{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# *Initial* **Setup**\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Library** *Settings*\n",
    "\n",
    "The Real Package Name must be found in https://pypi.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pfernan2\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pl_bolts\\callbacks\\data_monitor.py:20: UnderReviewWarning: The feature warn_missing_pkg is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  warn_missing_pkg(\"wandb\")\n",
      "C:\\Users\\pfernan2\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pl_bolts\\models\\self_supervised\\amdim\\amdim_module.py:35: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
      "C:\\Users\\pfernan2\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pl_bolts\\models\\self_supervised\\amdim\\amdim_module.py:93: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
      "C:\\Users\\pfernan2\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pl_bolts\\losses\\self_supervised_learning.py:234: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.nce_loss = AmdimNCELoss(tclip)\n",
      "C:\\Users\\pfernan2\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pl_bolts\\datamodules\\experience_source.py:18: UnderReviewWarning: The feature warn_missing_pkg is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  warn_missing_pkg(\"gym\")\n"
     ]
    }
   ],
   "source": [
    "# Library Import\n",
    "import pathlib\n",
    "import os\n",
    "import sys\n",
    "import io\n",
    "import gc\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import psutil\n",
    "import nilearn\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchsummary\n",
    "import pytorchtools as pytt\n",
    "import torchvision\n",
    "import pytorch_lightning as pl\n",
    "import pl_bolts                     # lightning_bolts\n",
    "import tensorboard\n",
    "#import tensorflow as tf\n",
    "#import keras\n",
    "import fvcore\n",
    "import matplotlib.pyplot as plt\n",
    "import itk\n",
    "import itkwidgets\n",
    "import time\n",
    "import timeit\n",
    "import warnings\n",
    "import tqdm\n",
    "import alive_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functionality Import\n",
    "from pathlib import Path\n",
    "from math import exp\n",
    "#from __future__ import annotations\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath\n",
    "from typing import List, Literal, Optional, Callable, Dict, Literal, Optional, Union, Tuple, Iterable\n",
    "from collections import OrderedDict, namedtuple\n",
    "from collections.abc import Sequence\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torch.nn.utils import spectral_norm\n",
    "from torch.nn.modules.loss import _Loss\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "#from pytorchtools import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pl_bolts.models.autoencoders.components import resnet18_encoder, resnet18_decoder\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "#from monai.metrics.regression import KernelType, SSIMMetric\n",
    "#from monai.utils import LossReduction, ensure_tuple_rep\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense, Dropout, LeakyReLU, Layer, Softmax, Input, BatchNormalization\n",
    "#from keras import backend as K\n",
    "#from keras import Model\n",
    "#from keras.callbacks import EarlyStopping\n",
    "#from keras.initializers import Constant, glorot_normal\n",
    "#from keras_visualizer import visualizer \n",
    "#from keras.optimizers import Adam\n",
    "#from tensorflow.keras.utils import plot_model\n",
    "from itertools import product\n",
    "from datetime import datetime\n",
    "\n",
    "from nilearn.image import load_img\n",
    "from nilearn.masking import unmask\n",
    "from PIL import Image\n",
    "from ipywidgets import interactive, IntSlider\n",
    "from tabulate import tabulate\n",
    "from tqdm.notebook import tqdm\n",
    "from alive_progress import alive_bar\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Control** *Station* | **Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Dataset Parametrizations Parser Initialization\n",
    "data_parser = argparse.ArgumentParser(\n",
    "    description = \"1D MUDI Dataset Settings\")\n",
    "data_parser.add_argument(                               # Dataset Version Variable\n",
    "    '--version', type = int,                            # Default: 0\n",
    "    default = 0,\n",
    "    help = \"Dataset Save Version\")\n",
    "data_parser.add_argument(                               # Dataset Batch Size Value\n",
    "    '--batch_size', type = int,                         # Default: 500\n",
    "    default = 300000,\n",
    "    help = \"Dataset Batch Size Value\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Dataset Label Parametrization Arguments\n",
    "data_parser.add_argument(                               # Control Variable for the Inclusion of Patient ID in Labels\n",
    "    '--patient_id', type = bool,                        # Default: True\n",
    "    default = False,\n",
    "    help = \"Control Variable for the Inclusion of Patient ID in Labels\")\n",
    "data_parser.add_argument(                               # Control Variable for the Conversion of 3 Gradient Directions\n",
    "    '--gradient_coord', type = bool,                    # Coordinates into 2 Gradient Direction Angles (suggested by prof. Chantal)\n",
    "    default = False,                                    # Default: True (3 Coordinate Gradient Values)\n",
    "    help = \"Control Variable for the Conversion of Gradient Direction Mode\")\n",
    "data_parser.add_argument(                               # Control Variable for the Rescaling & Normalization of Labels\n",
    "    '--label_norm', type = bool,                        # Default: True\n",
    "    default = True,\n",
    "    help = \"Control Variable for the Rescaling & Normalization of Labels\")\n",
    "data_settings = data_parser.parse_args(\"\")\n",
    "num_labels = 7\n",
    "if not(data_settings.patient_id): num_labels -= 1       # Exclusion of Patiend ID\n",
    "if not(data_settings.gradient_coord): num_labels -= 1   # Conversion of Gradient Coordinates to Angles\n",
    "data_parser.add_argument(                               # Dataset Number of Labels\n",
    "    '--num_labels', type = int,                         # Default: 7\n",
    "    default = num_labels,\n",
    "    help = \"MUDI Dataset Number of Labels\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Addition of File & Folderpath Arguments\n",
    "data_parser.add_argument(                               # Path for Main Dataset Folder\n",
    "    '--main_folderpath', type = str,\n",
    "    default = '../../Datasets/MUDI Dataset',\n",
    "    help = 'Main Folderpath for Root Dataset')\n",
    "data_settings = data_parser.parse_args(\"\")\n",
    "data_parser.add_argument(                               # Path for Parameter Value File\n",
    "    '--param_filepath', type = Path,\n",
    "    default = Path(f'{data_settings.main_folderpath}/Raw Data/parameters_new.xlsx'),\n",
    "    help = 'Input Filepath for Parameter Value Table')\n",
    "data_parser.add_argument(                               # Path for Parameter Value File\n",
    "    '--data_filepath', type = Path,\n",
    "    default = Path(f'{data_settings.main_folderpath}/Raw Data/data_.hdf5'),\n",
    "    help = 'Input Filepath for Parameter Value Table')\n",
    "data_parser.add_argument(                               # Path for Patient Information File\n",
    "    '--info_filepath', type = Path,\n",
    "    default = Path(f'{data_settings.main_folderpath}/Raw Data/header_.csv'),\n",
    "    help = 'Input Filepath for Patient Information Table')\n",
    "data_parser.add_argument(                               # Path for Folder Containing Mask Data Files\n",
    "    '--mask_folderpath', type = Path,\n",
    "    default = Path(f'{data_settings.main_folderpath}/Patient Mask'),\n",
    "    help = 'Input Folderpath for Segregated Patient Mask Data')\n",
    "data_parser.add_argument(                               # Path for Dataset Saved Files\n",
    "    '--save_folderpath', type = Path,\n",
    "    default = Path(f'{data_settings.main_folderpath}/Saved Data/V{data_settings.version}'),\n",
    "    help = 'Output Folderpath for MUDI Dataset Saved Versions')\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "\"\"\"\n",
    "# Dataset Splitting Arguments\n",
    "data_parser.add_argument(                               # List of Patients in MUDI Dataset\n",
    "    '--patient_list', type = list,                      # Default: [11, 12, 13, 14, 15]\n",
    "    default = [11, 12, 13, 14, 15],\n",
    "    help = \"List of Patients in MUDI Dataset\")\n",
    "data_parser.add_argument(                               # Number of Patients to be used in the Test Set\n",
    "    '--num_test_patients', type = int,                  # Default: 1\n",
    "    default = 2,\n",
    "    help = \"Number of Patients in Test Set\")\n",
    "data_parser.add_argument(                               # Selected Test Patient\n",
    "    '--sel_test_patients', type = int or list,          # Default: 14\n",
    "    default = [14, 15],\n",
    "    help = \"Selected Test Patient\")\n",
    "\"\"\"\n",
    "data_parser.add_argument(                               # Number / Percentage of Parameters for Training Set's Training\n",
    "    '--num_train_params', type = int,                   # Default: 500\n",
    "    default = 500,\n",
    "    help = \"Number / Percentage of Patients in the Training of the Training Set\")\n",
    "    \n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Boolean Control Input & Shuffling Arguments\n",
    "data_parser.add_argument(                       # Ability to Shuffle the Patients that compose both Training and Test Sets\n",
    "    '--patient_shuffle', type = bool,           # Default: False\n",
    "    default = False,\n",
    "    help = \"Ability to Shuffle the Patients that compose both Training and Test Sets\")\n",
    "data_parser.add_argument(                       # Ability to Shuffle the Samples inside both Training and Validation Sets\n",
    "    '--sample_shuffle', type = bool,            # Default: False\n",
    "    default = False,\n",
    "    help = \"Ability to Shuffle the Samples inside both Training and Validation Sets\")\n",
    "data_parser.add_argument(                       # Number of Workers for DataLoader Usage\n",
    "    '--num_workers', type = int,                # Default: 1\n",
    "    default = 12,\n",
    "    help = \"Number of Workers for DataLoader Usage\")\n",
    "data_settings = data_parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Access\n",
    "sys.path.append(f\"../../Datasets/MUDI Dataset/Dataset Reader\")\n",
    "from MUDI_1D import MUDI_1D"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Control** *Station* | **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [fcNN] Fully Connected Neural Network Model Parametrizations Parser Initialization\n",
    "model_parser = argparse.ArgumentParser(\n",
    "    description = \"fcNN Settings\")\n",
    "model_parser.add_argument(              # Model Version Variable\n",
    "    '--model_version', type = int,  # Default: 0\n",
    "    default = 0,\n",
    "    help = \"Experiment Version\")\n",
    "model_parser.add_argument(              # Dataset Version Variable\n",
    "    '--data_version', type = int,   # Default: 0\n",
    "    default = 0,\n",
    "    help = \"MUDI Dataset Version\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Addition of Filepath Arguments\n",
    "model_parser.add_argument(\n",
    "    '--reader_folderpath', type = Path,\n",
    "    default = Path(f'{data_settings.main_folderpath}/Dataset Reader'),\n",
    "    help = 'Input Folderpath for MUDI Dataset Reader')\n",
    "model_parser.add_argument(\n",
    "    '--data_folderpath', type = Path,\n",
    "    default = Path(f'{data_settings.main_folderpath}/Saved Data/V{data_settings.version}'),\n",
    "    help = 'Input Folderpath for MUDI Dataset Saved Versions')\n",
    "model_parser.add_argument(\n",
    "    '--model_folderpath', type = str,\n",
    "    default = 'Model Builds',\n",
    "    help = 'Input Folderpath for Model Build & Architecture')\n",
    "model_parser.add_argument(\n",
    "    '--script_folderpath', type = str,\n",
    "    default = 'Training Scripts',\n",
    "    help = 'Input Folderpath for Training & Testing Script Functions')\n",
    "model_parser.add_argument(\n",
    "    '--save_folderpath', type = str,\n",
    "    default = 'Saved Models',\n",
    "    help = 'Output Folderpath for Saved & Saving Models')\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Addition of Training Requirement Arguments\n",
    "model_parser.add_argument(              # Number of Epochs\n",
    "    '--num_epochs', type = int,     # Default: 1200\n",
    "    default = 300,\n",
    "    help = \"Number of Epochs in Training Mode\")\n",
    "model_settings = model_parser.parse_args(\"\")\n",
    "model_parser.add_argument(              # Base Learning Rate\n",
    "    '--base_lr', type = float,      # Default: 1e-4\n",
    "    default = 1e-3,\n",
    "    help = \"Base Learning Rate Value in Training Mode\")\n",
    "model_parser.add_argument(              # Weight Decay Value\n",
    "    '--weight_decay', type = float, # Default: 1e-4\n",
    "    default = 1e-4,\n",
    "    help = \"Weight Decay Value in Training Mode\")\n",
    "model_parser.add_argument(              # Learning Rate Decay Ratio\n",
    "    '--lr_decay', type = float,     # Default: 0.9\n",
    "    default = 0.9,\n",
    "    help = \"Learning Rate Decay Value in Training Mode\")\n",
    "model_parser.add_argument(              # Number of Epochs after which LR should Decay\n",
    "    '--step_decay', type = int,     # Default: int(model_settings.num_epochs / 10)\n",
    "    default = int(model_settings.num_epochs / 10),\n",
    "    help = \"Number of Epochs after which LR should Decay\")\n",
    "model_parser.add_argument(              # Early Stopping Epoch Patience Value\n",
    "    '--es_patience', type = int,    # Default: 1000 (no Early Stopping)\n",
    "    default = 50,\n",
    "    help = \"Early Stopping Epoch Patience Value\")\n",
    "    \n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Addition of Result Visualization Arguments\n",
    "model_parser.add_argument(                              # Selected Patient for Training Image Reconstruction\n",
    "    '--sel_train_patient', type = int,              # Default: 11\n",
    "    default = 11,\n",
    "    help = \"Selected Patient for Training Image Reconstruction\")\n",
    "model_parser.add_argument(                              # Selected Patient for Validation Image Reconstruction\n",
    "    '--sel_val_patient', type = int,                # Default: 15\n",
    "    default = 15,\n",
    "    help = \"Selected Patient for Validation Image Reconstruction\")\n",
    "model_parser.add_argument(                              # Selected Patient for Test Image Reconstruction\n",
    "    '--sel_test_patient', type = int,               # Default: 14\n",
    "    default = 14,\n",
    "    help = \"Selected Patient for Test Image Reconstruction\")\n",
    "model_parser.add_argument(                              # Ability to Shuffle the Parameters chosen for Reconstruction\n",
    "    '--recon_shuffle', type = bool,                 # Default: False\n",
    "    default = False,\n",
    "    help = \"Ability to Shuffle the Parameters chosen for Reconstruction\")\n",
    "model_parser.add_argument(                              # Selected Parameter for Training Image Reconstruction\n",
    "    '--sel_train_param', type = int,                # Default: 14\n",
    "    default = 300,\n",
    "    help = \"Selected Parameter for Training Image Reconstruction\")\n",
    "model_parser.add_argument(                              # Selected Parameter for Validation Image Reconstruction\n",
    "    '--sel_val_param', type = int,                  # Default: 14\n",
    "    default = 500,\n",
    "    help = \"Selected Parameter for Validation Image Reconstruction\")\n",
    "#model_parser.add_argument('--data_settings', default = data_settings)\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Addition of Model Architecture Arguments\n",
    "model_parser.add_argument(              # Dataset Number of Labels\n",
    "    '--num_labels', type = int,     # Default: 7\n",
    "    default = data_settings.num_labels,\n",
    "    help = \"MUDI Dataset Number of Labels\")\n",
    "model_parser.add_argument(              # Number of Parameter Settings for Training\n",
    "    '--in_params', type = int,      # Default: 500\n",
    "    default = int(data_settings.num_train_params),\n",
    "    help = \"Number of Parameter Settings for Training\")\n",
    "model_parser.add_argument(              # Total Number of Parameter Settings\n",
    "    '--out_params', type = int,     # Default: 1344\n",
    "    default = 1344,\n",
    "    help = \"Total Number of Parameter Settings\")\n",
    "model_parser.add_argument(              # Number of Hidden Layers in Neural Network\n",
    "    '--num_hidden', type = int,     # Default: 2\n",
    "    default = 2,\n",
    "    help = \"Number of Hidden Layers in Neural Network\")\n",
    "\n",
    "model_settings = model_parser.parse_args(\"\")\n",
    "model_settings.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [fcNN] Fully Connected Neural Network Model Parametrizations Parser Initialization\n",
    "parser = argparse.ArgumentParser(\n",
    "    description = \"fcNN Model Settings\")\n",
    "parser.add_argument(                            # Dataset Version Variable\n",
    "    '--data_version', type = int,               # Default: 0\n",
    "    default = 0,\n",
    "    help = \"Dataset Save Version\")\n",
    "parser.add_argument(                            # Model Version Variable\n",
    "    '--model_version', type = int,              # Default: 0\n",
    "    default = 0,\n",
    "    help = \"Experiment Version\")\n",
    "parser.add_argument(                            # Random Seed for Reproducibility\n",
    "    '--seed', type = int,                       # Default: 42\n",
    "    default = 42,\n",
    "    help = \"Random Seed for Reproducibility\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Dataset Settings | Label Parametrization Arguments\n",
    "parser.add_argument(                                    # Control Variable for the Inclusion of Patient ID in Labels\n",
    "    '--patient_id', type = bool,                        # Default: True\n",
    "    default = False,\n",
    "    help = \"Control Variable for the Inclusion of Patient ID in Labels\")\n",
    "parser.add_argument(                                    # Control Variable for the Conversion of 3 Gradient Directions\n",
    "    '--gradient_coord', type = bool,                    # Coordinates into 2 Gradient Direction Angles (suggested by prof. Chantal)\n",
    "    default = True,                                    # Default: True (3 Coordinate Gradient Values)\n",
    "    help = \"Control Variable for the Conversion of Gradient Direction Mode\")\n",
    "parser.add_argument(                                    # Control Variable for the Rescaling & Normalization of Labels\n",
    "    '--label_norm', type = str,                         # Default: auto\n",
    "    default = 'manual',\n",
    "    choices = ['auto', 'manual', None],\n",
    "    help = \"Control Variable for the Rescaling & Normalization of Labels\")\n",
    "settings = parser.parse_args(\"\"); num_labels = 7\n",
    "if not(settings.patient_id): num_labels -= 1                                                # Exclusion of Patiend ID\n",
    "if not(settings.gradient_coord) or settings.label_norm == 'manual': num_labels -= 1         # Conversion of Gradient Coordinates to Angles\n",
    "parser.add_argument(                                                                        # Dataset Number of Labels\n",
    "    '--num_labels', type = int,                                                             # Default: 7\n",
    "    default = num_labels,\n",
    "    help = \"MUDI Dataset Number of Labels\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Dataset Settings | Set Construction Arguments\n",
    "parser.add_argument(                            # Complete List of Patients in Dataset\n",
    "    '--patient_list', type = list,              # Default: [11, 12, 13, 14, 15]\n",
    "    default = [11, 12, 13, 14, 15],\n",
    "    help = \"Complete List of Patients in Dataset\")\n",
    "parser.add_argument(                            # List of Patients used in Training\n",
    "    '--train_patient_list', type = list,        # Default: [11, 12, 13]\n",
    "    default = [11, 12, 13],\n",
    "    help = \"List of Patients used in Training\")\n",
    "parser.add_argument(                            # List of Patients used in Validation\n",
    "    '--val_patient_list', type = list,          # Default: [15]\n",
    "    default = [15],\n",
    "    help = \"List of Patients used in Validation\")\n",
    "parser.add_argument(                            # List of Patients used in Testing\n",
    "    '--test_patient_list', type = list,         # Default: [14]\n",
    "    default = [14],\n",
    "    help = \"List of Patients used in Testing\")\n",
    "parser.add_argument(                            # Number of Workers for DataLoader Usage\n",
    "    '--num_workers', type = int,                # Default: 1\n",
    "    default = 12,\n",
    "    help = \"Number of Workers for DataLoader Usage\")\n",
    "parser.add_argument(                            # DataLoader Batch Size\n",
    "    '--batch_size', type = int,                 # Default: 250000\n",
    "    default = 1000,\n",
    "    help = \"DataLoader Batch Size\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Dataset Settings | Shuffling Arguments\n",
    "parser.add_argument(                                    # Ability to Shuffle Training DataLoaders' Samples\n",
    "    '--train_sample_shuffle', type = bool,              # Default: False\n",
    "    default = True,\n",
    "    help = \"Ability to Shuffle Training DataLoaders' Samples\")\n",
    "parser.add_argument(                                    # Ability to Shuffle Validation DataLoaders' Samples\n",
    "    '--val_sample_shuffle', type = bool,                # Default: False\n",
    "    default = False,\n",
    "    help = \"Ability to Shuffle Validation DataLoaders' Samples\")\n",
    "parser.add_argument(                                    # Ability to Shuffle Target Voxels\n",
    "    '--voxel_shuffle', type = bool,                     # Default: True\n",
    "    default = True,\n",
    "    help = \"Ability to Shuffle Target Voxels\")\n",
    "parser.add_argument(                                    # Control Variable for the Sharing of Parameters inbetween Patient Sets\n",
    "    '--interpatient_sharing', type = bool,              # Default: True (all Training Patient Sets will have, for the same epoch, ...\n",
    "    default = False,                                    # ... the same exact parameters to reconstruct the data to, defined by the 1st Patient\n",
    "    help = \"Control Variable for the Sharing of Parameters inbetween Patient Sets\")\n",
    "\n",
    "# Dataset Settings | Subsectioning Arguments\n",
    "parser.add_argument(                                    # Percentage of Used Target Voxels used in Training\n",
    "    '--train_target_voxel', type = int or float,        # Default: 60%\n",
    "    default = 100,\n",
    "    help = \"Percentage of Used Target Voxels used in Training\")\n",
    "parser.add_argument(                                    # Percentage of Used Target Voxels used in Validation\n",
    "    '--val_target_voxel', type = int or float,          # Default: 100%\n",
    "    default = 100,\n",
    "    help = \"Percentage of Used Target Voxels during Validation\")\n",
    "parser.add_argument(                                    # Selected Slice for Image Visualization\n",
    "    '--sel_slice', type = int,                          # Default: 25\n",
    "    default = 25,\n",
    "    help = \"Selected Slice for Image Visualization\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Paths | Dataset-Related File & Folderpath Arguments\n",
    "parser.add_argument(                                    # Path for Main Dataset Folder\n",
    "    '--main_folderpath', type = str,\n",
    "    default = '../../Datasets/MUDI Dataset',\n",
    "    help = 'Main Folderpath for Root Dataset')\n",
    "settings = parser.parse_args(\"\")\n",
    "parser.add_argument(                                    # Path for Parameter Value File\n",
    "    '--param_filepath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Raw Data/parameters_new.xlsx'),\n",
    "    help = 'Input Filepath for Parameter Value Table')\n",
    "parser.add_argument(                                    # Path for Parameter Value File\n",
    "    '--data_filepath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Raw Data/data_.hdf5'),\n",
    "    help = 'Input Filepath for Parameter Value Table')\n",
    "parser.add_argument(                                    # Path for Patient Information File\n",
    "    '--info_filepath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Raw Data/header_.csv'),\n",
    "    help = 'Input Filepath for Patient Information Table')\n",
    "parser.add_argument(                                    # Path for Folder Containing Mask Data Files\n",
    "    '--mask_folderpath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Patient Mask'),\n",
    "    help = 'Input Folderpath for Segregated Patient Mask Data')\n",
    "parser.add_argument(                                    # Path for Dataset Saved Files\n",
    "    '--datasave_folderpath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Saved Data/V{settings.data_version}'),\n",
    "    help = 'Output Folderpath for MUDI Dataset Saved Versions')\n",
    "\n",
    "# Paths | Model-Related File & Folderpath Arguments\n",
    "parser.add_argument(                                    # Path for Dataset Reader Script\n",
    "    '--reader_folderpath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Dataset Reader'),\n",
    "    help = 'Input Folderpath for MUDI Dataset Reader')\n",
    "parser.add_argument(                                    # Path for Model Build Script\n",
    "    '--build_folderpath', type = str,\n",
    "    default = 'Model Builds',\n",
    "    help = 'Input Folderpath for Model Build & Architecture')\n",
    "parser.add_argument(                                    # Path for Model Training Scripts\n",
    "    '--script_folderpath', type = str,\n",
    "    default = 'Training Scripts',\n",
    "    help = 'Input Folderpath for Training & Testing Script Functions')\n",
    "parser.add_argument(                                    # Path for Model Saved Files\n",
    "    '--modelsave_folderpath', type = str,\n",
    "    default = 'Saved Models',\n",
    "    help = 'Output Folderpath for Saved & Saving Models')\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Model Settings | Optimization Arguments\n",
    "parser.add_argument(                    # Number of Epochs\n",
    "    '--num_epochs', type = int,         # Default: 1200\n",
    "    default = 300,\n",
    "    help = \"Number of Epochs in Training Mode\")\n",
    "parser.add_argument(                    # Base Learning Rate\n",
    "    '--base_lr', type = float,          # Default: 1e-4\n",
    "    default = 1e-4,\n",
    "    help = \"Base Learning Rate Value in Training Mode\")\n",
    "parser.add_argument(                    # Weight Decay Value\n",
    "    '--weight_decay', type = float,     # Default: 1e-4\n",
    "    default = 1e-5,\n",
    "    help = \"Weight Decay Value in Training Mode\")\n",
    "parser.add_argument(                    # Learning Rate Decay Ratio\n",
    "    '--lr_decay', type = float,         # Default: 0.9\n",
    "    default = 0.9,\n",
    "    help = \"Learning Rate Decay Value in Training Mode\")\n",
    "parser.add_argument(                    # Early Stopping Epoch Patience Value\n",
    "    '--es_patience', type = int,        # Default: 1000 (no Early Stopping)\n",
    "    default = 5,\n",
    "    help = \"Early Stopping Epoch Patience Value\")\n",
    "parser.add_argument(                    # Early Stopping Delta Decay Value\n",
    "    '--es_delta', type = float,         # Default: 1e-5\n",
    "    default = 1e-5,\n",
    "    help = \"Early Stopping Delta Decay Value\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Model Settings | Architecture Arguments\n",
    "parser.add_argument(                    # Dataset Number of Training Parameters\n",
    "    '--in_channels', type = int,        # Default: 500\n",
    "    default = 500,\n",
    "    help = \"MUDI Dataset No. of Training Parameters / Model's No. of Input Channels\")\n",
    "parser.add_argument(                    # Total Number of Parameter Settings\n",
    "    '--out_channels', type = int,       # Default: 1344\n",
    "    default = 1344,\n",
    "    help = \"Total Number of Parameter Settings\")\n",
    "parser.add_argument(                    # Number of Hidden Layers in Neural Network\n",
    "    '--num_hidden', type = int,         # Default: 2\n",
    "    default = 2,\n",
    "    help = \"Number of Hidden Layers in Neural Network\")\n",
    "\n",
    "settings = parser.parse_args(\"\"); settings.device_ids = [0]\n",
    "settings.device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [fcglVNN] Fixed Conditional Generative Linear Voxel Neural Network Model Parametrizations Parser Initialization\n",
    "parser = argparse.ArgumentParser(\n",
    "    description = \"fcglVNN Model Settings\")\n",
    "parser.add_argument(                            # Dataset Version Variable\n",
    "    '--data_version', type = int,               # Default: 0\n",
    "    default = 0,\n",
    "    help = \"Dataset Save Version\")\n",
    "parser.add_argument(                            # Model Version Variable\n",
    "    '--model_version', type = int,              # Default: 0\n",
    "    default = 1,\n",
    "    help = \"Experiment Version\")\n",
    "parser.add_argument(                            # Random Seed for Reproducibility\n",
    "    '--seed', type = int,                       # Default: 42\n",
    "    default = 42,\n",
    "    help = \"Random Seed for Reproducibility\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Dataset Settings | Label Parametrization Arguments\n",
    "parser.add_argument(                                    # Control Variable for the Inclusion of Patient ID in Labels\n",
    "    '--patient_id', type = bool,                        # Default: True\n",
    "    default = False,\n",
    "    help = \"Control Variable for the Inclusion of Patient ID in Labels\")\n",
    "parser.add_argument(                                    # Control Variable for the Conversion of 3 Gradient Directions\n",
    "    '--gradient_coord', type = bool,                    # Coordinates into 2 Gradient Direction Angles (suggested by prof. Chantal)\n",
    "    default = True,                                    # Default: True (3 Coordinate Gradient Values)\n",
    "    help = \"Control Variable for the Conversion of Gradient Direction Mode\")\n",
    "parser.add_argument(                                    # Control Variable for the Rescaling & Normalization of Labels\n",
    "    '--label_norm', type = str,                         # Default: auto\n",
    "    default = 'manual',\n",
    "    choices = ['auto', 'manual', None],\n",
    "    help = \"Control Variable for the Rescaling & Normalization of Labels\")\n",
    "settings = parser.parse_args(\"\"); num_labels = 7\n",
    "if not(settings.patient_id): num_labels -= 1                                                # Exclusion of Patiend ID\n",
    "if not(settings.gradient_coord) or settings.label_norm == 'manual': num_labels -= 1         # Conversion of Gradient Coordinates to Angles\n",
    "parser.add_argument(                                                                        # Dataset Number of Labels\n",
    "    '--num_labels', type = int,                                                             # Default: 7\n",
    "    default = num_labels,\n",
    "    help = \"MUDI Dataset Number of Labels\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Dataset Settings | Set Construction Arguments\n",
    "parser.add_argument(                            # Complete List of Patients in Dataset\n",
    "    '--patient_list', type = list,              # Default: [11, 12, 13, 14, 15]\n",
    "    default = [11, 12, 13, 14, 15],\n",
    "    help = \"Complete List of Patients in Dataset\")\n",
    "parser.add_argument(                            # List of Patients used in Training\n",
    "    '--train_patient_list', type = list,        # Default: [11, 12, 13]\n",
    "    default = [11, 12, 13],\n",
    "    help = \"List of Patients used in Training\")\n",
    "parser.add_argument(                            # List of Patients used in Validation\n",
    "    '--val_patient_list', type = list,          # Default: [15]\n",
    "    default = [15],\n",
    "    help = \"List of Patients used in Validation\")\n",
    "parser.add_argument(                            # List of Patients used in Testing\n",
    "    '--test_patient_list', type = list,         # Default: [14]\n",
    "    default = [14],\n",
    "    help = \"List of Patients used in Testing\")\n",
    "parser.add_argument(                            # Number of Workers for DataLoader Usage\n",
    "    '--num_workers', type = int,                # Default: 1\n",
    "    default = 12,\n",
    "    help = \"Number of Workers for DataLoader Usage\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Dataset Settings | Shuffling Arguments\n",
    "parser.add_argument(                                    # Ability to Shuffle Training DataLoaders' Samples\n",
    "    '--train_sample_shuffle', type = bool,              # Default: False\n",
    "    default = True,\n",
    "    help = \"Ability to Shuffle Training DataLoaders' Samples\")\n",
    "parser.add_argument(                                    # Ability to Shuffle Validation DataLoaders' Samples\n",
    "    '--val_sample_shuffle', type = bool,                # Default: False\n",
    "    default = False,\n",
    "    help = \"Ability to Shuffle Validation DataLoaders' Samples\")\n",
    "parser.add_argument(                                    # Ability to Shuffle Target Parameters\n",
    "    '--param_shuffle', type = bool,                     # Default: True\n",
    "    default = True,\n",
    "    help = \"Ability to Shuffle Target Parameters\")\n",
    "parser.add_argument(                                    # Ability to Shuffle Target Voxels\n",
    "    '--voxel_shuffle', type = bool,                     # Default: True\n",
    "    default = True,\n",
    "    help = \"Ability to Shuffle Target Voxels\")\n",
    "parser.add_argument(                                    # Control Variable for the Sharing of Parameters inbetween Patient Sets\n",
    "    '--interpatient_sharing', type = bool,              # Default: True (all Training Patient Sets will have, for the same epoch, ...\n",
    "    default = False,                                    # ... the same exact parameters to reconstruct the data to, defined by the 1st Patient\n",
    "    help = \"Control Variable for the Sharing of Parameters inbetween Patient Sets\")\n",
    "\n",
    "# Dataset Settings | Subsectioning Arguments\n",
    "parser.add_argument(                                    # Selected Slice for Image Visualization\n",
    "    '--sel_slice', type = int,                          # Default: 25\n",
    "    default = 25,\n",
    "    help = \"Selected Slice for Image Visualization\")\n",
    "parser.add_argument(                                    # Percentage of Used Target Parameters used in Training\n",
    "    '--train_target_param', type = int or float,        # Default: 25% | 0.2% for 1 Target\n",
    "    default = 100,\n",
    "    help = \"Percentage of Used Target Parameters used in Training\")\n",
    "parser.add_argument(                                    # Percentage of Used Target Parameters used in Validation\n",
    "    '--val_target_param', type = int or float,          # Default: 5% | 0.9% for 2 Target\n",
    "    default = 100,\n",
    "    help = \"Percentage of Used Target Parameters used in Validation\")\n",
    "parser.add_argument(                                    # Percentage of Used Target Voxels used in Training\n",
    "    '--train_target_voxel', type = int or float,        # Default: 60%\n",
    "    default = 60,\n",
    "    help = \"Percentage of Used Target Voxels used in Training\")\n",
    "parser.add_argument(                                    # Percentage of Used Target Voxels used in Validation\n",
    "    '--val_target_voxel', type = int or float,          # Default: 100%\n",
    "    default = 100,\n",
    "    help = \"Percentage of Used Target Voxels during Validation\")\n",
    "parser.add_argument(                                    # Number of Parameters used in the Test Set\n",
    "    '--test_target_param', type = int,                  # Default: 100\n",
    "    default = 0,\n",
    "    help = \"Number of Parameters used in the Test Set\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Paths | Dataset-Related File & Folderpath Arguments\n",
    "parser.add_argument(                                    # Path for Main Dataset Folder\n",
    "    '--main_folderpath', type = str,\n",
    "    default = '../../Datasets/MUDI Dataset',\n",
    "    help = 'Main Folderpath for Root Dataset')\n",
    "settings = parser.parse_args(\"\")\n",
    "parser.add_argument(                                    # Path for Parameter Value File\n",
    "    '--param_filepath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Raw Data/parameters_new.xlsx'),\n",
    "    help = 'Input Filepath for Parameter Value Table')\n",
    "parser.add_argument(                                    # Path for Parameter Value File\n",
    "    '--data_filepath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Raw Data/data_.hdf5'),\n",
    "    help = 'Input Filepath for Parameter Value Table')\n",
    "parser.add_argument(                                    # Path for Patient Information File\n",
    "    '--info_filepath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Raw Data/header_.csv'),\n",
    "    help = 'Input Filepath for Patient Information Table')\n",
    "parser.add_argument(                                    # Path for Folder Containing Mask Data Files\n",
    "    '--mask_folderpath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Patient Mask'),\n",
    "    help = 'Input Folderpath for Segregated Patient Mask Data')\n",
    "parser.add_argument(                                    # Path for Dataset Saved Files\n",
    "    '--datasave_folderpath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Saved Data/V{settings.data_version}'),\n",
    "    help = 'Output Folderpath for MUDI Dataset Saved Versions')\n",
    "\n",
    "# Paths | Model-Related File & Folderpath Arguments\n",
    "parser.add_argument(                                    # Path for Dataset Reader Script\n",
    "    '--reader_folderpath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Dataset Reader'),\n",
    "    help = 'Input Folderpath for MUDI Dataset Reader')\n",
    "parser.add_argument(                                    # Path for Model Build Script\n",
    "    '--build_folderpath', type = str,\n",
    "    default = 'fcglVNN/Model Builds',\n",
    "    help = 'Input Folderpath for Model Build & Architecture')\n",
    "parser.add_argument(                                    # Path for Model Training Scripts\n",
    "    '--script_folderpath', type = str,\n",
    "    default = 'fcglVNN/Training Scripts',\n",
    "    help = 'Input Folderpath for Training & Testing Script Functions')\n",
    "parser.add_argument(                                    # Path for Model Saved Files\n",
    "    '--modelsave_folderpath', type = str,\n",
    "    default = 'fcglVNN/Saved Models',\n",
    "    help = 'Output Folderpath for Saved & Saving Models')\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Model Settings | Optimization Arguments\n",
    "parser.add_argument(                    # Number of Epochs\n",
    "    '--num_epochs', type = int,         # Default: 1200\n",
    "    default = 300,\n",
    "    help = \"Number of Epochs in Training Mode\")\n",
    "parser.add_argument(                    # Base Learning Rate\n",
    "    '--base_lr', type = float,          # Default: 1e-4\n",
    "    default = 1e-4,\n",
    "    help = \"Base Learning Rate Value in Training Mode\")\n",
    "parser.add_argument(                    # Weight Decay Value\n",
    "    '--weight_decay', type = float,     # Default: 1e-4\n",
    "    default = 1e-5,\n",
    "    help = \"Weight Decay Value in Training Mode\")\n",
    "parser.add_argument(                    # Learning Rate Decay Ratio\n",
    "    '--lr_decay', type = float,         # Default: 0.9\n",
    "    default = 0.9,\n",
    "    help = \"Learning Rate Decay Value in Training Mode\")\n",
    "parser.add_argument(                    # Early Stopping Epoch Patience Value\n",
    "    '--es_patience', type = int,        # Default: 1000 (no Early Stopping)\n",
    "    default = 50,\n",
    "    help = \"Early Stopping Epoch Patience Value\")\n",
    "parser.add_argument(                    # Early Stopping Delta Decay Value\n",
    "    '--es_delta', type = float,         # Default: 1e-5\n",
    "    default = 1e-5,\n",
    "    help = \"Early Stopping Delta Decay Value\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Model Settings | Architecture Arguments\n",
    "parser.add_argument(                    # Dataset Number of Training Parameters\n",
    "    '--in_channels', type = int,        # Default: 500\n",
    "    default = 500,\n",
    "    help = \"MUDI Dataset No. of Training Parameters / Model's No. of Input Channels\")\n",
    "parser.add_argument(                    # Number of Hidden Layers in Neural Network\n",
    "    '--num_hidden', type = int,         # Default: 2\n",
    "    default = 2,\n",
    "    help = \"Number of Hidden Layers in Neural Network\")\n",
    "parser.add_argument(                    # Hidden Layer's Top Number of Neurons\n",
    "    '--top_hidden', type = int,         # Default: 64\n",
    "    default = 1024,\n",
    "    help = \"Hidden Layer's Top Number of Neurons\")\n",
    "parser.add_argument(                    # Hidden Layer's Bottom Number of Neurons\n",
    "    '--bottom_hidden', type = int,      # Default: 64\n",
    "    default = 512,\n",
    "    help = \"Hidden Layer's Bottom Number of Neurons\")\n",
    "\n",
    "settings = parser.parse_args(\"\"); settings.device_ids = [0]\n",
    "settings.device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [cglVNN] Conditional Generative Linear Voxel Neural Network Model Parametrizations Parser Initialization\n",
    "parser = argparse.ArgumentParser(\n",
    "    description = \"fcglVNN Model Settings\")\n",
    "parser.add_argument(                            # Dataset Version Variable\n",
    "    '--data_version', type = int,               # Default: 0\n",
    "    default = 0,\n",
    "    help = \"Dataset Save Version\")\n",
    "parser.add_argument(                            # Model Version Variable\n",
    "    '--model_version', type = int,              # Default: 0\n",
    "    default = 0,\n",
    "    help = \"Experiment Version\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Dataset General Parametrization Arguments\n",
    "parser.add_argument(                            # Dataset Batch Size Value\n",
    "    '--batch_size', type = int,                 # Default: 1000\n",
    "    default = 50000,\n",
    "    help = \"Dataset Batch Size Value\")\n",
    "parser.add_argument(                            # Number of Workers for DataLoader Usage\n",
    "    '--num_workers', type = int,                # Default: 1\n",
    "    default = 12,\n",
    "    help = \"Number of Workers for DataLoader Usage\")\n",
    "parser.add_argument(                            # Ability to Shuffle the Samples inside both Training and Validation Sets\n",
    "    '--sample_shuffle', type = bool,            # Default: False\n",
    "    default = False,\n",
    "    help = \"Ability to Shuffle the Samples inside both Training and Validation Sets\")\n",
    "parser.add_argument(                            # Number of Training Parameters\n",
    "    '--num_train_params', type = int,           # Default: 500\n",
    "    default = 500,\n",
    "    help = \"No. of Training Parameters\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Dataset Label Parametrization Arguments\n",
    "parser.add_argument(                                    # Control Variable for the Inclusion of Patient ID in Labels\n",
    "    '--patient_id', type = bool,                        # Default: True\n",
    "    default = False,\n",
    "    help = \"Control Variable for the Inclusion of Patient ID in Labels\")\n",
    "parser.add_argument(                                    # Control Variable for the Conversion of 3 Gradient Directions\n",
    "    '--gradient_coord', type = bool,                    # Coordinates into 2 Gradient Direction Angles (suggested by prof. Chantal)\n",
    "    default = False,                                    # Default: True (3 Coordinate Gradient Values)\n",
    "    help = \"Control Variable for the Conversion of Gradient Direction Mode\")\n",
    "parser.add_argument(                                    # Control Variable for the Rescaling & Normalization of Labels\n",
    "    '--label_norm', type = bool,                        # Default: True\n",
    "    default = True,\n",
    "    help = \"Control Variable for the Rescaling & Normalization of Labels\")\n",
    "settings = parser.parse_args(\"\"); num_labels = 7\n",
    "if not(settings.patient_id): num_labels -= 1            # Exclusion of Patiend ID\n",
    "if not(settings.gradient_coord): num_labels -= 1        # Conversion of Gradient Coordinates to Angles\n",
    "parser.add_argument(                                    # Dataset Number of Labels\n",
    "    '--num_labels', type = int,                         # Default: 7\n",
    "    default = num_labels,\n",
    "    help = \"MUDI Dataset Number of Labels\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Addition of Dataset-Related File & Folderpath Arguments\n",
    "parser.add_argument(                                    # Path for Main Dataset Folder\n",
    "    '--main_folderpath', type = str,\n",
    "    default = '../../Datasets/MUDI Dataset',\n",
    "    help = 'Main Folderpath for Root Dataset')\n",
    "settings = parser.parse_args(\"\")\n",
    "parser.add_argument(                                    # Path for Parameter Value File\n",
    "    '--param_filepath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Raw Data/parameters_new.xlsx'),\n",
    "    help = 'Input Filepath for Parameter Value Table')\n",
    "parser.add_argument(                                    # Path for Parameter Value File\n",
    "    '--data_filepath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Raw Data/data_.hdf5'),\n",
    "    help = 'Input Filepath for Parameter Value Table')\n",
    "parser.add_argument(                                    # Path for Patient Information File\n",
    "    '--info_filepath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Raw Data/header_.csv'),\n",
    "    help = 'Input Filepath for Patient Information Table')\n",
    "parser.add_argument(                                    # Path for Folder Containing Mask Data Files\n",
    "    '--mask_folderpath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Patient Mask'),\n",
    "    help = 'Input Folderpath for Segregated Patient Mask Data')\n",
    "parser.add_argument(                                    # Path for Dataset Saved Files\n",
    "    '--datasave_folderpath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Saved Data/V{settings.data_version}'),\n",
    "    help = 'Output Folderpath for MUDI Dataset Saved Versions')\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Addition of Model-Related File & Folderpath Arguments\n",
    "parser.add_argument(                                    # Path for Dataset Reader Script\n",
    "    '--reader_folderpath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Dataset Reader'),\n",
    "    help = 'Input Folderpath for MUDI Dataset Reader')\n",
    "parser.add_argument(                                    # Path for Model Build Script\n",
    "    '--build_folderpath', type = str,\n",
    "    default = 'Model Builds',\n",
    "    help = 'Input Folderpath for Model Build & Architecture')\n",
    "parser.add_argument(                                    # Path for Model Training Scripts\n",
    "    '--script_folderpath', type = str,\n",
    "    default = 'Training Scripts',\n",
    "    help = 'Input Folderpath for Training & Testing Script Functions')\n",
    "parser.add_argument(                                    # Path for Model Saved Files\n",
    "    '--modelsave_folderpath', type = str,\n",
    "    default = 'Saved Models',\n",
    "    help = 'Output Folderpath for Saved & Saving Models')\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Addition of Training Requirement Arguments\n",
    "parser.add_argument(                    # Number of Epochs\n",
    "    '--num_epochs', type = int,         # Default: 1200\n",
    "    default = 300,\n",
    "    help = \"Number of Epochs in Training Mode\")\n",
    "settings = parser.parse_args(\"\")\n",
    "parser.add_argument(                    # Base Learning Rate\n",
    "    '--base_lr', type = float,          # Default: 1e-4\n",
    "    default = 1e-3,\n",
    "    help = \"Base Learning Rate Value in Training Mode\")\n",
    "parser.add_argument(                    # Weight Decay Value\n",
    "    '--weight_decay', type = float,     # Default: 1e-4\n",
    "    default = 1e-4,\n",
    "    help = \"Weight Decay Value in Training Mode\")\n",
    "parser.add_argument(                    # Learning Rate Decay Ratio\n",
    "    '--lr_decay', type = float,         # Default: 0.9\n",
    "    default = 0.9,\n",
    "    help = \"Learning Rate Decay Value in Training Mode\")\n",
    "parser.add_argument(                    # Number of Epochs after which LR should Decay\n",
    "    '--step_decay', type = int,         # Default: int(settings.num_epochs / 10)\n",
    "    default = int(settings.num_epochs / 10),\n",
    "    help = \"Number of Epochs after which LR should Decay\")\n",
    "parser.add_argument(                    # Early Stopping Epoch Patience Value\n",
    "    '--es_patience', type = int,        # Default: 1000 (no Early Stopping)\n",
    "    default = 50,\n",
    "    help = \"Early Stopping Epoch Patience Value\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Addition of Model Architecture Arguments\n",
    "parser.add_argument(                    # Dataset Number of Training Parameters\n",
    "    '--in_channels', type = int,        # Default: 500\n",
    "    default = settings.num_train_params,\n",
    "    help = \"MUDI Dataset No. of Training Parameters / Model's No. of Input Channels\")\n",
    "parser.add_argument(                    # Number of Hidden Layers in Neural Network\n",
    "    '--num_hidden', type = int,         # Default: 2\n",
    "    default = 2,\n",
    "    help = \"Number of Hidden Layers in Neural Network\")\n",
    "parser.add_argument(                    # Hidden Layer's Top Number of Neurons\n",
    "    '--top_hidden', type = int,         # Default: 64\n",
    "    default = 64,\n",
    "    help = \"Hidden Layer's Top Number of Neurons\")\n",
    "parser.add_argument(                    # Hidden Layer's Bottom Number of Neurons\n",
    "    '--bottom_hidden', type = int,      # Default: 64\n",
    "    default = 16,\n",
    "    help = \"Hidden Layer's Bottom Number of Neurons\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Addition of Result Visualization Arguments\n",
    "parser.add_argument(                                    # Selected Patient for Training Image Reconstruction\n",
    "    '--sel_train_patient', type = int,                  # Default: 11\n",
    "    default = 11,\n",
    "    help = \"Selected Patient for Training Image Reconstruction\")\n",
    "parser.add_argument(                                    # Selected Patient for Validation Image Reconstruction\n",
    "    '--sel_val_patient', type = int,                    # Default: 15\n",
    "    default = 15,\n",
    "    help = \"Selected Patient for Training Image Reconstruction\")\n",
    "parser.add_argument(                                    # Selected Patient for Test Image Reconstruction\n",
    "    '--sel_test_patient', type = int,                   # Default: 14\n",
    "    default = 14,\n",
    "    help = \"Selected Patient for Test Image Reconstruction\")\n",
    "parser.add_argument(                                    # Percentage of Reconstructed Parameters during Training\n",
    "    '--param_recon_train', type = int or float,         # Default: 25% | 0.2% for 1 Reconstruction\n",
    "    default = 25,\n",
    "    help = \"Percentage of Reconstructed Parameters during Training\")\n",
    "parser.add_argument(                                    # Percentage of Reconstructed Parameters for Full Image Reconstruction\n",
    "    '--param_recon_full', type = int or float,          # Default: 5% (20% of 25%) | 0.9% for 2 Reconstruction\n",
    "    default = 5,\n",
    "    help = \"Percentage of Reconstructed Parameters for Full Image Reconstruction\")\n",
    "parser.add_argument(                                    # Ability to Shuffle the Parameters for Reconstruction\n",
    "    '--param_shuffle', type = bool,                     # Default: True\n",
    "    default = True,\n",
    "    help = \"Ability to Shuffle the Parameters for Reconstruction\")\n",
    "\n",
    "settings = parser.parse_args(\"\")\n",
    "settings.device = torch.device('cuda:0') #)\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [cVNP] Conditional Voxel-Wise Neural Process Model Parametrizations Parser Initialization\n",
    "parser = argparse.ArgumentParser(\n",
    "    description = \"cVNP Model Settings\")\n",
    "parser.add_argument(                            # Dataset Version Variable\n",
    "    '--data_version', type = int,               # Default: 0\n",
    "    default = 7,\n",
    "    help = \"Dataset Save Version\")\n",
    "parser.add_argument(                            # Model Version Variable\n",
    "    '--model_version', type = int,              # Default: 0\n",
    "    default = 0,\n",
    "    help = \"Experiment Version\")\n",
    "parser.add_argument(                            # Random Seed for Reproducibility\n",
    "    '--seed', type = int,                       # Default: 42\n",
    "    default = 42,\n",
    "    help = \"Random Seed for Reproducibility\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Dataset Settings | Label Parametrization Arguments\n",
    "parser.add_argument(                                    # Control Variable for the Inclusion of Patient ID in Labels\n",
    "    '--patient_id', type = bool,                        # Default: True\n",
    "    default = False,\n",
    "    help = \"Control Variable for the Inclusion of Patient ID in Labels\")\n",
    "parser.add_argument(                                    # Control Variable for the Conversion of 3 Gradient Directions\n",
    "    '--gradient_coord', type = bool,                    # Coordinates into 2 Gradient Direction Angles (suggested by prof. Chantal)\n",
    "    default = True,                                    # Default: True (3 Coordinate Gradient Values)\n",
    "    help = \"Control Variable for the Conversion of Gradient Direction Mode\")\n",
    "parser.add_argument(                                    # Control Variable for the Rescaling & Normalization of Labels\n",
    "    '--label_norm', type = str,                         # Default: auto\n",
    "    default = 'manual',\n",
    "    choices = ['auto', 'manual', None],\n",
    "    help = \"Control Variable for the Rescaling & Normalization of Labels\")\n",
    "settings = parser.parse_args(\"\"); num_labels = 7\n",
    "if not(settings.patient_id): num_labels -= 1                                                # Exclusion of Patiend ID\n",
    "if not(settings.gradient_coord) or settings.label_norm == 'manual': num_labels -= 1         # Conversion of Gradient Coordinates to Angles\n",
    "parser.add_argument(                                                                        # Dataset Number of Labels\n",
    "    '--num_labels', type = int,                                                             # Default: 7\n",
    "    default = num_labels,\n",
    "    help = \"MUDI Dataset Number of Labels\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Dataset Settings | Set Construction Arguments\n",
    "parser.add_argument(                            # Complete List of Patients in Dataset\n",
    "    '--patient_list', type = list,              # Default: [11, 12, 13, 14, 15]\n",
    "    default = [11, 12, 13, 14, 15],\n",
    "    help = \"Complete List of Patients in Dataset\")\n",
    "parser.add_argument(                            # List of Patients used in Training\n",
    "    '--train_patient_list', type = list,        # Default: [11, 12, 13]\n",
    "    default = [11, 12, 13],\n",
    "    help = \"List of Patients used in Training\")\n",
    "parser.add_argument(                            # List of Patients used in Validation\n",
    "    '--val_patient_list', type = list,          # Default: [15]\n",
    "    default = [15],\n",
    "    help = \"List of Patients used in Validation\")\n",
    "parser.add_argument(                            # List of Patients used in Testing\n",
    "    '--test_patient_list', type = list,         # Default: [14]\n",
    "    default = [14],\n",
    "    help = \"List of Patients used in Testing\")\n",
    "parser.add_argument(                            # Number of Workers for DataLoader Usage\n",
    "    '--num_workers', type = int,                # Default: 1\n",
    "    default = 12,\n",
    "    help = \"Number of Workers for DataLoader Usage\")\n",
    "parser.add_argument(                            # DataLoader Batch Size\n",
    "    '--batch_size', type = int,                 # Default: 250000\n",
    "    default = 100000,\n",
    "    help = \"DataLoader Batch Size\")\n",
    "parser.add_argument(                            # DataLoader Sample Groupings Size\n",
    "    '--sample_size', type = int or str,         # Default: 1 (Normal Batching)\n",
    "    default = 200,\n",
    "    help = \"DataLoader Sample Groupings Size\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Dataset Settings | Shuffling Arguments\n",
    "parser.add_argument(                                    # Ability to Shuffle Training DataLoaders' Samples\n",
    "    '--train_sample_shuffle', type = bool,              # Default: False\n",
    "    default = True,\n",
    "    help = \"Ability to Shuffle Training DataLoaders' Samples\")\n",
    "parser.add_argument(                                    # Ability to Shuffle Validation DataLoaders' Samples\n",
    "    '--val_sample_shuffle', type = bool,                # Default: False\n",
    "    default = False,\n",
    "    help = \"Ability to Shuffle Validation DataLoaders' Samples\")\n",
    "parser.add_argument(                                    # Ability to Shuffle Target Parameters\n",
    "    '--param_shuffle', type = bool,                     # Default: True\n",
    "    default = False,\n",
    "    help = \"Ability to Shuffle Target Parameters\")\n",
    "parser.add_argument(                                    # Ability to Shuffle Target Voxels\n",
    "    '--voxel_shuffle', type = bool,                     # Default: True\n",
    "    default = True,\n",
    "    help = \"Ability to Shuffle Target Voxels\")\n",
    "parser.add_argument(                                    # Control Variable for the Sharing of Parameters inbetween Patient Sets\n",
    "    '--interpatient_sharing', type = bool,              # Default: True (all Training Patient Sets will have, for the same epoch, ...\n",
    "    default = False,                                    # ... the same exact parameters to reconstruct the data to, defined by the 1st Patient\n",
    "    help = \"Control Variable for the Sharing of Parameters inbetween Patient Sets\")\n",
    "\n",
    "# Dataset Settings | Subsectioning Arguments\n",
    "parser.add_argument(                                    # Selected Slice for Image Visualization\n",
    "    '--sel_slice', type = int,                          # Default: 25\n",
    "    default = 25,\n",
    "    help = \"Selected Slice for Image Visualization\")\n",
    "parser.add_argument(                                    # Percentage of Source / Target Parameter Combo Loops used in Training\n",
    "    '--train_param_loop', type = int,                   # Default: \n",
    "    default = 5,\n",
    "    help = \"Percentage of Source / Target Parameter Combo Loops used in Trainingn\")\n",
    "parser.add_argument(                                    # Percentage of Source / Target Parameter Combo Loops used in Validation\n",
    "    '--val_param_loop', type = int,                     # Default: 100\n",
    "    default = 0.01,\n",
    "    help = \"Percentage of Source / Target Parameter Combo Loops used in Validation\")\n",
    "    \n",
    "parser.add_argument(                                    # Percentage of Used Source Parameters used in Training\n",
    "    '--train_source_param', type = int or float,        # Default: 100%\n",
    "    default = 100,\n",
    "    help = \"Percentage of Used Source Parameters used in Training\")\n",
    "parser.add_argument(                                    # Percentage of Used Source Parameters used in Validation\n",
    "    '--val_source_param', type = int or float,          # Default: 100%\n",
    "    default = 100,\n",
    "    help = \"Percentage of Used Source Parameters used in Validation\")\n",
    "\n",
    "parser.add_argument(                                    # Percentage of Used Target Parameters used in Training\n",
    "    '--train_target_param', type = int or float,        # Default: 25% | 0.2% for 1 Target\n",
    "    default = 100,\n",
    "    help = \"Percentage of Used Target Parameters used in Training\")\n",
    "parser.add_argument(                                    # Percentage of Used Target Parameters used in Validation\n",
    "    '--val_target_param', type = int or float,          # Default: 5% | 0.9% for 2 Target\n",
    "    default = 100,\n",
    "    help = \"Percentage of Used Target Parameters used in Validation\")\n",
    "\n",
    "parser.add_argument(                                    # Percentage of Used Target Voxels used in Training\n",
    "    '--train_target_voxel', type = int or float,        # Default: 60%\n",
    "    default = 30,\n",
    "    help = \"Percentage of Used Target Voxels used in Training\")\n",
    "parser.add_argument(                                    # Percentage of Used Target Voxels used in Validation\n",
    "    '--val_target_voxel', type = int or float,          # Default: 100%\n",
    "    default = 100,\n",
    "    help = \"Percentage of Used Target Voxels during Validation\")\n",
    "parser.add_argument(                                    # Number of Parameters used in the Test Set\n",
    "    '--test_target_param', type = int,                  # Default: 100\n",
    "    default = 0,\n",
    "    help = \"Number of Parameters used in the Test Set\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Paths | Dataset-Related File & Folderpath Arguments\n",
    "parser.add_argument(                                    # Path for Main Dataset Folder\n",
    "    '--main_folderpath', type = str,\n",
    "    default = '../../Datasets/MUDI Dataset',\n",
    "    help = 'Main Folderpath for Root Dataset')\n",
    "settings = parser.parse_args(\"\")\n",
    "parser.add_argument(                                    # Path for Parameter Value File\n",
    "    '--param_filepath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Raw Data/parameters_new.xlsx'),\n",
    "    help = 'Input Filepath for Parameter Value Table')\n",
    "parser.add_argument(                                    # Path for Parameter Value File\n",
    "    '--data_filepath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Raw Data/data_.hdf5'),\n",
    "    help = 'Input Filepath for Parameter Value Table')\n",
    "parser.add_argument(                                    # Path for Patient Information File\n",
    "    '--info_filepath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Raw Data/header_.csv'),\n",
    "    help = 'Input Filepath for Patient Information Table')\n",
    "parser.add_argument(                                    # Path for Folder Containing Mask Data Files\n",
    "    '--mask_folderpath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Patient Mask'),\n",
    "    help = 'Input Folderpath for Segregated Patient Mask Data')\n",
    "parser.add_argument(                                    # Path for Dataset Saved Files\n",
    "    '--datasave_folderpath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Saved Data/V{settings.data_version}'),\n",
    "    help = 'Output Folderpath for MUDI Dataset Saved Versions')\n",
    "\n",
    "# Paths | Model-Related File & Folderpath Arguments\n",
    "parser.add_argument(                                    # Path for Dataset Reader Script\n",
    "    '--reader_folderpath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Dataset Reader'),\n",
    "    help = 'Input Folderpath for MUDI Dataset Reader')\n",
    "parser.add_argument(                                    # Path for Model Build Script\n",
    "    '--build_folderpath', type = str,\n",
    "    default = 'Model Builds',\n",
    "    help = 'Input Folderpath for Model Build & Architecture')\n",
    "parser.add_argument(                                    # Path for Model Training Scripts\n",
    "    '--script_folderpath', type = str,\n",
    "    default = 'Training Scripts',\n",
    "    help = 'Input Folderpath for Training & Testing Script Functions')\n",
    "parser.add_argument(                                    # Path for Model Saved Files\n",
    "    '--modelsave_folderpath', type = str,\n",
    "    default = 'Saved Models',\n",
    "    help = 'Output Folderpath for Saved & Saving Models')\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Model Settings | Optimization Arguments\n",
    "parser.add_argument(                    # Number of Epochs\n",
    "    '--num_epochs', type = int,         # Default: 1200\n",
    "    default = 300,\n",
    "    help = \"Number of Epochs in Training Mode\")\n",
    "parser.add_argument(                    # Base Learning Rate\n",
    "    '--base_lr', type = float,          # Default: 1e-4\n",
    "    default = 1e-4,\n",
    "    help = \"Base Learning Rate Value in Training Mode\")\n",
    "parser.add_argument(                    # Weight Decay Value\n",
    "    '--weight_decay', type = float,     # Default: 1e-4\n",
    "    default = 1e-5,\n",
    "    help = \"Weight Decay Value in Training Mode\")\n",
    "parser.add_argument(                    # Learning Rate Decay Ratio\n",
    "    '--lr_decay', type = float,         # Default: 0.9\n",
    "    default = 0.9,\n",
    "    help = \"Learning Rate Decay Value in Training Mode\")\n",
    "parser.add_argument(                    # Early Stopping Epoch Patience Value\n",
    "    '--es_patience', type = int,        # Default: 1000 (no Early Stopping)\n",
    "    default = 50,\n",
    "    help = \"Early Stopping Epoch Patience Value\")\n",
    "parser.add_argument(                    # Early Stopping Delta Decay Value\n",
    "    '--es_delta', type = float,         # Default: 1e-5\n",
    "    default = 1e-5,\n",
    "    help = \"Early Stopping Delta Decay Value\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Model Settings | Architecture Arguments\n",
    "parser.add_argument(                    # Number of Hidden Layers in Neural Network\n",
    "    '--num_hidden', type = int,         # Default: 2\n",
    "    default = 2,\n",
    "    help = \"Number of Hidden Layers in Neural Network\")\n",
    "parser.add_argument(                    # Hidden Layer's Top Number of Neurons\n",
    "    '--var_hidden', type = int,         # Default: 128\n",
    "    default = 64,\n",
    "    help = \"Hidden Layer's Top Number of Neurons\")\n",
    "\n",
    "settings = parser.parse_args(\"\"); settings.device_ids = [0]\n",
    "settings.device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2D CVAE-GAN] 2D Slice-Wise CVAE-GAN Parametrizations Parser Initialization\n",
    "parser = argparse.ArgumentParser(\n",
    "    description = \"2D CVAE-GAN Model Settings\")\n",
    "parser.add_argument(                            # Dataset Version Variable\n",
    "    '--data_version', type = int,               # Default: 0\n",
    "    default = 0,\n",
    "    help = \"Dataset Save Version\")\n",
    "parser.add_argument(                            # Model Version Variable\n",
    "    '--model_version', type = int,              # Default: 0\n",
    "    default = 0,\n",
    "    help = \"Experiment Version\")\n",
    "parser.add_argument(                            # Random Seed for Reproducibility\n",
    "    '--seed', type = int,                       # Default: 42\n",
    "    default = 42,\n",
    "    help = \"Random Seed for Reproducibility\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Dataset Settings | Label Parametrization Arguments\n",
    "parser.add_argument(                                    # Control Variable for the Inclusion of Patient ID in Labels\n",
    "    '--patient_id', type = bool,                        # Default: True\n",
    "    default = False,\n",
    "    help = \"Control Variable for the Inclusion of Patient ID in Labels\")\n",
    "parser.add_argument(                                    # Control Variable for the Conversion of 3 Gradient Directions\n",
    "    '--gradient_coord', type = bool,                    # Coordinates into 2 Gradient Direction Angles (suggested by prof. Chantal)\n",
    "    default = True,                                    # Default: True (3 Coordinate Gradient Values)\n",
    "    help = \"Control Variable for the Conversion of Gradient Direction Mode\")\n",
    "parser.add_argument(                                    # Control Variable for the Rescaling & Normalization of Labels\n",
    "    '--label_norm', type = str,                         # Default: auto\n",
    "    default = 'manual',\n",
    "    choices = ['auto', 'manual', None],\n",
    "    help = \"Control Variable for the Rescaling & Normalization of Labels\")\n",
    "settings = parser.parse_args(\"\"); num_labels = 7\n",
    "if not(settings.patient_id): num_labels -= 1                                                # Exclusion of Patiend ID\n",
    "if not(settings.gradient_coord) or settings.label_norm == 'manual': num_labels -= 1         # Conversion of Gradient Coordinates to Angles\n",
    "parser.add_argument(                                                                        # Dataset Number of Labels\n",
    "    '--num_labels', type = int,                                                             # Default: 7\n",
    "    default = num_labels,\n",
    "    help = \"MUDI Dataset Number of Labels\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Dataset Settings | Set Construction Arguments\n",
    "parser.add_argument(                            # Complete List of Patients in Dataset\n",
    "    '--patient_list', type = list,              # Default: [11, 12, 13, 14, 15]\n",
    "    default = [11, 12, 13, 14, 15],\n",
    "    help = \"Complete List of Patients in Dataset\")\n",
    "parser.add_argument(                            # List of Patients used in Training\n",
    "    '--train_patient_list', type = list,        # Default: [11, 12, 13]\n",
    "    default = [11, 12, 13],\n",
    "    help = \"List of Patients used in Training\")\n",
    "parser.add_argument(                            # List of Patients used in Validation\n",
    "    '--val_patient_list', type = list,          # Default: [15]\n",
    "    default = [15],\n",
    "    help = \"List of Patients used in Validation\")\n",
    "parser.add_argument(                            # List of Patients used in Testing\n",
    "    '--test_patient_list', type = list,         # Default: [14]\n",
    "    default = [14],\n",
    "    help = \"List of Patients used in Testing\")\n",
    "parser.add_argument(                            # Number of Workers for DataLoader Usage\n",
    "    '--num_workers', type = int,                # Default: 1\n",
    "    default = 12,\n",
    "    help = \"Number of Workers for DataLoader Usage\")\n",
    "parser.add_argument(                            # DataLoader Batch Size\n",
    "    '--batch_size', type = int,                 # Default: 250000\n",
    "    default = 100,\n",
    "    help = \"DataLoader Batch Size\")\n",
    "parser.add_argument(                            # Final Input Image after Zero Padding Pre-Processing\n",
    "    '--img_shape', type = int,                  # Default: 100\n",
    "    default = 96,\n",
    "    help = \"Final Input Image after Zero Padding Pre-Processing\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Dataset Settings | Shuffling Arguments\n",
    "parser.add_argument(                                    # Ability to Shuffle Training DataLoaders' Samples\n",
    "    '--train_sample_shuffle', type = bool,              # Default: False\n",
    "    default = True,\n",
    "    help = \"Ability to Shuffle Training DataLoaders' Samples\")\n",
    "parser.add_argument(                                    # Ability to Shuffle Validation DataLoaders' Samples\n",
    "    '--val_sample_shuffle', type = bool,                # Default: False\n",
    "    default = False,\n",
    "    help = \"Ability to Shuffle Validation DataLoaders' Samples\")\n",
    "parser.add_argument(                                    # Ability to Shuffle Target Parameters\n",
    "    '--param_shuffle', type = bool,                     # Default: True\n",
    "    default = False,\n",
    "    help = \"Ability to Shuffle Target Parameters\")\n",
    "parser.add_argument(                                    # Ability to Shuffle Target Slices\n",
    "    '--slice_shuffle', type = bool,                     # Default: True\n",
    "    default = True,\n",
    "    help = \"Ability to Shuffle Target Voxels\")\n",
    "parser.add_argument(                                    # Control Variable for the Sharing of Parameters inbetween Patient Sets\n",
    "    '--interpatient_sharing', type = bool,              # Default: True (all Training Patient Sets will have, for the same epoch, ...\n",
    "    default = False,                                    # ... the same exact parameters to reconstruct the data to, defined by the 1st Patient\n",
    "    help = \"Control Variable for the Sharing of Parameters inbetween Patient Sets\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Dataset Settings | Subsectioning Arguments\n",
    "parser.add_argument(                                    # Selected Slice for Image Visualization\n",
    "    '--sel_slice', type = int,                          # Default: 25\n",
    "    default = 25,\n",
    "    help = \"Selected Slice for Image Visualization\")\n",
    "\n",
    "parser.add_argument(                                    # Percentage of Used Source Parameters used in Training\n",
    "    '--train_source_param', type = int or float,        # Default: 100%\n",
    "    default = 100,\n",
    "    help = \"Percentage of Used Source Parameters used in Training\")\n",
    "parser.add_argument(                                    # Percentage of Used Source Parameters used in Validation\n",
    "    '--val_source_param', type = int or float,          # Default: 100%\n",
    "    default = 100,\n",
    "    help = \"Percentage of Used Source Parameters used in Validation\")\n",
    "\n",
    "parser.add_argument(                                    # Percentage of Used Target Parameters used in Training\n",
    "    '--train_target_param', type = int or float,        # Default: 25% | 0.2% for 1 Target\n",
    "    default = 100,\n",
    "    help = \"Percentage of Used Target Parameters used in Training\")\n",
    "parser.add_argument(                                    # Percentage of Used Target Parameters used in Validation\n",
    "    '--val_target_param', type = int or float,          # Default: 5% | 0.9% for 2 Target\n",
    "    default = 100,\n",
    "    help = \"Percentage of Used Target Parameters used in Validation\")\n",
    "parser.add_argument(                                    # Number of Parameters used in the Test Set\n",
    "    '--test_target_param', type = int,                  # Default: 100\n",
    "    default = 0,\n",
    "    help = \"Number of Parameters used in the Test Set\")\n",
    "\n",
    "parser.add_argument(                                    # Percentage of Used Target Voxels used in Training\n",
    "    '--train_target_slice', type = int or float,        # Default: 100%\n",
    "    default = 10,\n",
    "    help = \"Percentage of Used Target Voxels used in Training\")\n",
    "parser.add_argument(                                    # Percentage of Used Target Voxels used in Validation\n",
    "    '--val_target_slice', type = int or float,          # Default: 100%\n",
    "    default = 100,\n",
    "    help = \"Percentage of Used Target Voxels during Validation\")\n",
    "\n",
    "parser.add_argument(                                    # Percentage of Used Source / Target Parameter Combos used in Training\n",
    "    '--train_param_loop', type = int or float,          # Default: 60%\n",
    "    default = 10,\n",
    "    help = \"Percentage of Used Target Voxels used in Training\")\n",
    "parser.add_argument(                                    # Percentage of Used Source / Target Parameter Combos used in Validation\n",
    "    '--val_param_loop', type = int or float,            # Default: 60%\n",
    "    default = 10,\n",
    "    help = \"Percentage of Used Target Voxels used in Training\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Paths | Dataset-Related File & Folderpath Arguments\n",
    "parser.add_argument(                                    # Path for Main Dataset Folder\n",
    "    '--main_folderpath', type = str,\n",
    "    default = '../../Datasets/MUDI Dataset',\n",
    "    help = 'Main Folderpath for Root Dataset')\n",
    "settings = parser.parse_args(\"\")\n",
    "parser.add_argument(                                    # Path for Parameter Value File\n",
    "    '--param_filepath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Raw Data/parameters_new.xlsx'),\n",
    "    help = 'Input Filepath for Parameter Value Table')\n",
    "parser.add_argument(                                    # Path for Parameter Value File\n",
    "    '--data_filepath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Raw Data/data_.hdf5'),\n",
    "    help = 'Input Filepath for Parameter Value Table')\n",
    "parser.add_argument(                                    # Path for Patient Information File\n",
    "    '--info_filepath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Raw Data/header_.csv'),\n",
    "    help = 'Input Filepath for Patient Information Table')\n",
    "parser.add_argument(                                    # Path for Folder Containing Mask Data Files\n",
    "    '--mask_folderpath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Patient Mask'),\n",
    "    help = 'Input Folderpath for Segregated Patient Mask Data')\n",
    "parser.add_argument(                                    # Path for Dataset Saved Files\n",
    "    '--datasave_folderpath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Saved Data/V{settings.data_version}'),\n",
    "    help = 'Output Folderpath for MUDI Dataset Saved Versions')\n",
    "\n",
    "# Paths | Model-Related File & Folderpath Arguments\n",
    "parser.add_argument(                                    # Path for Dataset Reader Script\n",
    "    '--reader_folderpath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Dataset Reader'),\n",
    "    help = 'Input Folderpath for MUDI Dataset Reader')\n",
    "parser.add_argument(                                    # Path for Model Build Script\n",
    "    '--build_folderpath', type = str,\n",
    "    default = 'Model Builds',\n",
    "    help = 'Input Folderpath for Model Build & Architecture')\n",
    "parser.add_argument(                                    # Path for Model Training Scripts\n",
    "    '--script_folderpath', type = str,\n",
    "    default = 'Training Scripts',\n",
    "    help = 'Input Folderpath for Training & Testing Script Functions')\n",
    "parser.add_argument(                                    # Path for Model Saved Files\n",
    "    '--modelsave_folderpath', type = str,\n",
    "    default = 'Saved Models',\n",
    "    help = 'Output Folderpath for Saved & Saving Models')\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Model Settings | Optimization Arguments\n",
    "parser.add_argument(                    # Number of Epochs\n",
    "    '--num_epochs', type = int,         # Default: 1200\n",
    "    default = 300,\n",
    "    help = \"Number of Epochs in Training Mode\")\n",
    "parser.add_argument(                    # Base Learning Rate\n",
    "    '--base_lr', type = float,          # Default: 1e-4\n",
    "    default = 1e-4,\n",
    "    help = \"Base Learning Rate Value in Training Mode\")\n",
    "parser.add_argument(                    # Weight Decay Value\n",
    "    '--weight_decay', type = float,     # Default: 1e-4\n",
    "    default = 1e-5,\n",
    "    help = \"Weight Decay Value in Training Mode\")\n",
    "parser.add_argument(                    # Learning Rate Decay Ratio\n",
    "    '--lr_decay', type = float,         # Default: 0.9\n",
    "    default = 0.9,\n",
    "    help = \"Learning Rate Decay Value in Training Mode\")\n",
    "parser.add_argument(                    # Early Stopping Epoch Patience Value\n",
    "    '--es_patience', type = int,        # Default: 1000 (no Early Stopping)\n",
    "    default = 50,\n",
    "    help = \"Early Stopping Epoch Patience Value\")\n",
    "parser.add_argument(                    # Early Stopping Delta Decay Value\n",
    "    '--es_delta', type = float,         # Default: 1e-5\n",
    "    default = 1e-5,\n",
    "    help = \"Early Stopping Delta Decay Value\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# 2D CVAE-GAN Model Settings | Architecture Arguments\n",
    "parser.add_argument(                    # Number of Convolutional Blocks\n",
    "    '--num_hidden', type = int,         # Default: 2\n",
    "    default = 3,\n",
    "    help = \"Number of Convolutional Blocks\")\n",
    "parser.add_argument(                    # Latent Space Representation's Dimensionality\n",
    "    '--dim_latent', type = int,         # Default: 128\n",
    "    default = 128,\n",
    "    help = \"Latent Space Representation's Dimensionality\")\n",
    "parser.add_argument(                    # Hidden from Convolutional to Linear Sections Dimensionality\n",
    "    '--dim_hidden', type = int,         # Default: 1024\n",
    "    default = 1024,\n",
    "    help = \"Hidden from Convolutional to Linear Sections Dimensionality\")\n",
    "parser.add_argument(                    # GAN Discriminator\n",
    "    '--recon_level', type = int,        # Default: 3\n",
    "    default = 3,\n",
    "    help = \"Convolutional Blocks' Padding Value\")\n",
    "parser.add_argument(                    # Convolutional Blocks' Padding Value\n",
    "    '--padding', type = int,            # Default: 1\n",
    "    default = 2,\n",
    "    help = \"Convolutional Blocks' Padding Value\")\n",
    "parser.add_argument(                    # Convolutional Blocks' Kernel Size Value\n",
    "    '--kernel_size', type = int,        # Default: 3\n",
    "    default = 5,\n",
    "    help = \"Convolutional Blocks' Kernel Size Value\")\n",
    "\n",
    "settings = parser.parse_args(\"\"); settings.device_ids = [0]\n",
    "settings.device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [fcgCVAE] Fixed Conditional Generative Convolutional Variational AutoEncoder Model Parametrizations Parser Initialization\n",
    "parser = argparse.ArgumentParser(\n",
    "    description = \"fcgCVAE Model Settings\")\n",
    "parser.add_argument(                            # Dataset Version Variable\n",
    "    '--data_version', type = int,               # Default: 0\n",
    "    default = 0,\n",
    "    help = \"Dataset Save Version\")\n",
    "parser.add_argument(                            # Model Version Variable\n",
    "    '--model_version', type = int,              # Default: 0\n",
    "    default = 0,\n",
    "    help = \"Experiment Version\")\n",
    "parser.add_argument(                            # Random Seed for Reproducibility\n",
    "    '--seed', type = int,                       # Default: 42\n",
    "    default = 42,\n",
    "    help = \"Random Seed for Reproducibility\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Dataset Settings | Label Parametrization Arguments\n",
    "parser.add_argument(                                    # Control Variable for the Inclusion of Patient ID in Labels\n",
    "    '--patient_id', type = bool,                        # Default: True\n",
    "    default = False,\n",
    "    help = \"Control Variable for the Inclusion of Patient ID in Labels\")\n",
    "parser.add_argument(                                    # Control Variable for the Conversion of 3 Gradient Directions\n",
    "    '--gradient_coord', type = bool,                    # Coordinates into 2 Gradient Direction Angles (suggested by prof. Chantal)\n",
    "    default = True,                                    # Default: True (3 Coordinate Gradient Values)\n",
    "    help = \"Control Variable for the Conversion of Gradient Direction Mode\")\n",
    "parser.add_argument(                                    # Control Variable for the Rescaling & Normalization of Labels\n",
    "    '--label_norm', type = str,                         # Default: auto\n",
    "    default = 'manual',\n",
    "    choices = ['auto', 'manual', None],\n",
    "    help = \"Control Variable for the Rescaling & Normalization of Labels\")\n",
    "settings = parser.parse_args(\"\"); num_labels = 7\n",
    "if not(settings.patient_id): num_labels -= 1                                                # Exclusion of Patiend ID\n",
    "if not(settings.gradient_coord) or settings.label_norm == 'manual': num_labels -= 1         # Conversion of Gradient Coordinates to Angles\n",
    "parser.add_argument(                                                                        # Dataset Number of Labels\n",
    "    '--num_labels', type = int,                                                             # Default: 7\n",
    "    default = num_labels,\n",
    "    help = \"MUDI Dataset Number of Labels\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Dataset Settings | Set Construction Arguments\n",
    "parser.add_argument(                            # Complete List of Patients in Dataset\n",
    "    '--patient_list', type = list,              # Default: [11, 12, 13, 14, 15]\n",
    "    default = [11, 12, 13, 14, 15],\n",
    "    help = \"Complete List of Patients in Dataset\")\n",
    "parser.add_argument(                            # List of Patients used in Training\n",
    "    '--train_patient_list', type = list,        # Default: [11, 12, 13]\n",
    "    default = [11, 12, 13],\n",
    "    help = \"List of Patients used in Training\")\n",
    "parser.add_argument(                            # List of Patients used in Validation\n",
    "    '--val_patient_list', type = list,          # Default: [15]\n",
    "    default = [15],\n",
    "    help = \"List of Patients used in Validation\")\n",
    "parser.add_argument(                            # List of Patients used in Testing\n",
    "    '--test_patient_list', type = list,         # Default: [14]\n",
    "    default = [14],\n",
    "    help = \"List of Patients used in Testing\")\n",
    "parser.add_argument(                            # Number of Workers for DataLoader Usage\n",
    "    '--num_workers', type = int,                # Default: 1\n",
    "    default = 12,\n",
    "    help = \"Number of Workers for DataLoader Usage\")\n",
    "parser.add_argument(                            # Final Input Image after Zero Padding Pre-Processing\n",
    "    '--img_shape', type = int,                  # Default: 100\n",
    "    default = 96,\n",
    "    help = \"Final Input Image after Zero Padding Pre-Processing\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Dataset Settings | Shuffling Arguments\n",
    "parser.add_argument(                                    # Ability to Shuffle Training DataLoaders' Samples\n",
    "    '--train_sample_shuffle', type = bool,              # Default: False\n",
    "    default = True,\n",
    "    help = \"Ability to Shuffle Training DataLoaders' Samples\")\n",
    "parser.add_argument(                                    # Ability to Shuffle Validation DataLoaders' Samples\n",
    "    '--val_sample_shuffle', type = bool,                # Default: False\n",
    "    default = False,\n",
    "    help = \"Ability to Shuffle Validation DataLoaders' Samples\")\n",
    "\n",
    "parser.add_argument(                                    # Ability to Shuffle Target Parameters\n",
    "    '--param_shuffle', type = bool,                     # Default: True\n",
    "    default = True,\n",
    "    help = \"Ability to Shuffle Target Parameters\")\n",
    "parser.add_argument(                                    # Ability to Shuffle Target Slices\n",
    "    '--slice_shuffle', type = bool,                     # Default: True\n",
    "    default = True,\n",
    "    help = \"Ability to Shuffle Target Voxels\")\n",
    "parser.add_argument(                                    # Control Variable for the Sharing of Parameters inbetween Patient Sets\n",
    "    '--interpatient_sharing', type = bool,              # Default: True (all Training Patient Sets will have, for the same epoch, ...\n",
    "    default = False,                                    # ... the same exact parameters to reconstruct the data to, defined by the 1st Patient\n",
    "    help = \"Control Variable for the Sharing of Parameters inbetween Patient Sets\")\n",
    "\n",
    "# Dataset Settings | Subsectioning Arguments\n",
    "parser.add_argument(                                    # Selected Slice for Image Visualization\n",
    "    '--sel_slice', type = int,                          # Default: 25\n",
    "    default = 25,\n",
    "    help = \"Selected Slice for Image Visualization\")\n",
    "parser.add_argument(                                    # Percentage of Used Target Parameters used in Training\n",
    "    '--train_target_param', type = int or float,        # Default: 25% | 0.2% for 1 Target\n",
    "    default = 100,\n",
    "    help = \"Percentage of Used Target Parameters used in Training\")\n",
    "parser.add_argument(                                    # Percentage of Used Target Parameters used in Validation\n",
    "    '--val_target_param', type = int or float,          # Default: 5% | 0.9% for 2 Target\n",
    "    default = 100,\n",
    "    help = \"Percentage of Used Target Parameters used in Validation\")\n",
    "parser.add_argument(                                    # Number of Parameters used in the Test Set\n",
    "    '--test_target_param', type = int,                  # Default: 100\n",
    "    default = 0,\n",
    "    help = \"Number of Parameters used in the Test Set\")\n",
    "\n",
    "parser.add_argument(                                    # Percentage of Used Target Voxels used in Training\n",
    "    '--train_target_slice', type = int or float,        # Default: 100%\n",
    "    default = 10,\n",
    "    help = \"Percentage of Used Target Voxels used in Training\")\n",
    "parser.add_argument(                                    # Percentage of Used Target Voxels used in Validation\n",
    "    '--val_target_slice', type = int or float,          # Default: 100%\n",
    "    default = 100,\n",
    "    help = \"Percentage of Used Target Voxels during Validation\")\n",
    "\n",
    "parser.add_argument(                                    # Percentage of Used Source / Target Parameter Combos used in Training\n",
    "    '--train_param_loop', type = int or float,          # Default: 60%\n",
    "    default = 10,\n",
    "    help = \"Percentage of Used Target Voxels used in Training\")\n",
    "parser.add_argument(                                    # Percentage of Used Source / Target Parameter Combos used in Validation\n",
    "    '--val_param_loop', type = int or float,            # Default: 60%\n",
    "    default = 10,\n",
    "    help = \"Percentage of Used Target Voxels used in Training\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Paths | Dataset-Related File & Folderpath Arguments\n",
    "parser.add_argument(                                    # Path for Main Dataset Folder\n",
    "    '--main_folderpath', type = str,\n",
    "    default = '../../Datasets/MUDI Dataset',\n",
    "    help = 'Main Folderpath for Root Dataset')\n",
    "settings = parser.parse_args(\"\")\n",
    "parser.add_argument(                                    # Path for Parameter Value File\n",
    "    '--param_filepath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Raw Data/parameters_new.xlsx'),\n",
    "    help = 'Input Filepath for Parameter Value Table')\n",
    "parser.add_argument(                                    # Path for Parameter Value File\n",
    "    '--data_filepath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Raw Data/data_.hdf5'),\n",
    "    help = 'Input Filepath for Parameter Value Table')\n",
    "parser.add_argument(                                    # Path for Patient Information File\n",
    "    '--info_filepath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Raw Data/header_.csv'),\n",
    "    help = 'Input Filepath for Patient Information Table')\n",
    "parser.add_argument(                                    # Path for Folder Containing Mask Data Files\n",
    "    '--mask_folderpath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Patient Mask'),\n",
    "    help = 'Input Folderpath for Segregated Patient Mask Data')\n",
    "parser.add_argument(                                    # Path for Dataset Saved Files\n",
    "    '--datasave_folderpath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Saved Data/V{settings.data_version}'),\n",
    "    help = 'Output Folderpath for MUDI Dataset Saved Versions')\n",
    "\n",
    "# Paths | Model-Related File & Folderpath Arguments\n",
    "parser.add_argument(                                    # Path for Dataset Reader Script\n",
    "    '--reader_folderpath', type = Path,\n",
    "    default = Path(f'{settings.main_folderpath}/Dataset Reader'),\n",
    "    help = 'Input Folderpath for MUDI Dataset Reader')\n",
    "parser.add_argument(                                    # Path for Model Build Script\n",
    "    '--build_folderpath', type = str,\n",
    "    default = 'fcglVNN/Model Builds',\n",
    "    help = 'Input Folderpath for Model Build & Architecture')\n",
    "parser.add_argument(                                    # Path for Model Training Scripts\n",
    "    '--script_folderpath', type = str,\n",
    "    default = 'fcglVNN/Training Scripts',\n",
    "    help = 'Input Folderpath for Training & Testing Script Functions')\n",
    "parser.add_argument(                                    # Path for Model Saved Files\n",
    "    '--modelsave_folderpath', type = str,\n",
    "    default = 'fcglVNN/Saved Models',\n",
    "    help = 'Output Folderpath for Saved & Saving Models')\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Model Settings | Optimization Arguments\n",
    "parser.add_argument(                    # Number of Epochs\n",
    "    '--num_epochs', type = int,         # Default: 1200\n",
    "    default = 300,\n",
    "    help = \"Number of Epochs in Training Mode\")\n",
    "parser.add_argument(                    # Base Learning Rate\n",
    "    '--base_lr', type = float,          # Default: 1e-4\n",
    "    default = 1e-4,\n",
    "    help = \"Base Learning Rate Value in Training Mode\")\n",
    "parser.add_argument(                    # Weight Decay Value\n",
    "    '--weight_decay', type = float,     # Default: 1e-4\n",
    "    default = 1e-5,\n",
    "    help = \"Weight Decay Value in Training Mode\")\n",
    "parser.add_argument(                    # Learning Rate Decay Ratio\n",
    "    '--lr_decay', type = float,         # Default: 0.9\n",
    "    default = 0.9,\n",
    "    help = \"Learning Rate Decay Value in Training Mode\")\n",
    "parser.add_argument(                    # Early Stopping Epoch Patience Value\n",
    "    '--es_patience', type = int,        # Default: 1000 (no Early Stopping)\n",
    "    default = 50,\n",
    "    help = \"Early Stopping Epoch Patience Value\")\n",
    "parser.add_argument(                    # Early Stopping Delta Decay Value\n",
    "    '--es_delta', type = float,         # Default: 1e-5\n",
    "    default = 1e-5,\n",
    "    help = \"Early Stopping Delta Decay Value\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Model Settings | Architecture Arguments\n",
    "parser.add_argument(                    # Dataset Number of Training Parameters\n",
    "    '--in_channels', type = int,        # Default: 500\n",
    "    default = 500,\n",
    "    help = \"MUDI Dataset No. of Training Parameters / Model's No. of Input Channels\")\n",
    "parser.add_argument(                    # Number of Convolutional Blocks\n",
    "    '--num_hidden', type = int,         # Default: 2\n",
    "    default = 3,\n",
    "    help = \"Number of Convolutional Blocks\")\n",
    "parser.add_argument(                    # Latent Space Representation's Dimensionality\n",
    "    '--dim_latent', type = int,         # Default: 128\n",
    "    default = 128,\n",
    "    help = \"Latent Space Representation's Dimensionality\")\n",
    "\n",
    "parser.add_argument(                    # Hidden from Convolutional to Linear Sections Dimensionality\n",
    "    '--dim_hidden', type = int,         # Default: 1024\n",
    "    default = 1024,\n",
    "    help = \"Hidden from Convolutional to Linear Sections Dimensionality\")\n",
    "parser.add_argument(                    # Convolutional Blocks' Padding Value\n",
    "    '--padding', type = int,            # Default: 1\n",
    "    default = 2,\n",
    "    help = \"Convolutional Blocks' Padding Value\")\n",
    "parser.add_argument(                    # Convolutional Blocks' Kernel Size Value\n",
    "    '--kernel_size', type = int,        # Default: 3\n",
    "    default = 5,\n",
    "    help = \"Convolutional Blocks' Kernel Size Value\")\n",
    "\n",
    "settings = parser.parse_args(\"\"); settings.device_ids = [0]\n",
    "settings.device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **[Old]** **fcNN**\n",
    "\n",
    "### *Fully Connected Neural Network*\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data** *Reader*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D MUDI Dataset Initialization Class\n",
    "class MUDI_fcNN(keras.utils.Sequence):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,\n",
    "        subject: int or list\n",
    "    ):\n",
    "        \n",
    "        # Parameter & Patient Index Value Access\n",
    "        super(MUDI_fcNN).__init__()\n",
    "        self.settings = settings\n",
    "\n",
    "        # Vertical Splitting (Patient Selection)\n",
    "        self.idxv = pd.read_csv(self.settings.info_filepath,            # List of Index Values ...\n",
    "                                index_col = 0).to_numpy()               # ... pertaining to each Patient\n",
    "        self.idxv = self.idxv[np.isin(self.idxv[:, 1], subject), 0]     # Patient-Specific Index Values\n",
    "        self.idxv_list = np.arange(len(self.idxv))\n",
    "\n",
    "        # Horizontal Splitting (Parameter Selection)\n",
    "        self.idxh_train_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Training Labels (V{self.settings.data_version}).txt\")    # Filepath for Selected Training Labels\n",
    "        self.idxh_val_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Validation Labels (V{self.settings.data_version}).txt\")    # Filepath for Selected Validation Labels\n",
    "        self.idxh_train = np.sort(np.loadtxt(self.idxh_train_filepath)).astype(int)\n",
    "        self.idxh_val = np.sort(np.loadtxt(self.idxh_val_filepath)).astype(int)\n",
    "        #self.msk = np.logical_not(np.isin(np.arange(1344), self.idxh_train))\n",
    "        \n",
    "        # Parameter Value Initialization & Selection\n",
    "        self.params = pd.read_excel(self.settings.param_filepath)                                       # List of Dataset's Parameters\n",
    "        self.num_labels = self.settings.num_labels\n",
    "        if self.settings.gradient_coord:\n",
    "            self.params = self.params.drop(columns = ['Gradient theta', 'Gradient phi'])                # Choosing of Gradient Orientation\n",
    "        else: self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])      # from 3D Cartesian or Polar Referential\n",
    "        #assert(self.params.shape[1] == self.num_labels), \"ERROR: Labels wrongly Deleted!\"\n",
    "        if self.settings.label_norm:                                                                    # Control Boolean Value for the Normalization of Labels\n",
    "            self.scaler = StandardScaler()\n",
    "            self.params = pd.DataFrame( self.scaler.fit_transform(self.params),\n",
    "                                        columns = self.params.columns)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # DataLoader Length / No. Batches Computation Functionality\n",
    "    def __len__(self): return int(np.ceil(len(self.idxv) / float(self.settings.batch_size)))\n",
    "\n",
    "    # Single-Batch Generation Functionality\n",
    "    def __getitem__(self, idxv):\n",
    "        idxv = self.idxv_list[idxv * self.settings.batch_size : (idxv + 1) * self.settings.batch_size]\n",
    "        idxv = [self.idxv[k] for k in idxv]\n",
    "        X_train, X = self.__data_generation(idxv)\n",
    "        return X_train, X\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # End of Epoch Shuffling Functionality\n",
    "    def on_epoch_end(self):\n",
    "        self.idxv_list = np.arange(len(self.idxv))\n",
    "        if self.settings.sample_shuffle: np.random.shuffle(self.idxv_list)\n",
    "\n",
    "    # Data Generation Functionality\n",
    "    def __data_generation(self, idxv):\n",
    "        data = h5py.File(self.settings.data_filepath, 'r').get('data1')\n",
    "        X = data[idxv, :]; X_train = X[:, self.idxh_train]\n",
    "        return X_train, X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset DataLoader Creation\n",
    "trainset = MUDI_fcNN(settings, subject = [11, 12, 13])\n",
    "#valset = MUDI_1D(data_settings, subject = [15])\n",
    "#testset = MUDI_1D(data_settings, subject = [14])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Model* **Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pfernan2\\Desktop\\dMRI-Studio\\Experiments\\Autoencoders\\Autoencoders.ipynb Cell 18\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Linear Fully Connected Neural Network Model Class\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mfcNN\u001b[39;00m(keras\u001b[39m.\u001b[39mModel):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m# Constructor / Initialization Function\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         settings: argparse\u001b[39m.\u001b[39mArgumentParser\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#X23sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#X23sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         \u001b[39m# Class Variable Logging\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#X23sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "# Linear Fully Connected Neural Network Model Class\n",
    "class fcNN(keras.Model):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser\n",
    "        #in_params: int = 500,                   # Number of Input Parameter Settings\n",
    "        #out_params: int = 1344,                 # Number of Output Parameter Settings\n",
    "        #num_hidden: int = 2                     # Number of NN Hidden Layers\n",
    "    ):\n",
    "\n",
    "        # Class Variable Logging\n",
    "        super().__init__()\n",
    "        self.in_params = settings.in_params\n",
    "        self.out_params = settings.out_params\n",
    "        self.num_hidden = settings.num_hidden\n",
    "        assert(self.out_params > self.in_params),\"ERROR: Neural Network wrongly built!\"\n",
    "        self.net = Sequential(); num_neuron = self.in_params\n",
    "\n",
    "        # Neural Network Architecture Definition\n",
    "        num_fc = int(np.floor((self.out_params - self.in_params) / (self.num_hidden + 1)))\n",
    "        for i in range(self.num_hidden + 1):\n",
    "            if i == 0:\n",
    "                self.net.add(   Dense(input_dim = num_neuron, units = num_neuron + num_fc))\n",
    "                self.net.add(   LeakyReLU(alpha = 0.2))\n",
    "            elif i == self.num_hidden:\n",
    "                num_fc += 1; self.net.add(  Dense(units = num_neuron + num_fc))\n",
    "            else:\n",
    "                self.net.add(   Dense(units = num_neuron + num_fc))\n",
    "                self.net.add(   LeakyReLU(alpha = 0.2))\n",
    "            num_neuron += num_fc\n",
    "        assert(num_neuron == self.out_params), \"ERROR: Neural Network wrongly built!\"\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Neural Network Application Function\n",
    "    def call(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "    ):  return self.net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Initialization Example\n",
    "model = fcNN(model_settings)\n",
    "model.net.summary()\n",
    "\"\"\"visualizer_settings = {\n",
    "    'MAX_NEURONS': None,\n",
    "    'INPUT_DENSE_COLOR': 'teal',\n",
    "    'HIDDEN_DENSE_COLOR': 'gray',\n",
    "    'OUTPUT_DENSE_COLOR': 'crimson'}\"\"\"\n",
    "#visualizer( model.net, view = False, file_format = 'pdf')\n",
    "            #, file_name = 'fcNN')\n",
    "            #, settings = visualizer_settings)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training** *Script*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction Callback Class\n",
    "class ReconCallback(keras.callbacks.Callback):\n",
    "       \n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,              # Model Settings & Parametrizations\n",
    "    ):\n",
    "\n",
    "        # Class Variable Logging\n",
    "        super().__init__()\n",
    "        self.settings = settings\n",
    "        self.data = MUDI_1D(self.settings.data_settings); self.criterion = nn.MSELoss()\n",
    "\n",
    "        # TensorBoard Logger Initialization\n",
    "        self.train_logger = TensorBoardLogger(f'{self.settings.save_folderpath}/V{self.settings.model_version}', 'train')\n",
    "        self.val_logger = TensorBoardLogger(f'{self.settings.save_folderpath}/V{self.settings.model_version}', 'validation')\n",
    "        #self.train_log = f\"{self.settings.save_folderpath}/V{self.settings.model_version}/Training Performance/train\"\n",
    "        #self.val_log = f\"{self.settings.save_folderpath}/V{self.settings.model_version}/Training Performance/val\"\n",
    "        #self.train_writer = tf.summary.create_file_writer(self.train_log)\n",
    "        #self.val_writer = tf.summary.create_file_writer(self.val_log)\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Patient Image Reconstruction\n",
    "    def reconstruct(\n",
    "        self,\n",
    "        set: MRIDecoderSubjDataset,     # Keras DataLoader\n",
    "        pMask: torch.Tensor,            # Selected Patient's Mask\n",
    "        pX_img: torch.Tensor,           # Selected Patient Image\n",
    "        sel_slice: int = 25             # Selected Reconstruction Slice\n",
    "    ):\n",
    "        \n",
    "        # Fake 3D Image Generation\n",
    "        pX_fake = self.model.predict_generator(set)\n",
    "        pX_fake = unmask(pX_fake.T, pMask).get_fdata().T\n",
    "        assert(np.all(pX_img.shape == pX_fake.shape)), \"ERROR: Unmasking went Wrong!\"\n",
    "        recon_loss = self.criterion(torch.Tensor(pX_fake), torch.Tensor(pX_img))\n",
    "\n",
    "        # Randomly Selected Training & Validation Parameters for Visualization\n",
    "        if self.settings.recon_shuffle:\n",
    "            self.sel_train_param = np.random.choice(self.data.idxh_train, size = 1, replace = False)[0]\n",
    "            self.sel_val_param = np.random.choice(self.data.idxh_val, size = 1, replace = False)[0]\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # Training Parameter Example Original & Reconstructed Image Subplot\n",
    "        train_figure = plt.figure(figsize = (20, 10))\n",
    "        plt.xticks([]); plt.yticks([]); plt.grid(False); plt.tight_layout()\n",
    "        plt.subplot(1, 2, 1, title = f'Original Image (Parameter #{self.sel_train_param})')\n",
    "        plt.imshow(pX_img[self.sel_train_param, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        plt.subplot(1, 2, 2, title = f'Reconstructed Image (Parameter #{self.sel_train_param})')\n",
    "        plt.imshow(pX_fake[self.sel_train_param, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        #img_buffer = io.BytesIO(); plt.savefig(img_buffer, format = 'png')\n",
    "        #train_figure = Image.open(img_buffer); img_buffer.close()\n",
    "\n",
    "        # Validation Parameter Example Original & Reconstructed Image Subplot\n",
    "        val_figure = plt.figure(figsize = (20, 10))\n",
    "        plt.xticks([]); plt.yticks([]); plt.grid(False); plt.tight_layout()\n",
    "        plt.subplot(1, 2, 1, title = f'Original Image (Parameter #{self.sel_val_param})')\n",
    "        plt.imshow(pX_img[self.sel_val_param, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        plt.subplot(1, 2, 2, title = f'Reconstructed Image (Parameter #{self.sel_val_param})')\n",
    "        plt.imshow(pX_fake[self.sel_val_param, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        #img_buffer = io.BytesIO(); plt.savefig(img_buffer, format = 'png')\n",
    "        #val_figure = Image.open(img_buffer); img_buffer.close()\n",
    "        return recon_loss, train_figure, val_figure\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Functionality called upon the Start of Training\n",
    "    def on_train_begin(self, logs = None):\n",
    "\n",
    "        # Example Training Patient Download \n",
    "        self.pX_train, self.pMask_train = self.data.get_patient(self.settings.sel_train_patient)\n",
    "        self.pX_train_img = unmask(self.pX_train, self.pMask_train).get_fdata().T\n",
    "        self.train_set = MRIDecoderSubjDataset(  root_dir = f'{self.settings.data_settings.main_folderpath}/Raw Data/',\n",
    "                                                selecf = f'{self.settings.data_folderpath}/1D Training Labels (V{self.settings.data_version}).txt',\n",
    "                                                dataf = 'data_.hdf5', headerf = 'header_.csv',\n",
    "                                                subj_list = np.array([self.settings.sel_train_patient]),\n",
    "                                                batch_size = self.settings.data_settings.batch_size)\n",
    "        \n",
    "        # Example Validation Patient Download\n",
    "        self.pX_val, self.pMask_val = self.data.get_patient(self.settings.sel_val_patient)\n",
    "        self.pX_val_img = unmask(self.pX_val, self.pMask_val).get_fdata().T\n",
    "        self.val_set = MRIDecoderSubjDataset(  root_dir = f'{self.settings.data_settings.main_folderpath}/Raw Data/',\n",
    "                                                selecf = f'{self.settings.data_folderpath}/1D Training Labels (V{self.settings.data_version}).txt',\n",
    "                                                dataf = 'data_.hdf5', headerf = 'header_.csv',\n",
    "                                                subj_list = np.array([self.settings.sel_val_patient]),\n",
    "                                                batch_size = self.settings.data_settings.batch_size)\n",
    "\n",
    "        # Reconstruction Training & Validation Parameter Definition\n",
    "        if not self.settings.recon_shuffle:\n",
    "            self.sel_train_param = self.data.idxh_train[self.settings.sel_train_param]\n",
    "            self.sel_val_param = self.data.idxh_val[self.settings.sel_val_param]\n",
    "    \n",
    "    # Functionality called upon the End of a Training Epoch\n",
    "    def on_epoch_end(self, epoch, logs = None):\n",
    "\n",
    "        # Randomly Selected Training & Validation Parameters for Visualization\n",
    "        if self.settings.recon_shuffle:\n",
    "            self.sel_train_param = np.random.choice(self.data.idxh_train, size = 1, replace = False)[0]\n",
    "            self.sel_val_param = np.random.choice(self.data.idxh_val, size = 1, replace = False)[0]\n",
    "        \n",
    "        # Epoch Update for Losses & Training Image Reconstruction\n",
    "        train_recon_loss, tt_plot, tv_plot = self.reconstruct(  self.train_set, self.pMask_train,\n",
    "                                                                self.pX_train_img, sel_slice = 25)\n",
    "        val_recon_loss, vt_plot, vv_plot = self.reconstruct(    self.val_set, self.pMask_val,\n",
    "                                                                self.pX_val_img, sel_slice = 25)\n",
    "        \n",
    "        # TensorBoard Logger Model Visualizer, Update for Image Visualizer\n",
    "        self.train_logger.experiment.add_scalar(\"Reconstruction Loss\", train_recon_loss, epoch)\n",
    "        self.train_logger.experiment.add_figure(\"Training Image Reconstruction\", tt_plot, epoch)\n",
    "        self.train_logger.experiment.add_figure(\"Validation Image Reconstruction\", tv_plot, epoch)\n",
    "        self.val_logger.experiment.add_scalar(\"Reconstruction Loss\", val_recon_loss, epoch)\n",
    "        self.val_logger.experiment.add_figure(\"Training Image Reconstruction\", vt_plot, epoch)\n",
    "        self.val_logger.experiment.add_figure(\"Validation Image Reconstruction\", vv_plot, epoch)\n",
    "\n",
    "        \"\"\"\n",
    "        # TensorBoard Logger Model Visualizer, Update for Image Visualizer\n",
    "        with self.train_writer.as_default():\n",
    "            tf.summary.scalar('Reconstruction Loss', train_recon_loss, step = epoch)\n",
    "            tf.summary.image('Training Image Reconstruction', tt_plot, step = epoch)\n",
    "            tf.summary.image('Training Image Reconstruction', tv_plot, step = epoch)\n",
    "        self.train_writer.flush()\n",
    "        with self.val_writer.as_default():\n",
    "            tf.summary.scalar('Reconstruction Loss', val_recon_loss, step = epoch)\n",
    "            tf.summary.image('Training Image Reconstruction', vt_plot, step = epoch)\n",
    "            tf.summary.image('Training Image Reconstruction', vv_plot, step = epoch)\n",
    "        self.train_writer.flush()\n",
    "        \"\"\"\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **fcNN**\n",
    "\n",
    "### *Fully Connected Neural Network*\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data** *Reader*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D MUDI Dataset Initialization Class (V0)\n",
    "class MUDI_fcNN(Dataset):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,\n",
    "        subject: int or list,\n",
    "        target_voxel: int or float = 100\n",
    "    ):\n",
    "        \n",
    "        # Parameter & Patient Index Value Access\n",
    "        super(MUDI_fcNN).__init__()\n",
    "        self.settings = settings; self.target_voxel = target_voxel\n",
    "        self.data = h5py.File(self.settings.data_filepath, 'r').get('data1')\n",
    "        self.params = pd.read_excel(self.settings.param_filepath)\n",
    "\n",
    "        # Vertical Splitting (Patient Selection)\n",
    "        self.idxv = pd.read_csv(self.settings.info_filepath,            # List of Index Values ...\n",
    "                                index_col = 0).to_numpy()               # ... pertaining to each Patient\n",
    "        self.idxv = self.idxv[np.isin(self.idxv[:, 1], subject), 0]     # Patient-Specific Index Values\n",
    "\n",
    "        # Horizontal Splitting (Parameter Selection)\n",
    "        idxh_train_filepath = Path(f\"{self.settings.datasave_folderpath}/Training Labels (V{self.settings.data_version}).txt\")\n",
    "        self.idxh_train = np.sort(np.loadtxt(idxh_train_filepath)).astype(int)\n",
    "        assert(len(self.idxh_train) == self.settings.in_channels), \"ERROR: Data Reader wrongly Built!\"\n",
    "\n",
    "        # Vertical & Horizontal Sub-Sectioning & Shuffling\n",
    "        self.v_target = int((self.target_voxel * len(self.idxv)) / 100); self.shuffle()\n",
    "        print(f\"     > Utilizing {self.v_target} \\ {len(self.idxv)} of the Training Voxels\")\n",
    "\n",
    "        # Parameter Selection & Value Normalization / Scaling\n",
    "        if self.settings.gradient_coord:\n",
    "            self.params = self.params.drop(columns = ['Gradient theta', 'Gradient phi'])                # Choosing of Gradient Orientation\n",
    "        else: self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])\n",
    "        if self.settings.label_norm == 'auto':\n",
    "            print(f\"     > Automatic Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "            self.scaler = StandardScaler()\n",
    "            self.params = pd.DataFrame( self.scaler.fit_transform(self.params),\n",
    "                                        columns = self.params.columns)\n",
    "            scaler_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "            if not scaler_filepath.exists(): torch.save(self.scaler, scaler_filepath)\n",
    "        elif self.settings.label_norm == 'manual':\n",
    "            print(f\"     > Manual Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "            self.params[['Gradient theta', 'Gradient phi']] = self.cart2polar(self.params[['Gradient x', 'Gradient y', 'Gradient z']].values)\n",
    "            self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])\n",
    "            self.params['b Value'] = self.params['b Value'] / 10000\n",
    "            self.params['TI'] = self.params['TI'] / 10000\n",
    "            self.params['TE'] = (self.params['TE'] - 80) / 200\n",
    "        else: print(f\"     > No Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "        assert(self.params.shape[1] == self.settings.num_labels), \"ERROR: Labels wrongly Deleted!\"\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # DataLoader Length / No. Batches Computation Functionality\n",
    "    def __len__(self): return self.v_target\n",
    "\n",
    "    # Single-Batch Generation Functionality\n",
    "    def __getitem__(self, idx) -> tuple[np.ndarray, np.float32]:\n",
    "    \n",
    "        # Batch Data Generation\n",
    "        idxv = idx % self.v_target                                                  # Batch's Vertical Index for X_train\n",
    "        X_train = self.data[self.idxv_target[idxv], :][self.idxh_train]             # [in_channels] Training Data\n",
    "        X_target = self.data[self.idxv_target[idxv], :]                             # [out_channels] GT Target Data\n",
    "        return X_train, X_target\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "                \n",
    "    # Target Voxel Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def shuffle(\n",
    "        self,\n",
    "        idxv_target: np.array = None\n",
    "    ):  \n",
    "        if idxv_target is not None: self.idxv_target = idxv_target\n",
    "        else:\n",
    "            if self.settings.voxel_shuffle:\n",
    "                self.idxv_target = self.idxv[   np.sort(np.random.choice(len(self.idxv),\n",
    "                                                self.v_target, replace = False))]\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "        \n",
    "    # Label Scaler Download & Reverse Transformation\n",
    "    def label_unscale(\n",
    "        self,\n",
    "        y: np.array or pd.DataFrame\n",
    "    ):\n",
    "\n",
    "        # Label Scaler Download & Reverse Usage\n",
    "        try: self.scaler\n",
    "        except AttributeError:\n",
    "            scaler = torch.load(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "        return scaler.inverse_transform(y.reshape(1, -1))\n",
    "\n",
    "    # Cartesian to Polar Coordinate Conversion Functionality\n",
    "    def cart2polar(self, y: np.array):\n",
    "\n",
    "        # Cartesian to Polar Coordinates Conversion\n",
    "        phi = np.arccos(y[:, 2]).astype(np.float32); theta = np.arctan2(y[:, 1], y[:, 0])\n",
    "        theta = np.where(theta < 0, 2 * np.pi - np.abs(theta), theta).astype(np.float32)\n",
    "        theta = np.expand_dims(theta, axis = 1); phi = np.expand_dims(phi, axis = 1)\n",
    "        return pd.DataFrame(data = np.concatenate((theta, phi), axis = 1),\n",
    "                            columns = ['Gradient theta', 'Gradient phi'])\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Patient Data Generation Functionality\n",
    "    def get_img(settings, num_patient: int):\n",
    "\n",
    "        # Patient Data Access\n",
    "        data = h5py.File(settings.data_filepath, 'r').get('data1')\n",
    "        idxv = pd.read_csv( settings.info_filepath,             # List of Index Values ...\n",
    "                            index_col = 0).to_numpy()           # ... pertaining to each Patient\n",
    "        idxv = idxv[np.isin(idxv[:, 1], num_patient), 0]        # Patient-Specific Index Values\n",
    "        X = torch.Tensor(data[idxv, :])\n",
    "\n",
    "        # Patient Mask Access\n",
    "        mask = MUDI_fcNN.get_mask(settings, num_patient = num_patient)\n",
    "        img = unmask(X.T, mask).get_fdata().T\n",
    "        return torch.Tensor(img)\n",
    "\n",
    "    # Patient Mask Retrieval Functionality\n",
    "    def get_mask(settings, num_patient: int):\n",
    "        mask_filepath = Path(f\"{settings.mask_folderpath}/p{num_patient}.nii\")\n",
    "        assert(mask_filepath.exists()), f\"ERROR: Patient {num_patient}'s Mask not Found!\"\n",
    "        #return torch.Tensor(np.array(load_img(mask_filepath).dataobj, dtype = np.float32))\n",
    "        return load_img(mask_filepath)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     > Utilizing 108300 \\ 108300 of the Training Voxels\n",
      "     > Manual Normalization of all 5 Parameter Values\n"
     ]
    }
   ],
   "source": [
    "# Dataset DataLoader Creation\n",
    "trainset = MUDI_fcNN(       settings, subject = [11],\n",
    "                            target_voxel = settings.train_target_voxel)\n",
    "trainloader = DataLoader(   dataset = trainset,\n",
    "                            shuffle = settings.val_sample_shuffle,\n",
    "                            num_workers = 0,#settings.num_workers,\n",
    "                            batch_size = len(trainset.idxv_target),#settings.batch_size,\n",
    "                            pin_memory = False)\n",
    "mask = MUDI_fcNN.get_mask(settings, num_patient = 11)\n",
    "img = MUDI_fcNN.get_img(settings, num_patient = 11)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Model* **Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed Conditional Generative Linear Voxel Net Model Class\n",
    "class fcNN(nn.Module):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser\n",
    "    ):\n",
    "        \n",
    "        # Class Variable Logging\n",
    "        super().__init__(); self.settings = settings\n",
    "        self.net = []; self.arch = []\n",
    "        self.arch.insert(0, self.settings.in_channels)\n",
    "\n",
    "        # Neural Network Architecture Definition\n",
    "        var_hidden = int((self.settings.out_channels - self.settings.in_channels) / (self.settings.num_hidden + 1))\n",
    "        for i in range(1, self.settings.num_hidden + 2):\n",
    "            if i == self.settings.num_hidden + 1:\n",
    "                self.arch.insert(i, self.settings.out_channels)\n",
    "                self.net.append(    nn.Linear(      in_features = self.arch[i - 1],\n",
    "                                                    out_features = self.arch[i]))\n",
    "            else:\n",
    "                self.arch.insert(i, self.arch[i - 1] + var_hidden)\n",
    "                self.net.append(\n",
    "                    nn.Sequential(  nn.Linear(      in_features = self.arch[i - 1],\n",
    "                                                    out_features = self.arch[i]),\n",
    "                                    nn.BatchNorm1d( num_features = self.arch[i]),\n",
    "                                    nn.ReLU()))\n",
    "        self.net = nn.Sequential(*self.net)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Neural Network Application Function\n",
    "    def forward(\n",
    "        self,\n",
    "        input: np.ndarray or torch.Tensor\n",
    "    ):  return self.net(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fcNN(\n",
      "  (net): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=500, out_features=781, bias=True)\n",
      "      (1): BatchNorm1d(781, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=781, out_features=1062, bias=True)\n",
      "      (1): BatchNorm1d(1062, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (2): Linear(in_features=1062, out_features=1344, bias=True)\n",
      "  )\n",
      ")\n",
      "torch.Size([10, 1344])\n"
     ]
    }
   ],
   "source": [
    "# Model Initialization Example\n",
    "model = fcNN(settings)\n",
    "print(model)\n",
    "\n",
    "# Model Usage Example\n",
    "X_train = torch.rand((10, 500))\n",
    "print(model(X_train).shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training** *Script*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result Plotting Functionality (V0)\n",
    "def plot_results(\n",
    "    logger: TensorBoardLogger,\n",
    "    best_info: dict,\n",
    "    worst_info: dict,\n",
    "    patient_id: int = 14,\n",
    "    sel_slice: int = 25,\n",
    "    epoch = 0,\n",
    "    mode: str = 'Train',\n",
    "    loss: str = 'MSE Loss'\n",
    "):\n",
    "\n",
    "    # Set Example Reconstruction Results Image Plotting\n",
    "    plot = plt.figure(figsize = (20, 25)); plt.suptitle(f\"Overall {mode} | {loss}\")\n",
    "    plt.xticks([]); plt.yticks([]); plt.grid(False); plt.tight_layout()\n",
    "\n",
    "    # Set Example Original & Best Loss Reconstructed Image Subplots\n",
    "    plt.subplot(2, 2, 1, title =        f\"Best | Target Parameter #{best_info['idxh']}\")\n",
    "    plt.imshow(best_info['img_gt'][     sel_slice, :, :], cmap = plt.cm.binary)\n",
    "    plt.subplot(2, 2, 2, title =        f\"Best | Reconstruction | {loss}: {np.round(best_info['loss'], 5)}\")\n",
    "    plt.imshow(best_info['img_fake'][   sel_slice, :, :], cmap = plt.cm.binary)\n",
    "\n",
    "    # Set Example Original & Worst Loss Reconstructed Image Subplots\n",
    "    plt.subplot(2, 2, 3, title =        f\"Best | Target Parameter #{worst_info['idxh']}\")\n",
    "    plt.imshow(worst_info['img_gt'][    sel_slice, :, :], cmap = plt.cm.binary)\n",
    "    plt.subplot(2, 2, 4, title =        f\"Best | Reconstruction | {loss}: {np.round(worst_info['loss'], 5)}\")\n",
    "    plt.imshow(worst_info['img_fake'][  sel_slice, :, :], cmap = plt.cm.binary)\n",
    "\n",
    "    # Tensorboard Reconstruction Callback\n",
    "    logger.experiment.add_figure(f\"{mode} Image Results\", plot, epoch)\n",
    "    logger.experiment.add_scalar(\"Best Loss\", best_info['loss'], epoch)\n",
    "    logger.experiment.add_scalar(\"Worst Loss\", worst_info['loss'], epoch)\n",
    "    return logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fcNN Model Training Script (V0)\n",
    "def fcNN_train(\n",
    "    settings,\n",
    "):\n",
    "\n",
    "    # Seed Random State for Reproducibility\n",
    "    torch.manual_seed(settings.seed)\n",
    "    np.random.seed(settings.seed)\n",
    "    random.seed(settings.seed)\n",
    "\n",
    "    # Experiment Logs Directories Initialization\n",
    "    checkpoint_folderpath = os.path.join(f'{settings.modelsave_folderpath}/V{settings.model_version}', 'logs')\n",
    "    train_logger = TensorBoardLogger(checkpoint_folderpath, 'train')\n",
    "    val_mse_logger = TensorBoardLogger(checkpoint_folderpath, 'validation/mse')\n",
    "    val_ssim_logger = TensorBoardLogger(checkpoint_folderpath, 'validation/ssim')\n",
    "\n",
    "    # Training & Validation DataLoaders Initialization\n",
    "    train_set = []; val_set = []\n",
    "    train_loader = []; val_loader = []\n",
    "    for p, patient_id in enumerate(settings.patient_list):\n",
    "\n",
    "        # Patient Set & DataLoader Initialization\n",
    "        if patient_id in settings.train_patient_list:\n",
    "            print(f\"Patient #{patient_id} | Training Set:\")\n",
    "            train_set.append(   MUDI_fcNN(  settings, subject = [patient_id],\n",
    "                                            target_voxel = settings.train_target_voxel))\n",
    "            train_loader.append(DataLoader( dataset = train_set[-1], pin_memory = True,\n",
    "                                            shuffle = settings.train_sample_shuffle,\n",
    "                                            num_workers = settings.num_workers,\n",
    "                                            batch_size = settings.batch_size))\n",
    "        elif patient_id in settings.val_patient_list:\n",
    "            print(f\"Patient #{patient_id} | Validation Set:\")\n",
    "            val_set.append(     MUDI_fcNN(  settings, subject = [patient_id],\n",
    "                                            target_voxel = settings.val_target_voxel))\n",
    "            val_loader.append(  DataLoader( dataset = val_set[-1], pin_memory = True,\n",
    "                                            shuffle = settings.val_sample_shuffle,\n",
    "                                            num_workers = settings.num_workers,\n",
    "                                            batch_size = len(val_set[-1].idxv_target)))\n",
    "        else: print(f\"Patient #{patient_id} | Test Set:\\n     > Not Included\")\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Model & Optimizer Setup\n",
    "    print(f\"Running\\n     > Training fcNN Model with {torch.cuda.device_count()} GPUs!\")\n",
    "    model = nn.DataParallel(fcNN(settings), device_ids = settings.device_ids).to(settings.device)\n",
    "    optimizer = torch.optim.AdamW(  model.parameters(), lr = settings.base_lr,\n",
    "                                    weight_decay = settings.weight_decay)\n",
    "\n",
    "    # Model Checkpoint Loading\n",
    "    model_filepath = Path(f\"{settings.modelsave_folderpath}/V{settings.model_version}/Best fcNN.pt\")\n",
    "    if model_filepath.exists():\n",
    "        checkpoint = torch.load(model_filepath, map_location = 'cpu')#)settings.device)\n",
    "        model.load_state_dict(checkpoint['Model']); optimizer.load_state_dict(checkpoint['Optimizer'])\n",
    "        save_epoch = checkpoint['Current Epoch']; torch.set_rng_state(checkpoint['RNG State'])\n",
    "        print(f\"     > Loading fcNN Model for {settings.model_version}: {save_epoch} Past Epochs\")\n",
    "        del checkpoint\n",
    "    else: save_epoch = -1\n",
    "\n",
    "    # Criterion & Early Stopping Setup\n",
    "    mse_criterion = nn.MSELoss(reduction = 'mean')\n",
    "    earlyStopping = EarlyStopping(settings)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Epoch Iteration Loop\n",
    "    train_iter = 0; val_iter = 0\n",
    "    for epoch in range(save_epoch + 1, settings.num_epochs):\n",
    "\n",
    "        # Training Patient Loop\n",
    "        train_mse_loss = []; print(f\"Training Epoch #{epoch}:\")\n",
    "        for p, patient_id in enumerate(settings.train_patient_list):\n",
    "\n",
    "            # Training Iteration Loop\n",
    "            mask = MUDI_fcglVNN.get_mask(settings, num_patient = patient_id)\n",
    "            train_bar = tqdm(   enumerate(train_loader[p]), total = len(train_loader[p]),\n",
    "                desc = f'Epoch #{epoch} | Training Patient {patient_id}', unit = 'Batches')\n",
    "            for batch_idx, batch in train_bar:\n",
    "\n",
    "                # Forward Propagation\n",
    "                model.train(); model.zero_grad(); optimizer.zero_grad()\n",
    "                X_fake = model(batch[0].to(settings.device))\n",
    "                X_fake = torch.squeeze(X_fake, dim = 1)\n",
    "                gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "                # Backward Propagation\n",
    "                mse_loss = mse_criterion(X_fake, batch[1].to(settings.device))\n",
    "                mse_loss.backward(); optimizer.step(); del batch, X_fake\n",
    "                train_logger.experiment.add_scalar(\"Batch Loss\", mse_loss.item(), train_iter)\n",
    "                train_mse_loss.append(mse_loss.item()); train_iter += 1\n",
    "\n",
    "            # Inter-Patient Reconstruction Parameter Sharing Functionality\n",
    "            if settings.interpatient_sharing:\n",
    "                if p == 0: train_set[p].shuffle(); idxv_target_train = train_set[p].idxv_target\n",
    "                else:\n",
    "                    train_set[p].shuffle(idxv_target = idxv_target_train)\n",
    "                    assert(np.all(  train_set[p].idxv_target == train_set[0].idxv_target)\n",
    "                                    ), f\"     > ERROR: Parameter Sharing incorrectly setup!\"\n",
    "            else: train_set[p].shuffle()\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Validation Set Reconstruction Loss Checkpoints\n",
    "        best_mse = 1000; worst_mse = 0\n",
    "        best_ssim = 0; worst_ssim = 1000\n",
    "\n",
    "        # Validation Patient Loop\n",
    "        with torch.no_grad():\n",
    "            model.eval(); val_ssim_loss = []; val_mse_loss = []\n",
    "            for p, patient_id in enumerate(settings.val_patient_list):\n",
    "            \n",
    "                # Training Iteration Loop\n",
    "                mask = MUDI_fcglVNN.get_mask(settings, num_patient = patient_id)\n",
    "                val_bar = tqdm(   enumerate(val_loader[p]), total = len(val_loader[p]),\n",
    "                    desc = f'Epoch #{epoch} | Validation Patient {patient_id}', unit = 'Batches')\n",
    "                for batch_idx, batch in val_bar:\n",
    "            \n",
    "                    # Batch Handling\n",
    "                    img_gt = torch.Tensor(unmask(batch[1].reshape((1,\n",
    "                        len(batch[1]))), mask).get_fdata().T).to(settings.device)\n",
    "\n",
    "                    # Forward Propagation\n",
    "                    X_fake = torch.squeeze(model(batch[0].to(settings.device)), dim = 1)\n",
    "                    img_fake = torch.Tensor(unmask(X_fake.detach().cpu().reshape((1,\n",
    "                                            len(batch[1]))), mask).get_fdata().T)\n",
    "                    gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "                    # Loss Computation\n",
    "                    print(img_fake); print(img_gt.shape)\n",
    "                    mse_loss = mse_criterion(X_fake, batch[1].to(settings.device)).detach().cpu().numpy()\n",
    "                    ssim_loss, ssim_img = ssim( img_gt.cpu().numpy().astype(np.float32), \n",
    "                                                img_fake.cpu().numpy().astype(np.float32), full = True,\n",
    "                                        data_range = (torch.max(img_gt) - torch.min(img_gt)).cpu().numpy())\n",
    "                    ssim_loss = np.mean(ssim_loss); del ssim_img, batch, X_fake\n",
    "\n",
    "                    # Loss Appending \n",
    "                    val_mse_logger.experiment.add_scalar(\"Batch Loss\", mse_loss.item(), val_iter)\n",
    "                    val_ssim_logger.experiment.add_scalar(\"Batch Loss\", ssim_loss, val_iter)\n",
    "                    val_mse_loss.append(mse_loss.item()); val_ssim_loss.append(ssim_loss); val_iter += 1\n",
    "\n",
    "                    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "                    # Parameter-Wise MSE & SSIM Loss Assignation\n",
    "                    for i in range(self.settings.out_channels):\n",
    "\n",
    "                        # Parameter-Wise Loss Computation \n",
    "                        mse_loss = mse_criterion(   img_fake[i].cpu().numpy().astype(np.float32),\n",
    "                                                    img_gt[i].cpu().numpy().astype(np.float32))\n",
    "                        ssim_loss, ssim_img = ssim( img_gt[i].cpu().numpy().astype(np.float32), \n",
    "                                                    img_fake[i].cpu().numpy().astype(np.float32), full = True,\n",
    "                                        data_range = (torch.max(img_gt[i]) - torch.min(img_gt[i])).cpu().numpy())\n",
    "\n",
    "                        # Best & Worst MSE Result Saving\n",
    "                        if mse_loss.item() < best_mse:\n",
    "                            best_mse = mse_loss.item()\n",
    "                            best_mse_info = {   'loss': mse_loss.item(), 'idxh': i,\n",
    "                                                'img_gt': img_gt[i].detach().cpu(),\n",
    "                                                'img_fake': img_fake[i].detach().cpu()}\n",
    "                        if mse_loss.item() > worst_mse:\n",
    "                            worst_mse = mse_loss.item()\n",
    "                            worst_mse_info = {  'loss': mse_loss.item(), 'idxh': i,\n",
    "                                                'img_gt': img_gt[i].detach().cpu(),\n",
    "                                                'img_fake': img_fake[i].detach().cpu()}\n",
    "\n",
    "                        # Best & Worst SSIM Result Saving\n",
    "                        if ssim_loss > best_ssim:\n",
    "                            best_ssim = ssim_loss\n",
    "                            best_ssim_info = {  'loss': ssim_loss, 'idxh': i,\n",
    "                                                'img_gt': img_gt[i].detach().cpu(),\n",
    "                                                'img_fake': img_fake[i].detach().cpu()}\n",
    "                        if ssim_loss < worst_ssim:\n",
    "                            worst_ssim = ssim_loss\n",
    "                            worst_ssim_info = { 'loss': ssim_loss, 'idxh': i,\n",
    "                                                'img_gt': img_gt[i].detach().cpu(),\n",
    "                                                'img_fake': img_fake[i].detach().cpu()}\n",
    "                        gc.collect(); torch.cuda.empty_cache(); del img_gt, img_fake, ssim_img\n",
    "\n",
    "                # Inter-Patient Reconstruction Parameter Sharing Functionality\n",
    "                if settings.interpatient_sharing:\n",
    "                    if p == 0: val_set[p].shuffle(); idxv_target_val = val_set[p].idxv_target\n",
    "                    else:\n",
    "                        val_set[p].shuffle(idxv_target = idxv_target_val)\n",
    "                        assert(np.all(  val_set[p].idxv_target == val_set[0].idxv_target)\n",
    "                                        ), f\"     > ERROR: Parameter Sharing incorrectly setup!\"\n",
    "                else: val_set[p].shuffle()\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "\n",
    "                # MSE Epoch Results\n",
    "                val_mse_logger = plot_results(  logger = val_mse_logger,\n",
    "                                                best_info = best_mse_info,\n",
    "                                                worst_info = worst_mse_info,\n",
    "                                                sel_slice = settings.sel_slice,\n",
    "                                                mode = 'Validation', loss = 'MSE Loss',\n",
    "                                                patient_id = patient_id, epoch = epoch)\n",
    "\n",
    "                # SSIM Epoch Results\n",
    "                val_ssim_logger = plot_results( logger = val_ssim_logger,\n",
    "                                                best_info = best_ssim_info,\n",
    "                                                worst_info = worst_ssim_info,\n",
    "                                                sel_slice = settings.sel_slice,\n",
    "                                                mode = 'Validation', loss = 'SSIM Index',\n",
    "                                                patient_id = patient_id, epoch = epoch)\n",
    "                del best_mse_info, worst_mse_info, best_ssim_info, worst_ssim_info\n",
    "                \n",
    "        # End of Epoch Mean Loss Writing\n",
    "        train_mse_loss = np.mean(np.array(train_mse_loss))\n",
    "        val_mse_loss = np.mean(np.array(val_mse_loss))\n",
    "        val_ssim_loss = np.mean(np.array(val_ssim_loss))\n",
    "        train_logger.experiment.add_scalar(\"Mean Loss\", train_mse_loss, epoch)\n",
    "        val_mse_logger.experiment.add_scalar(\"Mean Loss\", val_mse_loss, epoch)        \n",
    "        val_ssim_logger.experiment.add_scalar(\"Mean Loss\", val_ssim_loss, epoch)\n",
    "        \n",
    "        # --------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Early Stopping Callback Application\n",
    "        early_stop = earlyStopping( loss = val_mse_loss, epoch = epoch,\n",
    "                                    model = model, optimizer = optimizer)\n",
    "        if early_stop: print(f'     > Training Finished at Epoch #{epoch}'); return\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **fcglVNN**\n",
    "\n",
    "### *Fixed Conditional Generative Linear Voxel-Wise Neural Network*\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Keras** *Version*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data** *Reader*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D MUDI Dataset Initialization Class\n",
    "class MUDI_fcglVNN(keras.utils.Sequence):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,\n",
    "        subject: int or list\n",
    "    ):\n",
    "        \n",
    "        # Parameter & Patient Index Value Access\n",
    "        super(MUDI_fcglVNN).__init__()\n",
    "        self.settings = settings\n",
    "\n",
    "        # Vertical Splitting (Patient Selection)\n",
    "        self.idxv = pd.read_csv(self.settings.info_filepath,            # List of Index Values ...\n",
    "                                index_col = 0).to_numpy()               # ... pertaining to each Patient\n",
    "        self.idxv = self.idxv[np.isin(self.idxv[:, 1], subject), 0]     # Patient-Specific Index Values\n",
    "        self.idxv_set = np.arange(len(self.idxv))\n",
    "\n",
    "        # Horizontal Splitting (Parameter Selection)\n",
    "        idxh_train_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Training Labels (V{self.settings.data_version}).txt\")    # Filepath for Selected Training Labels\n",
    "        idxh_val_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Validation Labels (V{self.settings.data_version}).txt\")    # Filepath for Selected Validation Labels\n",
    "        self.idxh_train = np.sort(np.loadtxt(idxh_train_filepath)).astype(int); self.num_train_params = len(self.idxh_train)\n",
    "        self.idxh_val = np.sort(np.loadtxt(idxh_val_filepath)).astype(int); self.num_val_params = len(self.idxh_val)\n",
    "        assert(self.num_train_params == self.settings.num_train_params), \"ERROR: Model wrongly Built!\"\n",
    "        #self.msk = np.logical_not(np.isin(np.arange(1344), self.idxh_train))\n",
    "        \n",
    "        # Parameter Value Initialization & Selection\n",
    "        self.params = pd.read_excel(self.settings.param_filepath)                                       # List of Dataset's Parameters\n",
    "        self.num_labels = self.settings.num_labels\n",
    "        if self.settings.gradient_coord:\n",
    "            self.params = self.params.drop(columns = ['Gradient theta', 'Gradient phi'])                # Choosing of Gradient Orientation\n",
    "        else: self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])      # from 3D Cartesian or Polar Referential\n",
    "        assert(self.params.shape[1] == self.num_labels), \"ERROR: Labels wrongly Deleted!\"\n",
    "        if self.settings.label_norm:                                                                    # Control Boolean Value for the Normalization of Labels\n",
    "            self.scaler = StandardScaler()\n",
    "            self.params = pd.DataFrame( self.scaler.fit_transform(self.params),\n",
    "                                        columns = self.params.columns)\n",
    "        \n",
    "        # Label Normalizer / Scaler Saving\n",
    "        scaler_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "        if not scaler_filepath.exists(): torch.save(self.scaler, scaler_filepath)\n",
    "        \n",
    "        # Random Selection of Parameters for Training Loop Reconstruction\n",
    "        self.num_train_recon = int((self.settings.param_recon_train * self.num_train_params) / 100)\n",
    "        self.num_val_recon = int((self.settings.param_recon_train * self.num_val_params) / 100)\n",
    "        self.num_recon = self.num_train_recon + self.num_val_recon\n",
    "        self.idxh_recon = np.hstack((   self.idxh_train[np.sort(np.random.choice(self.num_train_params,\n",
    "                                                                self.num_train_recon, replace = False))],\n",
    "                                        self.idxh_val[np.sort(np.random.choice(self.num_val_params,\n",
    "                                                                self.num_val_recon, replace = False))]))\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # DataLoader Length / No. Batches Computation Functionality\n",
    "    def __len__(self): return int(np.ceil((len(self.idxv) * self.num_recon) / float(self.settings.batch_size)))\n",
    "\n",
    "    # Single-Batch Generation Functionality\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # The first 'num_recon' Batches will contain the exact same Training Data 'X_train', but have its \n",
    "        # Target Parameter 'y_target' and Target Voxel Intensity GT 'X_target' changed, according to which\n",
    "        # Parameter the Training Data is being mapped to, allowing for a normal Training Step.\n",
    "\n",
    "        # Batch Vertical/Patient & Horizontal/Parameter Indexing \n",
    "        idxv = self.idxv_set[   (idx // self.num_recon) * self.settings.batch_size :            # Batch's Vertical Index for X_train\n",
    "                                ((idx // self.num_recon) + 1) * self.settings.batch_size]\n",
    "        idxv = [self.idxv[k] for k in idxv]; idxh = idx % self.num_recon                        # Batch's Horizontal Index for y_target\n",
    "        (X_train, y_target), X_target = self.get_data(idxv, idxh)\n",
    "        return (X_train, y_target), X_target\n",
    "    \n",
    "    # Label Scaler Download & Reverse Transformation\n",
    "    def label_unscale(\n",
    "        self,\n",
    "        y: np.array or pd.DataFrame\n",
    "    ):\n",
    "\n",
    "        # Label Scaler Download & Reverse Usage\n",
    "        try: self.scaler\n",
    "        except AttributeError:\n",
    "            scaler = torch.load(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "        return scaler.inverse_transform(y.reshape(1, -1))\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # End of Epoch Shuffling Functionality\n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        # Batch Shuffling\n",
    "        self.idxv_set = np.arange(len(self.idxv))\n",
    "        if self.settings.sample_shuffle: np.random.shuffle(self.idxv_set)\n",
    "\n",
    "        # Reconstruction Parameter Shuffling\n",
    "        if self.settings.param_shuffle:\n",
    "            self.idxh_recon = np.hstack((   self.idxh_train[np.sort(np.random.choice(self.num_train_params,\n",
    "                                            int((self.settings.param_recon_train * self.num_train_params) / 100), replace = False))],\n",
    "                                            self.idxh_val[np.sort(np.random.choice(self.num_val_params,\n",
    "                                            int((self.settings.param_recon_train * self.num_val_params) / 100), replace = False))]))\n",
    "\n",
    "    # Data Generation Functionality\n",
    "    def get_data(self, idxv, idxh):\n",
    "\n",
    "        # Data Access\n",
    "        data = h5py.File(self.settings.data_filepath, 'r').get('data1')\n",
    "        X_train = data[idxv, :][:, self.idxh_train]; batch_size = X_train.shape[0]              # [batch_size,  num_train_params] Training Data\n",
    "        y_target = self.params.iloc[idxh, :].values.reshape((1, self.settings.num_labels))      # [1,           num_labels] Target Parameters\n",
    "        y_target = y_target.repeat(batch_size, 0)                                               # [batch_size,  num_labels] Target Parameters\n",
    "        X_target = data[idxv, :][:, idxh].reshape((batch_size, 1))                              # [batch_size,  1] GT Target Data\n",
    "        return (X_train, y_target), X_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D MUDI Dataset Initialization Class\n",
    "class MUDI_fcglVNN(keras.utils.Sequence):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,\n",
    "        subject: int or list,\n",
    "        training: bool = True\n",
    "    ):\n",
    "        \n",
    "        # Parameter & Patient Index Value Access\n",
    "        super(MUDI_fcglVNN).__init__()\n",
    "        self.settings = settings\n",
    "\n",
    "        # Vertical Splitting (Patient Selection)\n",
    "        self.idxv = pd.read_csv(self.settings.info_filepath,            # List of Index Values ...\n",
    "                                index_col = 0).to_numpy()               # ... pertaining to each Patient\n",
    "        self.idxv = self.idxv[np.isin(self.idxv[:, 1], subject), 0]     # Patient-Specific Index Values\n",
    "        self.idxv_set = np.arange(len(self.idxv))\n",
    "\n",
    "        # Horizontal Splitting (Parameter Selection)\n",
    "        idxh_train_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Training Labels (V{self.settings.data_version}).txt\")    # Filepath for Selected Training Labels\n",
    "        idxh_val_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Validation Labels (V{self.settings.data_version}).txt\")    # Filepath for Selected Validation Labels\n",
    "        self.idxh_train = np.sort(np.loadtxt(idxh_train_filepath)).astype(int); self.num_train_params = len(self.idxh_train)\n",
    "        self.idxh_val = np.sort(np.loadtxt(idxh_val_filepath)).astype(int); self.num_val_params = len(self.idxh_val)\n",
    "        assert(self.num_train_params == self.settings.num_train_params), \"ERROR: Model wrongly Built!\"\n",
    "        #self.msk = np.logical_not(np.isin(np.arange(1344), self.idxh_train))\n",
    "        \n",
    "        # Parameter Value Initialization & Selection\n",
    "        self.params = pd.read_excel(self.settings.param_filepath)                                       # List of Dataset's Parameters\n",
    "        self.num_labels = self.settings.num_labels\n",
    "        if self.settings.gradient_coord:\n",
    "            self.params = self.params.drop(columns = ['Gradient theta', 'Gradient phi'])                # Choosing of Gradient Orientation\n",
    "        else: self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])      # from 3D Cartesian or Polar Referential\n",
    "        assert(self.params.shape[1] == self.num_labels), \"ERROR: Labels wrongly Deleted!\"\n",
    "        if self.settings.label_norm:                                                                    # Control Boolean Value for the Normalization of Labels\n",
    "            self.scaler = StandardScaler()\n",
    "            self.params = pd.DataFrame( self.scaler.fit_transform(self.params),\n",
    "                                        columns = self.params.columns)\n",
    "        \n",
    "        # Label Normalizer / Scaler Saving\n",
    "        scaler_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "        if not scaler_filepath.exists(): torch.save(self.scaler, scaler_filepath)\n",
    "        \n",
    "        # Random Selection of Parameters for Training Loop Reconstruction\n",
    "        if training: self.param_recon = self.settings.param_recon_train\n",
    "        else: self.param_recon = self.settings.param_recon_full\n",
    "        self.num_train_recon = int((self.param_recon * self.num_train_params) / 100)\n",
    "        self.num_val_recon = int((self.param_recon * self.num_val_params) / 100)\n",
    "        self.num_recon = self.num_train_recon + self.num_val_recon\n",
    "        #self.batch_size = self.settings.batch_size * self.num_recon\n",
    "        self.idxh_recon = np.hstack((   self.idxh_train[np.sort(np.random.choice(self.num_train_params,\n",
    "                                                                self.num_train_recon, replace = False))],\n",
    "                                        self.idxh_val[np.sort(np.random.choice(self.num_val_params,\n",
    "                                                                self.num_val_recon, replace = False))]))\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # DataLoader Length / No. Batches Computation Functionality\n",
    "    def __len__(self): return int(np.ceil(len(self.idxv) / self.settings.batch_size)) * self.num_recon\n",
    "\n",
    "    # Single-Batch Generation Functionality\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # The first 'num_recon' Batches will contain the exact same Training Data 'X_train', but have its \n",
    "        # Target Parameter 'y_target' and Target Voxel Intensity GT 'X_target' changed, according to which\n",
    "        # Parameter the Training Data is being mapped to, allowing for a normal Training Step.            \"\"\"\n",
    "\n",
    "        # Batch Vertical/Patient & Horizontal/Parameter Indexing \n",
    "        idxv = self.idxv_set[   (idx // self.num_recon) * self.settings.batch_size :        # Batch's Vertical Index for X_train\n",
    "                                ((idx // self.num_recon) + 1) * self.settings.batch_size]\n",
    "        idxv = [self.idxv[k] for k in idxv]; idxh = idx % self.num_recon                    # Batch's Horizontal Index for y_target\n",
    "        input, X_target = self.get_data(idxv, idxh)\n",
    "        return input, X_target\n",
    "    \n",
    "    # Label Scaler Download & Reverse Transformation\n",
    "    def label_unscale(\n",
    "        self,\n",
    "        y: np.array or pd.DataFrame\n",
    "    ):\n",
    "\n",
    "        # Label Scaler Download & Reverse Usage\n",
    "        try: self.scaler\n",
    "        except AttributeError:\n",
    "            scaler = torch.load(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "        return scaler.inverse_transform(y.reshape(1, -1))\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # End of Epoch Shuffling Functionality\n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        # Batch Shuffling\n",
    "        self.idxv_set = np.arange(len(self.idxv))\n",
    "        if self.settings.sample_shuffle: np.random.shuffle(self.idxv_set)\n",
    "\n",
    "        # Reconstruction Parameter Shuffling\n",
    "        if self.settings.param_shuffle:\n",
    "            self.idxh_recon = np.hstack((   self.idxh_train[np.sort(np.random.choice(self.num_train_params,\n",
    "                                            int((self.param_recon * self.num_train_params) / 100), replace = False))],\n",
    "                                            self.idxh_val[np.sort(np.random.choice(self.num_val_params,\n",
    "                                            int((self.param_recon * self.num_val_params) / 100), replace = False))]))\n",
    "\n",
    "    # Batch Data Generation Functionality\n",
    "    def get_data(self, idxv, idxh):\n",
    "\n",
    "        # Data Access\n",
    "        data = h5py.File(self.settings.data_filepath, 'r').get('data1')\n",
    "        X_train = data[idxv, :][:, self.idxh_train]; batch_size = X_train.shape[0]                          # [batch_size,  num_train_params] Training Data\n",
    "        #y_target = self.params.iloc[idxh, :].values.reshape((1, self.settings.num_labels))                 # [1,           num_labels] Target Parameters\n",
    "        y_target = self.params.iloc[self.idxh_recon[idxh]].values.reshape((1, self.settings.num_labels))    # [1,           num_labels] Target Parameters\n",
    "        y_target = y_target.repeat(batch_size, 0)                                                           # [batch_size,  num_labels] Target Parameters\n",
    "        X_target = data[idxv, :][:, self.idxh_recon[idxh]].reshape((batch_size, 1))                         # [batch_size,  1] GT Target Data\n",
    "        input = tf.keras.layers.concatenate([X_train, y_target], axis = 1)\n",
    "        return input, X_target\n",
    "    \n",
    "    # Patient Data Generation Functionality\n",
    "    def get_patient(settings, num_patient: int):\n",
    "\n",
    "        # Patient Data Access\n",
    "        data = h5py.File(settings.data_filepath, 'r').get('data1')\n",
    "        idxv = pd.read_csv( settings.info_filepath,             # List of Index Values ...\n",
    "                            index_col = 0).to_numpy()           # ... pertaining to each Patient\n",
    "        idxv = idxv[np.isin(idxv[:, 1], num_patient), 0]        # Patient-Specific Index Values\n",
    "        X = data[idxv, :]\n",
    "\n",
    "        # Patient Mask Access\n",
    "        mask_filepath = Path(f\"{settings.mask_folderpath}/p{num_patient}.nii\")\n",
    "        assert(mask_filepath.exists()), f\"ERROR: Patient {num_patient}'s Mask not Found!\"\n",
    "        mask = load_img(mask_filepath)\n",
    "        img = unmask(X.T, mask).get_fdata().T\n",
    "        return X, mask, img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset DataLoader Creation\n",
    "trainset = MUDI_fcglVNN(settings, #training = False,\n",
    "                        subject = [11])\n",
    "#X, mask, img = MUDI_fcglVNN.get_patient(settings, 11)\n",
    "#X_fake = model.predict_generator(trainset)\n",
    "\n",
    "# Build Testing\n",
    "for i in range(trainset.num_recon):\n",
    "    assert(np.all(trainset.__getitem__(i)[0][:, -5::] == trainset.__getitem__(i + trainset.num_recon)[0][:, -5::])), f\"{i}\"\n",
    "    assert(np.all(trainset.__getitem__(i)[0][:, 0:500] == trainset.__getitem__(i + 1)[0][:, 0:500])), f\"{i}\"\n",
    "    assert(np.all(trainset.__getitem__(i)[0][:, -5::] == trainset.params.iloc[trainset.idxh_recon[i]].values)), f\"{i}\"\n",
    "    #assert(np.all(trainset.__getitem__(i)[1] == X[int(i // trainset.num_recon) * settings.batch_size :\n",
    "    #                                              (int(i // trainset.num_recon) + 1) * settings.batch_size,\n",
    "    #                                              trainset.idxh_recon[i]].reshape(settings.batch_size, 1))), f\"{i}\"\n",
    "    #assert(np.where(np.arange(len(X_fake)) % trainset.num_recon == i)[0].shape[0] == 108300), f\"{i}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Model* **Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed Conditional Generative Linear Voxel Net Model Class (Seggregation)\n",
    "class fcglVNN(keras.Model):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser\n",
    "        #in_channels: int = 500,                 # Number of Input Parameter Settings\n",
    "        #num_labels: int = 5,                    # Number of Training Parameters / Input Channels\n",
    "        #num_hidden: int = 3,                    # Number of NN Hidden Layers\n",
    "        #var_hidden: int = 128                   # Deviance / Expansion of Hidden Layers\n",
    "    ):\n",
    "\n",
    "        # Class Variable Logging\n",
    "        super().__init__()\n",
    "        self.in_channels = settings.in_channels; self.num_labels = settings.num_labels\n",
    "        self.num_hidden = settings.num_hidden; self.var_hidden = settings.var_hidden\n",
    "        self.net = Sequential(); out_neuron = self.var_hidden\n",
    "\n",
    "        # Neural Network Architecture Definition\n",
    "        self.net.add(Dense( input_dim = self.in_channels + self.num_labels,\n",
    "                            units = self.var_hidden))\n",
    "        for i in range(self.num_hidden + 1):\n",
    "            if i == self.num_hidden: out_neuron = 1\n",
    "            else: out_neuron = int(out_neuron / 2)\n",
    "            self.net.add(   LeakyReLU(alpha = 0.2))\n",
    "            self.net.add(   Dense(units = out_neuron))\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Neural Network Application Function\n",
    "    def call(\n",
    "        self,\n",
    "        X_real: np.ndarray or tf.Tensor,\n",
    "        y_target: np.ndarray or tf.Tensor\n",
    "    ):  return self.net(tf.keras.layers.concatenate([X_real, y_target], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed Conditional Generative Linear Voxel Net Model Class (Simple)\n",
    "class fcglVNN(tf.keras.Model):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser\n",
    "        #in_channels: int = 500,                 # Number of Input Parameter Settings\n",
    "        #num_labels: int = 5,                    # Number of Training Parameters / Input Channels\n",
    "        #num_hidden: int = 3,                    # Number of NN Hidden Layers\n",
    "        #var_hidden: int = 128                   # Deviance / Expansion of Hidden Layers\n",
    "    ):\n",
    "        \n",
    "        # Class Variable Logging\n",
    "        super().__init__(); self.settings = settings\n",
    "        self.net = Sequential(); out_neuron = self.settings.var_hidden\n",
    "\n",
    "        # Neural Network Architecture Definition\n",
    "        self.net.add(Dense( input_dim = self.settings.in_channels + self.settings.num_labels,\n",
    "                            units = self.settings.var_hidden))\n",
    "        for i in range(self.settings.num_hidden + 1):\n",
    "            if i == self.settings.num_hidden: out_neuron = 1\n",
    "            else: out_neuron = int(out_neuron / 2)\n",
    "            self.net.add(   LeakyReLU(alpha = 0.2))\n",
    "            self.net.add(   Dense(units = out_neuron))\n",
    "\n",
    "        # Metric Function Initialization\n",
    "        #self.total_loss = keras.metrics.Mean(name = 'Epoch Loss')\n",
    "        #self.train_loss = keras.metrics.Mean(name = 'Epoch Loss | Training')\n",
    "        #self.val_loss = keras.metrics.Mean(name = 'Epoch Loss | Validation')\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Neural Network Application Function\n",
    "    def call(\n",
    "        self,\n",
    "        input: np.ndarray or tf.Tensor\n",
    "        #X_train: np.ndarray or tf.Tensor,\n",
    "        #y_target: np.ndarray or tf.Tensor\n",
    "    ):  return self.net(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed Conditional Generative Linear Voxel Net Model Class (Fixed)\n",
    "class fcglVNN(tf.keras.Model):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser\n",
    "    ):\n",
    "        \n",
    "        # Class Variable Logging\n",
    "        super().__init__(); self.settings = settings\n",
    "        self.net = Sequential(); self.arch = []\n",
    "        self.arch.insert(0, self.settings.in_channels + self.settings.num_labels)\n",
    "\n",
    "        # Neural Network Architecture Definition\n",
    "        var_hidden = int((self.settings.top_hidden - self.settings.bottom_hidden) / self.settings.num_hidden)\n",
    "        for i in range(1, self.settings.num_hidden + 1):\n",
    "            if i == 1: self.arch.insert(i, self.settings.bottom_hidden + var_hidden)\n",
    "            else: self.arch.insert(i, self.arch[i - 1] + var_hidden)\n",
    "            self.main_block(self.arch[i], self.arch[i - 1])\n",
    "        for i in range(self.settings.num_hidden + 1, (2 * self.settings.num_hidden) + 1):\n",
    "            self.arch.insert(i, self.arch[i - 1] - var_hidden)\n",
    "            self.main_block(self.arch[i], self.arch[i - 1])\n",
    "        self.net.add(Dense(input_dim = self.settings.bottom_hidden,\n",
    "                           units = 1, activation = None))\n",
    "\n",
    "\n",
    "    # Block Architecture Definition Functionality\n",
    "    def main_block(self, out_channels: int, in_channels: int = None):\n",
    "        if in_channels is not None:\n",
    "            self.net.add(   Dense(  input_dim = in_channels,\n",
    "                                    units = out_channels,\n",
    "                                    activation = None))\n",
    "        else: self.net.add( Dense(  units = out_channels,\n",
    "                                  activation = None))\n",
    "        self.net.add(   BatchNormalization())\n",
    "        self.net.add(   LeakyReLU(  alpha = 0.2))\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Neural Network Application Function\n",
    "    def call(\n",
    "        self,\n",
    "        input: np.ndarray or tf.Tensor\n",
    "    ):  return self.net(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Initialization Example\n",
    "model = fcglVNN(settings)\n",
    "print(model.net.summary())\n",
    "\n",
    "# Model Usage Example\n",
    "#X_real = tf.random.uniform([10, 500])\n",
    "#y_target = tf.random.uniform([10, 5])\n",
    "trainset = MUDI_fcglVNN(settings, subject = [11, 12, 13])\n",
    "print(model(trainset.__getitem__(0)[0]).shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training** *Script*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "# ------------------------------- Voxel-Wise Fixed cglVNN Build ------------------------------\n",
    "##############################################################################################\n",
    "\n",
    "# Fixed Conditional Generative Linear Voxel Net Model Class\n",
    "class fcglVNN(tf.keras.Model):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser\n",
    "        #in_channels: int = 500,                 # Number of Input Parameter Settings\n",
    "        #num_labels: int = 5,                    # Number of Training Parameters / Input Channels\n",
    "        #num_hidden: int = 3,                    # Number of NN Hidden Layers\n",
    "        #var_hidden: int = 128                   # Deviance / Expansion of Hidden Layers\n",
    "    ):\n",
    "\n",
    "        # Class Variable Logging\n",
    "        super().__init__(); self.settings = settings\n",
    "        self.net = Sequential(); out_neuron = self.settings.var_hidden\n",
    "\n",
    "        # Horizontal Splitting (Parameter Selection)\n",
    "        idxh_train_filepath = Path(f\"{self.settings.data_folderpath}/1D Training Labels (V{self.settings.data_version}).txt\")\n",
    "        idxh_val_filepath = Path(f\"{self.settings.data_folderpath}/1D Validation Labels (V{self.settings.data_version}).txt\")\n",
    "        self.idxh_train = np.sort(np.loadtxt(idxh_train_filepath)).astype(int)\n",
    "        self.idxh_val = np.sort(np.loadtxt(idxh_val_filepath)).astype(int)\n",
    "        self.num_train_params = len(self.idxh_train); self.num_val_params = len(self.idxh_val)\n",
    "\n",
    "        # Parameter Value Initialization & Selection\n",
    "        self.params = pd.read_excel(self.settings.data_settings.param_filepath)                         # List of Dataset's Parameters\n",
    "        if self.settings.data_settings.gradient_coord:\n",
    "            self.params = self.params.drop(columns = ['Gradient theta', 'Gradient phi'])                # Choosing of Gradient Orientation\n",
    "        else: self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])      # from 3D Cartesian or Polar Referential\n",
    "        assert(self.params.shape[1] == self.settings.num_labels), \"ERROR: Labels wrongly Deleted!\"\n",
    "        if self.settings.data_settings.label_norm:                                                      # Control Boolean Value for the Normalization of Labels\n",
    "            self.scaler = StandardScaler()\n",
    "            self.params = pd.DataFrame( self.scaler.fit_transform(self.params),\n",
    "                                        columns = self.params.columns)\n",
    "\n",
    "        # Neural Network Architecture Definition\n",
    "        self.net.add(Dense( input_dim = self.settings.in_channels + self.settings.num_labels,\n",
    "                            units = self.settings.var_hidden))\n",
    "        for i in range(self.settings.num_hidden + 1):\n",
    "            if i == self.settings.num_hidden: out_neuron = 1\n",
    "            else: out_neuron = int(out_neuron / 2)\n",
    "            self.net.add(   LeakyReLU(alpha = 0.2))\n",
    "            self.net.add(   Dense(units = out_neuron))\n",
    "\n",
    "        # Metric Function Initialization\n",
    "        self.total_loss = keras.metrics.Mean(name = 'Epoch Loss')\n",
    "        self.train_loss = keras.metrics.Mean(name = 'Epoch Loss | Training')\n",
    "        self.val_loss = keras.metrics.Mean(name = 'Epoch Loss | Validation')\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Neural Network Application Function\n",
    "    def call(\n",
    "        self,\n",
    "        input: np.ndarray or tf.Tensor\n",
    "        #X_train: np.ndarray or tf.Tensor,\n",
    "        #y_target: np.ndarray or tf.Tensor\n",
    "    ):  \n",
    "        print(input.shape)\n",
    "        X_train, y_target = input\n",
    "        return self.net(tf.keras.layers.concatenate([X_train, y_target], axis = 1))\n",
    "        #return self.net(input)\n",
    "\n",
    "    ##############################################################################################\n",
    "    # ------------------------------------- Training Script --------------------------------------\n",
    "    ##############################################################################################\n",
    "\n",
    "    # Functionality called upon the Start of Training Epoch\n",
    "    def on_epoch_begin(self, epoch, logs = None):\n",
    "\n",
    "        # Random Selection of Parameters for Training Loop Reconstruction\n",
    "        self.loss = 0; self.train_loss = 0; self.val_loss = 0\n",
    "        self.idx_recon_batch = np.hstack((  self.idxh_train[np.sort(np.random.choice(self.num_train_params,\n",
    "                                            int((self.settings.param_recon_train * self.num_train_params) / 100), replace = False))],\n",
    "                                            self.idxh_val[np.sort(np.random.choice(self.num_val_params,\n",
    "                                            int((self.settings.param_recon_train * self.num_val_params) / 100), replace = False))]))\n",
    "        print(self.idx_recon_batch.shape)\n",
    "        \n",
    "    # Training Step / Batch Loop\n",
    "    def train_step(self, data):        \n",
    "\n",
    "        # Voxel Reconstruction Loop\n",
    "        X_train, X = data\n",
    "        print(X_train.shape); print(X.shape)\n",
    "        with tf.GradientTape() as tape:\n",
    "            for i in self.idx_recon_batch:\n",
    "\n",
    "                # Forward Propagation\n",
    "                y_target = self.params.iloc[i, :].values                # Target Parameter (Single Value)\n",
    "                y_target = y_target.repeat(X_train.shape[0], 1)         # Target Parameter (Batch Repetition)\n",
    "                #input = tf.keras.layers.concatenate([X_train, y_target], axis = 1)\n",
    "                #print(input.shape)\n",
    "                X_target = self((X_train, y_target), training = True)   # Predicted Target Voxel Intensity\n",
    "                #X_target = self(input, training = True)\n",
    "                \n",
    "                # Loss Value Computation\n",
    "                loss = self.compiled_loss(X_target, X[:, i],                # Loss Computation using\n",
    "                            regularization_losses = self.losses)            # Compiled Loss Function (MSE)\n",
    "                print(loss.result())\n",
    "                self.loss += loss.result()\n",
    "                if i in self.idxh_train: self.train_loss += loss.result()   # Training Parameter Loss Computation\n",
    "                elif i in self.idxh_val: self.val += loss.result()          # Validation Parameter Loss Computation\n",
    "                else: print(\"ERROR: No Loss Computed!\")\n",
    "        \n",
    "        # Loss Value Update\n",
    "        self.total_loss.update_state(loss)                      # Total Epoch Loss Update\n",
    "        self.train_loss.update_state(self.train_loss)           # Training Parameter Loss Update\n",
    "        self.val_loss.update_state(self.val_loss)               # Validation Parameter Loss Update\n",
    "\n",
    "        # BackPropagation\n",
    "        var = self.trainable_variables                          # Trainable Variables Fetching\n",
    "        grad = tape.gradient(loss, var)                         # Gradient Computation\n",
    "        self.optimizer.apply_gradients(zip(grad, var))          # Optimizer Weight Update\n",
    "        return {'Epoch Loss': self.total_loss.result(),\n",
    "                'Epoch Loss | Training': self.train_loss.result(),\n",
    "                'Epoch Loss | Validation': self.val_loss.result()}\n",
    "    \n",
    "    # Loss Metrics Reset\n",
    "    @property\n",
    "    def metrics(self): return [self.total_loss, self.train_loss, self.val_loss]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "# ------------------------------- Voxel-Wise Fixed cglVNN Build ------------------------------\n",
    "##############################################################################################\n",
    "\n",
    "# Fixed Conditional Generative Linear Voxel Net Model Class\n",
    "class fcglVNN(tf.keras.Model):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser\n",
    "        #in_channels: int = 500,                 # Number of Input Parameter Settings\n",
    "        #num_labels: int = 5,                    # Number of Training Parameters / Input Channels\n",
    "        #num_hidden: int = 3,                    # Number of NN Hidden Layers\n",
    "        #var_hidden: int = 128                   # Deviance / Expansion of Hidden Layers\n",
    "    ):\n",
    "        \n",
    "        # Class Variable Logging\n",
    "        super().__init__(); self.settings = settings\n",
    "        self.net = Sequential(); out_neuron = self.settings.var_hidden\n",
    "\n",
    "        # Neural Network Architecture Definition\n",
    "        self.net.add(Dense( input_dim = self.settings.in_channels + self.settings.num_labels,\n",
    "                            units = self.settings.var_hidden))\n",
    "        for i in range(self.settings.num_hidden + 1):\n",
    "            if i == self.settings.num_hidden: out_neuron = 1\n",
    "            else: out_neuron = int(out_neuron / 2)\n",
    "            self.net.add(   LeakyReLU(alpha = 0.2))\n",
    "            self.net.add(   Dense(units = out_neuron))\n",
    "\n",
    "        # Metric Function Initialization\n",
    "        self.total_loss_metric = tf.keras.metrics.Mean(name = 'Loss')\n",
    "        self.train_loss_metric = tf.keras.metrics.Mean(name = 'Training Loss')\n",
    "        self.val_loss_metric = tf.keras.metrics.Mean(name = 'Validation Loss')\n",
    "        \n",
    "        # Reconstruction Parameter Initialization\n",
    "        self.num_train_recon = int((self.settings.param_recon_train * self.settings.num_train_params) / 100)\n",
    "        self.num_val_recon = int((self.settings.param_recon_train * (1344 - self.settings.num_train_params)) / 100)\n",
    "        self.num_recon = self.num_train_recon + self.num_val_recon; self.batch_idx = 0\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Custom Object Configuration Function\n",
    "    #@classmethod\n",
    "    #def from_config(cls, config): return cls(**config)\n",
    "    #def get_config(self): return {'Loss': self.total_loss.numpy()}\n",
    "\n",
    "    # Neural Network Application Function\n",
    "    def call(\n",
    "        self,\n",
    "        input: np.ndarray or tf.Tensor\n",
    "        #X_train: np.ndarray or tf.Tensor,\n",
    "        #y_target: np.ndarray or tf.Tensor\n",
    "    ):  return self.net(input)\n",
    "\n",
    "    ##############################################################################################\n",
    "    # ------------------------------------- Training Script --------------------------------------\n",
    "    ##############################################################################################\n",
    "\n",
    "    # Functionality called upon the End of Training Epoch\n",
    "    def on_epoch_end(self, epoch, logs = None): self.batch_idx = 0\n",
    "        \n",
    "    # Training Step / Batch Loop\n",
    "    def train_step(self, data):        \n",
    "\n",
    "        # Voxel Reconstruction Loop\n",
    "        input, X_gt = data#[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            # Forward Propagation\n",
    "            X_target = self(input, training = True)     # Predicted Target Voxel Intensity\n",
    "            loss = self.compiled_loss(X_gt, X_target,   # Loss Computation using\n",
    "                regularization_losses = self.losses)    # Compiled Loss Function (MSE)\n",
    "\n",
    "        # BackPropagation\n",
    "        var = self.trainable_variables                          # Trainable Variables Fetching\n",
    "        grad = tape.gradient(loss, var)                         # Gradient Computation\n",
    "        self.optimizer.apply_gradients(zip(grad, var))          # Optimizer Weight Update\n",
    "\n",
    "        # Loss Organization\n",
    "        self.total_loss_metric.update_state(loss)               # Total Epoch Loss Update\n",
    "        if self.batch_idx % self.num_recon < self.num_train_recon:\n",
    "            self.train_loss_metric.update_state(loss)           # Training Parameter Loss Update\n",
    "        else: self.val_loss_metric.update_state(loss)           # Validation Parameter Loss Update\n",
    "        self.batch_idx += 1\n",
    "        \n",
    "        return {'Loss': self.total_loss_metric.result(),\n",
    "                'Training Loss': self.train_loss_metric.result(),\n",
    "                'Validation Loss': self.val_loss_metric.result()}\n",
    "\n",
    "    # Loss Metrics Reset\n",
    "    @property\n",
    "    def metrics(self): return [self.total_loss_metric, self.train_loss_metric, self.val_loss_metric]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset DataLoader Creation\n",
    "trainset = MUDI_fcglVNN(settings, subject = [11, 12, 13])\n",
    "valset = MUDI_fcglVNN(settings, subject = [15])\n",
    "#testset = MUDI_fcglVNN(settings, subject = [14])\n",
    "\n",
    "# Model & Optimizer Initialization\n",
    "model = fcglVNN(settings)\n",
    "#plot_model(model, show_shapes = True, to_file = f'fcglVNN.png')\n",
    "model.compile(  optimizer =     'adam',\n",
    "                loss =          'mse',\n",
    "                metrics = [     FixedMean(name = 'Loss'),\n",
    "                                FixedMean(name = 'Training Loss'),\n",
    "                                FixedMean(name = 'Validation Loss')])\n",
    "\n",
    "# Model Training Method\n",
    "model.fit(trainset.__getitem__(0), epochs = 2,\n",
    "          validation_data = valset.__getitem__(0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Callback** *Script*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed Mean \n",
    "class FixedMean(tf.keras.metrics.Mean):\n",
    "    def update_state(self, y_true, y_pred, sample_weight = None):\n",
    "        super().update_state(y_pred, sample_weight = sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction Callback Class\n",
    "class ReconCallback(keras.callbacks.Callback):\n",
    "       \n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,              # Model Settings & Parametrizations\n",
    "    ):\n",
    "\n",
    "        # Class Variable Logging\n",
    "        super().__init__()\n",
    "        self.settings = settings; self.criterion = nn.MSELoss()\n",
    "\n",
    "        # TensorBoard Logger Initialization\n",
    "        self.train_logger = TensorBoardLogger(f'{self.settings.modelsave_folderpath}/V{self.settings.model_version}', 'train')\n",
    "        self.val_logger = TensorBoardLogger(f'{self.settings.modelsave_folderpath}/V{self.settings.model_version}', 'validation')\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Patient Image Reconstruction Functionality\n",
    "    def reconstruct(\n",
    "        self,\n",
    "        set: MUDI_fcglVNN,                  # Keras MUDI DataLoader\n",
    "        X: np.ndarray,                      # Selected Patient Data\n",
    "        mask: nib.nifti1.Nifti1Image,       # Selected Patient's Mask\n",
    "        img: np.ndarray,                    # Selected Patient Image\n",
    "        sel_slice: int = 25,                # Selected Reconstruction Slice\n",
    "        epoch: int = 0                      # Epoch Number\n",
    "    ):\n",
    "        \n",
    "        # Patient Image Reconstruction\n",
    "        X_fake = self.model.predict_generator(set)\n",
    "        best_train_loss = torch.ones(1); worst_train_loss = torch.zeros(1)\n",
    "        best_val_loss = torch.ones(1); worst_val_loss = torch.zeros(1)\n",
    "        \n",
    "        # Voxel Reconstruction Loop for all Selected Target Parameters\n",
    "        with alive_bar( len(set.idxh_recon),\n",
    "                        title = f'Epoch {epoch} |' +\n",
    "                        'Training Patient Reconstruction',\n",
    "                        force_tty = True) as progress_bar:\n",
    "            for i, param in enumerate(set.idxh_recon):\n",
    "\n",
    "                # Selected Target Parameter Image Reconstruction\n",
    "                X_param = X_fake[np.where(np.arange(len(X_fake)) % set.num_recon == i)[0]]\n",
    "                X_gt = X[:, param].T.reshape((len(X_param), 1))\n",
    "                loss = self.criterion(torch.Tensor(X_param), torch.Tensor(X_gt)); del X_gt\n",
    "                \n",
    "                # Loss Computation for Training Parameter\n",
    "                if param in set.idxh_train:\n",
    "                    if loss < best_train_loss:\n",
    "                        best_train_loss = loss\n",
    "                        best_train_idx = param\n",
    "                        X_train_best = X_param\n",
    "                    if loss > worst_train_loss:\n",
    "                        worst_train_loss = loss\n",
    "                        worst_train_idx = param\n",
    "                        X_train_worst = X_param\n",
    "\n",
    "                # Loss Computation for Validation Parameter\n",
    "                elif param in set.idxh_val:\n",
    "                    if loss < best_val_loss:\n",
    "                        best_val_loss = loss\n",
    "                        best_val_idx = param\n",
    "                        X_val_best = X_param\n",
    "                    if loss > worst_val_loss:\n",
    "                        worst_val_loss = loss\n",
    "                        worst_val_idx = param\n",
    "                        X_val_worst = X_param\n",
    "                \n",
    "                else: print(\"ERROR: Reconstruction Parameter not Found!\")\n",
    "                gc.collect(); torch.cuda.empty_cache()\n",
    "                time.sleep(0.01); progress_bar()\n",
    "        \n",
    "        # --------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Training Image Unmasking of Original & Reconstructed Results\n",
    "        X_train_best = unmask(X_train_best.T, mask).get_fdata().T\n",
    "        X_train_worst = unmask(X_train_worst.T, mask).get_fdata().T\n",
    "\n",
    "        # Training Example Original & Best Reconstructed Image Subplots\n",
    "        train_figure = plt.figure(figsize = (20, 20))\n",
    "        plt.xticks([]); plt.yticks([]); plt.grid(False); plt.tight_layout()\n",
    "        plt.subplot(2, 2, 1, title = f'Target Image (Parameter #{best_train_idx})')\n",
    "        plt.imshow(img[best_train_idx, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        plt.subplot(2, 2, 2, title = f'Best Reconstruction (Parameter #{best_train_idx})')\n",
    "        plt.imshow(X_train_best[0, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        del best_train_idx, X_train_best\n",
    "        \n",
    "        # Training Example Original & Worst Reconstructed Image Subplots\n",
    "        plt.subplot(2, 2, 3, title = f'Target Image (Parameter #{worst_train_idx})')\n",
    "        plt.imshow(img[worst_train_idx, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        plt.subplot(2, 2, 4, title = f'Worst Reconstruction (Parameter #{worst_train_idx})')\n",
    "        plt.imshow(X_train_worst[0, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        del worst_train_idx, X_train_worst\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Training Image Unmasking of Original & Reconstructed Results\n",
    "        X_val_best = unmask(X_val_best.T, mask).get_fdata().T\n",
    "        X_val_worst = unmask(X_val_worst.T, mask).get_fdata().T\n",
    "\n",
    "        # Training Example Original & Best Reconstructed Image Subplots\n",
    "        val_figure = plt.figure(figsize = (20, 20))\n",
    "        plt.xticks([]); plt.yticks([]); plt.grid(False); plt.tight_layout()\n",
    "        plt.subplot(2, 2, 1, title = f'Target Image (Parameter #{best_val_idx})')\n",
    "        plt.imshow(img[best_val_idx, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        plt.subplot(2, 2, 2, title = f'Best Reconstruction (Parameter #{best_val_idx})')\n",
    "        plt.imshow(X_val_best[0, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        del best_val_idx, X_val_best\n",
    "        \n",
    "        # Training Example Original & Worst Reconstructed Image Subplots\n",
    "        plt.subplot(2, 2, 3, title = f'Target Image (Parameter #{worst_val_idx})')\n",
    "        plt.imshow(img[worst_val_idx, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        plt.subplot(2, 2, 4, title = f'Worst Reconstruction (Parameter #{worst_val_idx})')\n",
    "        plt.imshow(X_val_worst[0, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        del worst_val_idx, X_val_worst\n",
    "        return train_figure, best_train_loss, worst_train_loss, val_figure, best_val_loss, worst_val_loss\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Functionality called upon the Start of Training\n",
    "    def on_train_begin(self, logs = None):\n",
    "\n",
    "        # Example Training Patient Download\n",
    "        self.trainset = MUDI_fcglVNN(   self.settings, training = False,\n",
    "                                        subject = self.settings.sel_train_patient)\n",
    "        self.X_train, self.mask_train, self.img_train = MUDI_fcglVNN.get_patient(self.settings,\n",
    "                                                            self.settings.sel_train_patient)\n",
    "\n",
    "        # Example Validation Patient Download\n",
    "        self.valset = MUDI_fcglVNN(     self.settings, training = False,\n",
    "                                        subject = self.settings.sel_val_patient)\n",
    "        self.X_val, self.mask_val, self.img_val = MUDI_fcglVNN.get_patient(  self.settings,\n",
    "                                                            self.settings.sel_val_patient)\n",
    "\n",
    "    # Functionality called upon the End of a Training Epoch\n",
    "    def on_epoch_end(self, epoch, logs = None):\n",
    "\n",
    "        # Epoch Update for Losses & Training Image Reconstruction\n",
    "        tt_plot, tt_best_loss, tt_worst_loss, tv_plot, tv_best_loss, tv_worst_loss = self.reconstruct(  self.trainset, self.X_train,\n",
    "                                                                                                        self.mask_train, self.img_train,\n",
    "                                                                                                        sel_slice = 25, epoch = epoch)\n",
    "        vt_plot, vt_best_loss, vt_worst_loss, vv_plot, vv_best_loss, vv_worst_loss = self.reconstruct(  self.valset, self.X_val,\n",
    "                                                                                                        self.mask_val, self.img_val,\n",
    "                                                                                                        sel_slice = 25, epoch = epoch)\n",
    "        \n",
    "        # TensorBoard Logger Model Visualizer, Update for Image Visualizer\n",
    "        self.train_logger.experiment.add_scalar(\"Best Reconstruction Loss | Training\", tt_best_loss, epoch)\n",
    "        self.train_logger.experiment.add_scalar(\"Worst Reconstruction Loss | Training\", tt_worst_loss, epoch)\n",
    "        self.train_logger.experiment.add_scalar(\"Best Reconstruction Loss | Validation\", tv_best_loss, epoch)\n",
    "        self.train_logger.experiment.add_scalar(\"Worst Reconstruction Loss | Validation\", tv_worst_loss, epoch)\n",
    "        self.train_logger.experiment.add_figure(\"Training Image Reconstruction\", tt_plot, epoch)\n",
    "        self.train_logger.experiment.add_figure(\"Validation Image Reconstruction\", tv_plot, epoch)\n",
    "\n",
    "        self.val_logger.experiment.add_scalar(\"Best Reconstruction Loss | Training\", vt_best_loss, epoch)\n",
    "        self.val_logger.experiment.add_scalar(\"Worst Reconstruction Loss | Training\", vt_worst_loss, epoch)\n",
    "        self.val_logger.experiment.add_scalar(\"Best Reconstruction Loss | Validation\", vv_best_loss, epoch)\n",
    "        self.val_logger.experiment.add_scalar(\"Worst Reconstruction Loss | Validation\", vv_worst_loss, epoch)\n",
    "        self.val_logger.experiment.add_figure(\"Training Image Reconstruction\", vt_plot, epoch)\n",
    "        self.val_logger.experiment.add_figure(\"Validation Image Reconstruction\", vv_plot, epoch)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pytorch** *Version*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **[Old]** **Data** *Reader*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D MUDI Dataset Initialization Class\n",
    "class MUDI_fcglVNN(Dataset):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,\n",
    "        subject: int or list,\n",
    "        training: bool = True\n",
    "    ):\n",
    "        \n",
    "        # Parameter & Patient Index Value Access\n",
    "        super(MUDI_fcglVNN).__init__()\n",
    "        self.settings = settings\n",
    "\n",
    "        # Vertical Splitting (Patient Selection)\n",
    "        self.idxv = pd.read_csv(self.settings.info_filepath,            # List of Index Values ...\n",
    "                                index_col = 0).to_numpy()               # ... pertaining to each Patient\n",
    "        self.idxv = self.idxv[np.isin(self.idxv[:, 1], subject), 0]     # Patient-Specific Index Values\n",
    "        self.idxv_set = np.arange(len(self.idxv))\n",
    "\n",
    "        # Horizontal Splitting (Parameter Selection)\n",
    "        idxh_train_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Training Labels (V{self.settings.data_version}).txt\")    # Filepath for Selected Training Labels\n",
    "        idxh_val_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Validation Labels (V{self.settings.data_version}).txt\")    # Filepath for Selected Validation Labels\n",
    "        self.idxh_train = np.sort(np.loadtxt(idxh_train_filepath)).astype(int); self.num_train_params = len(self.idxh_train)\n",
    "        self.idxh_val = np.sort(np.loadtxt(idxh_val_filepath)).astype(int); self.num_val_params = len(self.idxh_val)\n",
    "        assert(self.num_train_params == self.settings.num_train_params), \"ERROR: Model wrongly Built!\"\n",
    "        #self.msk = np.logical_not(np.isin(np.arange(1344), self.idxh_train))\n",
    "        \n",
    "        # Parameter Value Initialization & Selection\n",
    "        self.params = pd.read_excel(self.settings.param_filepath)                                       # List of Dataset's Parameters\n",
    "        self.num_labels = self.settings.num_labels\n",
    "        if self.settings.gradient_coord:\n",
    "            self.params = self.params.drop(columns = ['Gradient theta', 'Gradient phi'])                # Choosing of Gradient Orientation\n",
    "        else: self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])      # from 3D Cartesian or Polar Referential\n",
    "        assert(self.params.shape[1] == self.num_labels), \"ERROR: Labels wrongly Deleted!\"\n",
    "\n",
    "        # Label Normalization / Scaling\n",
    "        if self.settings.label_norm:                                                                    # Control Boolean Value for the Normalization of Labels\n",
    "            self.scaler = StandardScaler()\n",
    "            self.params = pd.DataFrame( self.scaler.fit_transform(self.params),\n",
    "                                        columns = self.params.columns)\n",
    "            scaler_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "            if not scaler_filepath.exists(): torch.save(self.scaler, scaler_filepath)\n",
    "        \n",
    "        # Label Manual Normalization\n",
    "        else:\n",
    "            self.params['b Value'] = self.params['b Value'] / 1000\n",
    "            self.params['TI'] = self.params['TI'] / 1000\n",
    "            self.params['TE'] = (self.params['TE'] - 80) / 200\n",
    "        \n",
    "        # Training / Reconstruction Parameter Initialization\n",
    "        if training:\n",
    "            self.param_recon = self.settings.param_recon_train\n",
    "            self.batch_size = self.settings.batch_size\n",
    "        else:\n",
    "            self.param_recon = self.settings.param_recon_full\n",
    "            self.batch_size = len(self.idxv)\n",
    "\n",
    "        # Random Selection of Parameters for Training Loop Reconstruction\n",
    "        self.num_train_recon = int((self.param_recon * self.num_train_params) / 100)\n",
    "        self.num_val_recon = int((self.param_recon * self.num_val_params) / 100)\n",
    "        self.num_recon = self.num_train_recon + self.num_val_recon\n",
    "        self.idxh_recon = np.hstack((   self.idxh_train[np.sort(np.random.choice(self.num_train_params,\n",
    "                                                                self.num_train_recon, replace = False))],\n",
    "                                        self.idxh_val[np.sort(np.random.choice(self.num_val_params,\n",
    "                                                                self.num_val_recon, replace = False))]))\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # DataLoader Length / No. Batches Computation Functionality\n",
    "    def __len__(self): return int(len(self.idxv) * self.num_recon)\n",
    "    #def __len__(self): return int(np.ceil(len(self.idxv) / self.batch_size)) * self.num_recon\n",
    "\n",
    "    # Single-Batch Generation Functionality\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # The first 'num_recon' Batches will contain the exact same Training Data 'X_train', but have its \n",
    "        # Target Parameter 'y_target' and Target Voxel Intensity GT 'X_target' changed, according to which\n",
    "        # Parameter the Training Data is being mapped to, allowing for a normal Training Step.            \"\"\"\n",
    "\n",
    "        # Batch Vertical/Patient & Horizontal/Parameter Indexing\n",
    "        idxv = self.idxv_set[   (index // self.num_recon) * self.batch_size :       # Batch's Vertical Index for X_train\n",
    "                                ((index // self.num_recon) + 1) * self.batch_size]\n",
    "        idxv = [self.idxv[k] for k in idxv]; idxh = index % self.num_recon          # Batch's Horizontal Index for y_target\n",
    "        input, X_target = self.get_data(idxv, idxh)\n",
    "        return torch.Tensor(input), torch.Tensor(X_target)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # End of Epoch Shuffling Functionality\n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        # Batch Shuffling\n",
    "        self.idxv_set = np.arange(len(self.idxv))\n",
    "        if self.settings.sample_shuffle: np.random.shuffle(self.idxv_set)\n",
    "\n",
    "        # Reconstruction Parameter Shuffling\n",
    "        if self.settings.param_shuffle:\n",
    "            self.idxh_recon = np.hstack((   self.idxh_train[np.sort(np.random.choice(self.num_train_params,\n",
    "                                            int((self.param_recon * self.num_train_params) / 100), replace = False))],\n",
    "                                            self.idxh_val[np.sort(np.random.choice(self.num_val_params,\n",
    "                                            int((self.param_recon * self.num_val_params) / 100), replace = False))]))\n",
    "    \n",
    "    # Label Scaler Download & Reverse Transformation\n",
    "    def label_unscale(\n",
    "        self,\n",
    "        y: np.array or pd.DataFrame\n",
    "    ):\n",
    "\n",
    "        # Label Scaler Download & Reverse Usage\n",
    "        try: self.scaler\n",
    "        except AttributeError:\n",
    "            scaler = torch.load(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "        return scaler.inverse_transform(y.reshape(1, -1))\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Batch Data Generation Functionality\n",
    "    def get_data(self, idxv, idxh):\n",
    "\n",
    "        # Data Access\n",
    "        data = h5py.File(self.settings.data_filepath, 'r').get('data1')\n",
    "        X_train = data[idxv, :][:, self.idxh_train]; batch_size = X_train.shape[0]                          # [batch_size,  num_train_params] Training Data\n",
    "        #y_target = self.params.iloc[idxh, :].values.reshape((1, self.settings.num_labels))                 # [1,           num_labels] Target Parameters\n",
    "        y_target = self.params.iloc[self.idxh_recon[idxh]].values.reshape((1, self.settings.num_labels))    # [1,           num_labels] Target Parameters\n",
    "        y_target = y_target.repeat(batch_size, 0)                                                           # [batch_size,  num_labels] Target Parameters\n",
    "        X_target = data[idxv, :][:, self.idxh_recon[idxh]].reshape((batch_size, 1))                         # [batch_size,  1] GT Target Data\n",
    "        input = np.hstack((X_train, y_target))\n",
    "        return input, X_target\n",
    "    \n",
    "    # Patient Data Generation Functionality\n",
    "    def get_patient(settings, num_patient: int):\n",
    "\n",
    "        # Patient Data Access\n",
    "        data = h5py.File(settings.data_filepath, 'r').get('data1')\n",
    "        idxv = pd.read_csv( settings.info_filepath,             # List of Index Values ...\n",
    "                            index_col = 0).to_numpy()           # ... pertaining to each Patient\n",
    "        idxv = idxv[np.isin(idxv[:, 1], num_patient), 0]        # Patient-Specific Index Values\n",
    "        X = torch.Tensor(data[idxv, :])\n",
    "\n",
    "        # Patient Mask Access\n",
    "        mask_filepath = Path(f\"{settings.mask_folderpath}/p{num_patient}.nii\")\n",
    "        assert(mask_filepath.exists()), f\"ERROR: Patient {num_patient}'s Mask not Found!\"\n",
    "        mask = torch.Tensor(load_img(mask_filepath))\n",
    "        img = unmask(X.T, mask).get_fdata().T\n",
    "        return X, mask, torch.Tensor(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D MUDI Dataset Initialization Class\n",
    "class MUDI_fcglVNN(Dataset):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,\n",
    "        subject: int or list,\n",
    "        training: bool = True\n",
    "    ):\n",
    "        \n",
    "        # Parameter & Patient Index Value Access\n",
    "        super(MUDI_fcglVNN).__init__()\n",
    "        self.settings = settings\n",
    "        self.data = h5py.File(self.settings.data_filepath, 'r').get('data1')\n",
    "\n",
    "        # Vertical Splitting (Patient Selection)\n",
    "        self.idxv = pd.read_csv(self.settings.info_filepath,            # List of Index Values ...\n",
    "                                index_col = 0).to_numpy()               # ... pertaining to each Patient\n",
    "        self.idxv = self.idxv[np.isin(self.idxv[:, 1], subject), 0]     # Patient-Specific Index Values\n",
    "\n",
    "        # Horizontal Splitting (Parameter Selection)\n",
    "        idxh_train_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Training Labels (V{self.settings.data_version}).txt\")    # Filepath for Selected Training Labels\n",
    "        idxh_val_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Validation Labels (V{self.settings.data_version}).txt\")    # Filepath for Selected Validation Labels\n",
    "        self.idxh_train = np.sort(np.loadtxt(idxh_train_filepath)).astype(int); self.num_train_params = len(self.idxh_train)\n",
    "        self.idxh_val = np.sort(np.loadtxt(idxh_val_filepath)).astype(int); self.num_val_params = len(self.idxh_val)\n",
    "        assert(self.num_train_params == self.settings.num_train_params), \"ERROR: Model wrongly Built!\"\n",
    "        #self.msk = np.logical_not(np.isin(np.arange(1344), self.idxh_train))\n",
    "        \n",
    "        # Parameter Value Initialization & Selection\n",
    "        self.params = pd.read_excel(self.settings.param_filepath)                                       # List of Dataset's Parameters\n",
    "        self.num_labels = self.settings.num_labels\n",
    "        if self.settings.gradient_coord:\n",
    "            self.params = self.params.drop(columns = ['Gradient theta', 'Gradient phi'])                # Choosing of Gradient Orientation\n",
    "        else: self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])      # from 3D Cartesian or Polar Referential\n",
    "        assert(self.params.shape[1] == self.num_labels), \"ERROR: Labels wrongly Deleted!\"\n",
    "\n",
    "        # Label Normalization / Scaling\n",
    "        if self.settings.label_norm:                                                                    # Control Boolean Value for the Normalization of Labels\n",
    "            self.scaler = StandardScaler()\n",
    "            self.params = pd.DataFrame( self.scaler.fit_transform(self.params),\n",
    "                                        columns = self.params.columns)\n",
    "            scaler_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "            if not scaler_filepath.exists(): torch.save(self.scaler, scaler_filepath)\n",
    "        \n",
    "        # Label Manual Normalization\n",
    "        else:\n",
    "            self.params['b Value'] = self.params['b Value'] / 1000\n",
    "            self.params['TI'] = self.params['TI'] / 1000\n",
    "            self.params['TE'] = (self.params['TE'] - 80) / 200\n",
    "        \n",
    "        # Training / Reconstruction Parameter Initialization\n",
    "        if training: self.param_recon = self.settings.param_recon_train\n",
    "        else: self.param_recon = self.settings.param_recon_val\n",
    "\n",
    "        # Random Selection of Parameters for Training Loop Reconstruction\n",
    "        self.num_train_recon = int((self.param_recon * self.num_train_params) / 100)\n",
    "        self.num_val_recon = int((self.param_recon * self.num_val_params) / 100)\n",
    "        self.num_recon = self.num_train_recon + self.num_val_recon\n",
    "        self.idxh_recon = np.hstack((   self.idxh_train[np.sort(np.random.choice(self.num_train_params,\n",
    "                                                                self.num_train_recon, replace = False))],\n",
    "                                        self.idxh_val[np.sort(np.random.choice(self.num_val_params,\n",
    "                                                                self.num_val_recon, replace = False))]))\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # DataLoader Length / No. Batches Computation Functionality\n",
    "    def __len__(self): return int(len(self.idxv) * self.num_recon)\n",
    "\n",
    "    # Single-Batch Generation Functionality\n",
    "    def __getitem__(self, index) -> tuple[np.ndarray, np.float32]:\n",
    "        \n",
    "        # The first 'num_recon' Batches will contain the exact same Training Data 'X_train', but have its \n",
    "        # Target Parameter 'y_target' and Target Voxel Intensity GT 'X_target' changed, according to which\n",
    "        # Parameter the Training Data is being mapped to, allowing for a normal Training Step.\n",
    "\n",
    "        # Batch Vertical/Patient & Horizontal/Parameter Indexing\n",
    "        #data = h5py.File(self.settings.data_filepath, 'r').get('data1')\n",
    "        idxv = index // self.num_recon      # Batch's Vertical Index for X_train\n",
    "        idxh = index % self.num_recon       # Batch's Horizontal Index for y_target\n",
    "        #print(idxv); print(idxh); print(self.idxv[idxv])\n",
    "        \n",
    "        # Batch Data Generation\n",
    "        X_train = self.data[self.idxv[idxv], :][self.idxh_train]                 # [num_train_params] Training Data\n",
    "        y_target = self.params.iloc[self.idxh_recon[idxh]].values           # [num_labels] Target Parameters\n",
    "        X_target = self.data[self.idxv[idxv], :][self.idxh_recon[idxh]]          # [    1    ] GT Target Data\n",
    "        input = np.hstack((X_train, y_target)).astype(np.float32)           # [num_train_params + num_labels] Input\n",
    "        return input, X_target\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # End of Epoch Shuffling Functionality\n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        # Batch Shuffling\n",
    "        self.idxv_set = np.arange(len(self.idxv))\n",
    "        if self.settings.sample_shuffle: np.random.shuffle(self.idxv_set)\n",
    "\n",
    "        # Reconstruction Parameter Shuffling\n",
    "        if self.settings.param_shuffle:\n",
    "            self.idxh_recon = np.hstack((   self.idxh_train[np.sort(np.random.choice(self.num_train_params,\n",
    "                                            int((self.param_recon * self.num_train_params) / 100), replace = False))],\n",
    "                                            self.idxh_val[np.sort(np.random.choice(self.num_val_params,\n",
    "                                            int((self.param_recon * self.num_val_params) / 100), replace = False))]))\n",
    "    \n",
    "    # Label Scaler Download & Reverse Transformation\n",
    "    def label_unscale(\n",
    "        self,\n",
    "        y: np.array or pd.DataFrame\n",
    "    ):\n",
    "\n",
    "        # Label Scaler Download & Reverse Usage\n",
    "        try: self.scaler\n",
    "        except AttributeError:\n",
    "            scaler = torch.load(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "        return scaler.inverse_transform(y.reshape(1, -1))\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Patient Data Generation Functionality\n",
    "    def get_patient(settings, num_patient: int):\n",
    "\n",
    "        # Patient Data Access\n",
    "        data = h5py.File(settings.data_filepath, 'r').get('data1')\n",
    "        idxv = pd.read_csv( settings.info_filepath,             # List of Index Values ...\n",
    "                            index_col = 0).to_numpy()           # ... pertaining to each Patient\n",
    "        idxv = idxv[np.isin(idxv[:, 1], num_patient), 0]        # Patient-Specific Index Values\n",
    "        X = torch.Tensor(data[idxv, :])\n",
    "\n",
    "        # Patient Mask Access\n",
    "        mask_filepath = Path(f\"{settings.mask_folderpath}/p{num_patient}.nii\")\n",
    "        assert(mask_filepath.exists()), f\"ERROR: Patient {num_patient}'s Mask not Found!\"\n",
    "        mask = load_img(mask_filepath)\n",
    "        img = unmask(X.T, mask).get_fdata().T\n",
    "        return X, mask, torch.Tensor(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D MUDI Dataset Initialization Class\n",
    "class MUDI_fcglVNN(Dataset):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,\n",
    "        subject: int or list,\n",
    "        training: bool = True\n",
    "    ):\n",
    "        \n",
    "        # Parameter & Patient Index Value Access\n",
    "        super(MUDI_fcglVNN).__init__()\n",
    "        self.settings = settings; self.training = training\n",
    "        self.data = h5py.File(self.settings.data_filepath, 'r').get('data1')\n",
    "\n",
    "        # Vertical Splitting (Patient Selection)\n",
    "        self.idxv = pd.read_csv(self.settings.info_filepath,            # List of Index Values ...\n",
    "                                index_col = 0).to_numpy()               # ... pertaining to each Patient\n",
    "        self.idxv = self.idxv[np.isin(self.idxv[:, 1], subject), 0]     # Patient-Specific Index Values\n",
    "\n",
    "        # Horizontal Splitting (Parameter Selection)\n",
    "        idxh_train_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Training Labels (V{self.settings.data_version}).txt\")    # Filepath for Selected Training Labels\n",
    "        idxh_val_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Validation Labels (V{self.settings.data_version}).txt\")    # Filepath for Selected Validation Labels\n",
    "        self.idxh_train = np.sort(np.loadtxt(idxh_train_filepath)).astype(int); self.num_train_params = len(self.idxh_train)\n",
    "        self.idxh_val = np.sort(np.loadtxt(idxh_val_filepath)).astype(int); self.num_val_params = len(self.idxh_val)\n",
    "        assert(self.num_train_params == self.settings.num_train_params), \"ERROR: Model wrongly Built!\"\n",
    "        #self.msk = np.logical_not(np.isin(np.arange(1344), self.idxh_train))\n",
    "        \n",
    "        # Parameter Value Initialization & Selection\n",
    "        self.params = pd.read_excel(self.settings.param_filepath)                                       # List of Dataset's Parameters\n",
    "        self.num_labels = self.settings.num_labels\n",
    "        if self.settings.gradient_coord:\n",
    "            self.params = self.params.drop(columns = ['Gradient theta', 'Gradient phi'])                # Choosing of Gradient Orientation\n",
    "        else: self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])      # from 3D Cartesian or Polar Referential\n",
    "        assert(self.params.shape[1] == self.num_labels), \"ERROR: Labels wrongly Deleted!\"\n",
    "\n",
    "        # Label Normalization / Scaling\n",
    "        if self.settings.label_norm:                                                                    # Control Boolean Value for the Normalization of Labels\n",
    "            print(\"Automatic Normalization of Parameter Values\")\n",
    "            self.scaler = StandardScaler()\n",
    "            self.params = pd.DataFrame( self.scaler.fit_transform(self.params),\n",
    "                                        columns = self.params.columns)\n",
    "            scaler_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "            if not scaler_filepath.exists(): torch.save(self.scaler, scaler_filepath)\n",
    "        \n",
    "        # Label Manual Normalization\n",
    "        else:\n",
    "            print(\"Manual Normalization of Parameter Values\")\n",
    "            self.params['b Value'] = self.params['b Value'] / 10000\n",
    "            self.params['TI'] = self.params['TI'] / 10000\n",
    "            self.params['TE'] = (self.params['TE'] - 80) / 200\n",
    "        \n",
    "        # Training / Reconstruction Parameter Initialization\n",
    "        if self.training: self.param_recon = self.settings.param_recon_train\n",
    "        else: self.param_recon = self.settings.param_recon_val\n",
    "\n",
    "        # Random Selection of Parameters for Training Loop Reconstruction\n",
    "        self.num_train_recon = int((self.param_recon * self.num_train_params) / 100)\n",
    "        self.num_val_recon = int((self.param_recon * self.num_val_params) / 100)\n",
    "        self.num_recon = self.num_train_recon + self.num_val_recon\n",
    "        self.idxh_recon = np.hstack((   self.idxh_train[np.sort(np.random.choice(self.num_train_params,\n",
    "                                                                self.num_train_recon, replace = False))],\n",
    "                                        self.idxh_val[np.sort(np.random.choice(self.num_val_params,\n",
    "                                                                self.num_val_recon, replace = False))]))\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # DataLoader Length / No. Batches Computation Functionality\n",
    "    def __len__(self): return int(len(self.idxv) * self.num_recon)\n",
    "\n",
    "    # Single-Batch Generation Functionality\n",
    "    def __getitem__(self, index) -> tuple[np.ndarray, np.float32]:\n",
    "        \n",
    "        # The first 'num_recon' Batches will contain the exact same Training Data 'X_train', but have its \n",
    "        # Target Parameter 'y_target' and Target Voxel Intensity GT 'X_target' changed, according to which\n",
    "        # Parameter the Training Data is being mapped to, allowing for a normal Training Step.\n",
    "\n",
    "        # Batch Vertical/Patient & Horizontal/Parameter Indexing\n",
    "        if self.training:\n",
    "            idxv = index // self.num_recon      # Batch's Vertical Index for X_train\n",
    "            idxh = index % self.num_recon       # Batch's Horizontal Index for y_target\n",
    "        else:\n",
    "            idxv = index % len(self.idxv)       # Batch's Vertical Index for X_train\n",
    "            idxh = index // len(self.idxv)      # Batch's Horizontal Index for y_target\n",
    "        \n",
    "        # Batch Data Generation\n",
    "        X_train = self.data[self.idxv[idxv], :][self.idxh_train]                # [num_train_params] Training Data\n",
    "        y_target = self.params.iloc[self.idxh_recon[idxh]].values               # [num_labels] Target Parameters\n",
    "        X_target = self.data[self.idxv[idxv], :][self.idxh_recon[idxh]]         # [    1    ] GT Target Data\n",
    "        input = np.hstack((X_train, y_target)).astype(np.float32)               # [num_train_params + num_labels] Input\n",
    "        return input, X_target\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # End of Epoch Shuffling Functionality\n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        # Batch Shuffling\n",
    "        self.idxv_set = np.arange(len(self.idxv))\n",
    "        if self.settings.sample_shuffle: np.random.shuffle(self.idxv_set)\n",
    "\n",
    "        # Reconstruction Parameter Shuffling\n",
    "        if self.settings.param_shuffle:\n",
    "            self.idxh_recon = np.hstack((   self.idxh_train[np.sort(np.random.choice(self.num_train_params,\n",
    "                                            int((self.param_recon * self.num_train_params) / 100), replace = False))],\n",
    "                                            self.idxh_val[np.sort(np.random.choice(self.num_val_params,\n",
    "                                            int((self.param_recon * self.num_val_params) / 100), replace = False))]))\n",
    "    \n",
    "    # Label Scaler Download & Reverse Transformation\n",
    "    def label_unscale(\n",
    "        self,\n",
    "        y: np.array or pd.DataFrame\n",
    "    ):\n",
    "\n",
    "        # Label Scaler Download & Reverse Usage\n",
    "        try: self.scaler\n",
    "        except AttributeError:\n",
    "            scaler = torch.load(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "        return scaler.inverse_transform(y.reshape(1, -1))\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Patient Data Generation Functionality\n",
    "    def get_patient(settings, num_patient: int):\n",
    "\n",
    "        # Patient Data Access\n",
    "        data = h5py.File(settings.data_filepath, 'r').get('data1')\n",
    "        idxv = pd.read_csv( settings.info_filepath,             # List of Index Values ...\n",
    "                            index_col = 0).to_numpy()           # ... pertaining to each Patient\n",
    "        idxv = idxv[np.isin(idxv[:, 1], num_patient), 0]        # Patient-Specific Index Values\n",
    "        X = torch.Tensor(data[idxv, :])\n",
    "\n",
    "        # Patient Mask Access\n",
    "        mask_filepath = Path(f\"{settings.mask_folderpath}/p{num_patient}.nii\")\n",
    "        assert(mask_filepath.exists()), f\"ERROR: Patient {num_patient}'s Mask not Found!\"\n",
    "        mask = load_img(mask_filepath)\n",
    "        img = unmask(X.T, mask).get_fdata().T\n",
    "        return X, mask, torch.Tensor(img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data** *Reader*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D MUDI Dataset Initialization Class (V0)\n",
    "class MUDI_fcglVNN(Dataset):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,\n",
    "        subject: int or list,\n",
    "        param_recon: int or float\n",
    "    ):\n",
    "        \n",
    "        # Parameter & Patient Index Value Access\n",
    "        super(MUDI_fcglVNN).__init__()\n",
    "        self.settings = settings; self.param_recon = param_recon\n",
    "        self.data = h5py.File(self.settings.data_filepath, 'r').get('data1')\n",
    "\n",
    "        # Vertical Splitting (Patient Selection)\n",
    "        self.idxv = pd.read_csv(self.settings.info_filepath,            # List of Index Values ...\n",
    "                                index_col = 0).to_numpy()               # ... pertaining to each Patient\n",
    "        self.idxv = self.idxv[np.isin(self.idxv[:, 1], subject), 0]     # Patient-Specific Index Values\n",
    "\n",
    "        # Horizontal Splitting (Parameter Selection)\n",
    "        idxh_train_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Training Labels (V{self.settings.data_version}).txt\")    # Filepath for Selected Training Labels\n",
    "        idxh_val_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Validation Labels (V{self.settings.data_version}).txt\")    # Filepath for Selected Validation Labels\n",
    "        self.idxh_train = np.sort(np.loadtxt(idxh_train_filepath)).astype(int); self.num_train_params = len(self.idxh_train)\n",
    "        self.idxh_val = np.sort(np.loadtxt(idxh_val_filepath)).astype(int); self.num_val_params = len(self.idxh_val)\n",
    "        assert(self.num_train_params == self.settings.num_train_params), \"ERROR: Model wrongly Built!\"\n",
    "        #self.msk = np.logical_not(np.isin(np.arange(1344), self.idxh_train))\n",
    "        \n",
    "        # Parameter Value Initialization & Selection\n",
    "        self.params = pd.read_excel(self.settings.param_filepath)                                       # List of Dataset's Parameters\n",
    "        self.num_labels = self.settings.num_labels\n",
    "        if self.settings.gradient_coord:\n",
    "            self.params = self.params.drop(columns = ['Gradient theta', 'Gradient phi'])                # Choosing of Gradient Orientation\n",
    "        else: self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])      # from 3D Cartesian or Polar Referential\n",
    "        #assert(self.params.shape[1] == self.num_labels), \"ERROR: Labels wrongly Deleted!\"\n",
    "\n",
    "        # Label Normalization / Scaling\n",
    "        if self.settings.label_norm == 'auto':                                                          # Control Boolean Value for the Normalization of Labels\n",
    "            print(\"Automatic Normalization of Parameter Values\")\n",
    "            self.scaler = StandardScaler()\n",
    "            self.params = pd.DataFrame( self.scaler.fit_transform(self.params),\n",
    "                                        columns = self.params.columns)\n",
    "            scaler_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "            if not scaler_filepath.exists(): torch.save(self.scaler, scaler_filepath)\n",
    "        \n",
    "        # Label Manual Normalization\n",
    "        elif self.settings.label_norm == 'manual':\n",
    "            print(\"Manual Normalization of Parameter Values\")\n",
    "            self.params[['Gradient theta', 'Gradient phi']] = self.cart2polar(self.params[['Gradient x', 'Gradient y', 'Gradient z']].values)\n",
    "            self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])\n",
    "            self.params['b Value'] = self.params['b Value'] / 10000\n",
    "            self.params['TI'] = self.params['TI'] / 10000\n",
    "            self.params['TE'] = (self.params['TE'] - 80) / 200\n",
    "        else: print(\"No Normalization of Parameter Values\")\n",
    "\n",
    "        # Random Selection of Parameters for Training Loop Reconstruction\n",
    "        self.num_train_recon = int((self.param_recon * self.num_train_params) / 100)\n",
    "        self.num_val_recon = int((self.param_recon * self.num_val_params) / 100)\n",
    "        self.num_recon = self.num_train_recon + self.num_val_recon\n",
    "        self.idxh_recon = np.hstack((   self.idxh_train[np.sort(np.random.choice(self.num_train_params,\n",
    "                                                                self.num_train_recon, replace = False))],\n",
    "                                        self.idxh_val[np.sort(np.random.choice(self.num_val_params,\n",
    "                                                                self.num_val_recon, replace = False))]))\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # DataLoader Length / No. Batches Computation Functionality\n",
    "    def __len__(self): return int(len(self.idxv) * self.num_recon)\n",
    "\n",
    "    # Single-Batch Generation Functionality\n",
    "    def __getitem__(self, index) -> tuple[np.ndarray, np.float32]:\n",
    "        \n",
    "        # The first 'num_recon' Batches will contain the exact same Training Data 'X_train', but have its \n",
    "        # Target Parameter 'y_target' and Target Voxel Intensity GT 'X_target' changed, according to which\n",
    "        # Parameter the Training Data is being mapped to, allowing for a normal Training Step.\n",
    "\n",
    "        # Batch Vertical/Patient & Horizontal/Parameter Indexing\n",
    "        idxv = index % len(self.idxv)       # Batch's Vertical Index for X_train\n",
    "        idxh = index // len(self.idxv)      # Batch's Horizontal Index for y_target\n",
    "        \n",
    "        # Batch Data Generation\n",
    "        X_train = self.data[self.idxv[idxv], :][self.idxh_train]                # [num_train_params] Training Data\n",
    "        y_target = self.params.iloc[self.idxh_recon[idxh]].values               # [num_labels] Target Parameters\n",
    "        X_target = self.data[self.idxv[idxv], :][self.idxh_recon[idxh]]         # [    1    ] GT Target Data\n",
    "        input = np.hstack((X_train, y_target)).astype(np.float32)               # [num_train_params + num_labels] Input\n",
    "        return input, X_target\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # End of Epoch Reconstruction Parameter Shuffling Functionality\n",
    "    def on_epoch_end(\n",
    "        self,\n",
    "        idxh_recon: np.array = None\n",
    "    ):\n",
    "        \n",
    "        # Batch Shuffling\n",
    "        self.idxv_set = np.arange(len(self.idxv))\n",
    "        if self.settings.sample_shuffle: np.random.shuffle(self.idxv_set)\n",
    "\n",
    "        # Reconstruction Parameter Shuffling\n",
    "        if idxh_recon is not None: self.idxh_recon = idxh_recon\n",
    "        else:\n",
    "            if self.settings.param_shuffle:\n",
    "                self.idxh_recon = np.hstack((   self.idxh_train[np.sort(np.random.choice(self.num_train_params,\n",
    "                                                int((self.param_recon * self.num_train_params) / 100), replace = False))],\n",
    "                                                self.idxh_val[np.sort(np.random.choice(self.num_val_params,\n",
    "                                                int((self.param_recon * self.num_val_params) / 100), replace = False))]))\n",
    "        \n",
    "    \n",
    "    # Label Scaler Download & Reverse Transformation\n",
    "    def label_unscale(\n",
    "        self,\n",
    "        y: np.array or pd.DataFrame\n",
    "    ):\n",
    "\n",
    "        # Label Scaler Download & Reverse Usage\n",
    "        try: self.scaler\n",
    "        except AttributeError:\n",
    "            scaler = torch.load(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "        return scaler.inverse_transform(y.reshape(1, -1))\n",
    "\n",
    "    # Cartesian to Polar Coordinate Conversion Functionality\n",
    "    def cart2polar(self, y: np.array):\n",
    "\n",
    "        # Cartesian to Polar Coordinates Conversion\n",
    "        phi = np.arccos(y[:, 2]).astype(np.float32); theta = np.arctan2(y[:, 1], y[:, 0])\n",
    "        theta = np.where(theta < 0, 2 * np.pi - np.abs(theta), theta).astype(np.float32)\n",
    "        theta = np.expand_dims(theta, axis = 1); phi = np.expand_dims(phi, axis = 1)\n",
    "        return pd.DataFrame(data = np.concatenate((theta, phi), axis = 1),\n",
    "                            columns = ['Gradient theta', 'Gradient phi'])\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Patient Data Generation Functionality\n",
    "    def get_patient(settings, num_patient: int):\n",
    "\n",
    "        # Patient Data Access\n",
    "        data = h5py.File(settings.data_filepath, 'r').get('data1')\n",
    "        idxv = pd.read_csv( settings.info_filepath,             # List of Index Values ...\n",
    "                            index_col = 0).to_numpy()           # ... pertaining to each Patient\n",
    "        idxv = idxv[np.isin(idxv[:, 1], num_patient), 0]        # Patient-Specific Index Values\n",
    "        X = torch.Tensor(data[idxv, :])\n",
    "\n",
    "        # Patient Mask Access\n",
    "        mask = MUDI_fcglVNN.get_mask(settings, num_patient = num_patient)\n",
    "        img = unmask(X.T, mask).get_fdata().T\n",
    "        return X, mask, torch.Tensor(img)\n",
    "\n",
    "    # Patient Mask Retrieval Functionality\n",
    "    def get_mask(settings, num_patient: int):\n",
    "        mask_filepath = Path(f\"{settings.mask_folderpath}/p{num_patient}.nii\")\n",
    "        assert(mask_filepath.exists()), f\"ERROR: Patient {num_patient}'s Mask not Found!\"\n",
    "        #return torch.Tensor(np.array(load_img(mask_filepath).dataobj, dtype = np.float32))\n",
    "        return load_img(mask_filepath)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D MUDI Dataset Initialization Class (V1)\n",
    "class MUDI_fcglVNN(Dataset):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,\n",
    "        subject: int or list,\n",
    "        mode: str = 'Train',\n",
    "        target_param: int or float = 100,\n",
    "        target_voxel: int or float = 100\n",
    "    ):\n",
    "        \n",
    "        # Parameter & Patient Index Value Access\n",
    "        super(MUDI_fcglVNN).__init__()\n",
    "        self.settings = settings; self.mode = mode\n",
    "        if mode == 'Train': self.mode = 'Target'\n",
    "        self.target_param = target_param; self.target_voxel = target_voxel\n",
    "        self.data = h5py.File(self.settings.data_filepath, 'r').get('data1')\n",
    "        self.params = pd.read_excel(self.settings.param_filepath)\n",
    "\n",
    "        # Vertical Splitting (Patient Selection)\n",
    "        self.idxv = pd.read_csv(self.settings.info_filepath,            # List of Index Values ...\n",
    "                                index_col = 0).to_numpy()               # ... pertaining to each Patient\n",
    "        self.idxv = self.idxv[np.isin(self.idxv[:, 1], subject), 0]     # Patient-Specific Index Values\n",
    "\n",
    "        # Horizontal Splitting (Parameter Selection)\n",
    "        idxh_train_filepath = Path(f\"{self.settings.datasave_folderpath}/Training Labels (V{self.settings.data_version}).txt\")\n",
    "        idxh_target_filepath = Path(f\"{self.settings.datasave_folderpath}/{self.mode} Labels (V{self.settings.data_version}).txt\")\n",
    "        self.idxh_train = np.sort(np.loadtxt(idxh_train_filepath)).astype(int)\n",
    "        if not idxh_target_filepath.exists(): self.idxh_target_full = self.label_gen()\n",
    "        else: self.idxh_target_full = np.sort(np.loadtxt(idxh_target_filepath)).astype(int)\n",
    "\n",
    "        # Vertical & Horizontal Sub-Sectioning & Shuffling\n",
    "        self.h_target = int((self.target_param * len(self.idxh_target_full)) / 100)\n",
    "        self.v_target = int((self.target_voxel * len(self.idxv)) / 100); self.shuffle()\n",
    "        print(f\"     > Utilizing {self.h_target} \\ {len(self.idxh_target_full)} of the Target Parameters\")\n",
    "        print(f\"     > Utilizing {self.v_target} \\ {len(self.idxv)} of the Training Voxels\")\n",
    "\n",
    "        # Parameter Selection & Value Normalization / Scaling\n",
    "        if self.settings.gradient_coord:\n",
    "            self.params = self.params.drop(columns = ['Gradient theta', 'Gradient phi'])                # Choosing of Gradient Orientation\n",
    "        else: self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])\n",
    "        if self.settings.label_norm == 'auto':\n",
    "            print(f\"     > Automatic Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "            self.scaler = StandardScaler()\n",
    "            self.params = pd.DataFrame( self.scaler.fit_transform(self.params),\n",
    "                                        columns = self.params.columns)\n",
    "            scaler_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "            if not scaler_filepath.exists(): torch.save(self.scaler, scaler_filepath)\n",
    "        elif self.settings.label_norm == 'manual':\n",
    "            print(f\"     > Manual Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "            self.params[['Gradient theta', 'Gradient phi']] = self.cart2polar(self.params[['Gradient x', 'Gradient y', 'Gradient z']].values)\n",
    "            self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])\n",
    "            self.params['b Value'] = self.params['b Value'] / 10000\n",
    "            self.params['TI'] = self.params['TI'] / 10000\n",
    "            self.params['TE'] = (self.params['TE'] - 80) / 200\n",
    "        else: print(f\"     > No Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "        assert(self.params.shape[1] == self.settings.num_labels), \"ERROR: Labels wrongly Deleted!\"\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # DataLoader Length / No. Batches Computation Functionality\n",
    "    def __len__(self): return self.v_target * self.h_target\n",
    "\n",
    "    # Single-Batch Generation Functionality\n",
    "    def __getitem__(self, idx) -> tuple[np.ndarray, np.float32]:\n",
    "        \n",
    "        # [Parameter Batch] Batch Vertical/Patient & Horizontal/Parameter Indexing\n",
    "        #idxv = idx // self.h_target         # Batch's Vertical Index for X_train\n",
    "        #idxh = idx % self.h_target          # Batch's Horizontal Index for y_target\n",
    "\n",
    "        # [Image Batch] Batch Vertical/Patient & Horizontal/Parameter Indexing\n",
    "        idxv = idx % self.v_target          # Batch's Vertical Index for X_train\n",
    "        idxh = idx // self.v_target         # Batch's Horizontal Index for y_target\n",
    "        \n",
    "        # Batch Data Generation\n",
    "        X_train = self.data[self.idxv_target[idxv], :][self.idxh_train]             # [num_train_params] Training Data\n",
    "        y_target = self.params.iloc[self.idxh_target[idxh]].values                  # [num_labels] Target Parameters\n",
    "        X_target = self.data[self.idxv_target[idxv], :][self.idxh_target[idxh]]     # [    1    ] GT Target Data\n",
    "        input = np.hstack((X_train, y_target)).astype(np.float32)                   # [num_train_params + num_labels] Input\n",
    "        return input, X_target\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Target Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def param_shuffle(\n",
    "        self,\n",
    "        idxh_target: np.array = None\n",
    "    ):\n",
    "        if idxh_target is not None: self.idxh_target = idxh_target\n",
    "        else:\n",
    "            if self.settings.param_shuffle:\n",
    "                self.idxh_target = self.idxh_target_full[   np.sort(np.random.choice(len(self.idxh_target_full),\n",
    "                                                            self.h_target, replace = False))]\n",
    "                \n",
    "    # Target Voxel Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def voxel_shuffle(\n",
    "        self,\n",
    "        idxv_target: np.array = None\n",
    "    ):  \n",
    "        if idxv_target is not None: self.idxv_target = idxv_target\n",
    "        else:\n",
    "            if self.settings.voxel_shuffle:\n",
    "                self.idxv_target = self.idxv[   np.sort(np.random.choice(len(self.idxv),\n",
    "                                                self.v_target, replace = False))]\n",
    "    \n",
    "    # Target Voxel & Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def shuffle(\n",
    "        self,\n",
    "        idxh_target: np.array = None,\n",
    "        idxv_target: np.array = None\n",
    "    ):  self.param_shuffle(idxh_target); self.voxel_shuffle(idxv_target)\n",
    "\n",
    "    # Random Target Parameter for Training & Test Sets Generation Functionality\n",
    "    def label_gen(self):\n",
    "\n",
    "        # Target & Test Label Index File Generation\n",
    "        idxh_target = np.delete(np.arange(self.params.shape[0]), self.idxh_train)\n",
    "        if self.settings.test_target_param != 0:\n",
    "            idxh_test = idxh_target[np.sort(np.random.choice(len(idxh_target),\n",
    "                                    self.settings.test_target_param, replace = False))]\n",
    "            idxh_target = np.delete(idxh_target, np.where(np.in1d(idxh_target, idxh_test)))\n",
    "            for i in range(self.settings.test_target_param): assert(idxh_test[i] not in idxh_target\n",
    "                ), f\"ERROR: Target Parameter #{i} for Training & Test Sets not mutually Exclusive\"\n",
    "            \n",
    "            # Target & Test Label Index File Saving\n",
    "            print(f\">     Saving File Target Parameters for Training ({len(idxh_target)}) & Test {len(idxh_test)} Set's\")\n",
    "            np.savetxt(Path(f\"{self.settings.datasave_folderpath}/Test Labels (V{self.settings.data_version}).txt\"), idxh_test)\n",
    "            np.savetxt(Path(f\"{self.settings.datasave_folderpath}/Target Labels (V{self.settings.data_version}).txt\"), idxh_target)\n",
    "        if self.mode == 'Train': return idxh_target\n",
    "        else: return idxh_test\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "        \n",
    "    # Label Scaler Download & Reverse Transformation\n",
    "    def label_unscale(\n",
    "        self,\n",
    "        y: np.array or pd.DataFrame\n",
    "    ):\n",
    "\n",
    "        # Label Scaler Download & Reverse Usage\n",
    "        try: self.scaler\n",
    "        except AttributeError:\n",
    "            scaler = torch.load(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "        return scaler.inverse_transform(y.reshape(1, -1))\n",
    "\n",
    "    # Cartesian to Polar Coordinate Conversion Functionality\n",
    "    def cart2polar(self, y: np.array):\n",
    "\n",
    "        # Cartesian to Polar Coordinates Conversion\n",
    "        phi = np.arccos(y[:, 2]).astype(np.float32); theta = np.arctan2(y[:, 1], y[:, 0])\n",
    "        theta = np.where(theta < 0, 2 * np.pi - np.abs(theta), theta).astype(np.float32)\n",
    "        theta = np.expand_dims(theta, axis = 1); phi = np.expand_dims(phi, axis = 1)\n",
    "        return pd.DataFrame(data = np.concatenate((theta, phi), axis = 1),\n",
    "                            columns = ['Gradient theta', 'Gradient phi'])\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Patient Data Generation Functionality\n",
    "    def get_img(settings, num_patient: int):\n",
    "\n",
    "        # Patient Data Access\n",
    "        data = h5py.File(settings.data_filepath, 'r').get('data1')\n",
    "        idxv = pd.read_csv( settings.info_filepath,             # List of Index Values ...\n",
    "                            index_col = 0).to_numpy()           # ... pertaining to each Patient\n",
    "        idxv = idxv[np.isin(idxv[:, 1], num_patient), 0]        # Patient-Specific Index Values\n",
    "        X = torch.Tensor(data[idxv, :])\n",
    "\n",
    "        # Patient Mask Access\n",
    "        mask = MUDI_fcglVNN.get_mask(settings, num_patient = num_patient)\n",
    "        img = unmask(X.T, mask).get_fdata().T\n",
    "        return torch.Tensor(img)\n",
    "\n",
    "    # Patient Mask Retrieval Functionality\n",
    "    def get_mask(settings, num_patient: int):\n",
    "        mask_filepath = Path(f\"{settings.mask_folderpath}/p{num_patient}.nii\")\n",
    "        assert(mask_filepath.exists()), f\"ERROR: Patient {num_patient}'s Mask not Found!\"\n",
    "        #return torch.Tensor(np.array(load_img(mask_filepath).dataobj, dtype = np.float32))\n",
    "        return load_img(mask_filepath)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     > Utilizing 844 \\ 844 of the Target Parameters\n",
      "     > Utilizing 108300 \\ 108300 of the Training Voxels\n",
      "     > Manual Normalization of all 5 Parameter Values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# DataLoader Iteration Example (V1)\\ntrain_iter = iter(trainloader)\\n#for i in range(len(trainloader)):\\nfor i in range(0, 2):\\n    batch = next(train_iter); target_param = trainset.params.iloc[trainset.idxh_target[i]].values\\n    assert(np.all(np.round(np.array(batch[0][0, -5::]), 5) == np.round(target_param, 5).astype('float32')))\\n    img_set = unmask(batch[1].reshape((1, len(trainset.idxv_target))), mask).get_fdata().T\\n    plt.subplot(1, 2, 1); plt.imshow(img_set[0, 25, :, :], cmap = plt.cm.binary)\\n    plt.subplot(1, 2, 2); plt.imshow(img[trainset.idxh_target[i], 25, :, :], cmap = plt.cm.binary)\\n    plt.show(); time.sleep(5)\\n\""
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset DataLoader Creation\n",
    "#trainset = MUDI_fcglVNN(    settings, subject = [11], param_recon = settings.param_recon_train)\n",
    "trainset = MUDI_fcglVNN(    settings, subject = [11], mode = 'Train',\n",
    "                            target_param = settings.train_target_param,\n",
    "                            target_voxel = 100)#settings.train_target_voxel)\n",
    "trainloader = DataLoader(   dataset = trainset,\n",
    "                            shuffle = settings.val_sample_shuffle,\n",
    "                            num_workers = 0,#settings.num_workers,\n",
    "                            batch_size = 10,#len(trainset.idxv_target),#settings.batch_size,\n",
    "                            pin_memory = False)\n",
    "mask = MUDI_fcglVNN.get_mask(settings, num_patient = 11)\n",
    "img = MUDI_fcglVNN.get_img(settings, num_patient = 11)\n",
    "\n",
    "\"\"\"\n",
    "# DataLoader Iteration Example (V0)\n",
    "train_bar = tqdm(   enumerate(trainloader), desc = 'Training',\n",
    "                    total = len(trainloader), unit = 'Batches')\n",
    "for batch_idx, batch in train_bar:\n",
    "    assert(torch.all(torch.eq(torch.Tensor(batch[0][:, :-5]), X[:, trainset.idxh_train])).item()), f'{batch_idx}'\n",
    "    assert(torch.all(torch.eq(torch.Tensor(batch[1]), X[:, trainset.idxh_recon[batch_idx]])).item()), f'{batch_idx}'\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# DataLoader Iteration Example (V1)\n",
    "train_iter = iter(trainloader)\n",
    "#for i in range(len(trainloader)):\n",
    "for i in range(0, 2):\n",
    "    batch = next(train_iter); target_param = trainset.params.iloc[trainset.idxh_target[i]].values\n",
    "    assert(np.all(np.round(np.array(batch[0][0, -5::]), 5) == np.round(target_param, 5).astype('float32')))\n",
    "    img_set = unmask(batch[1].reshape((1, len(trainset.idxv_target))), mask).get_fdata().T\n",
    "    plt.subplot(1, 2, 1); plt.imshow(img_set[0, 25, :, :], cmap = plt.cm.binary)\n",
    "    plt.subplot(1, 2, 2); plt.imshow(img[trainset.idxh_target[i], 25, :, :], cmap = plt.cm.binary)\n",
    "    plt.show(); time.sleep(5)\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Model* **Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed Conditional Generative Linear Voxel Net Model Class\n",
    "class fcglVNN(nn.Module):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser\n",
    "    ):\n",
    "        \n",
    "        # Class Variable Logging\n",
    "        super().__init__(); self.settings = settings\n",
    "        self.net = []; self.arch = []\n",
    "        self.arch.insert(0, self.settings.in_channels + self.settings.num_labels)\n",
    "\n",
    "        # Neural Network Architecture Definition\n",
    "        var_hidden = int((self.settings.top_hidden - self.settings.bottom_hidden) / self.settings.num_hidden)\n",
    "        for i in range(1, self.settings.num_hidden + 1):\n",
    "            if i == 1: self.arch.insert(i, self.settings.bottom_hidden + var_hidden)\n",
    "            else: self.arch.insert(i, self.arch[i - 1] + var_hidden)\n",
    "            self.main_block(self.arch[i], self.arch[i - 1])\n",
    "        for i in range(self.settings.num_hidden + 1, (2 * self.settings.num_hidden) + 1):\n",
    "            self.arch.insert(i, self.arch[i - 1] - var_hidden)\n",
    "            self.main_block(self.arch[i], self.arch[i - 1])\n",
    "        self.net.append(nn.Linear(in_features = self.settings.bottom_hidden, out_features = 1))\n",
    "        self.net = nn.Sequential(*self.net)\n",
    "\n",
    "    # Block Architecture Definition Functionality\n",
    "    def main_block(self, out_channels: int, in_channels: int):\n",
    "        self.net.append(\n",
    "            nn.Sequential(  nn.Linear(      in_features = in_channels,\n",
    "                                            out_features = out_channels),\n",
    "                            nn.BatchNorm1d( num_features = out_channels),\n",
    "                            nn.ReLU()))\n",
    "                            #nn.LeakyReLU(   negative_slope = 0.2)))\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Neural Network Application Function\n",
    "    def forward(\n",
    "        self,\n",
    "        input: np.ndarray or torch.Tensor\n",
    "    ):  return self.net(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 768]         388,608\n",
      "       BatchNorm1d-2                  [-1, 768]           1,536\n",
      "              ReLU-3                  [-1, 768]               0\n",
      "            Linear-4                 [-1, 1024]         787,456\n",
      "       BatchNorm1d-5                 [-1, 1024]           2,048\n",
      "              ReLU-6                 [-1, 1024]               0\n",
      "            Linear-7                  [-1, 768]         787,200\n",
      "       BatchNorm1d-8                  [-1, 768]           1,536\n",
      "              ReLU-9                  [-1, 768]               0\n",
      "           Linear-10                  [-1, 512]         393,728\n",
      "      BatchNorm1d-11                  [-1, 512]           1,024\n",
      "             ReLU-12                  [-1, 512]               0\n",
      "           Linear-13                    [-1, 1]             513\n",
      "================================================================\n",
      "Total params: 2,363,649\n",
      "Trainable params: 2,363,649\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.07\n",
      "Params size (MB): 9.02\n",
      "Estimated Total Size (MB): 9.09\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model.net, (settings.in_channels + settings.num_labels, ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fcglVNN(\n",
      "  (net): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=505, out_features=768, bias=True)\n",
      "      (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=768, out_features=1024, bias=True)\n",
      "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=768, bias=True)\n",
      "      (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (4): Linear(in_features=512, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "# Model Initialization Example\n",
    "model = fcglVNN(settings)\n",
    "print(model)\n",
    "\n",
    "# Model Usage Example\n",
    "#X_real = tf.random.uniform([10, settings.in_channels + settings.num_labels])\n",
    "#y_target = tf.random.uniform([10, settings.num_labels])\n",
    "#trainset = MUDI_fcglVNN(settings, subject = [11, 12, 13])\n",
    "print(model(next(iter(trainloader))[0]).shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***[Old]*** **Training** *Script*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fcglVNN Model Training Script\n",
    "def fcglVNN_train(\n",
    "    settings,\n",
    "    trainset: MUDI_fcglVNN,\n",
    "    valset: MUDI_fcglVNN\n",
    "):\n",
    "\n",
    "    # Seed Random State for Reproducibility\n",
    "    torch.manual_seed(settings.seed)\n",
    "    np.random.seed(settings.seed)\n",
    "    random.seed(settings.seed)\n",
    "\n",
    "    # Experiment Logs Directory\n",
    "    checkpoint_folderpath = os.path.join(f'{settings.modelsave_folderpath}/V{settings.model_version}', 'logs')\n",
    "    #visualizer_folderpath = os.path.join(f'{settings.modelsave_folderpath}/V{settings.model_version}', 'viz')\n",
    "    train_logger = SummaryWriter(checkpoint_folderpath)\n",
    "\n",
    "    # Model & Optimizer Setup\n",
    "    model = fcglVNN(settings)#.to(settings.device)\n",
    "    #model= nn.DataParallel(model, device_ids = [0, 1]).to(settings.device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(  model.parameters(), lr = settings.base_lr,\n",
    "                                    weight_decay = settings.weight_decay)\n",
    "\n",
    "    # Criterion & Early Stopping Setup\n",
    "    criterion = nn.MSELoss(reduction = 'mean')\n",
    "    earlyStopping = EarlyStopping(  patience = settings.es_patience,\n",
    "                                    path = Path(f'{settings.modelsave_folderpath}/V{settings.model_version}/fcglVNN.pt'),\n",
    "                                    delta = settings.es_delta)\n",
    "    \n",
    "    # Epoch Iteration Loop\n",
    "    train_iter = -1; val_iter = -1\n",
    "    for epoch in range(settings.num_epochs):\n",
    "\n",
    "        # Training Iteration Loop\n",
    "        #train_bar = tqdm(   enumerate(trainset), desc = 'Training',\n",
    "        #                    total = len(trainset), unit = 'Batches')\n",
    "        #for batch_idx, batch in train_bar:\n",
    "        train_loss = []; val_loss = []\n",
    "        with alive_bar( len(trainset),\n",
    "                        title = f'Epoch {epoch} | Training',\n",
    "                        force_tty = True) as train_bar:\n",
    "            for i in range(len(trainset)):\n",
    "\n",
    "                # Model & Optimizer Training Setup\n",
    "                model.train(); model.zero_grad()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward Propagation\n",
    "                batch = trainset.__getitem__(i); train_iter += 1\n",
    "                out = model(batch[0].to(settings.device))\n",
    "                out = torch.squeeze(out, dim = 1)\n",
    "                gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "                # Backward Propagation\n",
    "                loss = criterion(out, batch[1].to(settings.device))\n",
    "                loss.backward(); optimizer.step()\n",
    "                train_logger.add_scalar('train/Loss', loss.item(), train_iter)\n",
    "                train_loss.append(loss.item())\n",
    "                time.sleep(0.01); train_bar()\n",
    "        \n",
    "        # Validation Iteration Loop\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            with alive_bar( len(valset),\n",
    "                            title = f'Epoch {epoch} | Validation',\n",
    "                            force_tty = True) as val_bar:\n",
    "                for i in range(len(valset)):\n",
    "\n",
    "                    # Forward Propagation\n",
    "                    batch = valset.__getitem__(i); val_iter += 1\n",
    "                    out = model(batch[0].to(settings.device))\n",
    "                    out = torch.squeeze(out, dim = 1)\n",
    "                    gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "                    # Loss Computation\n",
    "                    loss = criterion(out, batch[1].to(settings.device))\n",
    "                    train_logger.add_scalar('val/Loss', loss.item(), val_iter)\n",
    "                    val_loss.append(loss.item())\n",
    "                    time.sleep(0.01); val_bar()\n",
    "        \n",
    "        # Epoch End Validation Loss Writing\n",
    "        mean_train_loss = np.mean(np.array(train_loss))\n",
    "        mean_val_loss = np.mean(np.array(val_loss))\n",
    "        train_logger.add_scalar('train/Mean Loss', mean_train_loss, epoch)\n",
    "        train_logger.add_scalar('val/Mean Loss', mean_val_loss, epoch)\n",
    "        trainset.on_epoch_end(); valset.on_epoch_end()\n",
    "        \n",
    "        # Early Stopping Callback Application\n",
    "        early_stop = earlyStopping( val_loss = mean_val_loss, epoch = epoch,\n",
    "                                    model = model, optimizer = optimizer)\n",
    "        if early_stop: print(f'Training Finished at Best Epoch #{epoch}'); return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fcglVNN Model Training Script\n",
    "def fcglVNN_train(\n",
    "    settings,\n",
    "    train_set: MUDI_fcglVNN,\n",
    "    val_set: MUDI_fcglVNN,\n",
    "    recon_set: MUDI_fcglVNN\n",
    "):\n",
    "\n",
    "    # Seed Random State for Reproducibility\n",
    "    torch.manual_seed(settings.seed)\n",
    "    np.random.seed(settings.seed)\n",
    "    random.seed(settings.seed)\n",
    "\n",
    "    # Experiment Logs Directories Initialization\n",
    "    checkpoint_folderpath = os.path.join(f'{settings.modelsave_folderpath}/V{settings.model_version}', 'logs')\n",
    "    train_logger = TensorBoardLogger(checkpoint_folderpath, 'train')\n",
    "    val_logger = TensorBoardLogger(checkpoint_folderpath, 'validation')\n",
    "    recon_logger = TensorBoardLogger(checkpoint_folderpath, 'recon')\n",
    "    X, mask, img = MUDI_fcglVNN.get_patient(settings, settings.sel_val_patient); del X\n",
    "\n",
    "    # Training & Reconstruction DataLoaders Initialization\n",
    "    train_loader = DataLoader(  dataset = train_set, shuffle = True,\n",
    "                                num_workers = settings.num_workers,\n",
    "                                batch_size = settings.batch_size,\n",
    "                                pin_memory = True)\n",
    "    val_loader = DataLoader(    dataset = val_set, shuffle = True,\n",
    "                                num_workers = settings.num_workers,\n",
    "                                batch_size = settings.batch_size,\n",
    "                                pin_memory = True)\n",
    "    recon_loader = DataLoader(  dataset = recon_set, shuffle = False,\n",
    "                                num_workers = settings.num_workers,\n",
    "                                batch_size = len(recon_set),\n",
    "                                pin_memory = True)\n",
    "\n",
    "    # Model & Optimizer Setup\n",
    "    print(f\"Training fcglVNN Model with {torch.cuda.device_count()} GPUs!\")\n",
    "    model = fcglVNN(settings)#.to(settings.device)\n",
    "    model = nn.DataParallel(model, device_ids = [0, 1]).to(settings.device)\n",
    "    optimizer = torch.optim.AdamW(  model.parameters(), lr = settings.base_lr,\n",
    "                                    weight_decay = settings.weight_decay)\n",
    "\n",
    "    # Criterion & Early Stopping Setup\n",
    "    criterion = nn.MSELoss(reduction = 'mean')\n",
    "    earlyStopping = EarlyStopping(patience = settings.es_patience, delta = settings.es_delta,\n",
    "        path = Path(f'{settings.modelsave_folderpath}/V{settings.model_version}/fcglVNN.pt'))\n",
    "    \n",
    "    # Epoch Iteration Loop\n",
    "    train_iter = 0; val_iter = 0\n",
    "    for epoch in range(settings.num_epochs):\n",
    "\n",
    "        # Training Iteration Loop\n",
    "        train_loss = []; val_loss = []\n",
    "        train_bar = tqdm(   enumerate(train_loader), total = len(train_loader),\n",
    "                            desc = f'Epoch #{epoch} | Training', unit = 'Batches')\n",
    "        for batch_idx, batch in train_bar:\n",
    "\n",
    "            # Model & Optimizer Training Setup\n",
    "            model.train(); model.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward Propagation\n",
    "            out = model(batch[0].to(settings.device))\n",
    "            out = torch.squeeze(out, dim = 1)\n",
    "            gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "            # Backward Propagation\n",
    "            loss = criterion(out, batch[1].to(settings.device))\n",
    "            loss.backward(); optimizer.step()\n",
    "            train_logger.experiment.add_scalar(\"Loss\", loss.item(), train_iter)\n",
    "            train_loss.append(loss.item()); train_iter += 1\n",
    "        \n",
    "        # Validation Iteration Loop\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            val_bar = tqdm( enumerate(val_loader), total = len(val_loader),\n",
    "                            desc = f'Epoch #{epoch} | Validation', unit = 'Batches')\n",
    "            for batch_idx, batch in val_bar:\n",
    "\n",
    "                # Forward Propagation\n",
    "                out = model(batch[0].to(settings.device))\n",
    "                out = torch.squeeze(out, dim = 1)\n",
    "                gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "                # Loss Computation\n",
    "                loss = criterion(out, batch[1].to(settings.device))\n",
    "                val_logger.experiment.add_scalar(\"Loss\", loss.item(), val_iter)\n",
    "                val_loss.append(loss.item()); val_iter += 1\n",
    "        \n",
    "        # Epoch End Validation Loss Writing\n",
    "        mean_train_loss = np.mean(np.array(train_loss))\n",
    "        mean_val_loss = np.mean(np.array(val_loss))\n",
    "        train_logger.experiment.add_scalar(\"Mean Loss\", mean_train_loss, epoch)\n",
    "        val_logger.experiment.add_scalar(\"Mean Loss\", mean_val_loss, epoch)\n",
    "\n",
    "        # Full Image Reconstruction for Selected Patients\n",
    "        X_recon, X = next(iter(recon_loader))\n",
    "        with torch.no_grad(): model.eval(); X_fake = model(X_recon); del X_recon\n",
    "        train_set.on_epoch_end(); val_set.on_epoch_end(); recon_set.on_epoch_end()\n",
    "\n",
    "        # Tensorboard Reconstruction Callback\n",
    "        result = ReconCallback( recon_set, X, X_fake, mask, img, sel_slice = 25, epoch = epoch)\n",
    "        recon_logger.experiment.add_scalar(\"Best Reconstruction Loss | Training\", result['Best Training Loss'], epoch)\n",
    "        recon_logger.experiment.add_scalar(\"Worst Reconstruction Loss | Training\", result['Worst Training Loss'], epoch)\n",
    "        recon_logger.experiment.add_scalar(\"Best Reconstruction Loss | Validation\", result['Best Validation Loss'], epoch)\n",
    "        recon_logger.experiment.add_scalar(\"Worst Reconstruction Loss | Validation\", result['Worst Validation Loss'], epoch)\n",
    "        recon_logger.experiment.add_figure(\"Training Parameter Reconstruction\", result['Training Plot'], epoch)\n",
    "        recon_logger.experiment.add_figure(\"Validation Parameter Reconstruction\", result['Validation Plot'], epoch)\n",
    "        recon_logger.experiment.add_scalar(\"Full Reconstruction Loss\", result['Full Reconstruction Loss'], epoch)\n",
    "        del X, X_fake, result\n",
    "\n",
    "        # Early Stopping Callback Application\n",
    "        early_stop = earlyStopping( val_loss = mean_val_loss, epoch = epoch,\n",
    "                                    model = model, optimizer = optimizer)\n",
    "        if early_stop: print(f'Training Finished at Best Epoch #{epoch}'); return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fcglVNN Model Training Script (V-1)\n",
    "def fcglVNN_train(\n",
    "    settings,\n",
    "    train_set: MUDI_fcglVNN,\n",
    "    val_set: MUDI_fcglVNN,\n",
    "    #recon_set: MUDI_fcglVNN\n",
    "):\n",
    "\n",
    "    # Seed Random State for Reproducibility\n",
    "    torch.manual_seed(settings.seed)\n",
    "    np.random.seed(settings.seed)\n",
    "    random.seed(settings.seed)\n",
    "\n",
    "    # Experiment Logs Directories Initialization\n",
    "    checkpoint_folderpath = os.path.join(f'{settings.modelsave_folderpath}/V{settings.model_version}', 'logs')\n",
    "    train_logger = TensorBoardLogger(checkpoint_folderpath, 'train')\n",
    "    val_logger = TensorBoardLogger(checkpoint_folderpath, 'validation')\n",
    "    recon_logger = TensorBoardLogger(checkpoint_folderpath, 'recon')\n",
    "    X, mask, img = MUDI_fcglVNN.get_patient(settings, settings.sel_val_patient); del X\n",
    "\n",
    "    # Training & Reconstruction DataLoaders Initialization\n",
    "    train_loader = DataLoader(  dataset = train_set,\n",
    "                                shuffle = settings.param_shuffle,\n",
    "                                num_workers = settings.num_workers,\n",
    "                                batch_size = settings.batch_size,\n",
    "                                pin_memory = True)\n",
    "    val_loader = DataLoader(    dataset = val_set, shuffle = False,\n",
    "                                num_workers = settings.num_workers,\n",
    "                                batch_size = len(val_set.idxv),\n",
    "                                #batch_size = settings.batch_size,\n",
    "                                pin_memory = True)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Model & Optimizer Setup\n",
    "    print(f\"Training fcglVNN Model with {torch.cuda.device_count()} GPUs!\")\n",
    "    model = fcglVNN(settings)#.to(settings.device)\n",
    "    model = nn.DataParallel(model, device_ids = [0, 1]).to(settings.device)\n",
    "    optimizer = torch.optim.AdamW(  model.parameters(), lr = settings.base_lr,\n",
    "                                    weight_decay = settings.weight_decay)\n",
    "\n",
    "    # Criterion & Early Stopping Setup\n",
    "    criterion = nn.MSELoss(reduction = 'mean')\n",
    "    earlyStopping = EarlyStopping(patience = settings.es_patience, delta = settings.es_delta,\n",
    "        path = Path(f'{settings.modelsave_folderpath}/V{settings.model_version}/fcglVNN.pt'))\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Epoch Iteration Loop\n",
    "    train_iter = 0; val_iter = 0\n",
    "    for epoch in range(settings.num_epochs):\n",
    "\n",
    "        # Training Iteration Loop\n",
    "        train_loss = []; val_loss = []; X_fake = []\n",
    "        train_bar = tqdm(   enumerate(train_loader), total = len(train_loader),\n",
    "                            desc = f'Epoch #{epoch} | Training', unit = 'Batches')\n",
    "        for batch_idx, batch in train_bar:\n",
    "\n",
    "            # Model & Optimizer Training Setup\n",
    "            model.train(); model.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward Propagation\n",
    "            out = model(batch[0].to(settings.device))\n",
    "            out = torch.squeeze(out, dim = 1)\n",
    "            gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "            # Backward Propagation\n",
    "            loss = criterion(out, batch[1].to(settings.device))\n",
    "            loss.backward(); optimizer.step()\n",
    "            train_logger.experiment.add_scalar(\"Loss\", loss.item(), train_iter)\n",
    "            train_loss.append(loss.item()); train_iter += 1\n",
    "        \n",
    "        # --------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Validation Set Reconstruction Loss Checkpoints\n",
    "        best_train_loss = torch.ones(1, dtype = torch.float64) * 1000\n",
    "        worst_train_loss = torch.zeros(1, dtype = torch.float64)\n",
    "        best_val_loss = torch.ones(1, dtype = torch.float64) * 1000\n",
    "        worst_val_loss = torch.zeros(1, dtype = torch.float64)\n",
    "        \n",
    "        # Validation Iteration Loop\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            val_bar = tqdm( enumerate(val_loader), total = len(val_loader),\n",
    "                            desc = f'Epoch #{epoch} | Validation', unit = 'Batches')\n",
    "            for batch_idx, batch in val_bar:\n",
    "\n",
    "                # Forward Propagation\n",
    "                X_fake = model(batch[0].to(settings.device))\n",
    "                #X_fake = torch.squeeze(out, dim = 0)\n",
    "                gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "                # Loss Computation\n",
    "                #loss = criterion(X_fake, batch[1].to(settings.device))\n",
    "                loss = criterion(X_fake.detach().cpu(), batch[1])\n",
    "                val_logger.experiment.add_scalar(\"Loss\", loss.item(), val_iter)\n",
    "                val_loss.append(loss.item()); val_iter += 1\n",
    "\n",
    "                # Loss Comparison for Training Parameter\n",
    "                param_idx = batch_idx % val_set.num_recon\n",
    "                if param_idx <= val_set.num_train_recon:\n",
    "                    if loss < best_train_loss:\n",
    "                        best_train_loss = loss\n",
    "                        best_train_idx = val_set.idxh_recon[param_idx]\n",
    "                        X_train_best = X_fake.detach().cpu()\n",
    "                    if loss > worst_train_loss:\n",
    "                        worst_train_loss = loss\n",
    "                        worst_train_idx = val_set.idxh_recon[param_idx]\n",
    "                        X_train_worst = X_fake.detach().cpu()\n",
    "                \n",
    "                # Loss Computation for Validation Parameter\n",
    "                else:\n",
    "                    if loss < best_val_loss:\n",
    "                        best_val_loss = loss\n",
    "                        best_val_idx = val_set.idxh_recon[param_idx]\n",
    "                        X_val_best = X_fake.detach().cpu()\n",
    "                    if loss > worst_val_loss:\n",
    "                        worst_val_loss = loss\n",
    "                        worst_val_idx = val_set.idxh_recon[param_idx]\n",
    "                        X_val_worst = X_fake.detach().cpu()\n",
    "                gc.collect(); torch.cuda.empty_cache(); del X_fake\n",
    "        \n",
    "        # Epoch End Validation Loss Writing\n",
    "        mean_train_loss = np.mean(np.array(train_loss))\n",
    "        mean_val_loss = np.mean(np.array(val_loss))\n",
    "        train_logger.experiment.add_scalar(\"Mean Loss\", mean_train_loss, epoch)\n",
    "        val_logger.experiment.add_scalar(\"Mean Loss\", mean_val_loss, epoch)\n",
    "        train_set.on_epoch_end(); val_set.on_epoch_end()\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Training Image Unmasking of Original & Reconstructed Results\n",
    "        X_train_best = unmask(X_train_best.T, mask).get_fdata().T\n",
    "        X_train_worst = unmask(X_train_worst.T, mask).get_fdata().T\n",
    "\n",
    "        # Training Example Original & Best Reconstructed Image Subplots\n",
    "        train_plot = plt.figure(figsize = (20, 20))\n",
    "        plt.xticks([]); plt.yticks([]); plt.grid(False); plt.tight_layout()\n",
    "        plt.subplot(2, 2, 1, title = f'Target Image (Parameter #{best_train_idx})')\n",
    "        plt.imshow(img[best_train_idx, settings.sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        plt.subplot(2, 2, 2, title = f'Best Reconstruction (Parameter #{best_train_idx})')\n",
    "        plt.imshow(X_train_best[0, settings.sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        del best_train_idx, X_train_best\n",
    "        \n",
    "        # Training Example Original & Worst Reconstructed Image Subplots\n",
    "        plt.subplot(2, 2, 3, title = f'Target Image (Parameter #{worst_train_idx})')\n",
    "        plt.imshow(img[worst_train_idx, settings.sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        plt.subplot(2, 2, 4, title = f'Worst Reconstruction (Parameter #{worst_train_idx})')\n",
    "        plt.imshow(X_train_worst[0, settings.sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        del worst_train_idx, X_train_worst\n",
    "\n",
    "        # Tensorboard Reconstruction Callback\n",
    "        recon_logger.experiment.add_figure(\"Training Parameter Reconstruction\", train_plot, epoch)\n",
    "        recon_logger.experiment.add_scalar(\"Best Reconstruction Loss | Training\", best_train_loss, epoch)\n",
    "        recon_logger.experiment.add_scalar(\"Worst Reconstruction Loss | Training\", worst_train_loss, epoch)\n",
    "        del train_plot, best_train_loss, worst_train_loss\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Training Image Unmasking of Original & Reconstructed Results\n",
    "        X_val_best = unmask(X_val_best.T, mask).get_fdata().T\n",
    "        X_val_worst = unmask(X_val_worst.T, mask).get_fdata().T\n",
    "\n",
    "        # Training Example Original & Best Reconstructed Image Subplots\n",
    "        val_plot = plt.figure(figsize = (20, 20))\n",
    "        plt.xticks([]); plt.yticks([]); plt.grid(False); plt.tight_layout()\n",
    "        plt.subplot(2, 2, 1, title = f'Target Image (Parameter #{best_val_idx})')\n",
    "        plt.imshow(img[best_val_idx, settings.sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        plt.subplot(2, 2, 2, title = f'Best Reconstruction (Parameter #{best_val_idx})')\n",
    "        plt.imshow(X_val_best[0, settings.sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        del best_val_idx, X_val_best\n",
    "        \n",
    "        # Training Example Original & Worst Reconstructed Image Subplots\n",
    "        plt.subplot(2, 2, 3, title = f'Target Image (Parameter #{worst_val_idx})')\n",
    "        plt.imshow(img[worst_val_idx, settings.sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        plt.subplot(2, 2, 4, title = f'Worst Reconstruction (Parameter #{worst_val_idx})')\n",
    "        plt.imshow(X_val_worst[0, settings.sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        del worst_val_idx, X_val_worst\n",
    "\n",
    "        # Tensorboard Reconstruction Callback\n",
    "        #result = ReconCallback(val_set, X, X_fake, mask, img, sel_slice = 25, epoch = epoch)\n",
    "        recon_logger.experiment.add_figure(\"Validation Parameter Reconstruction\", val_plot, epoch)\n",
    "        recon_logger.experiment.add_scalar(\"Best Reconstruction Loss | Validation\", best_val_loss, epoch)\n",
    "        recon_logger.experiment.add_scalar(\"Worst Reconstruction Loss | Validation\", worst_val_loss, epoch)\n",
    "        del val_plot, best_val_loss, worst_val_loss\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Early Stopping Callback Application\n",
    "        early_stop = earlyStopping( val_loss = mean_val_loss, epoch = epoch,\n",
    "                                    model = model, optimizer = optimizer)\n",
    "        if early_stop: print(f'Training Finished at Best Epoch #{epoch}'); return\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training** *Script*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result Plotting Functionality (V1)\n",
    "def plot_results(\n",
    "    logger: TensorBoardLogger, loss_: str,\n",
    "    best_idx: int, best_loss: torch.Tensor or np.float,\n",
    "    worst_idx: int, worst_loss: torch.Tensor or np.float,\n",
    "    img_best_gt, img_best_fake, img_worst_gt, img_worst_fake,\n",
    "    patient_id: int = 14, sel_slice: int = 25, epoch = 0\n",
    "):\n",
    "\n",
    "    # Set Example Reconstruction Results Image Plotting\n",
    "    plot = plt.figure(figsize = (20, 22))\n",
    "    plt.xticks([]); plt.yticks([]); plt.grid(False); plt.tight_layout()\n",
    "    plt.suptitle(f'Validation Patient {patient_id} | Parameter Results | {loss_} Loss')\n",
    "    if type(best_loss) == torch.Tensor: best_loss = best_loss.item(); worst_loss= worst_loss.item()\n",
    "\n",
    "    # Set Example Original & Best Loss Reconstructed Image Subplots\n",
    "    plt.subplot(2, 2, 1, title = f'Best {loss_} | Original | Parameter #{best_idx}')\n",
    "    plt.imshow(img_best_gt[0, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "    plt.subplot(2, 2, 2, title = f'Best {loss_} | Fake | {loss_}: {np.round(best_loss, 4)}')\n",
    "    plt.imshow(img_best_fake[0, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "    \n",
    "    # Set Example Original & Worst Loss Reconstructed Image Subplots\n",
    "    plt.subplot(2, 2, 3, title = f'Worst {loss_} | Original | Parameter #{worst_idx}')\n",
    "    plt.imshow(img_worst_gt[0, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "    plt.subplot(2, 2, 4, title = f'Worst {loss_} | Fake | {loss_}: {np.round(worst_loss, 4)}')\n",
    "    plt.imshow(img_worst_fake[0, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "\n",
    "    # Tensorboard Reconstruction Callback\n",
    "    logger.experiment.add_figure(f\"{loss_} Results\", plot, epoch)\n",
    "    logger.experiment.add_scalar(f\"Best {loss_}\", best_loss, epoch)\n",
    "    logger.experiment.add_scalar(f\"Worst {loss_}\", worst_loss, epoch)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fcglVNN Model Training Script (V0)\n",
    "def fcglVNN_train(\n",
    "    settings,\n",
    "):\n",
    "\n",
    "    # Seed Random State for Reproducibility\n",
    "    torch.manual_seed(settings.seed)\n",
    "    np.random.seed(settings.seed)\n",
    "    random.seed(settings.seed)\n",
    "\n",
    "    # Experiment Logs Directories Initialization\n",
    "    checkpoint_folderpath = os.path.join(f'{settings.modelsave_folderpath}/V{settings.model_version}', 'logs')\n",
    "    train_logger = TensorBoardLogger(checkpoint_folderpath, 'train')\n",
    "    val_logger = TensorBoardLogger(checkpoint_folderpath, 'validation')\n",
    "\n",
    "    # Training & Validation DataLoaders Initialization\n",
    "    train_set = []; val_set = []; test_set = []\n",
    "    train_loader = []; val_loader = []; test_loader = []\n",
    "    for p, patient_id in enumerate(settings.patient_list):\n",
    "\n",
    "        # Patient Set & DataLoader Initialization\n",
    "        if patient_id in settings.test_patient_list: print(f\"Patient #{patient_id} | Test Set:\\n      Not Included\")\n",
    "        else:\n",
    "            if patient_id in settings.train_patient_list:\n",
    "                train_set.append(   MUDI_fcglVNN(settings, subject = [patient_id],\n",
    "                                        param_recon = settings.param_recon_train))\n",
    "                train_loader.append(DataLoader( dataset = train_set[-1], shuffle = settings.sample_shuffle,\n",
    "                                                num_workers = settings.num_workers, pin_memory = True,\n",
    "                                                batch_size = len(train_set[-1].idxv)))\n",
    "                print(f\"Patient #{patient_id} | Training Set:\")\n",
    "            elif patient_id in settings.val_patient_list:\n",
    "                val_set.append(     MUDI_fcglVNN(settings, subject = [patient_id],\n",
    "                                        param_recon = settings.param_recon_val))\n",
    "                val_loader.append(  DataLoader( dataset = val_set[-1], shuffle = settings.sample_shuffle,\n",
    "                                                num_workers = settings.num_workers, pin_memory = True,\n",
    "                                                batch_size = len(val_set[-1].idxv)))\n",
    "                print(f\"Patient #{patient_id} | Validation Set:\")\n",
    "            else:\n",
    "                test_set.append(    MUDI_fcglVNN(settings, subject = [patient_id],\n",
    "                                        param_recon = settings.param_recon_val))\n",
    "                test_loader.append( DataLoader( dataset = test_set[-1], shuffle = settings.sample_shuffle,\n",
    "                                                num_workers = settings.num_workers, pin_memory = True,\n",
    "                                                batch_size = len(test_set[-1].idxv)))\n",
    "                print(f\"Patient #{patient_id} | Test Set:\")\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Model & Optimizer Setup\n",
    "    print(f\"Training fcglVNN Model with {torch.cuda.device_count()} GPUs!\")\n",
    "    model = fcglVNN(settings)#.to(settings.device)\n",
    "    model = nn.DataParallel(model, device_ids = settings.device_ids).to(settings.device)\n",
    "    optimizer = torch.optim.AdamW(  model.parameters(), lr = settings.base_lr,\n",
    "                                    weight_decay = settings.weight_decay)\n",
    "\n",
    "    # Model Checkpoint Loading\n",
    "    model_filepath = Path(f\"{settings.modelsave_folderpath}/V{settings.model_version}/fcglVNN.pt\")\n",
    "    if model_filepath.exists():\n",
    "        checkpoint = torch.load(model_filepath, map_location = settings.device)\n",
    "        model.load_state_dict(checkpoint['Model']); optimizer.load_state_dict(checkpoint['Optimizer'])\n",
    "        save_epoch = checkpoint['Current Epoch']; torch.set_rng_state(checkpoint['RNG State'])\n",
    "        print(f\"Loading fcglVNN Model for {settings.model_version}: {save_epoch} Past Epochs\")\n",
    "        del checkpoint\n",
    "    else: save_epoch = -1\n",
    "\n",
    "    # Criterion & Early Stopping Setup\n",
    "    mse_criterion = nn.MSELoss(reduction = 'mean')#; ssim_criterion = SSIMLoss()\n",
    "    earlyStopping = EarlyStopping(  patience = settings.es_patience,\n",
    "                                    delta = settings.es_delta,\n",
    "                                    path = model_filepath)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Epoch Iteration Loop\n",
    "    train_iter = 0; val_iter = 0\n",
    "    for epoch in range(save_epoch + 1, settings.num_epochs):\n",
    "\n",
    "        # Training Patient Loop\n",
    "        train_mse_loss = []; train_ssim_loss = []\n",
    "        for p, patient_id in enumerate(settings.train_patient_list):\n",
    "\n",
    "            # Training Iteration Loop\n",
    "            mask = MUDI_fcglVNN.get_mask(settings, num_patient = patient_id)\n",
    "            train_bar = tqdm(   enumerate(train_loader[p]), total = len(train_loader[p]),\n",
    "                desc = f'Epoch #{epoch} | Training Patient {patient_id}', unit = 'Batches')\n",
    "            for batch_idx, batch in train_bar:\n",
    "\n",
    "                # Model & Optimizer Training Setup\n",
    "                img_gt = torch.Tensor(unmask(batch[1].reshape((1,\n",
    "                    len(batch[1]))), mask).get_fdata().T).to(settings.device)\n",
    "                model.train(); model.zero_grad()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward Propagation\n",
    "                X_fake = model(batch[0].to(settings.device))\n",
    "                X_fake = torch.squeeze(X_fake, dim = 1)\n",
    "                img_fake = torch.Tensor(unmask(X_fake.detach().cpu().reshape((1,\n",
    "                                            len(batch[1]))), mask).get_fdata().T)\n",
    "                gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "                # Loss Computation\n",
    "                mse_loss = mse_criterion(X_fake, batch[1].to(settings.device))\n",
    "                ssim_loss, ssim_img = ssim( img_gt[0].cpu().numpy().astype(np.float32),\n",
    "                                            img_fake[0].cpu().numpy().astype(np.float32),\n",
    "                    full = True,data_range = (torch.max(img_gt) - torch.min(img_gt)).cpu().numpy())\n",
    "                ssim_loss = np.mean(ssim_loss); del ssim_img, batch, X_fake, img_gt, img_fake\n",
    "\n",
    "                # Backward Propagation\n",
    "                loss = Variable(((1 - (settings.mse_weight / 100)) * (1 - ssim_loss)) +\\\n",
    "                                ((settings.mse_weight / 100) * mse_loss), requires_grad=True)\n",
    "                print(f\"MSE Loss: {mse_loss.item()} | SSIM Index: {ssim_loss} | Loss: {loss.item()}\")\n",
    "                loss.backward(); optimizer.step()\n",
    "\n",
    "                # Loss Appending \n",
    "                train_logger.experiment.add_scalar(\"MSE Loss\", mse_loss.item(), train_iter)\n",
    "                train_logger.experiment.add_scalar(\"SSIM Index\", ssim_loss, train_iter)\n",
    "                train_mse_loss.append(mse_loss.item()); train_ssim_loss.append(ssim_loss); train_iter += 1\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "\n",
    "            # Inter-Patient Reconstruction Parameter Sharing Functionality\n",
    "            if settings.param_sharing:\n",
    "                if p == 0:\n",
    "                    train_set[p].on_epoch_end()\n",
    "                    idxh_recon = train_set[p].idxh_recon\n",
    "                else: train_set[p].on_epoch_end(idxh_recon)\n",
    "            else: train_set[p].on_epoch_end()\n",
    "        \n",
    "\n",
    "        # Validation Set Reconstruction Loss Checkpoints\n",
    "        best_train_mse = 1000; worst_train_mse = 0; best_val_mse = 1000; worst_val_mse = 0\n",
    "        best_train_ssim = 0; worst_train_ssim = 1000; best_val_ssim = 0; worst_val_ssim = 1000\n",
    "        #best_train_mse = torch.ones(1, dtype = torch.float64) * 1000; worst_train_mse = torch.zeros(1, dtype = torch.float64)\n",
    "\n",
    "        # Validation Patient Loop\n",
    "        with torch.no_grad():\n",
    "            for p, patient_id in enumerate(settings.val_patient_list):\n",
    "            \n",
    "                # Training Iteration Loop\n",
    "                mask = MUDI_fcglVNN.get_mask(settings, num_patient = patient_id)\n",
    "                model.eval(); val_ssim_loss = []; val_mse_loss = []\n",
    "                val_bar = tqdm(   enumerate(val_loader[p]), total = len(val_loader[p]),\n",
    "                    desc = f'Epoch #{epoch} | Validation Patient {patient_id}', unit = 'Batches')\n",
    "                for batch_idx, batch in val_bar:\n",
    "            \n",
    "                    # Batch Handling\n",
    "                    img_gt = torch.Tensor(unmask(batch[1].reshape((1,\n",
    "                        len(batch[1]))), mask).get_fdata().T).to(settings.device)\n",
    "\n",
    "                    # Forward Propagation\n",
    "                    X_fake = model(batch[0].to(settings.device))\n",
    "                    X_fake = torch.squeeze(X_fake, dim = 1)\n",
    "                    img_fake = torch.Tensor(unmask(X_fake.detach().cpu().reshape((1,\n",
    "                                            len(batch[1]))), mask).get_fdata().T)\n",
    "                    gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "                    # Loss Computation\n",
    "                    mse_loss = mse_criterion(X_fake, batch[1].to(settings.device)).cpu().numpy()\n",
    "                    ssim_loss, ssim_img = ssim( img_gt[0].cpu().numpy().astype(np.float32),\n",
    "                                                img_fake[0].cpu().numpy().astype(np.float32),\n",
    "                        full = True,data_range = (torch.max(img_gt) - torch.min(img_gt)).cpu().numpy())\n",
    "                    ssim_loss = np.mean(ssim_loss); del ssim_img, batch, X_fake\n",
    "\n",
    "                    # Loss Appending \n",
    "                    val_logger.experiment.add_scalar(\"MSE Loss\", mse_loss, val_iter)\n",
    "                    val_logger.experiment.add_scalar(\"SSIM Index\", ssim_loss, val_iter)\n",
    "                    val_mse_loss.append(mse_loss.item()); val_ssim_loss.append(ssim_loss); val_iter += 1\n",
    "\n",
    "                    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "                    # MSE & SSIM Loss Assignation for Training Parameters\n",
    "                    param_idx = batch_idx % val_set[p].num_recon\n",
    "                    if param_idx <= val_set[p].num_train_recon:\n",
    "                        if mse_loss < best_train_mse:\n",
    "                            best_train_mse = mse_loss\n",
    "                            best_train_mse_idx = val_set[p].idxh_recon[param_idx]\n",
    "                            X_best_train_mse_fake = img_fake.detach().cpu()\n",
    "                            X_best_train_mse_gt = img_gt.detach().cpu()\n",
    "                        if mse_loss > worst_train_mse:\n",
    "                            worst_train_mse = mse_loss\n",
    "                            worst_train_mse_idx = val_set[p].idxh_recon[param_idx]\n",
    "                            X_worst_train_mse_fake = img_fake.detach().cpu()\n",
    "                            X_worst_train_mse_gt = img_gt.detach().cpu()\n",
    "                        if ssim_loss > best_train_ssim:\n",
    "                            best_train_ssim = ssim_loss\n",
    "                            best_train_ssim_idx = val_set[p].idxh_recon[param_idx]\n",
    "                            X_best_train_ssim_fake = img_fake.detach().cpu()\n",
    "                            X_best_train_ssim_gt = img_gt.detach().cpu()\n",
    "                        if ssim_loss < worst_train_ssim:\n",
    "                            worst_train_ssim = ssim_loss\n",
    "                            worst_train_ssim_idx = val_set[p].idxh_recon[param_idx]\n",
    "                            X_worst_train_ssim_fake = img_fake.detach().cpu()\n",
    "                            X_worst_train_ssim_gt = img_gt.detach().cpu()\n",
    "\n",
    "                    # MSE & SSIM Loss Assignation for Validation Parameters\n",
    "                    else:\n",
    "                        if mse_loss < best_val_mse:\n",
    "                            best_val_mse = mse_loss\n",
    "                            best_val_mse_idx = val_set[p].idxh_recon[param_idx]\n",
    "                            X_best_val_mse_fake = img_fake.detach().cpu()\n",
    "                            X_best_val_mse_gt = img_gt.detach().cpu()\n",
    "                        if mse_loss > worst_val_mse:\n",
    "                            worst_val_mse = mse_loss\n",
    "                            worst_val_mse_idx = val_set[p].idxh_recon[param_idx]\n",
    "                            X_worst_val_mse_fake = img_fake.detach().cpu()\n",
    "                            X_worst_val_mse_gt = img_gt.detach().cpu()\n",
    "                        if ssim_loss > best_val_ssim:\n",
    "                            best_val_ssim = ssim_loss\n",
    "                            best_val_ssim_idx = val_set[p].idxh_recon[param_idx]\n",
    "                            X_best_val_ssim_fake = img_fake.detach().cpu()\n",
    "                            X_best_val_ssim_gt = img_gt.detach().cpu()\n",
    "                        if ssim_loss < worst_val_ssim:\n",
    "                            worst_val_ssim = ssim_loss\n",
    "                            worst_val_ssim_idx = val_set[p].idxh_recon[param_idx]\n",
    "                            X_worst_val_ssim_fake = img_fake.detach().cpu()\n",
    "                            X_worst_val_ssim_gt = img_gt.detach().cpu()\n",
    "                    gc.collect(); torch.cuda.empty_cache(); del img_gt, img_fake\n",
    "\n",
    "                # Inter-Patient Reconstruction Parameter Sharing Functionality\n",
    "                if settings.param_sharing:\n",
    "                    if p == 0:\n",
    "                        val_set[p].on_epoch_end()\n",
    "                        idxh_recon = val_set[p].idxh_recon\n",
    "                    else: val_set[p].on_epoch_end(idxh_recon)\n",
    "                else: val_set[p].on_epoch_end()\n",
    "        \n",
    "        # Epoch End Validation Loss Writing\n",
    "        train_mse_loss = np.mean(np.array(train_mse_loss)); val_mse_loss = np.mean(np.array(val_mse_loss))\n",
    "        train_logger.experiment.add_scalar(\"Mean MSE Loss\", train_mse_loss, epoch)\n",
    "        val_logger.experiment.add_scalar(\"Mean MSE Loss\", val_mse_loss, epoch)        \n",
    "        train_logger.experiment.add_scalar(\"Mean SSIM Loss\", train_ssim_loss, epoch)\n",
    "        val_logger.experiment.add_scalar(\"Mean SSIM Loss\", val_ssim_loss, epoch)\n",
    "        \n",
    "        # --------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Training Parameter Example MSE Epoch Results\n",
    "        val_logger = plot_results(  logger = val_logger, sel_slice = settings.sel_slice,\n",
    "                                    epoch = epoch, set_ = 'Training', loss_ = 'MSE',\n",
    "                                    best_idx = best_train_mse_idx, worst_idx = worst_train_mse_idx,\n",
    "                                    best_loss = best_train_mse, worst_loss = worst_train_mse,\n",
    "                                    img_best_gt = X_best_train_mse_gt, img_best_fake = X_best_train_mse_fake,\n",
    "                                    img_worst_gt = X_worst_train_mse_gt, img_worst_fake = X_worst_train_mse_fake)\n",
    "        del best_train_mse_idx, X_best_train_mse_gt, X_best_train_mse_fake, best_train_mse,\\\n",
    "            worst_train_mse_idx, X_worst_train_mse_gt, X_worst_train_mse_fake, worst_train_mse\n",
    "        \n",
    "        # Validation Parameter Example MSE Epoch Results\n",
    "        val_logger = plot_results(  logger = val_logger, sel_slice = settings.sel_slice,\n",
    "                                    epoch = epoch, set_ = 'Validation', loss_ = 'MSE',\n",
    "                                    best_idx = best_val_mse_idx, worst_idx = worst_val_mse_idx,\n",
    "                                    best_loss = best_val_mse, worst_loss = worst_val_mse,\n",
    "                                    img_best_gt = X_best_val_mse_gt, img_best_fake = X_best_val_mse_fake,\n",
    "                                    img_worst_gt = X_worst_val_mse_gt, img_worst_fake = X_worst_val_mse_fake)\n",
    "        del best_val_mse_idx, X_best_val_mse_gt, X_best_val_mse_fake, best_val_mse,\\\n",
    "            worst_val_mse_idx, X_worst_val_mse_gt, X_worst_val_mse_fake, worst_val_mse\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Training Parameter Example SSIM Epoch Results\n",
    "        val_logger = plot_results(  logger = val_logger, sel_slice = settings.sel_slice,\n",
    "                                    epoch = epoch, set_ = 'Training', loss_ = 'SSIM',\n",
    "                                    best_idx = best_train_ssim_idx, worst_idx = worst_train_ssim_idx,\n",
    "                                    best_loss = best_train_ssim, worst_loss = worst_train_ssim,\n",
    "                                    img_best_gt = X_best_train_ssim_gt, img_best_fake = X_best_train_ssim_fake,\n",
    "                                    img_worst_gt = X_worst_train_ssim_gt, img_worst_fake = X_worst_train_ssim_fake)\n",
    "        del best_train_ssim_idx, X_best_train_ssim_gt, X_best_train_ssim_fake, best_train_ssim,\\\n",
    "            worst_train_ssim_idx, X_worst_train_ssim_gt, X_worst_train_ssim_fake, worst_train_ssim\n",
    "        \n",
    "        # Validation Parameter Example SSIM Epoch Results\n",
    "        val_logger = plot_results(  logger = val_logger, sel_slice = settings.sel_slice,\n",
    "                                    epoch = epoch, set_ = 'Validation', loss_ = 'SSIM',\n",
    "                                    best_idx = best_val_ssim_idx, worst_idx = worst_val_ssim_idx,\n",
    "                                    best_loss = best_val_ssim, worst_loss = worst_val_ssim,\n",
    "                                    img_best_gt = X_best_val_ssim_gt, img_best_fake = X_best_val_ssim_fake,\n",
    "                                    img_worst_gt = X_worst_val_ssim_gt, img_worst_fake = X_worst_val_ssim_fake)\n",
    "        del best_val_ssim_idx, X_best_val_ssim_gt, X_best_val_ssim_fake, best_val_ssim,\\\n",
    "            worst_val_ssim_idx, X_worst_val_ssim_gt, X_worst_val_ssim_fake, worst_val_ssim\n",
    "        \n",
    "        # --------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Early Stopping Callback Application\n",
    "        mean_val_loss = loss = Variable(((settings.mse_weight / 100) * val_mse_loss)\\\n",
    "                        + ((1 - (settings.mse_weight / 100)) * (1 - val_ssim_loss)))\n",
    "        early_stop = earlyStopping( val_loss = mean_val_loss, epoch = epoch,\n",
    "                                    model = model, optimizer = optimizer)\n",
    "        if early_stop: print(f'Training Finished at Best Epoch #{epoch}'); return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fcglVNN Model Training Script (V1)\n",
    "def fcglVNN_train(\n",
    "    settings,\n",
    "):\n",
    "\n",
    "    # Seed Random State for Reproducibility\n",
    "    torch.manual_seed(settings.seed)\n",
    "    np.random.seed(settings.seed)\n",
    "    random.seed(settings.seed)\n",
    "\n",
    "    # Experiment Logs Directories Initialization\n",
    "    checkpoint_folderpath = os.path.join(f'{settings.modelsave_folderpath}/V{settings.model_version}', 'logs')\n",
    "    train_logger = TensorBoardLogger(checkpoint_folderpath, 'train')\n",
    "    val_logger = TensorBoardLogger(checkpoint_folderpath, 'validation')\n",
    "\n",
    "    # Training & Validation DataLoaders Initialization\n",
    "    train_set = []; val_set = []; viz_logger = []\n",
    "    train_loader = []; val_loader = []\n",
    "    for p, patient_id in enumerate(settings.patient_list):\n",
    "\n",
    "        # Patient Set & DataLoader Initialization\n",
    "        if patient_id in settings.train_patient_list:\n",
    "            train_set.append(   MUDI_fcglVNN(   settings, subject = [patient_id], mode = 'Train',\n",
    "                                                target_param = settings.train_target_param,\n",
    "                                                target_voxel = settings.train_target_voxel))\n",
    "            train_loader.append(DataLoader(     dataset = train_set[-1], pin_memory = True,\n",
    "                                                shuffle = settings.train_sample_shuffle,\n",
    "                                                num_workers = settings.num_workers,\n",
    "                                                batch_size = settings.batch_size))\n",
    "            print(f\"Patient #{patient_id} | Training Set:\")\n",
    "        elif patient_id in settings.val_patient_list:\n",
    "            val_set.append(     MUDI_fcglVNN(   settings, subject = [patient_id], mode = 'Train',\n",
    "                                                target_param = settings.val_target_param,\n",
    "                                                target_voxel = settings.val_target_voxel))\n",
    "            val_loader.append(  DataLoader(     dataset = val_set[-1], pin_memory = True,\n",
    "                                                shuffle = settings.val_sample_shuffle,\n",
    "                                                num_workers = settings.num_workers,\n",
    "                                                batch_size = len(val_set[-1].idxv_target)))\n",
    "            viz_logger.append(  TensorBoardLogger(checkpoint_folderpath, f'validation/p{patient_id}'))\n",
    "            print(f\"Patient #{patient_id} | Validation Set:\")\n",
    "        else: print(f\"Patient #{patient_id} | Test Set:     > Not Included\")\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Model & Optimizer Setup\n",
    "    print(f\"Running\\n     > Training fcglVNN Model with {torch.cuda.device_count()} GPUs!\")\n",
    "    model = fcglVNN(settings)#.to(settings.device)\n",
    "    model = nn.DataParallel(model, device_ids = settings.device_ids).to(settings.device)\n",
    "    optimizer = torch.optim.AdamW(  model.parameters(), lr = settings.base_lr,\n",
    "                                    weight_decay = settings.weight_decay)\n",
    "\n",
    "    # Model Checkpoint Loading\n",
    "    model_filepath = Path(f\"{settings.modelsave_folderpath}/V{settings.model_version}/Best fcglVNN.pt\")\n",
    "    if model_filepath.exists():\n",
    "        checkpoint = torch.load(model_filepath, map_location = settings.device)\n",
    "        model.load_state_dict(checkpoint['Model']); optimizer.load_state_dict(checkpoint['Optimizer'])\n",
    "        save_epoch = checkpoint['Current Epoch']; torch.set_rng_state(checkpoint['RNG State'])\n",
    "        print(f\"     > Loading fcglVNN Model for {settings.model_version}: {save_epoch} Past Epochs\")\n",
    "        del checkpoint\n",
    "    else: save_epoch = -1\n",
    "\n",
    "    # Criterion & Early Stopping Setup\n",
    "    mse_criterion = nn.MSELoss(reduction = 'mean')\n",
    "    earlyStopping = EarlyStopping(settings)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Epoch Iteration Loop\n",
    "    train_iter = 0; val_iter = 0\n",
    "    for epoch in range(save_epoch + 1, settings.num_epochs):\n",
    "\n",
    "        # Training Patient Loop\n",
    "        train_mse_loss = []; print(f\"Training Epoch #{epoch}:\")\n",
    "        for p, patient_id in enumerate(settings.train_patient_list):\n",
    "\n",
    "            # Training Iteration Loop\n",
    "            mask = MUDI_fcglVNN.get_mask(settings, num_patient = patient_id)\n",
    "            train_bar = tqdm(   enumerate(train_loader[p]), total = len(train_loader[p]),\n",
    "                desc = f'Epoch #{epoch} | Training Patient {patient_id}', unit = 'Batches')\n",
    "            for batch_idx, batch in train_bar:\n",
    "\n",
    "                # Forward Propagation\n",
    "                model.train(); model.zero_grad(); optimizer.zero_grad()\n",
    "                X_fake = model(batch[0].to(settings.device))\n",
    "                X_fake = torch.squeeze(X_fake, dim = 1)\n",
    "                gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "                # Backward Propagation\n",
    "                mse_loss = mse_criterion(X_fake, batch[1].to(settings.device))\n",
    "                mse_loss.backward(); optimizer.step(); del batch, X_fake\n",
    "                train_logger.experiment.add_scalar(\"MSE Loss\", mse_loss.item(), train_iter)\n",
    "                train_mse_loss.append(mse_loss.item()); train_iter += 1\n",
    "\n",
    "            # Inter-Patient Reconstruction Parameter Sharing Functionality\n",
    "            if settings.interpatient_sharing:\n",
    "                if p == 0: train_set[p].shuffle(); idxh_target_train = train_set[p].idxh_target\n",
    "                else:\n",
    "                    train_set[p].shuffle(idxh_target = idxh_target_train)\n",
    "                    assert(np.all(  train_set[p].idxh_target == train_set[0].idxh_target)\n",
    "                                    ), f\"     > ERROR: Parameter Sharing incorrectly setup!\"\n",
    "            else: train_set[p].shuffle()\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Validation Set Reconstruction Loss Checkpoints\n",
    "        best_mse = 1000; worst_mse = 0\n",
    "        best_ssim = 0; worst_ssim = 1000\n",
    "\n",
    "        # Validation Patient Loop\n",
    "        with torch.no_grad():\n",
    "            model.eval(); val_ssim_loss = []; val_mse_loss = []\n",
    "            for p, patient_id in enumerate(settings.val_patient_list):\n",
    "            \n",
    "                # Training Iteration Loop\n",
    "                mask = MUDI_fcglVNN.get_mask(settings, num_patient = patient_id)\n",
    "                val_bar = tqdm(   enumerate(val_loader[p]), total = len(val_loader[p]),\n",
    "                    desc = f'Epoch #{epoch} | Validation Patient {patient_id}', unit = 'Batches')\n",
    "                for batch_idx, batch in val_bar:\n",
    "            \n",
    "                    # Batch Handling\n",
    "                    img_gt = torch.Tensor(unmask(batch[1].reshape((1,\n",
    "                        len(batch[1]))), mask).get_fdata().T).to(settings.device)\n",
    "\n",
    "                    # Forward Propagation\n",
    "                    X_fake = torch.squeeze(model(batch[0].to(settings.device)), dim = 1)\n",
    "                    img_fake = torch.Tensor(unmask(X_fake.detach().cpu().reshape((1,\n",
    "                                            len(batch[1]))), mask).get_fdata().T)\n",
    "                    gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "                    # Loss Computation\n",
    "                    mse_loss = mse_criterion(X_fake, batch[1].to(settings.device)).detach().cpu().numpy()\n",
    "                    ssim_loss, ssim_img = ssim( img_gt[0].cpu().numpy().astype(np.float32), \n",
    "                                                img_fake[0].cpu().numpy().astype(np.float32), full = True,\n",
    "                                        data_range = (torch.max(img_gt) - torch.min(img_gt)).cpu().numpy())\n",
    "                    ssim_loss = np.mean(ssim_loss); del ssim_img, batch, X_fake\n",
    "\n",
    "                    # Loss Appending \n",
    "                    val_logger.experiment.add_scalar(\"MSE Loss\", mse_loss.item(), val_iter)\n",
    "                    val_logger.experiment.add_scalar(\"SSIM Index\", ssim_loss, val_iter)\n",
    "                    val_mse_loss.append(mse_loss.item()); val_ssim_loss.append(ssim_loss); val_iter += 1\n",
    "\n",
    "                    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "                    # MSE & SSIM Loss Assignation for Parameters\n",
    "                    param_idx = batch_idx % val_set[p].h_target\n",
    "                    if mse_loss < best_mse:\n",
    "                        best_mse = mse_loss\n",
    "                        best_mse_idx = val_set[p].idxh_target[param_idx]\n",
    "                        img_fake_best_mse = img_fake.detach().cpu()\n",
    "                        img_gt_best_mse = img_gt.detach().cpu()\n",
    "                    if mse_loss > worst_mse:\n",
    "                        worst_mse = mse_loss\n",
    "                        worst_mse_idx = val_set[p].idxh_target[param_idx]\n",
    "                        img_fake_worst_mse = img_fake.detach().cpu()\n",
    "                        img_gt_worst_mse = img_gt.detach().cpu()\n",
    "                    if ssim_loss > best_ssim:\n",
    "                        best_ssim = ssim_loss\n",
    "                        best_ssim_idx = val_set[p].idxh_target[param_idx]\n",
    "                        img_fake_best_ssim = img_fake.detach().cpu()\n",
    "                        img_gt_best_ssim = img_gt.detach().cpu()\n",
    "                    if ssim_loss < worst_ssim:\n",
    "                        worst_ssim = ssim_loss\n",
    "                        worst_ssim_idx = val_set[p].idxh_target[param_idx]\n",
    "                        img_fake_worst_ssim = img_fake.detach().cpu()\n",
    "                        img_gt_worst_ssim = img_gt.detach().cpu()\n",
    "                    gc.collect(); torch.cuda.empty_cache(); del img_gt, img_fake\n",
    "\n",
    "                # Inter-Patient Reconstruction Parameter Sharing Functionality\n",
    "                if settings.interpatient_sharing:\n",
    "                    if p == 0: val_set[p].shuffle(); idxh_target_val = val_set[p].idxh_target\n",
    "                    else:\n",
    "                        val_set[p].shuffle(idxh_target = idxh_target_val)\n",
    "                        assert(np.all(  val_set[p].idxh_target == val_set[0].idxh_target)\n",
    "                                        ), f\"     > ERROR: Parameter Sharing incorrectly setup!\"\n",
    "                else: val_set[p].shuffle()\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "\n",
    "                # MSE Epoch Results\n",
    "                viz_logger[p] = plot_results(   epoch = epoch, loss_ = 'MSE',\n",
    "                                                logger = viz_logger[p], sel_slice = settings.sel_slice,\n",
    "                                                best_idx = best_mse_idx, worst_idx = worst_mse_idx,\n",
    "                                                best_loss = best_mse, worst_loss = worst_mse,\n",
    "                                                img_best_gt = img_gt_best_mse, img_best_fake = img_fake_best_mse,\n",
    "                                                img_worst_gt = img_gt_worst_mse, img_worst_fake = img_fake_worst_mse)\n",
    "                del best_mse_idx, img_gt_best_mse, img_fake_best_mse, best_mse,\\\n",
    "                    worst_mse_idx, img_gt_worst_mse, img_fake_worst_mse, worst_mse\n",
    "\n",
    "                # SSIM Epoch Results\n",
    "                viz_logger[p] = plot_results(   epoch = epoch, loss_ = 'SSIM',\n",
    "                                                logger = viz_logger[p], sel_slice = settings.sel_slice,\n",
    "                                                best_idx = best_ssim_idx, worst_idx = worst_ssim_idx,\n",
    "                                                best_loss = best_ssim, worst_loss = worst_ssim,\n",
    "                                                img_best_gt = img_gt_best_ssim, img_best_fake = img_fake_best_ssim,\n",
    "                                                img_worst_gt = img_gt_worst_ssim, img_worst_fake = img_fake_worst_ssim)\n",
    "                del best_ssim_idx, img_gt_best_ssim, img_fake_best_ssim, best_ssim,\\\n",
    "                    worst_ssim_idx, img_gt_worst_ssim, img_fake_worst_ssim, worst_ssim\n",
    "                \n",
    "        # End of Epoch Mean Loss Writing\n",
    "        train_mse_loss = np.mean(np.array(train_mse_loss))\n",
    "        val_mse_loss = np.mean(np.array(val_mse_loss))\n",
    "        val_ssim_loss = np.mean(np.array(val_ssim_loss))\n",
    "        train_logger.experiment.add_scalar(\"Mean MSE Loss\", train_mse_loss, epoch)\n",
    "        val_logger.experiment.add_scalar(\"Mean MSE Loss\", val_mse_loss, epoch)        \n",
    "        val_logger.experiment.add_scalar(\"Mean SSIM Index\", val_ssim_loss, epoch)\n",
    "        \n",
    "        # --------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Early Stopping Callback Application\n",
    "        early_stop = earlyStopping( loss = val_mse_loss, epoch = epoch,\n",
    "                                    model = model, optimizer = optimizer)\n",
    "        if early_stop: print(f'     > Training Finished at Epoch #{epoch}'); return\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Performance* **Callbacks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping Callback Functionality\n",
    "class EarlyStopping:\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings\n",
    "    ):\n",
    "        self.best_path = Path(f\"{settings.modelsave_folderpath}/V{settings.model_version}/Best fcglVNN.pt\")\n",
    "        self.local_path = Path(f\"{settings.modelsave_folderpath}/V{settings.model_version}/fcglVNN.pt\")\n",
    "        self.patience = settings.es_patience; self.delta = settings.es_delta; self.early_stop = False\n",
    "        self.counter = 0; self.best_score = -np.inf; self.local_score = -np.inf; self.local_loss = np.Inf; self.best_loss = np.inf\n",
    "    \n",
    "    # Callback Application Function\n",
    "    def __call__(\n",
    "        self,\n",
    "        loss,\n",
    "        model,\n",
    "        optimizer,\n",
    "        epoch: int = 0\n",
    "    ):  \n",
    "\n",
    "        # Best / First Local Result Checkpoint Saving\n",
    "        if -loss > self.local_score + self.delta or self.local_score is None:\n",
    "            self.save_checkpoint(loss, model, optimizer, epoch, best = False)\n",
    "            self.local_score = -loss; self.counter = 0\n",
    "        \n",
    "        # Checkpoint Counter Startup\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            print(f'     > EarlyStopping Counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience: self.early_stop = True\n",
    "        \n",
    "        # Best / First Overall Result Checkpoint Saving\n",
    "        if -loss > self.best_score or self.best_score is None:\n",
    "            self.save_checkpoint(loss, model, optimizer, epoch, best = True)\n",
    "            self.best_score = -loss\n",
    "        return self.early_stop\n",
    "\n",
    "    # Model Saving Functionality\n",
    "    def save_checkpoint(\n",
    "        self,\n",
    "        loss,\n",
    "        model,\n",
    "        optimizer,\n",
    "        epoch: int = 0,\n",
    "        best: bool = False\n",
    "    ):\n",
    "        if best: path = self.best_path\n",
    "        else: path = self.local_path\n",
    "        if best: print(f\"     > Loss Decreased ({self.best_loss:.6f} --> {loss:.6f})\\n     > Saving Best Model\"); self.best_loss = loss\n",
    "        else: print(f\"     > Loss Decreased ({self.local_loss:.6f} --> {loss:.6f})\\n     > Saving Model\"); self.local_loss = loss\n",
    "        torch.save({'Model': model.state_dict(),\n",
    "                    'Optimizer': optimizer.state_dict(),\n",
    "                    'Current Epoch': epoch,\n",
    "                    'RNG State': torch.get_rng_state()}, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction Callback Functionality\n",
    "def ReconCallback(\n",
    "    set: MUDI_fcglVNN,                  # Keras MUDI DataLoader\n",
    "    X: torch.Tensor,                    # Selected Patient Data\n",
    "    X_fake: torch.Tensor,               # Selected Patient Reconstruction\n",
    "    mask: nib.nifti1.Nifti1Image,       # Selected Patient's Mask\n",
    "    img: np.ndarray,                    # Selected Patient Image\n",
    "    sel_slice: int = 25,                # Selected Reconstruction Slice\n",
    "    epoch: int = 0                      # Epoch Number\n",
    "):\n",
    "\n",
    "    # Patient Image Reconstruction\n",
    "    recon_loss = nn.MSELoss()(X_fake, X)\n",
    "    best_train_loss = torch.ones(1, dtype = torch.float64) * 1000\n",
    "    worst_train_loss = torch.zeros(1, dtype = torch.float64)\n",
    "    best_val_loss = torch.ones(1, dtype = torch.float64) * 1000\n",
    "    worst_val_loss = torch.zeros(1, dtype = torch.float64)\n",
    "\n",
    "    # Voxel Reconstruction Loop for all Selected Target Parameters\n",
    "    with alive_bar( len(set.idxh_recon),\n",
    "                    title = f'Epoch {epoch} | Reconstruction',\n",
    "                    force_tty = True) as progress_bar:\n",
    "        for i, param in enumerate(set.idxh_recon):\n",
    "\n",
    "            # Selected Target Parameter Image Reconstruction\n",
    "            X_param = X_fake[np.where(np.arange(len(X_fake)) % set.num_recon == i)[0]]\n",
    "            X_gt = X[np.where(np.arange(len(X)) % set.num_recon == i)[0]]\n",
    "            #X_gt = X[:, param].T.reshape((len(X_param), 1))\n",
    "            loss = nn.MSELoss()(X_param, X_gt); del X_gt\n",
    "            \n",
    "            # Loss Computation for Training Parameter\n",
    "            if param in set.idxh_train:\n",
    "                if loss < best_train_loss:\n",
    "                    best_train_loss = loss\n",
    "                    best_train_idx = param\n",
    "                    X_train_best = X_param\n",
    "                if loss > worst_train_loss:\n",
    "                    worst_train_loss = loss\n",
    "                    worst_train_idx = param\n",
    "                    X_train_worst = X_param\n",
    "\n",
    "            # Loss Computation for Validation Parameter\n",
    "            elif param in set.idxh_val:\n",
    "                if loss < best_val_loss:\n",
    "                    best_val_loss = loss\n",
    "                    best_val_idx = param\n",
    "                    X_val_best = X_param\n",
    "                if loss > worst_val_loss:\n",
    "                    worst_val_loss = loss\n",
    "                    worst_val_idx = param\n",
    "                    X_val_worst = X_param\n",
    "            \n",
    "            else: print(\"ERROR: Reconstruction Parameter not Found!\")\n",
    "            gc.collect(); torch.cuda.empty_cache()\n",
    "            time.sleep(0.01); progress_bar()\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Training Image Unmasking of Original & Reconstructed Results\n",
    "    X_train_best = unmask(X_train_best.T, mask).get_fdata().T\n",
    "    X_train_worst = unmask(X_train_worst.T, mask).get_fdata().T\n",
    "\n",
    "    # Training Example Original & Best Reconstructed Image Subplots\n",
    "    train_figure = plt.figure(figsize = (20, 20))\n",
    "    plt.xticks([]); plt.yticks([]); plt.grid(False); plt.tight_layout()\n",
    "    plt.subplot(2, 2, 1, title = f'Target Image (Parameter #{best_train_idx})')\n",
    "    plt.imshow(img[best_train_idx, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "    plt.subplot(2, 2, 2, title = f'Best Reconstruction (Parameter #{best_train_idx})')\n",
    "    plt.imshow(X_train_best[0, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "    del best_train_idx, X_train_best\n",
    "    \n",
    "    # Training Example Original & Worst Reconstructed Image Subplots\n",
    "    plt.subplot(2, 2, 3, title = f'Target Image (Parameter #{worst_train_idx})')\n",
    "    plt.imshow(img[worst_train_idx, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "    plt.subplot(2, 2, 4, title = f'Worst Reconstruction (Parameter #{worst_train_idx})')\n",
    "    plt.imshow(X_train_worst[0, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "    del worst_train_idx, X_train_worst\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Training Image Unmasking of Original & Reconstructed Results\n",
    "    X_val_best = unmask(X_val_best.T, mask).get_fdata().T\n",
    "    X_val_worst = unmask(X_val_worst.T, mask).get_fdata().T\n",
    "\n",
    "    # Training Example Original & Best Reconstructed Image Subplots\n",
    "    val_figure = plt.figure(figsize = (20, 20))\n",
    "    plt.xticks([]); plt.yticks([]); plt.grid(False); plt.tight_layout()\n",
    "    plt.subplot(2, 2, 1, title = f'Target Image (Parameter #{best_val_idx})')\n",
    "    plt.imshow(img[best_val_idx, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "    plt.subplot(2, 2, 2, title = f'Best Reconstruction (Parameter #{best_val_idx})')\n",
    "    plt.imshow(X_val_best[0, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "    del best_val_idx, X_val_best\n",
    "    \n",
    "    # Training Example Original & Worst Reconstructed Image Subplots\n",
    "    plt.subplot(2, 2, 3, title = f'Target Image (Parameter #{worst_val_idx})')\n",
    "    plt.imshow(img[worst_val_idx, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "    plt.subplot(2, 2, 4, title = f'Worst Reconstruction (Parameter #{worst_val_idx})')\n",
    "    plt.imshow(X_val_worst[0, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "    del worst_val_idx, X_val_worst\n",
    "    return {'Full Reconstruction Loss': recon_loss,\n",
    "            'Training Plot': train_figure,\n",
    "            'Best Training Loss': best_train_loss,\n",
    "            'Worst Training Loss': worst_train_loss,\n",
    "            'Validation Plot': val_figure,\n",
    "            'Best Validation Loss': best_val_loss,\n",
    "            'Worst Validation Loss': worst_val_loss}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structural Similarity (SSIM) Loss Function\n",
    "class SSIMLoss(torch.nn.Module):\n",
    "\n",
    "    #https://github.com/Po-Hsun-Su/pytorch-ssim/blob/master/pytorch_ssim/__init__.py\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        window_size: int = 11,\n",
    "        size_average: bool = True\n",
    "    ):\n",
    "        super(SSIMLoss, self).__init__()\n",
    "        self.window_size = window_size; self.size_average = size_average\n",
    "        self.num_channel = 1; self.window = self.create_window(window_size, self.num_channel)\n",
    "\n",
    "    # Loss Application Function\n",
    "    def forward(\n",
    "        self,\n",
    "        X_gt: torch.Tensor,\n",
    "        X_pred: torch.Tensor\n",
    "    ):\n",
    "\n",
    "        # Loss Function Application\n",
    "        num_channel = X_gt.shape[1]\n",
    "        if num_channel == self.num_channel and self.window.data.type() == X_gt.data.type(): window = self.window\n",
    "        else:\n",
    "            window = self.create_window(self.window_size, num_channel)\n",
    "            if X_gt.is_cuda: window = window.cuda(X_gt.get_device())\n",
    "            window = window.type_as(X_gt)\n",
    "            self.window = window; self.num_channel = num_channel\n",
    "        return self.ssim_loss(X_gt, X_pred, window, self.window_size, num_channel, self.size_average)\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Gaussian Function Creation Functionality\n",
    "    def gaussian(\n",
    "        self,\n",
    "        window_size: int,\n",
    "        sigma: float\n",
    "    ):\n",
    "        gaussian = torch.Tensor([exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\n",
    "        return gaussian / gaussian.sum()\n",
    "\n",
    "    # Window Creation Functionality\n",
    "    def create_window(\n",
    "        self,\n",
    "        window_size: int,\n",
    "        num_channel: int\n",
    "    ):\n",
    "        window1D = self.gaussian(window_size, 1.5).unsqueeze(1)\n",
    "        window2D = window1D.mm(window1D.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "        return Variable(window2D.expand(num_channel, 1, window_size, window_size).contiguous())\n",
    "\n",
    "    # Structural Similarity Application Function\n",
    "    def ssim_loss(\n",
    "        self,\n",
    "        X_gt: torch.Tensor,\n",
    "        X_pred: torch.Tensor,\n",
    "        window,\n",
    "        window_size: int,\n",
    "        num_channel: int,\n",
    "        size_average: bool = True\n",
    "    ):\n",
    "\n",
    "        # Gaussian Properties Computation (Mu)\n",
    "        mu1 = F.conv2d(X_gt, window, padding = window_size // 2, groups = num_channel)\n",
    "        mu2 = F.conv2d(X_pred, window, padding = window_size // 2, groups = num_channel)\n",
    "        square_mu1 = mu1.pow(2); square_mu2 = mu2.pow(2); C1 = 0.01**2; C2 = 0.03**2\n",
    "\n",
    "        # Gaussian Properties Computation (Sigma)\n",
    "        sigma1 = F.conv2d(X_gt * X_gt, window, padding = window_size // 2, groups = num_channel) - square_mu1\n",
    "        sigma2 = F.conv2d(X_pred * X_pred, window, padding = window_size // 2, groups = num_channel) - square_mu2\n",
    "        sigma = F.conv2d(X_gt * X_pred, window, padding = window_size//2, groups = num_channel) - (mu1 * mu2)\n",
    "\n",
    "        # Structural Similarity Index Map Construction\n",
    "        ssim_map = ((2 * (mu1 * mu2) + C1) * (2 * sigma + C2)) / ((square_mu1 + square_mu2 + C1) * (square_mu1 + square_mu2 + C2))\n",
    "        if size_average: return ssim_map.mean()\n",
    "        else: return ssim_map.mean(1).mean(1).mean(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structural Similarity (SSIM) Loss Function (Original)\n",
    "\n",
    "#https://github.com/Po-Hsun-Su/pytorch-ssim/tree/master\n",
    "\n",
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
    "    return gauss/gauss.sum()\n",
    "\n",
    "def create_window(window_size, channel):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
    "    return window\n",
    "\n",
    "def _ssim(img1, img2, window, window_size, channel, size_average = True):\n",
    "    mu1 = F.conv2d(img1, window, padding = window_size//2, groups = channel)\n",
    "    mu2 = F.conv2d(img2, window, padding = window_size//2, groups = channel)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1*mu2\n",
    "\n",
    "    sigma1_sq = F.conv2d(img1*img1, window, padding = window_size//2, groups = channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2*img2, window, padding = window_size//2, groups = channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1*img2, window, padding = window_size//2, groups = channel) - mu1_mu2\n",
    "\n",
    "    C1 = 0.01**2\n",
    "    C2 = 0.03**2\n",
    "\n",
    "    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "    if size_average:\n",
    "        return ssim_map.mean()\n",
    "    else:\n",
    "        return ssim_map.mean(1).mean(1).mean(1)\n",
    "\n",
    "class SSIM(torch.nn.Module):\n",
    "    def __init__(self, window_size = 11, size_average = True):\n",
    "        super(SSIM, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.size_average = size_average\n",
    "        self.channel = 1\n",
    "        self.window = create_window(window_size, self.channel)\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        (_, channel, _, _) = img1.size()\n",
    "\n",
    "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
    "            window = self.window\n",
    "        else:\n",
    "            window = create_window(self.window_size, channel)\n",
    "            \n",
    "            if img1.is_cuda:\n",
    "                window = window.cuda(img1.get_device())\n",
    "            window = window.type_as(img1)\n",
    "            \n",
    "            self.window = window\n",
    "            self.channel = channel\n",
    "\n",
    "\n",
    "        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n",
    "\n",
    "def ssim(img1, img2, window_size = 11, size_average = True):\n",
    "    (_, channel, _, _) = img1.size()\n",
    "    window = create_window(window_size, channel)\n",
    "    \n",
    "    if img1.is_cuda:\n",
    "        window = window.cuda(img1.get_device())\n",
    "    window = window.type_as(img1)\n",
    "    \n",
    "    return _ssim(img1, img2, window, window_size, channel, size_average)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Performance* **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fcglVNN Model Testing Script (V1)\n",
    "def fcglVNN_test(\n",
    "    settings,\n",
    "    patient_id: int = 15\n",
    "):\n",
    "        \n",
    "    # Seed Random State for Reproducibility\n",
    "    torch.manual_seed(settings.seed)\n",
    "    np.random.seed(settings.seed)\n",
    "    random.seed(settings.seed)\n",
    "\n",
    "    # Model & Optimizer Setup\n",
    "    print(f\"Evaluation\\n     > Testing fcglVNN Model with {torch.cuda.device_count()} GPUs!\")\n",
    "    model = fcglVNN(settings)#.to(settings.device)\n",
    "    model = nn.DataParallel(model, device_ids = settings.device_ids).to(settings.device)\n",
    "    #optimizer = torch.optim.AdamW(  model.parameters(), lr = settings.base_lr,\n",
    "    #                                weight_decay = settings.weight_decay)\n",
    "\n",
    "    # Model Checkpoint Loading\n",
    "    model_filepath = Path(f\"{settings.modelsave_folderpath}/V{settings.model_version}/Best fcglVNN.pt\")\n",
    "    assert(model_filepath.exists()), f\"ERROR: fcglVNN Model (V{settings.model_version}) not Found!\"\n",
    "    checkpoint = torch.load(model_filepath, map_location = settings.device)\n",
    "    model.load_state_dict(checkpoint['Model'])\n",
    "    #optimizer.load_state_dict(checkpoint['Optimizer'])\n",
    "    save_epoch = checkpoint['Current Epoch']\n",
    "    torch.set_rng_state(checkpoint['RNG State'])\n",
    "\n",
    "    # Experiment Logs Directories Initialization\n",
    "    checkpoint_folderpath = os.path.join(f'{settings.modelsave_folderpath}/V{settings.model_version}', 'logs')\n",
    "    mse_criterion = nn.MSELoss(reduction = 'mean'); del checkpoint\n",
    "    test_logger = TensorBoardLogger(checkpoint_folderpath, f'test/epoch{save_epoch}/p{patient_id}')\n",
    "    print(f\"     > Evaluating fcglVNN Model for Version #{settings.model_version}: {save_epoch} Past Epochs\")\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # DataSet & DataLoader Initialization\n",
    "    mask = MUDI_fcglVNN.get_mask(settings, num_patient = patient_id)\n",
    "    test_set = MUDI_fcglVNN(    settings, subject = [patient_id], mode = 'Train',\n",
    "                                target_param = settings.val_target_param,\n",
    "                                target_voxel = settings.val_target_voxel)\n",
    "    test_loader = DataLoader(   dataset = test_set, shuffle = False,\n",
    "                                num_workers = 0,#settings.num_workers,\n",
    "                                batch_size = len(test_set.idxv_target),\n",
    "                                pin_memory = False)\n",
    "    \n",
    "    img_fake = np.empty((len(test_set.idxh_target), mask.shape[2], mask.shape[1], mask.shape[0]))\n",
    "    img_mse = np.empty((len(test_set.idxh_target), mask.shape[2], mask.shape[1], mask.shape[0]))\n",
    "    img_ssim = np.empty((len(test_set.idxh_target), mask.shape[2], mask.shape[1], mask.shape[0]))\n",
    "\n",
    "    # Batch Iteration Loop\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_bar = tqdm(   enumerate(test_loader), total = len(test_loader),\n",
    "            desc = f'Test Patient {patient_id}', unit = 'Batches')\n",
    "        for batch_idx, batch in test_bar:\n",
    "\n",
    "            # Forward Propagation\n",
    "            img_gt = torch.Tensor(unmask(batch[1].reshape((1,\n",
    "                        len(batch[1]))), mask).get_fdata().T).to(settings.device)\n",
    "            X_fake = torch.squeeze(model(batch[0].to(settings.device)), dim = 1)\n",
    "            img_fake[batch_idx] = torch.Tensor(unmask(X_fake.detach().cpu().reshape((1,\n",
    "                                    len(batch[1]))), mask).get_fdata().T).cpu().numpy()\n",
    "            gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "            # Loss Computation\n",
    "            mse_loss = mse_criterion(X_fake, batch[1].to(settings.device)).detach().cpu().numpy()\n",
    "            ssim_loss, img_ssim[batch_idx] = ssim(  img_gt[0].cpu().numpy().astype(np.float32), \n",
    "                                                    img_fake[batch_idx].astype(np.float32), full = True,\n",
    "                                            data_range = (torch.max(img_gt) - torch.min(img_gt)).cpu().numpy())\n",
    "            img_mse[batch_idx] = (img_fake[batch_idx] - img_gt[0].cpu().numpy()) ** 2\n",
    "            ssim_loss = np.mean(ssim_loss); del batch, X_fake\n",
    "            \n",
    "            # --------------------------------------------------------------------------------------------\n",
    "\n",
    "            # Target Parameter Plot Initialization\n",
    "            param_target = test_set.idxh_target[batch_idx % test_set.h_target]; test_plot = plt.figure(figsize = (20, 22))\n",
    "            plt.suptitle(f'Test Patient #{patient_id} | Parameter #{param_target} | Slice #{settings.sel_slice}' +\n",
    "                                                f'\\nMSE: {np.round(mse_loss, 5)} | SSIM: {np.round(ssim_loss, 5)}\\n')\n",
    "            plt.xticks([]); plt.yticks([]); plt.grid(False); plt.tight_layout(); gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "            # Original, Reconstruction & Loss Heatmap Plotting\n",
    "            plt.subplot(2, 2, 1, title = 'Original Scan'); plt.imshow(img_gt[0, settings.sel_slice, :, :], cmap = plt.cm.binary)\n",
    "            plt.subplot(2, 2, 2, title = 'Reconstructed Scan'); plt.imshow(img_fake[batch_idx, settings.sel_slice, :, :], cmap = plt.cm.binary)\n",
    "            plt.subplot(2, 2, 3, title = 'MSE Loss Heatmap'); plt.imshow(img_mse[batch_idx, settings.sel_slice, :, :], cmap = 'hot')\n",
    "            plt.subplot(2, 2, 4, title = 'SSIM Index Mask'); plt.imshow(img_ssim[batch_idx, settings.sel_slice, :, :], cmap = plt.cm.binary)\n",
    "            \n",
    "            # Tensorboard Reconstruction Callback\n",
    "            test_logger.experiment.add_figure(f\"Target Results\", test_plot, batch_idx)\n",
    "            test_logger.experiment.add_scalar(f\"MSE Loss\", mse_loss, batch_idx)\n",
    "            test_logger.experiment.add_scalar(f\"SSIM Index\", ssim_loss, batch_idx)\n",
    "    \n",
    "    # Result Image Saving\n",
    "    img_fake = nib.Nifti1Image(img_fake.T, affine = np.eye(4)); img_fake.header.get_xyzt_units()\n",
    "    img_mse = nib.Nifti1Image(img_mse.T, affine = np.eye(4)); img_mse.header.get_xyzt_units()\n",
    "    img_ssim = nib.Nifti1Image(img_ssim.T, affine = np.eye(4)); img_ssim.header.get_xyzt_units()\n",
    "    nib.save(img_fake, Path(f\"{checkpoint_folderpath}/test/epoch{save_epoch}/p{patient_id}/img_fake.nii.gz\"))\n",
    "    nib.save(img_mse, Path(f\"{checkpoint_folderpath}/test/epoch{save_epoch}/p{patient_id}/img_mse.nii.gz\"))\n",
    "    nib.save(img_ssim, Path(f\"{checkpoint_folderpath}/test/epoch{save_epoch}/p{patient_id}/img_ssim.nii.gz\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5sAAAIBCAYAAADH4auBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAACgHklEQVR4nOzdd3xVRf7/8XcgkMSEBBKSEFoo0kVFUERRXEURRQWxF0CwYy+rfHfBLupa2F0Byyq4Cj8VVFbXtSAqKiLWtUuTXgIBklBDyfz+8JG7nM8Zcm/CxYC+no9HHrtz7plz5p5zvTPDPZ/PJDjnnAAAAAAAiKMa1d0AAAAAAMBvD5NNAAAAAEDcMdkEAAAAAMQdk00AAAAAQNwx2QQAAAAAxB2TTQAAAABA3DHZBAAAAADEHZNNAAAAAEDcMdkEAAAAAMQdk00AAIAqev/995WQkKD333+/upuyTxk/frwSEhKquxn4jbr99tvVrFmzuB5z0KBBoWMmJCTo9ttvj+t5fmuYbAIAgCpJSEiI6S8eE7FNmzbp9ttvj/lY5ZPA8r9atWqpRYsWGjBggH7++edKn3/MmDEaP358pevFy7333qspU6ZUqa5zTpmZmXr88cclSV999ZUSEhK0cOHC0L733HOPTj31VOXm5lY4kL799tu99zo5OblKbazIzsevUaOGGjZsqBNOOOE3P8Gv7Ge+unz99ddKSEjQ7NmzJUmPPPKId6I3bdo0DR48WK1bt9Z+++2nFi1a6OKLL9aKFSsC+23atEmjR4/WCSecoLy8PNWpU0edOnXS2LFjtWPHjri3f/Xq1br22mvVtm1bpaSkKCcnR4cddphuueUWbdiwIe7ni7frr79e3bp1i5QPOuig0H+3lbmmCxcu3OV3+fPPP1/p9iVW6V0BAIDfvWeffTZQ/uc//6mpU6eGtrdr1263z7Vp0ybdcccdkqRjjjkm5nrXXHONDj30UG3btk1ffvmlnnjiCb3++uv69ttv1bBhw5iPM2bMGNWvX1+DBg0KbD/66KO1efNm1a5dO+ZjVcW9996rM844Q3379q103blz52rdunU6/PDDJUkzZ85Ubm6ud0Lw5z//WQ0aNFCnTp301ltvRT322LFjlZaWFinXrFmz0u2LxfHHH68BAwbIOacFCxZozJgxOvbYY/X666+rd+/ee+Sc1a2qn/lf26xZs5SZmanWrVtL+uXzVf5Z29ktt9yitWvX6swzz1SrVq30888/69FHH9W///1v/fe//1WDBg0kST///LOuvvpqHXfccbrhhhuUnp6ut956S1deeaU++eQTPfPMM3Fr+9q1a9WlSxeVlJRo8ODBatu2rdasWaNvvvlGY8eO1RVXXBH4fFubN29WYmL1TqdmzZoVud7r16/Xd999p/vvvz+wT1Wu6bnnnquTTjopsG3nSW2smGwCAIAqueCCCwLlTz75RFOnTg1tr05HHXWUzjjjDEnSRRddpNatW+uaa67RM888o2HDhu328WvUqLFHfs2Lp08//VRpaWk64IADJP0yGejatat33wULFqhZs2YqLCxUdnZ21GOfccYZql+/flzb69O6devA56pfv3468MADNWrUqN2ebG7cuFGpqam728R9Rrzf76effqrDDjss8lj0zJkzdcMNN4T2e/jhh9W9e3fVqPG/BytPPPFE9ejRQ48++qjuvvtuSVKDBg307bffqkOHDpH9LrvsMg0ePFjjxo3T8OHDtf/++8el7U899ZQWL16sGTNm6Igjjgi8VlJSEvUfkar7v/3t27frq6++0rXXXivpl3tRVlamww47LLBfVa7pIYccEpfvch6jBQAAe0xZWZlGjRqlDh06KDk5Wbm5ubrsssu0bt26wH6ff/65evXqpfr16yslJUXNmzfX4MGDJf3yWFf5xOeOO+6IPNJVlVipY489VtIvkypJGjdunI499ljl5OQoKSlJ7du319ixYwN1mjVrpu+//17Tp0+PnLv8l6ZdxWzOmjVLJ554ojIyMrTffvupR48emjFjRmCf8kdR582bp0GDBqlu3brKyMjQRRddpE2bNkX2S0hI0MaNG/XMM89Ezm9/YbU2bNigwsJCFRYW6qOPPlLHjh21bt06FRYWaubMmWrfvr0KCwtD96GycW7OOZWUlMg5V6l6u6tjx46qX79+5D5++OGHOvPMM9W0aVMlJSWpSZMmuv7667V58+ZAvUGDBiktLU3z58/XSSedpDp16uj888+v0jEWL16sPn36KC0tTY0aNdLo0aMlSd9++62OPfZYpaamKj8/XxMnTgy1v6ioSNddd52aNGmipKQk7b///rr//vtVVlYmKbbP/E8//aQzzjhDmZmZSk5OVpcuXfTqq68GzlMeGzt9+nRdeeWVysnJUePGjSX98ivYddddp2bNmikpKUk5OTk6/vjj9eWXX0a9/uWfpcLCQs2aNUsHHHCACgsL9f3332vp0qVq1aqVCgsLA4+hHn300YGJZvm2zMxM/fjjj5Ft9evXD0yKyvXr10+SAvvurvnz56tmzZreX2LT09OjTiZ930PLli3TkCFD1LBhQyUlJal58+a64oortHXr1sg+0e5/RbZt2xa59jNmzNCWLVsi1/u9995Ts2bNVFZWpsLCQm3btk1S1a/pxo0bA+2uCn7ZBAAAe8xll12m8ePH66KLLtI111yjBQsW6NFHH9VXX32lGTNmqFatWlq1apVOOOEEZWdn69Zbb1XdunW1cOFCvfzyy5Kk7OzsyCNt/fr10+mnny5JOvDAAyvdnvnz50uSsrKyJP3yGGiHDh106qmnKjExUa+99pquvPJKlZWVaejQoZKkUaNG6eqrr1ZaWpr+9Kc/SZJyc3N3eY53331XvXv3VufOnXXbbbepRo0akUnthx9+GPrV4ayzzlLz5s01cuRIffnll/rHP/6hnJycyKNwzz77rC6++GIddthhuvTSSyVJLVu2rPB9XnXVVaFH43b+pfK+++7Tfffdp/z8fG/sZqxatGihDRs2KDU1VX379tVDDz1U4bWJl3Xr1mndunWRX2MmTZqkTZs26YorrlBWVpY+/fRT/f3vf9fSpUs1adKkQN3t27erV69e6t69ux588EHtt99+lT7Gjh071Lt3bx199NF64IEHNGHCBF111VVKTU3Vn/70J51//vk6/fTT9dhjj2nAgAHq1q2bmjdvLumXx2N79OihZcuW6bLLLlPTpk318ccfa9iwYVqxYoVGjRoV9TP//fff68gjj1SjRo106623KjU1VS+++KL69u2rl156KTKJKHfllVcqOztbI0aM0MaNGyVJl19+uSZPnqyrrrpK7du315o1a/TRRx/pxx9/1CGHHFLh9e/UqZMWLVoUKX/33Xd68MEHI+VTTjlFkjRw4MAKY503bNigDRs2xPTr+MqVKyUprr+k5+fna8eOHXr22Wc1cODA3T7e8uXLddhhh6moqEiXXnqp2rZtq2XLlmny5MnatGmTateuHdP9r8iMGTP0hz/8IbCtc+fOgXL5f+vvvfdehY9gV3RN77jjDt18881KSEhQ586ddc899+iEE06I4SoYDgAAIA6GDh3qdh5afPjhh06SmzBhQmC/N998M7D9lVdecZLcZ599tstjr1692klyt912W0xtee+995wk9/TTT7vVq1e75cuXu9dff901a9bMJSQkRM61adOmUN1evXq5Fi1aBLZ16NDB9ejRY5fnee+995xzzpWVlblWrVq5Xr16ubKyssh+mzZtcs2bN3fHH398ZNttt93mJLnBgwcHjtmvXz+XlZUV2JaamuoGDhwY03t3zrnvv//eTZ061U2ePNlJcg899JCbOnWqu/XWW11SUpJ7++233dSpU91HH33krR/teo8aNcpdddVVbsKECW7y5Mnu2muvdYmJia5Vq1auuLg4avvGjRvnYh2GSnJDhgxxq1evdqtWrXKzZs1yxx13XOR9Oee/jyNHjnQJCQlu0aJFkW0DBw50ktytt94a2r+yx7j33nsj29atW+dSUlJcQkKCe/755yPbf/rpp9B1vOuuu1xqaqqbM2dO4Fy33nqrq1mzplu8eLFzruJ7cNxxx7mOHTu6LVu2RLaVlZW5I444wrVq1Sqyrfw6d+/e3W3fvj1wjIyMDDd06NDQsWPx0UcfualTp7rhw4e7xMRE98Ybb7ipU6e63r17uy5duripU6e6qVOnuu+//77C49x1111Okps2bVqF+5WWlrr27du75s2bu23btkVt32233eby8/Oj7rdy5UqXnZ3tJLm2bdu6yy+/3E2cONEVFRWF9h04cGDomPb+DBgwwNWoUcP7XVb+fRDr/d+VtWvXRq5v165d3QknnOCmTp3q3nzzTVe7dm33pz/9KfL62rVrd3mcXV3TRYsWuRNOOMGNHTvWvfrqq27UqFGuadOmrkaNGu7f//53hW3zYbIJAADiwk42r7nmGpeRkeFWrVrlVq9eHfhLS0tzF198sXPufxO22267zW3dutV77KpONu1fdna2++c//+mtU1RU5FavXu3uvfdeJykw4Ix1svnll186Se6ZZ54JveeLL77YJSUluR07djjn/jfZ/PTTTwPHfPjhh52kwKStspPNcv/6179crVq13IYNG5xzv9yjY445Jmq9yl5v55ybMGGCk+RGjhwZdd/KTjbtX3Jysrvhhhsi13JnGzZscKtXr3bTp093ktyUKVMir5VPFHeePPrEcoxVq1YF6hx88MEuLS0t8I8MzjlXt25dd+GFF0bKBx54oDvxxBNDn4933nnHSXLPPfecc27X92DNmjUuISHB3XXXXaFj3HHHHU6SW7p0qXPuf9f5mWeeCb3H/Px816VLF7ds2bIKr0VFrr/+etetW7dIuUOHDu7222+Pqe706dNdYmKiO+uss6Lue8kllzhJ7vXXX4/p2LFONp1zbvny5e7yyy93ubm5kc9X7dq13Z133hm4l9Emmzt27HDp6enutNNOq/B8sd7/aMrKylxWVpZ7/PHHnXPOffbZZ06SW7hwYUz1K3NN16xZ43Jzc12bNm1iOvbOeIwWAADsEXPnzlVxcbFycnK8r69atUqS1KNHD/Xv31933HGHHnnkER1zzDHq27evzjvvPCUlJe1WG0aMGKGjjjpKNWvWVP369dWuXbtA9sgZM2botttu08yZMwNxkpJUXFysjIyMSp1v7ty5klThI3nFxcWqV69epNy0adPA6+WvrVu3Tunp6ZU6v/TLY5rl7+XNN9/UwQcfrM2bN2vz5s169913dfLJJ6uwsFBSfB9JPO+883TjjTfqnXfe0a233hq340rSaaedpquuukoJCQmqU6eOOnToEEhys3jxYo0YMUKvvvpqKA61uLg4UE5MTIzELe6sMsdITk4OJVDKyMhQ48aNQ+uHZmRkBI43d+5cffPNN7tMwFT+38WuzJs3T845DR8+XMOHD9/lMRo1ahQplz/Cu7MHHnhAAwcOVJMmTdS5c2eddNJJGjBggFq0aFHh+YuLiyOxgNOmTdOxxx6rwsJCrV27Vt9//73uvvtuFRYWqlatWrv87+enn35Sv379dMABB+gf//hHhef7y1/+oieffFJ33XVXKDtqPOTl5Wns2LEaM2aM5s6dq7feekv333+/RowYoby8PF188cUxHWf16tUqKSmJJOLald25/2VlZVq7dq2kX+Is16xZo4MOOkiFhYV644031LhxY6WmpqqwsFB16tTZ5fdnZa9pZmamLrroIt13331aunSp97+fXWGyCQAA9oiysjLl5ORowoQJ3tfLB1sJCQmaPHmyPvnkE7322mt66623NHjwYD300EP65JNPKlx6IJqOHTuqZ8+e3tfmz5+v4447Tm3bttXDDz+sJk2aqHbt2vrPf/6jRx55JKZkHVZ5nb/85S86+OCDvfvY97Or5UJcFZPuPPDAA5ElM8rtPLD98ccfI/F1VT3HrjRp0iQyGI6nxo0b7/I+7tixQ8cff7zWrl2rW265RW3btlVqaqqWLVumQYMGhe5jUlJSKFFNZY+xq3sWy70sKyvT8ccfrz/+8Y/efcuXENmV8rbcdNNN6tWrl3cfm1k0JSUltM9ZZ52lo446Sq+88orefvtt/eUvf9H999+vl19+ucIMv6eddpqmT58eKX/zzTeBOMPyeNEePXp41whdsmSJTjjhBGVkZOg///mP6tSps8tzjR8/Xrfccosuv/xy/fnPf97lfvGQkJCg1q1bq3Xr1jr55JPVqlUrTZgwIebJZqx25/4vXrw49A8HNrlR+X/r48aN8yYSq+o1bdKkiaRflothsgkAAKpdy5Yt9c477+jII4/0Dnatww8/XIcffrjuueceTZw4Ueeff76ef/55XXzxxaFfi+LhtddeU2lpqV599dXAr4vvvfdeaN9Yz1+euCc9PX2Xk6OqqMz7HzBggLp3765NmzbptNNOi0x8P/jgA91///167bXXQpOteHDOaeHCherUqVPcj12Rb7/9VnPmzNEzzzyjAQMGRLZPnTr1Vz1GrFq2bKkNGzZE/Xzs6p6X//JYq1at3f6M5eXl6corr9SVV16pVatW6ZBDDtE999xT4WTzoYce0rp16zRz5kzdcccd+ve//63ExET9/e9/17Jly3TfffdJUuDX+3Jr1qzRCSecoNLSUk2bNk15eXm7PM+//vUvXXzxxTr99NMjmX5/LS1atFC9evW0YsWKmOtkZ2crPT1d3333XYX7xXr/fRo0aBD5TN5xxx1KTk7WLbfcIuecTj31VF1//fWRjNu+7LO7c01//vlnSYppSaSdsfQJAADYI8466yzt2LFDd911V+i17du3q6ioSNIvj4vaX9jKfxUsLS2VpEjG0PI68VD+K9TO5y4uLta4ceNC+6ampsZ07s6dO6tly5Z68MEHA8s+lFu9enWV2hrr+aVfBso9e/ZUnTp1lJCQoCFDhqhnz57aunWrOnXqpBNOOEE9e/bcrYmK732MHTtWq1ev1oknnljl41aF7z465/TXv/71Vz1GrM466yzNnDlTb731Vui1oqIibd++XdKuP/M5OTk65phj9Pjjj3snQ7F8xnbs2BF6NDgnJ0cNGzaM/De3K507d1bPnj21fft2HXDAATrxxBPVs2dPFRQURD5XPXv2DGVI3bhxo0466SQtW7ZM//nPf9SqVatdnuODDz7QOeeco6OPPloTJkzYI/84Iv2yRFF5dt6dffrpp1qzZo3atGkT87Fq1Kihvn376rXXXtPnn38eer38sxXr/fdJTk6OXN/Fixfr5JNPVs+ePdWkSRNt2bJFAwYMiLxuJ/KxXlPf52fZsmV6+umndeCBB1b4DwQ+/LIJAAD2iB49euiyyy7TyJEj9d///lcnnHCCatWqpblz52rSpEn661//qjPOOEPPPPOMxowZo379+qlly5Zav369nnzySaWnp0fiiVJSUtS+fXu98MILat26tTIzM3XAAQdEjY+qyAknnKDatWvrlFNO0WWXXaYNGzboySefVE5OTmgQ37lzZ40dO1Z333239t9/f+Xk5ER+QdhZjRo19I9//EO9e/dWhw4ddNFFF6lRo0ZatmyZ3nvvPaWnp+u1116rdFs7d+6sd955Rw8//LAaNmyo5s2bq2vXrhXWmTFjhtq2bRv5henjjz8OLVxvPfvss1q0aFEk5vODDz7Q3XffLUm68MILlZ+fL+mXJSPOPvtsdezYUcnJyfroo4/0/PPP6+CDD9Zll11W6fe3O9q2bauWLVvqpptu0rJly5Senq6XXnopFHe5p48Rq5tvvlmvvvqq+vTpo0GDBqlz587auHGjvv32W02ePFkLFy6MrDe7q8/86NGj1b17d3Xs2FGXXHKJWrRooYKCAs2cOVNLly7V119/XWEb1q9fr8aNG+uMM87QQQcdpLS0NL3zzjv67LPP9NBDD8X0PmbMmBH5PG3ZskVfffWV/u///m+X+59//vn69NNPNXjwYP3444+BtR3T0tLUt29fSdKiRYt06qmnKiEhQWeccUZo2ZkDDzywSsse+Tz77LOaMGGC+vXrp86dO6t27dr68ccf9fTTTys5ObnC9+Nz77336u2331aPHj106aWXql27dlqxYoUmTZqkjz76SHXr1o35/ldk6dKlWrx4ceT6f/zxx8rKytrl5Lgy1/SPf/xjJMSgYcOGWrhwoR5//HFt3Lixav/4UumUQgAAAB42G225J554wnXu3NmlpKS4OnXquI4dO7o//vGPbvny5c65XzK4nnvuua5p06YuKSnJ5eTkuD59+rjPP/88cJyPP/7Yde7c2dWuXTtqptTyLLGTJk2qsM2vvvqqO/DAA11ycrJr1qyZu//++93TTz/tJLkFCxZE9lu5cqU7+eSTXZ06dZykSGZam4223FdffeVOP/10l5WV5ZKSklx+fr4766yzAks8lGejXb16daBueQbRnc//008/uaOPPtqlpKQ4STFlpj3xxBPdkCFDnHPObd261aWkpES9Hj169PBmf7Xv8eKLL3bt27d3derUcbVq1XL777+/u+WWW1xJSUnUdu38HmMhKeoSHT/88IPr2bOnS0tLc/Xr13eXXHKJ+/rrr50kN27cuMh+AwcOdKmpqXvkGD169HAdOnQIbc/Pz3cnn3xyYNv69evdsGHD3P777+9q167t6tev74444gj34IMPBjIyV/SZnz9/vhswYIBr0KCBq1WrlmvUqJHr06ePmzx5cmSf8utsl+IoLS11N998szvooINcnTp1XGpqqjvooIPcmDFjvNfG2r59u0tLS3PPPvusc+6XpVDkydBrr8OuPls7Z3ndVSbp8r9YMiTHmo32m2++cTfffLM75JBDXGZmpktMTHR5eXnuzDPPdF9++WVg31iWPnHul6VDBgwY4LKzs11SUpJr0aKFGzp0qCstLY3sE+v935Xnn3/eJScnR/a9+OKLQ5+xnVXmmk6cONEdffTRLjs72yUmJrr69eu7fv36uS+++CJqu3wSnItzZDgAAABQgfHjx+uiiy6Ke4IiQJJuv/12jR8/XgsXLqzupvzuEbMJAAAAAIg7JpsAAAAAgLhjsgkAAAAAiDtiNgEAAAAAcccvmwAAAACAuGOyCQAAAACIOyabAAAAQAwSEhI0fvz46m4GsM9gsgkAABAH48ePV0JCghISEvTRRx+FXnfOqUmTJkpISFCfPn0Cr23YsEG33XabDjjgAKWmpiorK0sHH3ywrr32Wi1fvjyy3+233x45h+9v5cqVVW7/U089pXbt2ik5OVmtWrXS3//+95jrlpaW6pZbblHDhg2VkpKirl27aurUqd59P/74Y3Xv3l377befGjRooGuuuUYbNmzw7vvll1/q1FNPVWZmpvbbbz8dcMAB+tvf/hbYZ9u2bbrjjjvUokULJSUlqUWLFrr77ru1ffv2wH6fffaZrrrqKnXo0EGpqalq2rSpzjrrLM2ZMyfm91kZr732mnr06KGcnBztt99+atGihc466yy9+eabgf1Wr16ta6+9Vm3btlVKSopycnJ02GGH6ZZbbglcl0GDBiktLS1Q95hjjlFCQoJatWrlbcPUqVMjn43JkydX+b1U5v76PP/88zrkkEOUnJys7OxsDRkyRIWFhaH9iouL9cc//lGtWrVSSkqK8vPzNWTIEC1evNh73BdeeEHdunVTamqq6tatqyOOOELvvvtuYJ9d/bdy3333BfZ75ZVX1KtXLzVs2FBJSUlq3LixzjjjDH333Xcxv0+EJVZ3AwAAAH5LkpOTNXHiRHXv3j2wffr06Vq6dKmSkpIC27dt26ajjz5aP/30kwYOHKirr75aGzZs0Pfff6+JEyeqX79+atiwYaDO2LFjQxMPSapbt26V2vz444/r8ssvV//+/XXDDTfoww8/1DXXXKNNmzbplltuiVp/0KBBmjx5sq677jq1atVK48eP10knnaT33nsvcB3++9//6rjjjlO7du308MMPa+nSpXrwwQc1d+5cvfHGG4Fjvv322zrllFPUqVMnDR8+XGlpaZo/f76WLl0a2O+CCy7QpEmTNHjwYHXp0kWffPKJhg8frsWLF+uJJ56I7Hf//fdrxowZOvPMM3XggQdq5cqVevTRR3XIIYfok08+0QEHHFCla+fz4IMP6uabb1aPHj00bNgw7bfffpo3b57eeecdPf/88zrxxBMlSWvXrlWXLl1UUlKiwYMHq23btlqzZo2++eYbjR07VldccYX3Pu8sOTlZ8+bN06effqrDDjss8NqECROUnJysLVu27Nb7ifX++owdO1ZXXnmljjvuuMg9/+tf/6rPP/9cs2bNUnJysiSprKxMxx9/vH744QddeeWVat26tebNm6cxY8borbfe0o8//qg6depEjnv77bfrzjvv1BlnnKFBgwZp27Zt+u6777Rs2bJQG44//ngNGDAgsK1Tp06B8rfffqt69erp2muvVf369bVy5Uo9/fTTOuywwzRz5kwddNBBVb18v28OAAAAu23cuHFOkjv99NNd/fr13bZt2wKvX3LJJa5z584uPz/fnXzyyZHtL774opPkJkyYEDrm5s2bXXFxcaR82223OUlu9erVcWv3pk2bXFZWVqBNzjl3/vnnu9TUVLd27doK68+aNctJcn/5y18C7W7ZsqXr1q1bYN/evXu7vLy8wHt68sknnST31ltvRbYVFxe73Nxc169fP7djx45dnvvTTz91ktzw4cMD22+88UaXkJDgvv7668i2GTNmuNLS0sB+c+bMcUlJSe7888+v8D2Wk+TGjRtX4T7btm1z6enp7vjjj/e+XlBQEPn/DzzwgJPkZsyYEdqvuLjYbd68OVIeOHCgS01NDezTo0cP16FDB9emTRt33XXXBV7bvHmzS09Pd/3793eS3KRJk6K9Pa/K3F+rtLTU1a1b1x199NGurKwssv21115zktzf/va3yLYZM2Y4Se7RRx8NHOPpp592ktzLL78c2TZz5kyXkJDgHn744ajtl+SGDh0adT+flStXusTERHfZZZdVqT6c4zFaAACAODr33HO1Zs2awGOGW7du1eTJk3XeeeeF9p8/f74k6cgjjwy9lpycrPT09Cq1Y/Hixfrpp5+i7vfee+9pzZo1uvLKKwPbhw4dqo0bN+r111+vsP7kyZNVs2ZNXXrppYF2DxkyRDNnztSSJUskSSUlJZo6daouuOCCwHsaMGCA0tLS9OKLL0a2TZw4UQUFBbrnnntUo0YNbdy4UWVlZaFzf/jhh5Kkc845J7D9nHPOkXNOL7zwQmTbEUccodq1awf2a9WqlTp06KAff/yxwvdYGYWFhSopKfHeT0nKycmJ/P/58+erZs2aOvzww0P7paenR371i+bcc8/VCy+8ELhGr732mjZt2qSzzjrLW+enn37a5eOpO4v1/vp89913Kioq0tlnn62EhITI9j59+igtLU3PP/98ZFtJSYkkKTc3N3CMvLw8SVJKSkpk26hRo9SgQQNde+21cs7t8jHsnW3evLnSv/CWPwJdVFRUqXr4HyabAAAAcdSsWTN169ZN/+///b/ItjfeeEPFxcWhSZEk5efnS5L++c9/ysW4/PnatWtVWFgY+LMD4gEDBqhdu3ZRj/XVV19Jkrp06RLY3rlzZ9WoUSPyekX1W7duHZoUlz/S+d///lfSL48pbt++PXSe2rVr6+CDDw6c55133lF6erqWLVumNm3aKC0tTenp6briiisCE4bS0lJJwYmIJO23336SpC+++KLCtjvnVFBQoPr161e4X2Xk5OQoJSVFr732mtauXVvhvvn5+dqxY4eeffbZ3TrneeedpxUrVuj999+PbJs4caKOO+64wOR2Z+3atQs9WuoT6/312dX9Kd/21VdfRSbIXbp0UWpqqoYPH653331Xy5Yt0/Tp0/XHP/5Rhx56qHr27BmpO23aNB166KH629/+puzsbNWpU0d5eXl69NFHve0YP368UlNTlZKSovbt22vixIm7bHNRUZFWr16tb7/9VhdffLFKSkp03HHH7XJ/VIzJJgAAQJydd955mjJlijZv3izpl9i5Hj16hGIvJalv375q06aNRowYoebNm+uiiy7S008/rVWrVu3y+G3atFF2dnbgz/frWCxWrFihmjVrhiYltWvXVlZWViBB0a7ql//6tLPybeX1V6xYEdhu9935PHPnztX27dt12mmnqVevXnrppZc0ePBgPfbYY7rooosi+7Vp00aSNGPGjMDxyn/x9MXv7WzChAlatmyZzj777Ar3q4waNWro5ptv1hdffKGmTZvqpJNO0r333qsvv/wytO/gwYOVnZ2tQYMGqV27drriiiv0//7f/1NxcXGlztmqVSt16dIlMokqKirSf/7zH+8v6ZUV6/3dVbsSEhJC92f27NlavXq1Nm/erHXr1kmS6tevrxdeeEHFxcU67rjj1LhxYx1zzDFq2LCh3n33XSUm/pJqZt26dSosLNSMGTM0fPhw3XrrrXrhhRd08MEH6+qrr9bjjz8eONcRRxyhe+65R1OmTNHYsWNVs2ZNnX/++Ro7dqy3zYcffrhycnJ04IEH6sUXX9Sf//xnDRkyJPYLhqDqfYoXAADgt6E8ZvOzzz5zq1atcomJie7FF190JSUlLiUlxT355JPOOReK2XTOuaKiInfzzTe7/Px8J8lJcjVq1HBXXXWV27JlS2S/8pjNl156yU2dOjXw9/HHH1ep3YMHD3YpKSne15o0aeJOO+20Cuu3aNHC9e7dO7R9/vz5TpJ75JFHnHPO/fOf/3SS3KxZs0L7XnjhhS4jIyNwTEnu8ssvD+x32WWXOUluzpw5zrlfYgfz8/Ndbm6ue+mll9zChQvdCy+84LKyslxiYqJr2bLlLtv9448/uvT0dNetWze3ffv2Ct9jOcUQs1lu4sSJrnv37q5GjRqRe9qpUyf3ww8/BPZbvny5u/zyy11ubm5kv9q1a7s777wzEOdYUcymc849/PDDrl69eq60tNQ9+eSTLiUlxZWUlLj33ntvt2I2Y72/u3L22We7xMRE9+CDD7r58+e7Dz74wB100EGuVq1aTpJbsmRJZN9Zs2a5k046yd1zzz1uypQp7vbbb3f77befO+OMMyL7LF68OHKdnn/++cj2HTt2uPbt27vGjRtX2J7S0lJ3wAEHuLp167pNmzaFXv/444/dm2++6caMGeMOPfRQd+ONN7qtW7dWeEzsGr9sAgAAxFl2drZ69uypiRMn6uWXX9aOHTt0xhln7HL/jIwMPfDAA1q4cKEWLlyop556Sm3atNGjjz6qu+66K7T/0UcfrZ49ewb+unXrVqW2pqSkaOvWrd7XtmzZ4n0E0tYvf1zS1i1/fef/3dW+O5+n/P+fe+65gf3Kf6mbOXOmpF9iB19//XVlZWWpf//+atasmQYMGKARI0YoMzNzl5lcV65cqZNPPlkZGRmRmMR4O/fcc/Xhhx9q3bp1evvtt3Xeeefpq6++0imnnBJ4FDgvL09jx47VihUrNHv27MijoSNGjNBTTz0V8/nOOeccFRcX64033tCECRPUp0+fQPbWqor1/u7K448/rpNOOkk33XSTWrZsqaOPPlodO3bUKaecIkmRe/Tzzz/rD3/4gwYPHqz/+7//02mnnabbbrtNY8aM0eTJkyPZisvPV6tWrcB/UzVq1NDZZ5+tpUuXVhiLWrt2bV111VUqKiryPmbdrVs39erVS1dccYXeeustPffccxo2bFiF7xG7xmQTAABgDzjvvPP0xhtv6LHHHlPv3r1jXpYkPz9fgwcP1owZM1S3bl1NmDBhj7YzLy9PO3bsCD22u3XrVq1Zs8b76K+tX/6I7M7Kt5XXL3/sclf77nye8v9vk8WUP+pb/uilJHXo0EHfffedvvvuO3344Ydavny5LrnkEhUWFqp169ahcxUXF6t3794qKirSm2++GfX97a709HQdf/zxmjBhggYOHKj58+dr1qxZof0SEhLUunVrXX311frggw9Uo0aNSt37vLw8HXPMMXrooYf0wQcfxOUR2vLjxnJ/dyUjI0P/+te/tGjRIk2fPl0LFy7Us88+qxUrVig7Ozvy38X48eO1ZcuW0Bq0p556qqT/PSqdmZmp5ORkZWVlhf6RwPf58GnSpIkkRY2prVevno499tg9/t/gbxmTTQAAgD2gX79+qlGjhj755JMqDfzr1aunli1begf68XTwwQdLkj7//PPA9s8//1xlZWWR1yuqP2fOnEg20XLlE6ry+gcccIASExND59m6dav++9//Bs7TuXNnSeGYy/L4wOzs7MD2hIQEdejQQd27d1dmZqbee+89lZWVBZLKSL/8GnfKKadozpw5+ve//6327dtX+N7irTw5UrR72qJFC9WrV6/S9/68887Thx9+qPT0dJ100klVbufOYr2/0TRt2lRHH3208vPzI78q7nx/CgoK5JzTjh07AvW2bdsmSdq+fbukX37BPPjgg7V69erQL/K7+nxYP//8c0z7Sb9ksa1sDC3+h8kmAADAHpCWlqaxY8fq9ttvjzwy6PP111+rsLAwtH3RokX64YcfIklwKivWpU+OPfZYZWZmhhKmjB07Vvvtt59OPvnkyLbCwkL99NNP2rRpU2TbGWecoR07duiJJ56IbCstLdW4cePUtWvXyK9IGRkZ6tmzp5577jmtX78+su+zzz6rDRs26Mwzz4xsK1+uwz5G+o9//EOJiYk65phjdvl+Nm/erOHDhysvLy/wGO6OHTt09tlna+bMmZo0aVKVHzuOZtOmTZHHfK3yR0HL7+msWbO0cePG0H6ffvqp1qxZU+l7f8YZZ0QePbXLvFixLn0S6/2VYv/MDRs2TNu3b9f1118f2da6dWs55wJL4EiKZHXu1KlTZNvZZ5+tHTt26Jlnnols27JliyZMmKD27dtHfm1dvXp16Nzr16/XqFGjVL9+/cg/akjyJuRauHChpk2bFsqgjNglVncDAAAAfqsGDhwYdZ+pU6fqtttu06mnnqrDDz9caWlp+vnnn/X000+rtLRUt99+e6jO5MmTvfGIxx9/fOTR0wEDBmj69OlRl1NJSUnRXXfdpaFDh+rMM89Ur1699OGHH+q5557TPffco8zMzMi+jz76qO644w699957kQlf165ddeaZZ2rYsGFatWqV9t9/fz3zzDOR2NOd3XPPPTriiCPUo0cPXXrppVq6dKkeeughnXDCCTrxxBMj+3Xq1EmDBw/W008/re3bt6tHjx56//33NWnSJA0bNizw6OZZZ52lhg0bqn379iopKdHTTz+tn3/+Wa+//nogZvHGG2/Uq6++qlNOOUVr167Vc889F2jbBRdcUOF1itWmTZt0xBFH6PDDD9eJJ56oJk2aqKioSFOmTNGHH36ovn37RiZOzz77rCZMmKB+/fqpc+fOql27tn788Uc9/fTTSk5O1v/93/9V6twZGRnez4tPu3btIte1IpW5v77P3H333afvvvtOXbt2VWJioqZMmaK3335bd999tw499NDIfoMGDdKDDz6oyy67TF999ZU6dOigL7/8Uv/4xz/UoUMH9evXL7LvZZddpn/84x8aOnSo5syZo6ZNm+rZZ5/VokWL9Nprr0X2Gz16tKZMmaJTTjlFTZs21YoVK/T0009r8eLFevbZZwMT8o4dO+q4447TwQcfrHr16mnu3Ll66qmntG3bNt13330xXVN4VG9+IgAAgN+GnbPRVsRmo/3555/diBEj3OGHH+5ycnJcYmKiy87OdieffLJ79913A3XLs9Hu6u+9996L7NujRw9XmaHeE0884dq0aeNq167tWrZs6R555JFANtSdz7/zeZz7JSvsTTfd5Bo0aOCSkpLcoYce6t58803veT788EN3xBFHuOTkZJedne2GDh3qSkpKQvtt3brV3X777S4/P9/VqlXL7b///t7Mp/fff79r27atS05OdvXq1XOnnnqq++qrr0L7lV+PXf3FQjFko922bZt78sknXd++fV1+fr5LSkpy++23n+vUqZP7y1/+4kpLSyP7fvPNN+7mm292hxxyiMvMzHSJiYkuLy/PnXnmme7LL78MHDdaNtpd2VU2WkmuR48e0d+0i/3++j5z//73v91hhx3m6tSp4/bbbz93+OGHuxdffNF7nqVLl7rBgwe75s2bu9q1a7u8vDx3ySWXuNWrV4f2LSgocAMHDnSZmZkuKSnJde3aNdSmt99+2x1//PGuQYMGrlatWq5u3bruhBNOcNOmTQsd77bbbnNdunRx9erVc4mJia5hw4bunHPOcd98801M1wh+Cc7FuHowAAAA8DuWkJCgcePGadCgQdXdFGCfQMwmAAAAACDumGwCAAAAAOKOySYAAAAAIO7IRgsAAADEgFQnQOXwyyYAAAAAIO6YbAIAAAAA4o7JJgAAAAAg7phsAgAAAADijskmAAAAACDumGwCAAAAAOKOySYAAAAAIO6YbAIAAAAA4o7JJgAAAAAg7phsAgAAAADijskmAAAAACDumGwCAAAAAOKOySYAAAAAIO6YbAIAAAAA4o7JJgAAAAAg7phsAgAAAADijskmAAAAACDumGxir3X77bcrISGhSnXHjx+vhIQELVy4ML6N2snChQuVkJCg8ePH77FzAAAA7IzxB/YlTDYRd99//70uuOACNWrUSElJSWrYsKHOP/98ff/999XdtGrx/vvvKyEhQZMnT67upgAAfqfK/xG2/C8xMVGNGjXSoEGDtGzZsupuXtyNGTOm2idj1d0Gxh/YGzDZRFy9/PLLOuSQQzRt2jRddNFFGjNmjIYMGaL33ntPhxxyiF555ZWYj/XnP/9ZmzdvrlI7LrzwQm3evFn5+flVqg8AwG/RnXfeqWeffVaPPfaYevfureeee049evTQli1bqrtpcVXdE729pQ1AdUus7gbgt2P+/Pm68MIL1aJFC33wwQfKzs6OvHbttdfqqKOO0oUXXqhvvvlGLVq02OVxNm7cqNTUVCUmJioxsWof0Zo1a6pmzZpVqgsAwG9V79691aVLF0nSxRdfrPr16+v+++/Xq6++qrPOOquaW1c9yscdAOKPXzYRN3/5y1+0adMmPfHEE4GJpiTVr19fjz/+uDZu3KgHHnggsr08LvOHH37Qeeedp3r16ql79+6B13a2efNmXXPNNapfv77q1KmjU089VcuWLVNCQoJuv/32yH6+mM1mzZqpT58++uijj3TYYYcpOTlZLVq00D//+c/AOdauXaubbrpJHTt2VFpamtLT09W7d299/fXXcbpS/3tvc+bM0QUXXKCMjAxlZ2dr+PDhcs5pyZIlOu2005Senq4GDRrooYceCtTfunWrRowYoc6dOysjI0Opqak66qij9N5774XOtWbNGl144YVKT09X3bp1NXDgQH399dfeeI+ffvpJZ5xxhjIzM5WcnKwuXbro1Vdfjdv7BgDsXY466ihJv/yD8c5i7Q+Kiop0/fXXq1mzZkpKSlLjxo01YMAAFRYWRvZZtWqVhgwZotzcXCUnJ+uggw7SM888EzhOeRzigw8+qCeeeEItW7ZUUlKSDj30UH322WeBfVeuXKmLLrpIjRs3VlJSkvLy8nTaaadF+vxmzZrp+++/1/Tp0yOPDR9zzDGS/jc+mD59uq688krl5OSocePGkqRBgwapWbNmofe4qxwSzz33nA477DDtt99+qlevno4++mi9/fbbUdtQft2uu+46NWnSRElJSdp///11//33q6ysLHR9Bw0apIyMjEgfXlRUFGpLrBh/4NfGL5uIm9dee03NmjWLdFzW0UcfrWbNmun1118PvXbmmWeqVatWuvfee+Wc2+U5Bg0apBdffFEXXnihDj/8cE2fPl0nn3xyzG2cN2+ezjjjDA0ZMkQDBw7U008/rUGDBqlz587q0KGDJOnnn3/WlClTdOaZZ6p58+YqKCjQ448/rh49euiHH35Qw4YNYz5fNGeffbbatWun++67T6+//rruvvtuZWZm6vHHH9exxx6r+++/XxMmTNBNN92kQw89VEcffbQkqaSkRP/4xz907rnn6pJLLtH69ev11FNPqVevXvr000918MEHS5LKysp0yimn6NNPP9UVV1yhtm3b6l//+pcGDhwYasv333+vI488Uo0aNdKtt96q1NRUvfjii+rbt69eeukl9evXL27vGwCwdyifoNWrVy+yLdb+YMOGDTrqqKP0448/avDgwTrkkENUWFioV199VUuXLlX9+vW1efNmHXPMMZo3b56uuuoqNW/eXJMmTdKgQYNUVFSka6+9NtCeiRMnav369brsssuUkJCgBx54QKeffrp+/vln1apVS5LUv39/ff/997r66qvVrFkzrVq1SlOnTtXixYvVrFkzjRo1SldffbXS0tL0pz/9SZKUm5sbOM+VV16p7OxsjRgxQhs3bqz0dbvjjjt0++2364gjjtCdd96p2rVra9asWXr33Xd1wgknVNiGTZs2qUePHlq2bJkuu+wyNW3aVB9//LGGDRumFStWaNSoUZIk55xOO+00ffTRR7r88svVrl07vfLKK94+vLIYf+BX44A4KCoqcpLcaaedVuF+p556qpPkSkpKnHPO3XbbbU6SO/fcc0P7lr9W7osvvnCS3HXXXRfYb9CgQU6Su+222yLbxo0b5yS5BQsWRLbl5+c7Se6DDz6IbFu1apVLSkpyN954Y2Tbli1b3I4dOwLnWLBggUtKSnJ33nlnYJskN27cuArf83vvveckuUmTJoXe26WXXhrZtn37dte4cWOXkJDg7rvvvsj2devWuZSUFDdw4MDAvqWlpYHzrFu3zuXm5rrBgwdHtr300ktOkhs1alRk244dO9yxxx4bavtxxx3nOnbs6LZs2RLZVlZW5o444gjXqlWrCt8jAGDvVt4vvvPOO2716tVuyZIlbvLkyS47O9slJSW5JUuWRPaNtT8YMWKEk+Refvnl0PnKysqcc86NGjXKSXLPPfdc5LWtW7e6bt26ubS0tMh4oLxPzcrKcmvXro3s+69//ctJcq+99ppz7pe+TpL7y1/+UuH77dChg+vRo8cur0P37t3d9u3bA68NHDjQ5efnh+rY8cjcuXNdjRo1XL9+/ULjhfL3XVEb7rrrLpeamurmzJkT2H7rrbe6mjVrusWLFzvnnJsyZYqT5B544IHIPtu3b3dHHXUU4w/sM3iMFnGxfv16SVKdOnUq3K/89ZKSksD2yy+/POo53nzzTUm//Gvkzq6++uqY29m+ffvAL6/Z2dlq06aNfv7558i2pKQk1ajxy38aO3bs0Jo1a5SWlqY2bdroyy+/jPlcsbj44osj/79mzZrq0qWLnHMaMmRIZHvdunVDbaxZs6Zq164t6Zd/PVy7dq22b9+uLl26BNr45ptvqlatWrrkkksi22rUqKGhQ4cG2rF27Vq9++67Ouuss7R+/XoVFhaqsLBQa9asUa9evTR37tzfZLZCAPi96dmzp7Kzs9WkSROdccYZSk1N1auvvhp5lLQy/cFLL72kgw46yPvLU/ljp//5z3/UoEEDnXvuuZHXatWqpWuuuUYbNmzQ9OnTA/XOPvvswK+s5X12eR+YkpKi2rVr6/3339e6deuqfB0uueSSKud2mDJlisrKyjRixIjIeKFcLEu2TZo0SUcddZTq1asXub6FhYXq2bOnduzYoQ8++EDSL9cuMTFRV1xxRaRuzZo1KzXu2RXGH/i18Bgt4qJ8Elk+6dyVXU1KmzdvHvUcixYtUo0aNUL77r///jG3s2nTpqFt9erVC3RYZWVl+utf/6oxY8ZowYIF2rFjR+S1rKysmM9VlfZkZGQoOTlZ9evXD21fs2ZNYNszzzyjhx56SD/99JO2bdsW2b7z9Vm0aJHy8vK03377BeraazZv3jw55zR8+HANHz7c29ZVq1apUaNGsb85AMBeZ/To0WrdurWKi4v19NNP64MPPlBSUlLk9cr0B/Pnz1f//v0rPN+iRYvUqlWr0KSsXbt2kdd3ZvvF8olneT+dlJSk+++/XzfeeKNyc3N1+OGHq0+fPhowYIAaNGgQwxX4RSzjjl2ZP3++atSoofbt21ep/ty5c/XNN9+E8luUW7VqlaT/9eFpaWmB19u0aVOl8+6M8Qd+LUw2ERcZGRnKy8vTN998U+F+33zzjRo1aqT09PTA9pSUlD3ZvIhd/Sum2ylO9N5779Xw4cM1ePBg3XXXXcrMzFSNGjV03XXXhQL390R7Ymnjc889p0GDBqlv3766+eablZOTo5o1a2rkyJGhJA+xKH9fN910k3r16uXdpzKTegDA3umwww6LZKPt27evunfvrvPOO0+zZ89WWlpatfcHsfSB1113nU455RRNmTJFb731loYPH66RI0fq3XffVadOnWI6j2/csatfJXf+R+d4KCsr0/HHH68//vGP3tdbt24d1/P5MP7Ar4XJJuKmT58+evLJJ/XRRx9FMsru7MMPP9TChQt12WWXVen4+fn5Kisr04IFC9SqVavI9nnz5lW5zT6TJ0/WH/7wBz311FOB7UVFRaF/8asukydPVosWLfTyyy8HOsfbbrstsF9+fr7ee+89bdq0KfCvi/aalS9FU6tWLfXs2XMPthwAsLconyT84Q9/0KOPPqpbb721Uv1By5Yt9d1331W4T35+vr755huVlZUFft386aefIq9XRcuWLXXjjTfqxhtv1Ny5c3XwwQfroYce0nPPPScptsdZrXr16nkzvdpfX1u2bKmysjL98MMPkYQ4PrtqQ8uWLbVhw4ao1zc/P1/Tpk3Thg0bAr9uzp49u8J6exLjD1QWMZuIm5tvvlkpKSm67LLLQo9crF27Vpdffrn2228/3XzzzVU6fvm/eI0ZMyaw/e9//3vVGrwLNWvWDGXEnTRp0l4VM1D+r487t3PWrFmaOXNmYL9evXpp27ZtevLJJyPbysrKNHr06MB+OTk5OuaYY/T4449rxYoVofOtXr06ns0HAOwljjnmGB122GEaNWqUtmzZUqn+oH///vr666/1yiuvhPYr759OOukkrVy5Ui+88ELkte3bt+vvf/+70tLS1KNHj0q1d9OmTdqyZUtgW8uWLVWnTh2VlpZGtqWmplZ6iZCWLVuquLg48JTWihUrQu+vb9++qlGjhu68887QE08798u7asNZZ52lmTNn6q233gq9VlRUpO3bt0v65dpt375dY8eOjby+Y8eOuI97KoPxByqLXzYRN61atdIzzzyj888/Xx07dtSQIUPUvHlzLVy4UE899ZQKCwv1//7f/1PLli2rdPzOnTurf//+GjVqlNasWRNZ+mTOnDmSqvavmD59+vTRnXfeqYsuukhHHHGEvv32W02YMCHyr297gz59+ujll19Wv379dPLJJ2vBggV67LHH1L59e23YsCGyX9++fXXYYYfpxhtv1Lx589S2bVu9+uqrWrt2raTgNRs9erS6d++ujh076pJLLlGLFi1UUFCgmTNnaunSpXFdZxQAsPe4+eabdeaZZ2r8+PG6/PLLY+4Pbr75Zk2ePFlnnnmmBg8erM6dO2vt2rV69dVX9dhjj+mggw7SpZdeqscff1yDBg3SF198oWbNmmny5MmaMWOGRo0aFTWxoDVnzhwdd9xxOuuss9S+fXslJibqlVdeUUFBgc4555zIfp07d9bYsWN19913a//991dOTo6OPfbYCo99zjnn6JZbblG/fv10zTXXaNOmTRo7dqxat24dSH6z//77609/+pPuuusuHXXUUTr99NOVlJSkzz77TA0bNtTIkSMrbMPNN9+sV199VX369Iksv7Zx40Z9++23mjx5shYuXKj69evrlFNO0ZFHHqlbb71VCxcuVPv27fXyyy+ruLi4Utcsnhh/oNKqIwUuftu++eYbd+6557q8vDxXq1Yt16BBA3fuuee6b7/9NrRveQru1atX7/K1nW3cuNENHTrUZWZmurS0NNe3b183e/ZsJymQrntXS5+cfPLJofP06NEjkJp8y5Yt7sYbb3R5eXkuJSXFHXnkkW7mzJmh/eKx9Il93wMHDnSpqaneNnbo0CFSLisrc/fee6/Lz893SUlJrlOnTu7f//63N2376tWr3Xnnnefq1KnjMjIy3KBBg9yMGTOcJPf8888H9p0/f74bMGCAa9CggatVq5Zr1KiR69Onj5s8eXKF7xEAsHcr7xc/++yz0Gs7duxwLVu2dC1btowsBxJrf7BmzRp31VVXuUaNGrnatWu7xo0bu4EDB7rCwsLIPgUFBe6iiy5y9evXd7Vr13YdO3YM9Z3lfapvSRPttLxZYWGhGzp0qGvbtq1LTU11GRkZrmvXru7FF18M1Fm5cqU7+eSTXZ06dZykSP9d0XVwzrm3337bHXDAAa527dquTZs27rnnnvOOR5xz7umnn3adOnVySUlJrl69eq5Hjx5u6tSpUdvgnHPr1693w4YNc/vvv7+rXbu2q1+/vjviiCPcgw8+6LZu3Rq4vhdeeKFLT093GRkZ7sILL3RfffUV4w/sMxKcM88LAvuY//73v+rUqZOee+45nX/++dXdnH3ClClT1K9fP3300Uc68sgjq7s5AADgd4Dxx+8PMZvYp2zevDm0bdSoUapRo4aOPvroamjR3s9es/J4j/T0dB1yyCHV1CoAAPBbxvgDEjGb2Mc88MAD+uKLL/SHP/xBiYmJeuONN/TGG2/o0ksvVZMmTaq7eXulq6++Wps3b1a3bt1UWlqql19+WR9//LHuvffeX23JGQAA8PvC+AOSxGO02KdMnTpVd9xxh3744Qdt2LBBTZs21YUXXqg//elPSkzk3058Jk6cqIceekjz5s3Tli1btP/+++uKK67QVVddVd1NAwAAv1GMPyAx2QQAAAAA7AHEbAIAAAAA4m6PTTZHjx6tZs2aKTk5WV27dtWnn366p04FAAD2YowJAOD3aY88RvvCCy9owIABeuyxx9S1a1eNGjVKkyZN0uzZs5WTk1Nh3bKyMi1fvlx16tQJLPgKAIidc07r169Xw4YNVaMGD7Gg+jAmAIDqVZ1jgj0y2ezatasOPfRQPfroo5J+6SyaNGmiq6++WrfeemuFdZcuXUpWUQCIkyVLlqhx48bV3Qz8jjEmAIC9Q3WMCeKevnPr1q364osvNGzYsMi2GjVqqGfPnpo5c2Zo/9LSUpWWlkbK5XPfJUuWKD09Pd7NA4DfhZKSEjVp0kR16tSp7qbgd4wxAQBUv+ocE8R9sllYWKgdO3YoNzc3sD03N1c//fRTaP+RI0fqjjvuCG1PT0+nYwGA3cSjh6hOjAkAYO9RHWOCag/kGTZsmIqLiyN/S5Ysqe4mAQCAasCYAAB+W+L+y2b9+vVVs2ZNFRQUBLYXFBSoQYMGof2TkpKUlJQU72YAAIBqxpgAAH7f4v7LZu3atdW5c2dNmzYtsq2srEzTpk1Tt27d4n06AACwl2JMAAC/b3H/ZVOSbrjhBg0cOFBdunTRYYcdplGjRmnjxo266KKL9sTpAADAXooxAQD8fu2RyebZZ5+t1atXa8SIEVq5cqUOPvhgvfnmm6EEAQAA4LeNMQEA/H7tkXU2d0dJSYkyMjJUXFxM5jkAqCK+S/FbwOcYAHZfdX6XVns2WgAAAADAbw+TTQAAAABA3DHZBAAAAADEHZNNAAAAAEDcMdkEAAAAAMQdk00AAAAAQNwx2QQAAAAAxB2TTQAAAABA3DHZBAAAAADEHZNNAAAAAEDcMdkEAAAAAMQdk00AAAAAQNwx2QQAAAAAxB2TTQAAAABA3DHZBAAAAADEHZNNAAAAAEDcMdkEAAAAAMQdk00AAAAAQNwx2QQAAAAAxB2TTQAAAABA3DHZBAAAAADEHZNNAAAAAEDcMdkEAAAAAMQdk00AAAAAQNwx2QQAAAAAxB2TTQAAAABA3DHZBAAAAADEHZNNAAAAAEDcMdkEAAAAAMQdk00AAAAAQNwx2QQAAAAAxB2TTQAAAABA3DHZBAAAAADEXaUnmx988IFOOeUUNWzYUAkJCZoyZUrgdeecRowYoby8PKWkpKhnz56aO3duvNoLAAD2EowJAAAVqfRkc+PGjTrooIM0evRo7+sPPPCA/va3v+mxxx7TrFmzlJqaql69emnLli273VgAALD3YEwAAKhIYmUr9O7dW7179/a+5pzTqFGj9Oc//1mnnXaaJOmf//yncnNzNWXKFJ1zzjmhOqWlpSotLY2US0pKKtskAABQDRgTAAAqEteYzQULFmjlypXq2bNnZFtGRoa6du2qmTNneuuMHDlSGRkZkb8mTZrEs0kAAKAaMCYAAMR1srly5UpJUm5ubmB7bm5u5DVr2LBhKi4ujvwtWbIknk0CAADVgDEBAKDSj9HGW1JSkpKSkqq7GUDcbdu2LbQtISEhUN66dWuFr0tSYmJihfvY1wFgX8WYAL9VOz8eXq6srCxQtuMG51yoTu3atQPlmjVrVvg6UN3i+stmgwYNJEkFBQWB7QUFBZHXAADAbx9jAgBAXCebzZs3V4MGDTRt2rTItpKSEs2aNUvdunWL56kAAMBejDEBAKDSz99t2LBB8+bNi5QXLFig//73v8rMzFTTpk113XXX6e6771arVq3UvHlzDR8+XA0bNlTfvn3j2W4AAFDNGBMAACpS6cnm559/rj/84Q+R8g033CBJGjhwoMaPH68//vGP2rhxoy699FIVFRWpe/fuevPNN5WcnBy/VgO7wcZN+GIion1ei4uLQ9ts3ISNx5R+WZNuZ+vWrQuUN23aFKqTlpYWKNevXz9Qrlu3bqiOjeMkrhPAnsCYAPu6zZs3B8o2jlKSUlNTKzxGUVFRaJvNr+A77vr16wPl1atXV9g2KTw+yc7ODpSzsrJCdWwcdK1atUL7AHtKgvONtKtRSUmJMjIyVFxcrPT09OpuDn6DmGzi94DvUvwW8DnGnsZkE78H1fldGteYTQAAAAAAJCabAAAAAIA9gGfrsNfYvn171H3sGlS+daui1bGPwPrWdKtXr16F+9hHXaTw466+NTNXrFhRYVvWrl0bqmMfvbGP8zRv3jxUJz8/P1Deb7/9KjymxNpcAIC9hw1F2bFjR2ifaGOCGjXCv6nYOrbfrVOnTqiODbex/WVhYWGoju13fWOC5cuXB8r2sdqSkpJQHdv+ZcuWBcpNmzYN1bHb7Hv0tY1HbREv/LIJAAAAAIg7JpsAAAAAgLhjsgkAAAAAiDsmmwAAAACAuCNBEOLCJvexgfy+4HObpMYmy7HJdCRpzZo1gbJNIOBL9uNLELCzzMzM0Da7lqVdH9OXIMgG8qekpIT2scexdXwJEKKdZ86cOaF9bJKBdu3aBcq+ZED23HZtTpIFAABiYftmm7jHrkvts2rVqkDZJtORwuMGe17fmtnR1r/My8sL1bHjBHvepUuXhurEsralHRNs2LAhUPYlTrTJimx/P2/evKjn6dChQ6DsGyfZ9tp75htvAT78sgkAAAAAiDsmmwAAAACAuGOyCQAAAACIO2I2UWk2JkIKxwzYeEtf/KJdmPinn34KlH2LGdu4QhvPYGMZpHB8om2LXXhZktatWxcoz58/P1D2xaB+/vnngfKWLVtC+9i4DxtH4Ysvsew+NhZGkn744YdA2cZj2BgVn9atWwfKaWlpUdsCAPh92bx5c2ibjWlcuXJloBxL32HHBPaYUngMYNvi6+tsf5ienh4op6amhurYfBHff/99oOzrhxcsWBAo2zGPFM4PYdvri4u04w8bW+lri43jtOMiGysqhfM2tGjRIlCuW7duqI5vnADwyyYAAAAAIO6YbAIAAAAA4o7JJgAAAAAg7phsAgAAAADijgRBiMoG3BcWFob2sYst2wQ7NgBfCgfC2wWcfYl7bHKfaMkBpHCwfFFRUaBcr169UB277euvvw6UfckN7HsuKCgI7WOTJNiEAdnZ2aE60ZIZ+K6TTdhkF5y2yQ6kcPIFe51atmwZqpObmxso+xIGAAB+O2xiO9uvSeEkgTYBjS9pYM2aNQPltWvXRq1jk/nY/tCX+MaOCWx/mJeXF6pjj2OTF/kS+djrZMcIUjgRoh3T2KSCUnj8Ee0aSOHEjkuWLAmU7f3ytcW2tVmzZqE69tplZWWF9sHvD79sAgAAAADijskmAAAAACDumGwCAAAAAOKOmE2E2LhHG8+waNGiUB0bz2Cf9fctrGzZRYZ9MRA2ftHGeNjXfcd1zkWtY2Mt7Pux8Yw+sSwMbfdZvXp1qI6NU7H3p1GjRlHbYq+/vW5S+D3bRaB98bB2m30/dsFq3z72/gAA9h62b7D5CJYtWxaqY/sG24fafti3T7T+3ichISFQ9vUvdh9fDgZry5YtgXKtWrUqfF0Kj2F8Mac2b4Ntmy/O08Zkbtq0KVD2xZzaa2tjOO37kcLjHJv7wR5TCl8HO+bx5aWw78c39sO+jV82AQAAAABxx2QTAAAAABB3TDYBAAAAAHFHzObvjH3G3sYLSOFn7BcuXBgo++IVExODHyUb4+GLi4y2ZqZdK1IKx1bYOrYdUvg92n3s+p4+NobAF0dh348vvsSuQ2nX8/Qd18ZA2PhLXx17XWxMhy+G1m6z1823Dpdl19TyncfGkxCzCQDVI1osnxTuI23snm8tSxt7aGM4fWMCGze4Y8eOqOexYwJbx5al8BjAttXX19kYU7vetb0mUngM4IuLtPukpaUFyr5xkL2W9j361kK379mWfX21fc92LOJbS9yKZZ1NOyYgZvO3h182AQAAAABxx2QTAAAAABB3TDYBAAAAAHHHZBMAAAAAEHckCPqdsYHkNnGMJC1evDhQtskBfIH9NnDfJhHyBfbvv//+FbbVl4jIJuGxbfEFltvAd1v2BbmXlpYGyjaI37c4sy/A3rILGtv2+pIB2LbYe2aTMUlSampqoGyTAfiuU0ZGRqBskxD4kknZRATRkhBI4YQOdh+7wDMAYM+wCYJKSkpC+9jkN2vXrg2UfcnwbP9hxwC+vi4nJ6fC4/rGBHZM42uLZRPf2KRItu2+OjapkO1zpXCf6UtWVL9+/QrPY8tSeKxh71ksYwLbfl+iPjsmiJasUJKKi4srPK5vTBBtH994C/sWftkEAAAAAMQdk00AAAAAQNxVarI5cuRIHXrooapTp45ycnLUt29fzZ49O7DPli1bNHToUGVlZSktLU39+/ePaS0eAACw72BMAACIplIxm9OnT9fQoUN16KGHavv27fq///s/nXDCCfrhhx8iz4Nff/31ev311zVp0iRlZGToqquu0umnn64ZM2bskTeAitl4DBtD4IuBsNtsPIPvmXsbV2jjDHwxBDYW1MYQ+OIb7PuxdXyLJttz2zhPewwpetyE7xrYa+uLHbHts7EwvvthF49es2ZNoOy7TtFiTm3sqCTVrVs3ULbxmPaYUjh+1Mbh+K6Bjb+oV69eoOyLDfXdVwDVizHBvsd+v9r+fd26daE60eL3fXGFtl+KFifpO48vP4Rl22LjCH35CWz8qD2Pr9+y+0R7fz6+sYbdZsdFvjGB7attnKSvLfba2jhJ35jAxmza49oYTin6mMB3T+09suf1XTeb+wF7t0pNNt98881Aefz48crJydEXX3yho48+WsXFxXrqqac0ceJEHXvssZKkcePGqV27dvrkk090+OGHx6/lAACg2jAmAABEs1sxm+X/mpKZmSlJ+uKLL7Rt2zb17Nkzsk/btm3VtGlTzZw503uM0tJSlZSUBP4AAMC+hTEBAMCq8mSzrKxM1113nY488kgdcMABkqSVK1eqdu3aoZ/4c3NztXLlSu9xRo4cqYyMjMhfkyZNqtokAABQDRgTAAB8qrzO5tChQ/Xdd9/po48+2q0GDBs2TDfccEOkXFJSQucSRzaewT4/v2zZslAdG5sXS3yGjXGwz+D74jNsnEEsa2ba89hYPt+6Tza2wq435fuXcxvPYK9bLHV8624tWbIkUI52DaTwtbOxCr61Uu09tDEPvvPY49r2+9YeszG0dv01H3vP7DpjPvYz51sTDED1YUywb7D9iY0JtDGDUvi7P1qOBin6Oo6+2HwbS2mP4VuD2e5jy7622X7L5kWw/bIUbr/NneCrY8crderUCe1j8zbEkvfAXn+bB8G3hqllx0WxxEXasu88vvwc0c5jxwT2Otn1V6XwfWUtzr1blSabV111lf7973/rgw8+UOPGjSPbGzRooK1bt6qoqCjwL5kFBQVq0KCB91hJSUneSQUAANj7MSYAAOxKpR6jdc7pqquu0iuvvKJ3331XzZs3D7zeuXNn1apVS9OmTYtsmz17thYvXqxu3brFp8UAAKDaMSYAAERTqV82hw4dqokTJ+pf//qX6tSpE4m5yMjIUEpKijIyMjRkyBDdcMMNyszMVHp6uq6++mp169aNrHMAAPyGMCYAAERTqcnm2LFjJUnHHHNMYPu4ceM0aNAgSdIjjzyiGjVqqH///iotLVWvXr00ZsyYuDQWAADsHRgTAACiqdRkM5ZFa5OTkzV69GiNHj26yo1C1digdym86O6KFSsC5dWrV0c9TiyB5NEWRfYlpLHHtQkDfMkA7HFssoPExPBH2h7Hts33ubZJd+w+vmtt97HJDqRw+21iAntNpPB1SUtLi1rHBtxHS9bgY5MB+OKoCgsLK9zHV8feI5s0yXdtdxXfVY6EQcCvjzHB3s2XmM/2bTYhkE18I0UfE/j6INvX2e99X+Ibm+DPHtf3PW/PY5MZ+T6jtm+z/aMveZFNpGT3sUl7pHA/7EssaBPb2Gvte8/RkgbacZ8Uvk72WvvGdfY92nvoG2/Zz5Mdf8USj22P60v82LBhw0DZvmd7TVC9dmudTQAAAAAAfJhsAgAAAADijskmAAAAACDuqrTOJvYO9tl+33Pt9jl2G4/hi4+LFo/he07fxhDYOAlffIaNIbB1fM/c2/dj37PvGti4CbvP2rVrQ3WixQD6zmMXM/bFTdg4A1snNTU1VMdeJ3vPbAynFL4f9vr72m/r2HgNXx3Lxmf46tiYIV+MkFWvXr1A2fcZBIDfM/ud7evfbZ9jYxF939mxfPdHa0ssop3H971v+xN7Xt/YI1r/sW7dutA2X0zjzmIZf/muSZ06dQJlG8Ppi3G04wTbd9tcEL622Pfji++NNvbw5eKw2+z78Z3H5rew4y/feTIzMwNlO87D3oVfNgEAAAAAccdkEwAAAAAQd0w2AQAAAABxR+DTPszGCNj1paTwOpr22fhY1sy0MQO+Z+PtGlOxxE1Y9jl939pdNt7Ett8X3xAtXjEjIyNUx8Z02BiOn376KVQnKysralts3EQsa4/Z49h1rGJZh8vGtfjW+7L31d5TX9tycnICZRt/4lsr1R7HflZ8a78WFxcHyrGsw2VjRQDgt8x+D/ryBtgcBb71oK1oYwJf32C/123ZN/aw7Y+Wb0EKjwksX/8YLb7P9mNS+BrY67Zs2bJQHRtXGEvMaSz5FWyehvXr1wfKvvds+3M7RvBdx2hrifrWMLVrYtv4UV+/HG18aPt/KTwms+/Zd9184xH8OvhlEwAAAAAQd0w2AQAAAABxx2QTAAAAABB3TDYBAAAAAHFHgqB9mF1g1xfgXVBQECjHEuBt2WQAsSz6bIPefQH5ycnJFe5jjyGFg9ptoLyPrWMD1Fu1ahWqY6+tPcaiRYtCdWwyAN9CxNESKdnXpXDioVgWY7bv0SaKsAt5S9GTPvjej11c2iZb8iVEsImsbPt9n6+lS5dWuI9NVOQ7DwmDAPyW2X7LlzTQJgiyfZBvTGD7nGgJdqToYwIfm+TF9h++MY59z/Z73pd8xvY59jxNmzYN1bHXyfaHvr7bntt33ex18h3HsvfIHsM3JrD9u93HJhmSwu211ymWMYFNtuQbE9j3HMtnZc2aNYGy/Yz6xgT2uCQM+vXwyyYAAAAAIO6YbAIAAAAA4o7JJgAAAAAg7ojZ3IfYZ+x37NgRKPviM+yz8PXq1QuUfc/G27gIex4buyCF4ybs8/O+OtFiCHx1bAyBjQ+ItsCzFI538MXy2eti4zqzs7NDdWy8oi8+w56rpKSkwrZJ4VgKG2fgi8+oW7duoGzfjy9m08aG2uvvu072Hto6y5cvD9Wx98jGtdh7KoVjZG28RqdOnUJ17PsBgN8S+91v+2Ff/27j+9LT0wNlG98vhccW9jy+fsuOGyx7DCkcs2nb4hsT2P7D9lO+89jj2twPtl/zHcfGdc6ePTtUxx7XF68YrW2+a2vvu22v7z3b8Ym9lr6YTTvWsJ8d35jA5uKwbbF5RKTw59TeU19spR1b2DGNbYcUHv/i18MvmwAAAACAuGOyCQAAAACIOyabAAAAAIC4I2ZzH2Kfsd+wYUOgvHr16lCdaLEVvmf7o8WB+Or41kaM9rqNJ41lXUQb8xDLumLRYghWrVoVqlNcXBwod+/ePVDu3LlzqI6NB/DFrNh7aOMofOtW2fth42HtOlZS+NrZfewxfOexcRK+NU3tPrGs52ljQ2zbbNyOFP2z4ruHvusCAL8Vto+x8fB2TU0p/D1v+5xY+i1f7GS0tsWyVqetY3Ma+PqGaHGQvjwO9j3bcZGv37Jjgnbt2gXKubm5oTrR1q6Wwn2b7VN9YwJfXO3OfLGJ0fJd+GJD7Vgp2hqaUvg9xzImsDGb9hi+a2CPY4/hGw/b8RZ+PfyyCQAAAACIOyabAAAAAIC4Y7IJAAAAAIg7JpsAAAAAgLgjQdA+xAZa28VxfQHRlg1y9yXUseexQeK+BAI2cN8mEPAtkmwTFdjEMTZwXvIv7hutjm2L3cd33WxSgRNPPDFQ7tKlS6iOfT9Lly4N7WPfY7TkRVI4sN8m/6lfv36ojl3w2N4fX2B/YWFhoJyXl1fhMXxts+WWLVuG6tikDzbpgC9xhGXvoe+++xIeAMBvhf3es2MCX4IgyyYa9CWfseOEWBIE2e9fmyTQlwDQ9rv2/fnOa49j6/jGK9ESC65ZsyZq22wfmp+fH6pjr63t+6Tw9Y7Wp0rhREN2XJSVlRWqY/t3e17f2Mq2Nz09PVD23UPbNrtPo0aNQnXstbXjRd81sImh7H224zEpeiJL7Dn8sgkAAAAAiDsmmwAAAACAuGOyCQAAAACIO2I291K+uAn7vLmN//PF+9nn1u0xfPEMdh/7DL7vuXfbXrsIry/ez7bf7lOVZ+7twtG+OtHiXKRwvIm9Tr5Fk3/++ecK2+Y7ro1B8bU/JycnULaxIr54RXstV65cGSg3bdo0VMeee926dYFy48aNQ3WindcXT2rjPuznwJ5XCl8nG+vq+6xEi+HwfSYBYG/k+563/a6NfYslXjFa/+g7jo2X8/XL9jg27s6Xx8HGmNrv+Vjej+3HfH2q3Wb7F9/4y57H9h9169YN1bG5E3ztt+eK1tdJ4TFBdnZ2hW2VwrGTdrzii6W07bUxnGlpaaE6dowTS/yljRfdtGlToGxjX33nse/Pdw/t+7GfUd9nEvHBL5sAAAAAgLhjsgkAAAAAiLtKTTbHjh2rAw88UOnp6UpPT1e3bt30xhtvRF7fsmWLhg4dqqysLKWlpal///7eRxQBAMC+jTEBACCaSsVsNm7cWPfdd59atWol55yeeeYZnXbaafrqq6/UoUMHXX/99Xr99dc1adIkZWRk6KqrrtLpp5+uGTNm7Kn2/2b51pOyz63bGDQbRyFVLZbSPgsf7Rl8Kbx+p32W33eeaPGjscSOWLHEENh4AN/6UjYuMpZrbeMifdfJrilp76kvLjIjIyNQttfNF5Ni37Ntv43DlcKxIYsWLarwdSkckxltvVUpeoyKr232WlYlvpd1N4H4Ykzw6/F9l9p491jWv7R9qO0/fP2WHTfY71Lfd7aNG7Sx+r4+1Naxx/V9h9v3HMt4xb5ne018YwLbftvnZGZmhurYsYavD7VjFjsm8OU9sDkjbH/oi6GNNr7yja3sPbJrh/vW2bRtszGavvGKPXcsn+NoYwLf+4n22ceeU6nJ5imnnBIo33PPPRo7dqw++eQTNW7cWE899ZQmTpyoY489VpI0btw4tWvXTp988okOP/zw+LUaAABUK8YEAIBoqhyzuWPHDj3//PPauHGjunXrpi+++ELbtm1Tz549I/u0bdtWTZs21cyZM3d5nNLSUpWUlAT+AADAvoMxAQDAp9KTzW+//VZpaWlKSkrS5ZdfrldeeUXt27fXypUrVbt27VD659zc3NDjhTsbOXKkMjIyIn9NmjSp9JsAAAC/PsYEAICKVHqy2aZNG/33v//VrFmzdMUVV2jgwIH64YcfqtyAYcOGqbi4OPK3ZMmSKh8LAAD8ehgTAAAqUqmYTemXINz9999fktS5c2d99tln+utf/6qzzz5bW7duVVFRUeBfMgsKCtSgQYNdHi8pKYmFVBVejNkGlkvSihUrAmUboO5LkmID+22AtH1dCgdNx5IMwAbU26B3X8B6tKQDvkV5bbC5LfuuQbQFqX0B+DYpjz1u06ZNQ3XsNrtoshQOqI923aTwdYhlMWn7nm2yn3Xr1oXq2PdsP28LFiwI1bEJHWySBN8CzvbzZffxfVZ897Widvjq2H343gF2H2OCPWPz5s2Bsu9xYpvZ137n+ZLsRevPY7n2sSR1s8lwbN/m+063fYHt62wiQincX/jaEq2OPa9N5CeF+2p7P3yf6Xbt2gXKc+fODe1jxwS2nJWVFapj76F9P74xjX2PixcvDpTtGFQKJ0pcvXp1oGwTBkn+vriidkjhMVksnxX72bbXwNeOWJIiYc/Y7XU2y8rKVFpaqs6dO6tWrVqaNm1a5LXZs2dr8eLF6tat2+6eBgAA7OUYEwAAdlapXzaHDRum3r17q2nTplq/fr0mTpyo999/X2+99ZYyMjI0ZMgQ3XDDDcrMzFR6erquvvpqdevWjaxzAAD8xjAmAABEU6nJ5qpVqzRgwACtWLFCGRkZOvDAA/XWW2/p+OOPlyQ98sgjqlGjhvr376/S0lL16tVLY8aM2SMNBwAA1YcxAQAgmkpNNp966qkKX09OTtbo0aM1evTo3WrU75F9vtwXm2C32efNfc+oR1sU2ffMun323cbYxRJ/aeM1fPEmtm0tWrQIlBs2bBiqY+MIbTyj7/3YGBS76HBRUVGoTrR4E19MxCGHHBIo2/gGKXyP8vLyAmVfvImN3bFxkb5YkWbNmgXKX331VaDsi8+wWR/t9fctgGwXoLbX2heDaj+DNh7DF69sP1/2HsYS5+nbB0DVMSbYc+z3l29MYPsGG0tpv2ul6DGNvjr2uzOWcYQ9j42/9PVBtk7r1q2jnue7774LlO11870f20/ZGE3feaLlV/DlTjjooIMCZRtj62ufPa6vLXab7bvtGMHXvs8//zxQ9uXIsGMLGz/qy/lhP5Pr168PlG1MqhQeW9hxkm9sa2M/bdt89922jZjNX89ux2wCAAAAAGAx2QQAAAAAxB2TTQAAAABA3FV6nU3sGfaZ9MLCwqj72DgK3/PzdpuNm/DFb9jn2GOJA7HrJNmYCF+8nD1327ZtQ/tYdp2kV155JVD2xRXa+EsbM+Bbi8yuj2VjBO11lMJxnOVrz+3s22+/DZTtPV27dm2ojo3zaNy4caDsux82BsV+DnzrbNq2+GIrrGjrntqYTin8+bLt963zZuNNbNt818Ce28bC2M+s77gAUB3s97Evt4Dtm2NZR9v2u3YfX51o5/H17/b71ZZ98XK2X7V9na9vsH3d1KlTA2XfGo3R2ubr321OCduf+K6b7U/atGkT2ufHH38MbduZL5ZyzZo1gXKrVq2i1rFtsZ8D35jAXhe7FrfvHto69rr42mb7b3v9feue2usfLT+JFI4ftXHDvvEwY4L44JdNAAAAAEDcMdkEAAAAAMQdk00AAAAAQNwx2QQAAAAAxB0JgqqBDbaXwskAfAs424BnmwwnlmQ/lk3oIoWDwEtKSgJlX0Ide5xY2mbZJDC+hXwbNmwYKOfm5gbKs2fPDtWxizHba2KTAUlSfn5+oGyD3H1JB2xQu22bJM2aNStQtkH5vgQI9vqvWLEiUPYtFJ2dnR0o16lTJ1D2Benbe2avk28Rbnvf7XXxfVZssL8NwPcF5Ns6NiGF73NskyjYz6DvPCQDAPBr840JYvn+tfvY7/BYkv3YcYWvr7b9kj2Grz+MxpegzbbF7uP7nrd9tR2/+PrH9PT0QNmOt+wxJSkrK6vCtvqugb0/9rxS+J7Zfsu+H99x58yZEyj7EjbZ8Ygdb8WS5MnatGlTaJsdB9nr5BsTROt3fYkf7fW2Yxo77pPC19a21SaTjKVtiA2/bAIAAAAA4o7JJgAAAAAg7phsAgAAAADijpjNauBbbNY+L++LtbDPl9uYRt9CxJZ9jt0XB2Kf07fxGrEsymvLvvdjt9kFd33xGYWFhVH3sey1tfF/vphNGyNgYxN++OGHUJ1mzZoFyr5Yi65duwbKc+fOrbCtkpSTkxPatjNffK+9r/Y6+Y5pz23jQuz9kcKfjVg+k7Ytdh/fZ8XGZ8Ty34tti72H0eKZAaC62O84X9ya/e60sZSxjCPs97Gvf492jFjGBPb7OFo8oO+4vnhSu4/tk3znsXGDmZmZgXKjRo1Cdexxbf+xePHiUB3bz/rGBB07dgyUFy5cGCj74iJtbKF9P774UXtce398car2s2Gvv+++2/tsr5NvTGA/p/Y8vs++/e8j2hjU1xY7pvHlCUF88MsmAAAAACDumGwCAAAAAOKOySYAAAAAIO6I2awGvrg8+3y5b20fu4993jyWdavsM/h2rSVJ2rBhQ4XH9Z3HxjPYZ+x96xdFW+vKF99g4yLsGpTt27cP1bHxFza20vecvo1ttTGaNtZSktLS0io8jxSOpbTv2a6h6Tuu5Vub067faa+/jVuVwnEeNrbCV6devXqBsv3c+mJs7GfDln3rcNlYC9/nybKffd9adgBQ3XzxZXabb91A+50dbd1N3z6Wb+xh4wbt97qvD/Jt25kv34L9Xl+7dm2g7IsRtHkc7DVp3LhxqI6NpczLy6uwHVL4utkYyAULFoTq2FhEX1tse5cvXx4o+3Iy2L7YXkvfmMYeJ1puDincZ9rz+NYNteMVO47wxWxGGxP4/vuINl7xffajrSXui3FGfHBlAQAAAABxx2QTAAAAABB3TDYBAAAAAHHHZBMAAAAAEHckCKoGvmBnG7jsC9K3iVNsgLcvGYtNRmSDxH3nscexwea+Or5g/4raKkl16tQJlAsKCgJl38LEq1atCpRt8p/69euH6tjrZpP9+BL5NGjQIFC2Qfu+92v3sceQwskM5s2bFyj7Au5tELs9t72OPjaRko+97zZJgi9BhU1UYK+/7zNp22/fXywLK0f7vPmOY5Md+BIIAMCvzTcmsGJJimb7uli+4zZv3hwo+/rqaMfx9Q32u9++R98xbV9mEwTZ5IW+fWwSHl/bbF9gxxW++2GTKRYVFUU9z+rVqwPl3Nzc0D523PPtt99GrWPvkU1sk5mZGbWOvZa+fteOH22/6xsL2gRB9rr5kvBES3DkS+5n75F9f77Pl30/tsyYYM/hl00AAAAAQNwx2QQAAAAAxB2TTQAAAABA3BGzWQ18z4Xb589jea7dxnD4Fmu2MRy2bOM1fOe2z7X7RHsW3hcHYs9jYyB8dTIyMgJlew1sTKQUfv7fLlC9bt26qOex5syZE9pmF3X2xX3YtthyLAsrxxLfY8USz2BjTuxnxV43SVq/fn2gHEtMh/2cRitL4c+KvQa+eBP7nqPFuQDA3sJ+R/v6Q/v9Gq1/kcLfr/a71DcmsPGXscS22ePa8/q+f21/bnMN+M5rYwLtdbJ5KqRwPgjbt8XSn2zcuDFQXrx4cahOLDGBdtxj9/GNCaJdf989tNe/du3aFR5Dij7G9N1De13sPjbPgxS9P/eNQe01sPv4cn7Ya2nHK8Rs7jmMtgAAAAAAccdkEwAAAAAQd0w2AQAAAABxR8xmNfA9Fx4tvkyqWtxatDULfXF49ll3+5y7r060uE5f3IE9j12fybeumN22ZcuWqO2wdey6XL44TxubsGbNmkDZxjNK4Xu2ZMmS0D52HU0bb+KLL7F1bAynr46Ni7CxPb7rZOMX7D6+NTNtzKat44vZjNa2WNbmjCU+w973WNbmtPfd1xYAiKdYxgS+7yJbz65T6eun7HenHUf4+oZo6y3afthXJ5Yxjq1j349vHGH7E9sWX1yhzU9g4wx972fp0qWBss314LvWtm+bO3du1LbY92P7WN8+9h7aMY4UvpZVyeNgx36+z4rti+0+vvGjvU72PvviS217o8VwStHzNPiugR1D+z63iI5fNgEAAAAAccdkEwAAAAAQd0w2AQAAAABxt1uTzfvuu08JCQm67rrrItu2bNmioUOHKisrS2lpaerfv78KCgp2t50AAGAvxpgAAGBVOdL1s88+0+OPP64DDzwwsP3666/X66+/rkmTJikjI0NXXXWVTj/9dM2YMWO3G/tb4QtStgHQvoBomxjGJgzwJQOKluDEBoD72meP4TumDfqOJXmRDeC2iXBiSSBg2+K7brZtdsHj1atXh+qsWrUqUN6wYUOg3LFjx1AdGxhvF6SWwtchlsWkMzMzA2WbnMEXcG8T3dj7HMt9t5833/2oV69eaNvOfEH6NpGCPa8vqVC0pAO+z6TdFktCBBICAVXDmKDqfGMC+z3v+26KlpjPV8d+D9q+Otb2RXvdJt2JlpjIx/ZTvj4o2rjINyaw/blNCORLOGffox03dOnSJep55s+fH9on2rjBJgPy1bGfFd97ttfFJuHx9Yd2mx2fxDKWtef13Xff9Y52HrstWtnXllj6exICxUeVftncsGGDzj//fD355JOBwWZxcbGeeuopPfzwwzr22GPVuXNnjRs3Th9//LE++eQT77FKS0tVUlIS+AMAAPsGxgQAgF2p0mRz6NChOvnkk9WzZ8/A9i+++ELbtm0LbG/btq2aNm2qmTNneo81cuRIZWRkRP6aNGlSlSYBAIBqwJgAALArlZ5sPv/88/ryyy81cuTI0GsrV65U7dq1Q2sH5ubmauXKld7jDRs2TMXFxZE/39qEAABg78OYAABQkUo9jLxkyRJde+21mjp1amjB9KpKSkryLtT7WxZLfIbvmftYnpePdtxoZSn8HLuNCfS1zcbhRYvL853HPhtv4w6lcDxDtEWtJamoqChQttfR95iWjRWx8Sa+WBkbi2DP6zu3jemwgzIpvECzvWfFxcWhOjb+1bbNFzdhF4+2sa2+uAobT5KRkVHhMaTwZ8FeE18de55YFvu257FxOdHinQBUjDHBnmP7w1jiFWPJlWD73Wg5Gnxs/+6L97P9lG2L7/s32vjEV8f237b9vs9lYWFhoBxt/CKFr1O0OENfW+z9ksKxrbYf9rXfvmc7VoolR4Z9P75xnW1bLLGttr12TOO7h1WJ57XfEfa8vv9eot0P35gT8VGpXza/+OILrVq1SocccogSExOVmJio6dOn629/+5sSExOVm5urrVu3hgbZBQUFatCgQTzbDQAAqhFjAgBANJX6ZfO4447Tt99+G9h20UUXqW3btrrlllvUpEkT1apVS9OmTVP//v0lSbNnz9bixYvVrVu3+LUaAABUK8YEAIBoKjXZrFOnjg444IDAttTUVGVlZUW2DxkyRDfccIMyMzOVnp6uq6++Wt26ddPhhx8ev1YDAIBqxZgAABBN3BeQeeSRR1SjRg31799fpaWl6tWrl8aMGRPv0+zTYlnfz/f8vBXtGXzfce0z6r7n5+3z/vb5ed9z7Ta2IpZn4W0d33WJxsY8+mJ9bFtsHV98ho09zM3NDZR9SStszIBdH9MnltgEG3+5YMGCQNkXm2A/P751NS173218hi821F5bu0amvY6+OjYuxHc/LPtZ8X2+7DWw9yeWaw9g9zAmiM7X98USU2fF0ldHiz30fS9WJabO9kv2PL622f7bHiOWOE/bf9h+TArnBbD7+NautrGH+fn5gfKKFStCdexxc3JyQvtEixP0xdDafvann34KlH1jQVvH9oe+axstj4Pv2trjpKWlVdgOKTwmsPfQjtmk6HGqvnwk9r8h27aqjEERm92ebL7//vuBcnJyskaPHq3Ro0fv7qEBAMA+hDEBAGBnVVpnEwAAAACAijDZBAAAAADEHZNNAAAAAEDcxT1BEKKLJZGPL7jZBlHbYGZfchwbYG8DvG3Zd1xb9gWS2/PY4G3f4r/2uPa6+BLf2Pdo2//999+H6tgg9nr16gXKK1euDNWxyQCaNGkSKPsWZ7bB9K1atQrtY+9rLAsR22QM8+bNC5RtogIpfI9iSVZkEwDZIH37/qTwdUhNTQ2UfUktbNvs5yCWhEf2mvgC+21SpKZNmwbKvkQFAPBr8yWBiSVpoO1n7fegbxwRLQmKr6/2tS8a+x1ty75xRDS+dtgxgU0U8+OPP4bq2IQztn+0Set8+zRr1ixQLigoCNUpLCwMlDt27BjaJ1qyJZvERgonMLLJiXyJ+ex1ycrKqvCYUrj99rr5xo+2vXYc4evfo439fJ9Z+99DLONH2za71m8sSbhQNfyyCQAAAACIOyabAAAAAIC4Y7IJAAAAAIg7Yjb3EvaZdBvLJ4VjC+0z9rE8C29jHnznsTEb9pl7X0yHLw61ovP66tiYAl9MR7RFeZctWxaqY2MNe/XqFSj74i+jvZ/GjRuHttnYEF9bbJyEjQ31xVZ+8cUXgbKNmygpKQnVsXEs9v34rm20GCFfbImNGbKfFV/sS3p6eoXn9V17+9+HreP7fNm2FBUVBcq+WJhY4qABYE+z34O+eLI1a9YEyvY7zyfad2cssaH2e93Xh0aLRYzle96+H18dO+6xcaq+Psj2mQcddFCF7fCxfajNVyCFxzSLFi0K7WPHANnZ2YFyTk5OqM6sWbMCZZuXwuYrkKTc3NxA2V5LX19nt9lru3bt2lCdaLkQfJ8Le1xb9t0Pu4/9HPvGw/Z+xDImsMchrrNq+GUTAAAAABB3TDYBAAAAAHHHZBMAAAAAEHfEbO6lfM+FR1u/yMfGWsQSs2mf/7cxgvaYkj9GYGe+92NjBux5bVkKXwO7jy8ewMZJ2vfsWw/TxsLY2ATfeWy85ZIlS0L72HjXgw8+OOpx7fW3MR4dOnQI1bHv2b6fWNaytNfaxlpK0ddfi+Ue2s+Or21ViemwMc02Tsf3OY4WqwsAvwbbF/i+a+13px0T+L7jLPtd6uuDbP9n8yDEMiaIZa1Oe27bX/pyDdj+PFoeAV8dG5vYpk2bUJ3FixdXWPZdA/uefXkcbD/VuXPnqMe161vaPvWAAw4I1bH9t80BEsv9sdctlrWqbZxkLP1utP5eih6r6/sc28+THRP4Yo9jid9FdIysAAAAAABxx2QTAAAAABB3TDYBAAAAAHHHZBMAAAAAEHckCNpL2KBpX2IVG0RtE8XYoHEpHNxsyzZ4WwoHUdvz+pKo2OQyNtDaF6xt69hrYJPaSOFkOTZhQF5eXqiOXbjXXtuGDRuG6tj3WFhYGCjbZECS1LFjx9A2yyYrsPfDtlUKL+rcpEmTQNl+DiTp559/DpSLi4sD5fr164fq2EWpbcIAXzIAe/1t0H4swfV2n1gW+7afW9/ny9apSoIKAKgOsSS6sd+D9jva9uVS1cYEts+0bfN9Z9ttsSQ8sn2QPY9NaiOF+zbbB2VkZITq2MQwGzduDJQbNWoUqmP73dmzZwfKvmSLNtnP8uXLQ/vYc9vrZNsqhfv8nj17Bsp16tQJ1fnpp58CZTum8dWxSYXsmM2XGDJakiebjEkKfxZi6astO+b0JZOyn8lYzsuYID74ZRMAAAAAEHdMNgEAAAAAccdkEwAAAAAQd8Rs7iXs8+V2oV8pvLCyXcTWF2thn7G38Rm+89jn1u0z9r6Fb33Px1d0TCkcW2GP62ubjUtt1apVoGxjPiSpoKCgwrb54gqzsrICZXttffEZ9hrk5+eH9rFxN3ZxbB/fAtM7++GHH0LbfLEhO/MtkmzjM2ysgu892/thr0Es991eW1+ckb2vtv2+exgtHsMXi0F8BoC9gf0u8uVxsDkMbEyab0wQbdzg63ftd7b9Pva1zcZb2vcTy3e2PYaNb5TC16B58+aBcsuWLUN1bG4EewzfdbNjAnse3/ux16lp06ahfWxMph0j+GIcW7duXeG5v//++1Cd+fPnB8rR4nAlKS0tLbRtZ75xhO2/bdk3frTtt23xjQlsvGgsORqixSv7MCaID37ZBAAAAADEHZNNAAAAAEDcMdkEAAAAAMQdk00AAAAAQNyRIGgvYQOVfQl3fEHr0erYQGsbnO1LUBNtQd1YFpe2SQZsggEpHHht66xatSpUxyapscl/fAHt+++/f6Bsg/ZtEiUpfN1skL4v6ZBNXuBLqJOXl1fhPr5EC/a+fvPNN4GyDfyXwgkQ7OfLF/RuF3W298z3fqIlgfBd22htsUmHfOe299nXNpt4IZYEAr5kDADwa4slmUm05CWxJECx/bmvf492Xt/YxJ7bHtf3/WuPY+usW7cuVMceZ/HixYGy7zu9Xr16FZZ9iW/stoYNGwbKts+VwomHfO+5UaNGgXJGRkag7EvcY8ca3333XaDsGztZNsGOr212vGjvj+862SRVtv2+saDdxx43lqSUKSkpgbLvvtv7YT+jtu27Og4qj182AQAAAABxx2QTAAAAABB3TDYBAAAAAHFHzOZewj7Hbp8/l6IvxuyL2YwWD+eLB4i2KK9vgV0bm2fP44sDsXGPti3Lly8P1bFxBrNnzw6UfTGPzZo1C5RPOumkQDknJydUx15L+yy/L+7A7mPbKkmZmZmBct26dQNl36LVxcXFgbKNRfTFONo4AxursGDBglCdlStXBsr5+fmBsm9B6mgxp777bj8/9rPj+0zaWB0ba2wX3JbC98Nea188KQDsDez3ly92LFpsmy+m0+5j+w9fnWj9eSwxm7Zv8MXhFRYWVrjP6tWrQ3UsGzu5Zs2a0D423vLkk0+u8HUpfP1jiYe14wjbB0nhHBLp6emB8tq1a0N1bB9p749vHGHHI/Ye2msvha93/fr1A+Xc3NxQHTs2sp8n332PFifs+3zZ+2zHODb2VQrfMztuYEyw5/DLJgAAAAAg7phsAgAAAADirlKTzdtvv10JCQmBv7Zt20Ze37Jli4YOHaqsrCylpaWpf//+3iUiAADAvo0xAQAgmkrHbHbo0EHvvPPO/w6w0/PZ119/vV5//XVNmjRJGRkZuuqqq3T66adrxowZ8Wntb5h9zt0X72ef7fc9Y2/ZtZNiWevKPvseS6yFjS+xx/U9c2+Pa8+7cOHCUB0bQ2Db4oul/OGHHwJlu6bWmWeeGapjYyttnKFdG0sKx2f42mJjbGzshS8OxMYetG7dOlD2XVt7XBvDMWfOnFAdGyNr40vs/ZHCMZvR1lv17WM/17HE/9jz+s7Tpk2bQDk7OztQ9t0fAJXDmGDPsPFj9ntSCn8P2lh2X/xltDGBL/eD3cf23b44e/v9ar/DfXVsf277HJtXQAr3WzbHge+6rVixIlC261/v/A8m5Wz/YeMk7etS+PpXZR1H33jLjglsXgpfDKQ9t722S5cuDdWx19uOS335O+x9t/fZ3h8p3H/Hsgao/e/D7uO7rs2bNw+UGRP8eip9ZRMTE9WgQYPQ9uLiYj311FOaOHGijj32WEnSuHHj1K5dO33yySc6/PDDd7+1AABgr8GYAABQkUrHbM6dO1cNGzZUixYtdP7552vx4sWSpC+++ELbtm1Tz549I/u2bdtWTZs21cyZM3d5vNLSUpWUlAT+AADA3o8xAQCgIpWabHbt2lXjx4/Xm2++qbFjx2rBggU66qijtH79eq1cuVK1a9cOPXqXm5vrffSh3MiRI5WRkRH5a9KkSZXeCAAA+PUwJgAARFOpx2h79+4d+f8HHnigunbtqvz8fL344ovedSFjMWzYMN1www2RcklJCZ0LAAB7OcYEAIBodisatm7dumrdurXmzZun448/Xlu3blVRUVHgXzILCgq88RzlkpKSogZI/x75AqJt0LQN5Pcll7FB7DbY3CaskcLB5TaQ3Jd0wLIJBHyPQkW77746NrjcBpb7Bjh2Ued58+YFyr6ENJZ9z76222vtCza32+y5fffQvqdWrVoFynahZSkcuG8zQPoSFdi22KRCNvmE7zi2jm9hZbuPvW42OZMUvi72fvgWsfYloNiZ7xoAqDrGBHuO7/vK9g32O8/XV9u+OZbEdrY/sX2Bb7xit9m2+ZLL2PGI/Rz4+mo7JrB9ga9PteOGJUuWRD1PtGR+9hd8KXydfIns0tLSAmU7/qpTp06ojh0L2mR46enpoTp2DGCvm+8923sULamjFH4/dh9fwqZoYwKb1FEKf77s59Y3JrD/PcQylkV87NZoa8OGDZo/f77y8vLUuXNn1apVS9OmTYu8Pnv2bC1evFjdunXb7YYCAIC9F2MCAIBVqV82b7rpJp1yyinKz8/X8uXLddttt6lmzZo699xzlZGRoSFDhuiGG25QZmam0tPTdfXVV6tbt25knQMA4DeGMQEAIJpKTTaXLl2qc889V2vWrFF2dra6d++uTz75JLJWzSOPPKIaNWqof//+Ki0tVa9evTRmzJg90nAAAFB9GBMAAKKp1GTz+eefr/D15ORkjR49WqNHj96tRsG/sLKNEYglXrGoqChQts/l++ImbGyCjfP0xUDYOAMbb7lu3bpQHcvW8S1MbN+zfS7fF99gYwBtbIUv3sS+Z7uAsC/W1cYZ+OIz7LmilaXwfbXv0RdjY6+lvc+HHnpoqE7Tpk0D5VmzZgXK5Usa7CwrK6vCsi+e9LPPPguU7efJ9/mycSA27sO38HUsxwVQdYwJfj2+MYH93rPf877+xPYNvuNa0cYEvvPYtti+2sYM+s5j9/HVsWxf7fvej7aPfV0Kx/fZGFrfdbTbYolTtefxtcXGska7bpK0du3aQDk5OTlQbtmyZdS22djW5cuXh+qU/0NTOdtX++K1v/rqq0DZxqTashS+Z76xn2Wvrb0/xHDuOWTIAAAAAADEHZNNAAAAAEDcMdkEAAAAAMTdbq2ziT3Ht6aWfcbePm/uW1fIrvNk1zyy6yZJ4ef/7Xl8MQT2PLZs4xmlX5JLVFTHF/No22tjRXzv58ADDwyUDzvssEDZ937s9Y8l3s/GTvrWpbRxBfbcvtgX2xYbA7Fo0aJQnS+++KLC4/rWurJrYp588smBso2rkKTVq1cHyh07dgyU7WdWklatWhUo2+vmu9aNGjUKlG0Mp29tTrtPtDXcAGBv5esb7HecjTnz9bvR8iv4+lCb68F+Z/v6UBufaMcevrhC2zfYcmFhYaiOfT82T4Wvr2vXrl2g3LNnz0DZF/9nr38s63PbvszX50SLG/SNBaO1xTd2stclWh4EKRx/2aJFi0D5559/DtWxn6cjjjgiUPa9n48//jhQttfAd99tPgh7DWzbpfAYx36OfXlPEB/8sgkAAAAAiDsmmwAAAACAuGOyCQAAAACIOyabAAAAAIC4I0HQXsqXWMUupGwDpH0L7Npg/3Xr1lX4uu88NljeJhCSwkHuNvDaJmeRoic8Wrx4caiODXJv27ZtoOwL8D7mmGMC5S5dugTK6enpoTr2GthAf18SG/sefce11yXaIsNS+B69//77gfK0adNCdWywvD2Pb3Hphg0bBsoHHXRQoHz88ceH6qxZsyZQtosv+xII2Gtrr5NN+CCFr5uVl5cX2mYTHsSS5AkA9ka+5DL2uzQnJydQ9iWPs3VsYkGbyEcK9ye+hGzR6thxg28cES3pji9RzMqVKwPl3NzcQNmX+CY/Pz9QtkkEbT8mhftmX8Imy/ZtvnGdHTfY62L7bincR77++uuB8owZM6K2xbbfN0azCXXsfe/Tp0+ojh2j2X7366+/DtWxCY3sdfIlPIqWxLFevXqhOjYpUrRxBeKHXzYBAAAAAHHHZBMAAAAAEHdMNgEAAAAAcccDy/sQ+3y5XejeF39pY+rss/C+5/Rt3ISNFfHV8cWT7Gzt2rWhbXXr1g2UbayIXdBZknr37h0ot2rVKlD2XQMbn2jLvkWG7fP/dh9fHIW9tr54ANs+Gz/ju44FBQWB8ksvvRQof/7556E6Npa1WbNmgbKv/Tae97vvvguUfTEqduFk+9mxnz/fcWKJa7GxFrHEx9qFxlmwGcBvie1jbOy6jZ+TpJKSkkDZft/6vudtHKH9bvXVsftYvth8+x1t4yRtfKYU7uvatGkTKNtcBL469hr4YkftGCCWOuvXrw9ti7aPHRP4Yk7tPXz11VcDZV9cpI1Lbd++faDsGxPYcdvcuXMDZV+/a6+3HfP4xnX282XHQb7PUrR97JjBt48vNhd7Br9sAgAAAADijskmAAAAACDumGwCAAAAAOKOmM19iI1nsM/LN2/ePFTHxjjYGIhY1rqycSG+Z+Ft/MXSpUsD5RUrVoTqRGtr06ZNQ/vY92zXX7LrZ0nh9Udt23xrhtln+W2cp289zFjWzLQ2b94cKPviYW3Mg42TPPzww6O2xR7Xxsv62mKtXr06tM1+Nux79sVJdujQocK2+dbHsve1QYMGgbJdc3ZXxwGA3wobN2jj/WysvhSOzY9l/Uvb/9n+xfc9b/uTZcuWBcq2H5bC/a6NZ7TxmFI4FtFeA1+fatsyZ86cQNnGM0rhPsbGw/piHm0sqy+21daz1813XDsmaNeuXaDsGwva62L57mG0mFN7HaVw7g07RvCNPWz7bVvsep9SOGeJjRW1r0uMCaoTv2wCAAAAAOKOySYAAAAAIO6YbAIAAAAA4o7JJgAAAAAg7kgQtA+rU6dOoOxLSGMTqdhEPr4AcBugbpMQ+NhEPTaZjC9BkA18twH3vkRENgjcJhTwLeBsA9Rt2bcYs72Wdp+qJgiyge82eYGvLTYxwVlnnRUo+5IO2IQHP//8c6BsF6iWwkkgfAkDLLvos01C4DuP/Uza++EL4m/SpEmgbBcv9yUIAoDfEzsm8PUnNtlKSUlJoGyTz0hScXFxoGy/s20/LIXHFjNnzgyUbX8vhRPF2P7E1zfYJEi2ji9RjB1b2OPa9ydFT6RUu3btUB3b//n2sfcoISGhwvNIUk5OTqB82mmnBcq+MUFhYWGg/N1334X2sew9tMf19e927Gc/O7622aSHduzhSypk77u9zyQD2rvwyyYAAAAAIO6YbAIAAAAA4o7JJgAAAAAg7ojZ/A3xxRm0bNkyULbxAd9//32ojo3rTEpKCpR9sRY2JtPGB9g4UCkcX7lmzZoK2ypJK1euDJRtrJ4vvsGeJysrK1D2xRDYeEt7bX0LJEeLDZXCMRv2WvvY49iFrX1xEzYux8bd2jgKKXwdbAyqvT++42zcuDG0j5Wbmxso21gLX/yljemwxwAABNmcAJLUqlWrQNn2ZT/88EOojo3nt32F7e8lad26dYGy/Q739e+2b7a5IHz91tdffx0o27hVG+8vhfuPaHkEpHB/GEt8rL1ONh5TCo+vbB3fce1xDjzwwEDZNz7x5bPY2YYNG6K2zY7j7D2Wwp+FWGI2GzduHCjbMYD97Pj2YUywd+OXTQAAAABA3DHZBAAAAADEHZNNAAAAAEDcEbP5G+KLB7Cxey1atAiUly1bFqpjn8u3cZCrVq0K1bHP7ts4AxsTIYWfsbcxAzZeQwqvL9W7d+9A2ReXYGME7PP/qampoTo2DtLGa/jEErNpj2vvmW9NU3vuaGVJSk9PD5Tbtm0bKPtibGwMxKJFiwJlu36Wj11vzca1SOHPoL1ndg1Nyb9WGgBg13x9g/2Ozs/PD5RtXgQpHLNpcxoUFBSE6tj1O23/kpmZGapj10a0+SHsus5S+P1ccMEFgbKv77D9rO2nfHkQbF9t+3dfLKJvW7TjxnIMe/3tffbVsfu0b98+UPbdQzvemj9/fqDsy+Ng18i040dfTga7Zqb9TPriMZs2bRrahr0Xv2wCAAAAAOKOySYAAAAAIO6YbAIAAAAA4q7Sk81ly5bpggsuUFZWllJSUtSxY0d9/vnnkdedcxoxYoTy8vKUkpKinj17au7cuXFtNAAAqH6MCQAAFalUgqB169bpyCOP1B/+8Ae98cYbys7O1ty5cwNB3Q888ID+9re/6ZlnnlHz5s01fPhw9erVSz/88IM3+QnixwbKS9LGjRsDZbtocseOHUN1bHC5DcpPS0sL1bEB9TbJkA0sl6R58+YFyjYJQZ8+fUJ1zjvvvEDZl3jIsu+ndu3agbINYJfCi2HbhEe+5D92WyxJBmxbfHVsMgDbXl+CAVsnlqRIpaWlgbINyvclhrLtt+exCaqk8ELR9lrzPQHsGxgT7N18CdqKi4sDZfud3aFDh1Ad24faxDC+ZD/23tq+zSagk6TvvvsuULbjiL59+4bqDBgwIFC2/Zavf4+W3CeWxD6xJBG0fbOvr46WIMjHnsu+R9v/++rUrVs3ULaJfaRwkkabeNCXxNG+H/sZtGNQKTyOsPfHN17BvqVSk837779fTZo00bhx4yLbmjdvHvn/zjmNGjVKf/7zn3XaaadJkv75z38qNzdXU6ZM0TnnnBM6ZmlpaWCQazOYAQCAvQ9jAgBANJV6jPbVV19Vly5ddOaZZyonJ0edOnXSk08+GXl9wYIFWrlypXr27BnZlpGRoa5du2rmzJneY44cOVIZGRmRvyZNmlTxrQAAgF8LYwIAQDSVmmz+/PPPGjt2rFq1aqW33npLV1xxha655ho988wzkv63PpN9jCE3N9e7dpMkDRs2TMXFxZG/JUuWVOV9AACAXxFjAgBANJV6jLasrExdunTRvffeK0nq1KmTvvvuOz322GMaOHBglRqQlJQUiuFC/Nhn3W1cXuPGjUN17PP/ixcvDpQ3bNgQqmOPa2NFV6xYEarTokWLQLlbt26Bcu/evUN1bAxgLLEVlo0P8MVa2HgMX4ymVZX4DHueWOrY9+xrf7QYCPu6FL6H9lr7PivRzuOLQbVxHwD2TYwJ9j32e9321Ts/Bl3O5iyw3/u+2Pxt27ZVeAxfzGbbtm0D5T/84Q+B8s6/kJezYxw7fvF9lmwfGks/bMUrZrMqdWxMpn0/vjjVaP9N+cY4Nu7Wxub6zmPba4/hOw8xmb99lfplMy8vT+3btw9sa9euXWQyUp6spaCgILBPQUFBTIlcAADAvoExAQAgmkpNNo888kjNnj07sG3OnDnKz8+X9Mu/iDVo0EDTpk2LvF5SUqJZs2aFfrUCAAD7LsYEAIBoKvUY7fXXX68jjjhC9957r8466yx9+umneuKJJ/TEE09I+uXn8+uuu0533323WrVqFUlz3rBhQ2/KagAAsG9iTAAAiKZSk81DDz1Ur7zyioYNG6Y777xTzZs316hRo3T++edH9vnjH/+ojRs36tJLL1VRUZG6d++uN998k/W09hI2zsC3tlKjRo0CZfsMvm/NzKKiokDZxvd17949VMeu8WnXX/K1zbbfxhn64gGixWf42HgTuxakj42jiCX+0taJZW3OWNbUihbL6ou1iBanGksclY1b8a39CuC3gTHBb48vnt9mBI6W10EKx4LaYxx11FGhOgcffHCgbGMEff2ajQW1/aGv744Wo+nru23fVpV4TF9cZ1X2iTaO8LXF/vdmr5sd80jhMUC09Ul9bbHXmjHB71OlJpuS1KdPH/Xp02eXryckJOjOO+/UnXfeuVsNAwAAezfGBACAilQqZhMAAAAAgFgw2QQAAAAAxB2TTQAAAABA3FU6ZhP7Nhss7wuet8H/NtnPli1bQnVssLmtY9dik8KB4r7kPpYNfLcB6r7A+Kos2GxFSw7g28fHXqeqiOX92Gtpz1uVREq+OvbcsdxDAMDeITU1Neo+dkzQokWLQNnX99kEfzk5OYFyq1atQnXS09MDZdsH+ZLh2X1iSQgYLblPLMn9qqIqCYJiaYt9j74kT7ZOLG2x7LX1JQiyYwBfW/D7wy+bAAAAAIC4Y7IJAAAAAIg7JpsAAAAAgLgjwAohNm7CPuufn58fqpOdnR0o2ziQrKysqOe1cSG+mAIbD2DrxBK/GAsbixDLeWzchK/9NuYkllhKe5xoMSq+Ova89v1IUlJSUmhbNMRoAsBvW506dQJl23/4xgRNmjQJlJOTkwPlzMzMqOf19VOW7be2bdsWtU484ghjyb9g+2HfmCBaLKgvTjVa/KUvTtWy+/iutS+nR0XtkIjRhB+/bAIAAAAA4o7JJgAAAAAg7phsAgAAAADijoArRGXjNWw5Xnyxh9FUJc7w1xJL/Ggs79nGUpSWlgbKNhbGx57HF2+yN19LAMDeoW7duhWW46UqY4K0tLQ90JLoYsnRUJXjxHIM25/7xgTR1hL1jQn21FgPvz/8sgkAAAAAiDsmmwAAAACAuGOyCQAAAACIOyabAAAAAIC4I0EQEINYEuzYxD0+dsHjDRs2RK0TLQHQ1q1bo57HJhnavHlzqE56enrUtgAA8Htnk/35+n/bz9o6klSrVq0Kj2P7bik8JrDjkW3btoXq2DGBFcv4BagqftkEAAAAAMQdk00AAAAAQNwx2QQAAAAAxB0xm0AVJCUlhbYVFhZGrWcXnF6/fn2g7IvP2G+//QJluxizfV2SatSoUWE5Nzc3alsBAEB0vjFBQUFBoGz7YSmcK8HmcahKfgUbBypJzrkKyw0aNKjwmMDu4JdNAAAAAEDcMdkEAAAAAMQdk00AAAAAQNwRswnESaNGjaLus2bNmkDZxnD44j5btmy5ew0DAAC/qqZNm0bdp6ioKFC262avWLEiVKdVq1a71S7g18YvmwAAAACAuGOyCQAAAACIOyabAAAAAIC4Y7IJAAAAAIg7EgQBv6KsrKwKy7EkFAAAAPu+unXrVlhu0aLFr9cYYA/hl00AAAAAQNwx2QQAAAAAxF2lJpvNmjVTQkJC6G/o0KGSpC1btmjo0KHKyspSWlqa+vfvr4KCgj3ScAAAUH0YEwAAoqnUZPOzzz7TihUrIn9Tp06VJJ155pmSpOuvv16vvfaaJk2apOnTp2v58uU6/fTT499qAABQrRgTAACiSXDOuapWvu666/Tvf/9bc+fOVUlJibKzszVx4kSdccYZkqSffvpJ7dq108yZM3X44YfHdMySkhJlZGSouLhY6enpVW0aAPyu8V2KXxtjAgDYO1Xnd2mVYza3bt2q5557ToMHD1ZCQoK++OILbdu2TT179ozs07ZtWzVt2lQzZ87c5XFKS0tVUlIS+AMAAPsOxgQAAJ8qTzanTJmioqIiDRo0SJK0cuVK1a5dO5S2OTc3VytXrtzlcUaOHKmMjIzIX5MmTaraJAAAUA0YEwAAfKo82XzqqafUu3dvNWzYcLcaMGzYMBUXF0f+lixZslvHAwAAvy7GBAAAn8SqVFq0aJHeeecdvfzyy5FtDRo00NatW1VUVBT4l8yCggI1aNBgl8dKSkpSUlJSVZoBAACqGWMCAMCuVOmXzXHjxiknJ0cnn3xyZFvnzp1Vq1YtTZs2LbJt9uzZWrx4sbp167b7LQUAAHsdxgQAgF2p9C+bZWVlGjdunAYOHKjExP9Vz8jI0JAhQ3TDDTcoMzNT6enpuvrqq9WtW7eYs84BAIB9B2MCAEBFKj3ZfOedd7R48WINHjw49NojjzyiGjVqqH///iotLVWvXr00ZsyYuDQUAADsXRgTAAAqslvrbO4JrKkFALuP71L8FvA5BoDdt0+uswkAAAAAwK4w2QQAAAAAxB2TTQAAAABA3DHZBAAAAADEHZNNAAAAAEDcMdkEAAAAAMQdk00AAAAAQNwx2QQAAAAAxB2TTQAAAABA3DHZBAAAAADEHZNNAAAAAEDcMdkEAAAAAMQdk00AAAAAQNwx2QQAAAAAxB2TTQAAAABA3DHZBAAAAADEHZNNAAAAAEDcMdkEAAAAAMQdk00AAAAAQNwx2QQAAAAAxB2TTQAAAABA3DHZBAAAAADEHZNNAAAAAEDcMdkEAAAAAMQdk00AAAAAQNwx2QQAAAAAxB2TTQAAAABA3DHZBAAAAADEHZNNAAAAAEDcMdkEAAAAAMQdk00AAAAAQNwx2QQAAAAAxF2lJps7duzQ8OHD1bx5c6WkpKhly5a666675JyL7OOc04gRI5SXl6eUlBT17NlTc+fOjXvDAQBA9WFMAACIplKTzfvvv19jx47Vo48+qh9//FH333+/HnjgAf3973+P7PPAAw/ob3/7mx577DHNmjVLqamp6tWrl7Zs2RL3xgMAgOrBmAAAEE2C2/mfIKPo06ePcnNz9dRTT0W29e/fXykpKXruuefknFPDhg1144036qabbpIkFRcXKzc3V+PHj9c555wT9RwlJSXKyMhQcXGx0tPTq/CWAAB8l2JPY0wAAPuG6vwurdQvm0cccYSmTZumOXPmSJK+/vprffTRR+rdu7ckacGCBVq5cqV69uwZqZORkaGuXbtq5syZ3mOWlpaqpKQk8AcAAPZujAkAANEkVmbnW2+9VSUlJWrbtq1q1qypHTt26J577tH5558vSVq5cqUkKTc3N1AvNzc38po1cuRI3XHHHVVpOwAAqCaMCQAA0VTql80XX3xREyZM0MSJE/Xll1/qmWee0YMPPqhnnnmmyg0YNmyYiouLI39Lliyp8rEAAMCvgzEBACCaSv2yefPNN+vWW2+NxFl07NhRixYt0siRIzVw4EA1aNBAklRQUKC8vLxIvYKCAh188MHeYyYlJSkpKamKzQcAANWBMQEAIJpK/bK5adMm1agRrFKzZk2VlZVJkpo3b64GDRpo2rRpkddLSko0a9YsdevWLQ7NBQAAewPGBACAaCr1y+Ypp5yie+65R02bNlWHDh301Vdf6eGHH9bgwYMlSQkJCbruuut09913q1WrVmrevLmGDx+uhg0bqm/fvnui/QAAoBowJgAARFOpyebf//53DR8+XFdeeaVWrVqlhg0b6rLLLtOIESMi+/zxj3/Uxo0bdemll6qoqEjdu3fXm2++qeTk5Lg3HgAAVA/GBACAaCq1zuavgTW1AGD38V2K3wI+xwCw+/aZdTYBAAAAAIgFk00AAAAAQNwx2QQAAAAAxB2TTQAAAABA3DHZBAAAAADEHZNNAAAAAEDcMdkEAAAAAMQdk00AAAAAQNwx2QQAAAAAxB2TTQAAAABA3DHZBAAAAADEHZNNAAAAAEDcMdkEAAAAAMQdk00AAAAAQNwx2QQAAAAAxB2TTQAAAABA3DHZBAAAAADEHZNNAAAAAEDcMdkEAAAAAMQdk00AAAAAQNwx2QQAAAAAxB2TTQAAAABA3DHZBAAAAADEHZNNAAAAAEDcMdkEAAAAAMQdk00AAAAAQNwx2QQAAAAAxB2TTQAAAABA3DHZBAAAAADEHZNNAAAAAEDcMdkEAAAAAMQdk00AAAAAQNwx2QQAAAAAxF1idTfAcs5JkkpKSqq5JQCw7yr/Di3/TgX2RYwJAGD3VeeYYK+bbK5fv16S1KRJk2puCQDs+9avX6+MjIzqbgZQJYwJACB+qmNMkOD2sn/2Lisr0/Lly1WnTh2tX79eTZo00ZIlS5Senl7dTatQSUkJbd1D9qX20tY9Z19q797QVuec1q9fr4YNG6pGDSImsG9iTLDn7Uttlfat9u5LbZX2rfbS1sqpzjHBXvfLZo0aNdS4cWNJUkJCgiQpPT19r/8glaOte86+1F7auufsS+2t7rbyiyb2dYwJfj37Ululfau9+1JbpX2rvbQ1dtU1JuCfuwEAAAAAccdkEwAAAAAQd3v1ZDMpKUm33XabkpKSqrspUdHWPWdfai9t3XP2pfbuS20F9hX70n9XtHXP2Zfauy+1Vdq32ktb9x17XYIgAAAAAMC+b6/+ZRMAAAAAsG9isgkAAAAAiDsmmwAAAACAuGOyCQAAAACIOyabAAAAAIC422snm6NHj1azZs2UnJysrl276tNPP63uJkmSPvjgA51yyilq2LChEhISNGXKlMDrzjmNGDFCeXl5SklJUc+ePTV37txqaevIkSN16KGHqk6dOsrJyVHfvn01e/bswD5btmzR0KFDlZWVpbS0NPXv318FBQW/elvHjh2rAw88UOnp6UpPT1e3bt30xhtv7HXt9LnvvvuUkJCg6667LrJtb2rv7bffroSEhMBf27Zt98q2StKyZct0wQUXKCsrSykpKerYsaM+//zzyOt7039jzZo1C13bhIQEDR06VNLed22BfRVjgt3HmODXwZggvhgT7Pv2ysnmCy+8oBtuuEG33XabvvzySx100EHq1auXVq1aVd1N08aNG3XQQQdp9OjR3tcfeOAB/e1vf9Njjz2mWbNmKTU1Vb169dKWLVt+5ZZK06dP19ChQ/XJJ59o6tSp2rZtm0444QRt3Lgxss/111+v1157TZMmTdL06dO1fPlynX766b96Wxs3bqz77rtPX3zxhT7//HMde+yxOu200/T999/vVe20PvvsMz3++OM68MADA9v3tvZ26NBBK1asiPx99NFHe2Vb161bpyOPPFK1atXSG2+8oR9++EEPPfSQ6tWrF9lnb/pv7LPPPgtc16lTp0qSzjzzTOn/t3M/IU33cRzA39bcSgJnmJsrJqssE0nMoQyLDttFPESH8ODBkAhtkkEHvUSnMgiC6mD0Bw2MpIL175CZf3YIK7KJSmFaQztoo4O2SjLc5zlEP55lPT3w/ObvO5/3C36wfb+/w5svftn7y+YPaq0tUbJiJ9AHO0HisRPoi51gmRAFlZSUiN/v194vLCyIw+GQ5uZmA1MtBkACgYD2PhaLid1ul9OnT2tjMzMzYrFY5Pr16wYkjBeJRASABINBEfmeLTU1VW7evKnd8+rVKwEg/f39RsXUZGRkyOXLl5XNGY1GJTc3V7q6umT37t3S0NAgIuqt6/Hjx6WwsPCXc6plbWxslJ07d/52XvU91tDQIJs2bZJYLKbc2hIlK3aCxGAn0Bc7gf7YCZYH5b7ZnJ+fx8DAAHw+nza2YsUK+Hw+9Pf3G5jsz8LhMKanp+Oyp6eno7S0VInss7OzAIC1a9cCAAYGBvDt27e4vHl5eXA6nYbmXVhYQEdHBz5//gyPx6NsTr/fj4qKirhcgJrrOjY2BofDgY0bN6KqqgqTk5NKZr179y7cbjf27duHrKwsFBUV4dKlS9q8yntsfn4e7e3tqKmpQUpKinJrS5SM2AkSh51AX+wE+mMnWB6UO2x++PABCwsLsNlsceM2mw3T09MGpfp3fuRTMXssFsORI0dQVlaGgoICAN/zms1mWK3WuHuNyjs8PIw1a9bAYrGgtrYWgUAA+fn5yuUEgI6ODrx48QLNzc2L5lTLW1paira2Njx48AAtLS0Ih8PYtWsXotGoclnfvn2LlpYW5ObmorOzE3V1dTh8+DCuXr0KQO09dvv2bczMzGD//v0A1Ps7IEpG7ASJwU6gL3aCxGAnWB5MRgegpeH3+zEyMhL3u3zVbN26FYODg5idncWtW7dQXV2NYDBodKxF3r17h4aGBnR1dWHVqlVGx/mj8vJy7fX27dtRWlqKnJwc3LhxA6tXrzYw2WKxWAxutxsnT54EABQVFWFkZAQXLlxAdXW1wen+2ZUrV1BeXg6Hw2F0FCKif8ROoB92gsRhJ1gelPtmMzMzEytXrlz0dKb379/DbrcblOrf+ZFPtez19fW4f/8+ent7sWHDBm3cbrdjfn4eMzMzcfcblddsNmPz5s0oLi5Gc3MzCgsLcfbsWeVyDgwMIBKJYMeOHTCZTDCZTAgGgzh37hxMJhNsNptSeX9mtVqxZcsWjI+PK7e22dnZyM/Pjxvbtm2b9hMfVffYxMQEHj16hAMHDmhjqq0tUTJiJ9AfO4G+2AkSh51geVDusGk2m1FcXIzu7m5tLBaLobu7Gx6Px8Bkf+ZyuWC32+Oyf/z4EU+fPjUku4igvr4egUAAPT09cLlccfPFxcVITU2Nyzs6OorJyUkl1joWi+Hr16/K5fR6vRgeHsbg4KB2ud1uVFVVaa9VyvuzT58+4c2bN8jOzlZubcvKyhY9iv/169fIyckBoN4e+6G1tRVZWVmoqKjQxlRbW6JkxE6gH3aCxGAnSBx2gmXC6CcU/UpHR4dYLBZpa2uTly9fysGDB8Vqtcr09LTR0SQajUooFJJQKCQA5MyZMxIKhWRiYkJERE6dOiVWq1Xu3LkjQ0NDsmfPHnG5XDI3N7fkWevq6iQ9PV36+vpkampKu758+aLdU1tbK06nU3p6euT58+fi8XjE4/EsedampiYJBoMSDodlaGhImpqaJCUlRR4+fKhUzt/5+5PnRNTKe/ToUenr65NwOCyPHz8Wn88nmZmZEolElMv67NkzMZlMcuLECRkbG5Nr165JWlqatLe3a/eotMdEvj8Z0+l0SmNj46I5ldaWKFmxE+iDnWDpsBPog51geVDysCkicv78eXE6nWI2m6WkpESePHlidCQREent7RUAi67q6moR+f4Y5mPHjonNZhOLxSJer1dGR0cNyfqrnACktbVVu2dubk4OHTokGRkZkpaWJnv37pWpqaklz1pTUyM5OTliNptl3bp14vV6tQ8VlXL+zs8fLCrlrayslOzsbDGbzbJ+/XqprKyU8fFxJbOKiNy7d08KCgrEYrFIXl6eXLx4MW5epT0mItLZ2SkAfplBtbUlSlbsBP8dO8HSYSfQDztB8ksREVmqb1GJiIiIiIjo/0G5/9kkIiIiIiKi5MfDJhEREREREemOh00iIiIiIiLSHQ+bREREREREpDseNomIiIiIiEh3PGwSERERERGR7njYJCIiIiIiIt3xsElERERERES642GTiIiIiIiIdMfDJhEREREREemOh00iIiIiIiLS3V+zNrUtNV6N6wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Interactive Reconstruction Plot Functionality\n",
    "def recon_plot(\n",
    "    num_param: int = 0,\n",
    "    num_slice: int = 0\n",
    "):\n",
    "\n",
    "    # Forward Propagation\n",
    "    target_param = torch.Tensor(recon_set.params.iloc[num_param].values)\n",
    "    input = torch.cat((X_train, target_param.repeat(len(recon_set.idxv), 1)), dim = 1)\n",
    "    with torch.no_grad(): model.eval(); X_fake = model(input.to(settings.device)).T\n",
    "    #loss = criterion(X_fake[0], X.T[num_param])\n",
    "    img_fake = torch.Tensor(unmask(X_fake, mask).get_fdata().T)\n",
    "    mse_loss = mse_criterion(X_fake[0], X.T[num_param])\n",
    "    ssim_loss = ssim_criterion(img_fake, img[list([num_param])])\n",
    "    \n",
    "    # Original Training Example Image Subplot\n",
    "    figure = plt.figure(figsize = (15, 5))\n",
    "    plt.suptitle(f'Test Patient #{sel_patient} | Parameters #{num_param} | Slice #{num_slice}' +\n",
    "                 f'\\nMSE: {round(mse_loss.item(), 5)} | SSIM: {round(ssim_loss.item(), 5)}\\n')\n",
    "    plt.xticks([]); plt.yticks([]); plt.grid(False); plt.tight_layout()\n",
    "    \n",
    "    # Original Image Scan Subplot\n",
    "    plt.subplot(1, 3, 1, title = 'Original Image')\n",
    "    plt.imshow(img[num_param, num_slice, :, :], cmap = plt.cm.binary)\n",
    "\n",
    "    # Reconstructed image Scan Subplot\n",
    "    plt.subplot(1, 3, 2, title = 'Reconstructed Image')\n",
    "    plt.imshow(img_fake[0, num_slice, :, :], cmap = plt.cm.binary)\n",
    "\n",
    "    # MSE Loss Heatmap Subplot\n",
    "    #plt.subplot(1, 3, 3, title = 'MSE Loss Heatmap')\n",
    "    #plt.imshow(heatmap[0, num_slice, :, :], cmap = 'hot')\n",
    "    \n",
    "\n",
    "# Parameter + Slice Slider Interactive Construction\n",
    "#param_slider = IntSlider(value = 0, min = 0, max = img.shape[0] - 1, description = 'Parameter', continuous_update = False)\n",
    "#slice_slider = IntSlider(value = 0, min = 0, max = img.shape[1] - 1, description = 'Slice', continuous_update = False)\n",
    "#interactive(recon_plot, num_param = param_slider, num_slice = slice_slider)\n",
    "recon_plot(num_param = 22, num_slice = 25)     #1200"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **cglVNN**\n",
    "\n",
    "### *Conditional Generative Linear Voxel-Wise Neural Network*\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data** *Reader*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Major Scale**: A *Training Batch* is repeated only for *num_recon * num_train_params* times\n",
    "\n",
    "**Medium Scale**: A *Training Parameter* is repeated for *num_recon* times, every *num_train_params* interval\n",
    "\n",
    "**Minor Scale**: A *Target Parameter* is not repeated, and will happen every *num_recon* interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D MUDI Dataset Initialization Class\n",
    "class MUDI_cglVNN(keras.utils.Sequence):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,\n",
    "        subject: int or list,\n",
    "        training: bool = True\n",
    "    ):\n",
    "        \n",
    "        # Parameter & Patient Index Value Access\n",
    "        super(MUDI_cglVNN).__init__()\n",
    "        self.settings = settings\n",
    "\n",
    "        # Vertical Splitting (Patient Selection)\n",
    "        self.idxv = pd.read_csv(self.settings.info_filepath,            # List of Index Values ...\n",
    "                                index_col = 0).to_numpy()               # ... pertaining to each Patient\n",
    "        self.idxv = self.idxv[np.isin(self.idxv[:, 1], subject), 0]     # Patient-Specific Index Values\n",
    "        self.idxv_set = np.arange(len(self.idxv))\n",
    "\n",
    "        # Horizontal Splitting (Parameter Selection)\n",
    "        idxh_train_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Training Labels (V{self.settings.data_version}).txt\")    # Filepath for Selected Training Labels\n",
    "        idxh_val_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Validation Labels (V{self.settings.data_version}).txt\")    # Filepath for Selected Validation Labels\n",
    "        self.idxh_train = np.sort(np.loadtxt(idxh_train_filepath)).astype(int); self.num_train_params = len(self.idxh_train)\n",
    "        self.idxh_val = np.sort(np.loadtxt(idxh_val_filepath)).astype(int); self.num_val_params = len(self.idxh_val)\n",
    "        assert(self.num_train_params == self.settings.num_train_params), \"ERROR: Model wrongly Built!\"\n",
    "        #self.msk = np.logical_not(np.isin(np.arange(1344), self.idxh_train))\n",
    "        \n",
    "        # Parameter Value Initialization & Selection\n",
    "        self.params = pd.read_excel(self.settings.param_filepath)                                       # List of Dataset's Parameters\n",
    "        self.num_labels = self.settings.num_labels\n",
    "        if self.settings.gradient_coord:\n",
    "            self.params = self.params.drop(columns = ['Gradient theta', 'Gradient phi'])                # Choosing of Gradient Orientation\n",
    "        else: self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])      # from 3D Cartesian or Polar Referential\n",
    "        assert(self.params.shape[1] == self.num_labels), \"ERROR: Labels wrongly Deleted!\"\n",
    "        if self.settings.label_norm:                                                                    # Control Boolean Value for the Normalization of Labels\n",
    "            self.scaler = StandardScaler()\n",
    "            self.params = pd.DataFrame( self.scaler.fit_transform(self.params),\n",
    "                                        columns = self.params.columns)\n",
    "        \n",
    "        # Label Normalizer / Scaler Saving\n",
    "        scaler_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "        if not scaler_filepath.exists(): torch.save(self.scaler, scaler_filepath)\n",
    "        \n",
    "        # Random Selection of Parameters for Training Loop Reconstruction\n",
    "        if training:\n",
    "            self.param_recon = self.settings.param_recon_train\n",
    "            self.batch_size = self.settings.batch_size\n",
    "        else:\n",
    "            self.param_recon = self.settings.param_recon_full\n",
    "            self.batch_size = len(self.idxv)\n",
    "        self.num_train_recon = int((self.param_recon * self.num_train_params) / 100)\n",
    "        self.num_val_recon = int((self.param_recon * self.num_val_params) / 100)\n",
    "        self.num_recon = self.num_train_recon + self.num_val_recon\n",
    "        #self.batch_size = self.settings.batch_size * self.num_recon\n",
    "        self.idxh_recon = np.hstack((   self.idxh_train[np.sort(np.random.choice(self.num_train_params,\n",
    "                                                                self.num_train_recon, replace = False))],\n",
    "                                        self.idxh_val[np.sort(np.random.choice(self.num_val_params,\n",
    "                                                                self.num_val_recon, replace = False))]))\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # DataLoader Length / No. Batches Computation Functionality\n",
    "    def __len__(self): return int(np.ceil(len(self.idxv) / self.batch_size)) * self.num_recon * self.settings.num_train_params\n",
    "\n",
    "    # Single-Batch Generation Functionality\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # Batch Vertical/Patient Indexing\n",
    "        idxv = int(idx // (self.num_recon * self.settings.num_train_params))\n",
    "        idxv = self.idxv_set[   idxv * self.batch_size :\n",
    "                                (idxv + 1) * self.batch_size]\n",
    "        idxv = [self.idxv[k] for k in idxv]\n",
    "\n",
    "        # Batch Horizontal/Parameter Indexing\n",
    "        idxh_train = int((idx // self.num_recon) % self.settings.num_train_params)\n",
    "        idxh_target = int(idx % self.num_recon)\n",
    "        input, X_target = self.get_data(idxv, idxh_train, idxh_target)\n",
    "        return input, X_target\n",
    "    \n",
    "    # Label Scaler Download & Reverse Transformation\n",
    "    def label_unscale(\n",
    "        self,\n",
    "        y: np.array or pd.DataFrame\n",
    "    ):\n",
    "\n",
    "        # Label Scaler Download & Reverse Usage\n",
    "        try: self.scaler\n",
    "        except AttributeError:\n",
    "            scaler = torch.load(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "        return scaler.inverse_transform(y.reshape(1, -1))\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # End of Epoch Shuffling Functionality\n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        # Batch Shuffling\n",
    "        self.idxv_set = np.arange(len(self.idxv))\n",
    "        if self.settings.sample_shuffle: np.random.shuffle(self.idxv_set)\n",
    "\n",
    "        # Reconstruction Parameter Shuffling\n",
    "        if self.settings.param_shuffle:\n",
    "            self.idxh_recon = np.hstack((   self.idxh_train[np.sort(np.random.choice(self.num_train_params,\n",
    "                                            int((self.param_recon * self.num_train_params) / 100), replace = False))],\n",
    "                                            self.idxh_val[np.sort(np.random.choice(self.num_val_params,\n",
    "                                            int((self.param_recon * self.num_val_params) / 100), replace = False))]))\n",
    "\n",
    "    # Batch Data Generation Functionality\n",
    "    def get_data(self, idxv, idxh_train, idxh_target):\n",
    "\n",
    "        # Data Access\n",
    "        data = h5py.File(self.settings.data_filepath, 'r').get('data1')\n",
    "        X_train = data[idxv, :][:, self.idxh_train[idxh_train]].reshape((len(idxv), 1))                             # [batch_size,  1] Training Data\n",
    "        y_train = self.params.iloc[self.idxh_train[idxh_train]].values.reshape((1, self.settings.num_labels))       # [1,           num_labels] Training Parameters\n",
    "        y_target = self.params.iloc[self.idxh_recon[idxh_target]].values.reshape((1, self.settings.num_labels))     # [1,           num_labels] Target Parameters\n",
    "        y_train = y_train.repeat(len(idxv), 0); y_target = y_target.repeat(len(idxv), 0);                           # [batch_size,  num_labels] Training & Target Parameters\n",
    "        X_target = data[idxv, :][:, self.idxh_recon[idxh_target]].reshape((len(idxv), 1))                           # [batch_size,  1] GT Target Data\n",
    "        input = tf.keras.layers.concatenate([X_train, y_train, y_target], axis = 1)                                 # [batch_size,  1 + (2 * num_labels)] Input\n",
    "        return input, X_target\n",
    "    \n",
    "    # Patient Data Generation Functionality\n",
    "    def get_patient(settings, num_patient: int):\n",
    "\n",
    "        # Patient Data Access\n",
    "        data = h5py.File(settings.data_filepath, 'r').get('data1')\n",
    "        idxv = pd.read_csv( settings.info_filepath,             # List of Index Values ...\n",
    "                            index_col = 0).to_numpy()           # ... pertaining to each Patient\n",
    "        idxv = idxv[np.isin(idxv[:, 1], num_patient), 0]        # Patient-Specific Index Values\n",
    "        X = data[idxv, :]\n",
    "\n",
    "        # Patient Mask Access\n",
    "        mask_filepath = Path(f\"{settings.mask_folderpath}/p{num_patient}.nii\")\n",
    "        assert(mask_filepath.exists()), f\"ERROR: Patient {num_patient}'s Mask not Found!\"\n",
    "        mask = load_img(mask_filepath)\n",
    "        img = unmask(X.T, mask).get_fdata().T\n",
    "        return X, mask, img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset DataLoader Creation\n",
    "trainset = MUDI_cglVNN( settings, training = False,\n",
    "                        subject = [11])\n",
    "X, mask, img = MUDI_cglVNN.get_patient(settings, 11)\n",
    "X_fake = model.predict_generator(trainset)\n",
    "\n",
    "# Build Testing\n",
    "#for i in range(trainset.num_recon):\n",
    "#    assert(np.all(trainset.__getitem__(i)[0][:, -5::] == trainset.__getitem__(i + trainset.num_recon)[0][:, -5::])), f\"{i}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Model* **Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed Conditional Generative Linear Voxel Net Model Class (Fixed)\n",
    "class cglVNN(tf.keras.Model):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser\n",
    "    ):\n",
    "        \n",
    "        # Class Variable Logging\n",
    "        super().__init__(); self.settings = settings\n",
    "        self.net = Sequential(); self.arch = []\n",
    "        self.arch.insert(0, 1 + (2 * self.settings.num_labels))\n",
    "\n",
    "        # Neural Network Architecture Definition\n",
    "        var_hidden = int((self.settings.top_hidden - self.settings.bottom_hidden) / self.settings.num_hidden)\n",
    "        for i in range(1, self.settings.num_hidden + 1):\n",
    "            if i == 1: self.arch.insert(i, self.settings.bottom_hidden * 2)\n",
    "            else: self.arch.insert(i, int(self.arch[i - 1] * 2))\n",
    "            self.main_block(self.arch[i], self.arch[i - 1])\n",
    "        for i in range(self.settings.num_hidden + 1, (2 * self.settings.num_hidden) + 1):\n",
    "            self.arch.insert(i, int(self.arch[i - 1] / 2))\n",
    "            self.main_block(self.arch[i], self.arch[i - 1])\n",
    "        self.net.add(Dense(input_dim = self.settings.bottom_hidden, units = 1))\n",
    "\n",
    "    # Block Architecture Definition Functionality\n",
    "    def main_block(self, out_channels: int, in_channels: int = None):\n",
    "        if in_channels is not None:\n",
    "            self.net.add(   Dense(  input_dim = in_channels,\n",
    "                                    units = out_channels))\n",
    "        else: self.net.add( Dense(  units = out_channels))\n",
    "        self.net.add(   BatchNormalization())\n",
    "        self.net.add(   LeakyReLU(  alpha = 0.2))\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Neural Network Application Function\n",
    "    def call(\n",
    "        self,\n",
    "        input: np.ndarray or tf.Tensor\n",
    "    ):  return self.net(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Initialization Example\n",
    "model = cglVNN(settings)\n",
    "print(model.net.summary())\n",
    "\n",
    "# Model Usage Example\n",
    "#X_real = tf.random.uniform([10, 500])\n",
    "#y_target = tf.random.uniform([10, 5])\n",
    "trainset = MUDI_cglVNN(settings, subject = [11, 12, 13])\n",
    "print(model(trainset.__getitem__(0)[0]).shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Performance* **Callbacks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction Callback Class\n",
    "class ReconCallback(keras.callbacks.Callback):\n",
    "       \n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,              # Model Settings & Parametrizations\n",
    "    ):\n",
    "\n",
    "        # Class Variable Logging\n",
    "        super().__init__()\n",
    "        self.settings = settings; self.criterion = nn.MSELoss()\n",
    "\n",
    "        # TensorBoard Logger Initialization\n",
    "        self.train_logger = TensorBoardLogger(f'{self.settings.modelsave_folderpath}/V{self.settings.model_version}', 'train')\n",
    "        self.val_logger = TensorBoardLogger(f'{self.settings.modelsave_folderpath}/V{self.settings.model_version}', 'validation')\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Patient Image Reconstruction Functionality\n",
    "    def reconstruct(\n",
    "        self,\n",
    "        set: MUDI_fcglVNN,                  # Keras MUDI DataLoader\n",
    "        X: np.ndarray,                      # Selected Patient Data\n",
    "        mask: nib.nifti1.Nifti1Image,       # Selected Patient's Mask\n",
    "        img: np.ndarray,                    # Selected Patient Image\n",
    "        sel_slice: int = 25,                # Selected Reconstruction Slice\n",
    "        epoch: int = 0                      # Epoch Number\n",
    "    ):\n",
    "        \n",
    "        # Reconstruction Loop from all Training Parameters\n",
    "        X_fake = self.model.predict_generator(set)\n",
    "\n",
    "        with alive_bar( self.settings.num_train_params * len(set.idxh_recon),\n",
    "                        title = f'Epoch {epoch} |' +\n",
    "                        'Patient Reconstruction Callback',\n",
    "                        force_tty = True) as progress_bar:\n",
    "            for idx_train, param_train in enumerate(set.idxh_train):\n",
    "\n",
    "                # Reconstruction Loop for all Selected Target Parameters\n",
    "                for idx_target, param_target in range(set.idxh_recon):\n",
    "\n",
    "                    # Training -> Target Parameter Image Reconstruction\n",
    "                    X_param = self.model.predict_generator(set.__getitem__())\n",
    "\n",
    "                    gc.collect(); torch.cuda.empty_cache()\n",
    "                    time.sleep(0.01); progress_bar()\n",
    "        \n",
    "\n",
    "        \"\"\"\n",
    "        # Patient Image Reconstruction\n",
    "        X_fake = self.model.predict_generator(set)\n",
    "        best_train_loss = torch.ones(1, dtype = torch.float64) * 1000\n",
    "        worst_train_loss = torch.zeros(1, dtype = torch.float64)\n",
    "        best_val_loss = torch.ones(1, dtype = torch.float64) * 1000\n",
    "        worst_val_loss = torch.zeros(1, dtype = torch.float64)\n",
    "        \n",
    "        # Voxel Reconstruction Loop for all Selected Target Parameters\n",
    "        with alive_bar( len(set.idxh_recon),\n",
    "                        title = f'Epoch {epoch} |' +\n",
    "                        'Training Patient Reconstruction',\n",
    "                        force_tty = True) as progress_bar:\n",
    "            for i, param in enumerate(set.idxh_recon):\n",
    "\n",
    "                # Selected Target Parameter Image Reconstruction\n",
    "                X_param = X_fake[np.where(np.arange(len(X_fake)) % set.num_recon == i)[0]]\n",
    "                X_gt = X[:, param].T.reshape((len(X_param), 1))\n",
    "                loss = self.criterion(torch.Tensor(X_param), torch.Tensor(X_gt)); del X_gt\n",
    "                \n",
    "                # Loss Computation for Training Parameter\n",
    "                if param in set.idxh_train:\n",
    "                    if loss < best_train_loss:\n",
    "                        best_train_loss = loss\n",
    "                        best_train_idx = param\n",
    "                        X_train_best = X_param\n",
    "                    if loss > worst_train_loss:\n",
    "                        worst_train_loss = loss\n",
    "                        worst_train_idx = param\n",
    "                        X_train_worst = X_param\n",
    "\n",
    "                # Loss Computation for Validation Parameter\n",
    "                elif param in set.idxh_val:\n",
    "                    if loss < best_val_loss:\n",
    "                        best_val_loss = loss\n",
    "                        best_val_idx = param\n",
    "                        X_val_best = X_param\n",
    "                    if loss > worst_val_loss:\n",
    "                        worst_val_loss = loss\n",
    "                        worst_val_idx = param\n",
    "                        X_val_worst = X_param\n",
    "                \n",
    "                else: print(\"ERROR: Reconstruction Parameter not Found!\")\n",
    "                gc.collect(); torch.cuda.empty_cache()\n",
    "                time.sleep(0.01); progress_bar()\n",
    "        \n",
    "        # --------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Training Image Unmasking of Original & Reconstructed Results\n",
    "        X_train_best = unmask(X_train_best.T, mask).get_fdata().T\n",
    "        X_train_worst = unmask(X_train_worst.T, mask).get_fdata().T\n",
    "\n",
    "        # Training Example Original & Best Reconstructed Image Subplots\n",
    "        train_figure = plt.figure(figsize = (20, 20))\n",
    "        plt.xticks([]); plt.yticks([]); plt.grid(False); plt.tight_layout()\n",
    "        plt.subplot(2, 2, 1, title = f'Target Image (Parameter #{best_train_idx})')\n",
    "        plt.imshow(img[best_train_idx, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        plt.subplot(2, 2, 2, title = f'Best Reconstruction (Parameter #{best_train_idx})')\n",
    "        plt.imshow(X_train_best[0, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        del best_train_idx, X_train_best\n",
    "        \n",
    "        # Training Example Original & Worst Reconstructed Image Subplots\n",
    "        plt.subplot(2, 2, 3, title = f'Target Image (Parameter #{worst_train_idx})')\n",
    "        plt.imshow(img[worst_train_idx, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        plt.subplot(2, 2, 4, title = f'Worst Reconstruction (Parameter #{worst_train_idx})')\n",
    "        plt.imshow(X_train_worst[0, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        del worst_train_idx, X_train_worst\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Training Image Unmasking of Original & Reconstructed Results\n",
    "        X_val_best = unmask(X_val_best.T, mask).get_fdata().T\n",
    "        X_val_worst = unmask(X_val_worst.T, mask).get_fdata().T\n",
    "\n",
    "        # Training Example Original & Best Reconstructed Image Subplots\n",
    "        val_figure = plt.figure(figsize = (20, 20))\n",
    "        plt.xticks([]); plt.yticks([]); plt.grid(False); plt.tight_layout()\n",
    "        plt.subplot(2, 2, 1, title = f'Target Image (Parameter #{best_val_idx})')\n",
    "        plt.imshow(img[best_val_idx, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        plt.subplot(2, 2, 2, title = f'Best Reconstruction (Parameter #{best_val_idx})')\n",
    "        plt.imshow(X_val_best[0, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        del best_val_idx, X_val_best\n",
    "        \n",
    "        # Training Example Original & Worst Reconstructed Image Subplots\n",
    "        plt.subplot(2, 2, 3, title = f'Target Image (Parameter #{worst_val_idx})')\n",
    "        plt.imshow(img[worst_val_idx, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        plt.subplot(2, 2, 4, title = f'Worst Reconstruction (Parameter #{worst_val_idx})')\n",
    "        plt.imshow(X_val_worst[0, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        del worst_val_idx, X_val_worst\n",
    "        return train_figure, best_train_loss, worst_train_loss, val_figure, best_val_loss, worst_val_loss\n",
    "        \"\"\"\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Functionality called upon the Start of Training\n",
    "    def on_train_begin(self, logs = None):\n",
    "\n",
    "        # Example Training Patient Download\n",
    "        self.trainset = MUDI_cglVNN(self.settings, training = False,\n",
    "                                    subject = self.settings.sel_train_patient)\n",
    "        self.X_train, self.mask_train, self.img_train = MUDI_cglVNN.get_patient(self.settings,\n",
    "                                                                self.settings.sel_train_patient)\n",
    "\n",
    "        # Example Validation Patient Download\n",
    "        self.valset = MUDI_cglVNN(  self.settings, training = False,\n",
    "                                    subject = self.settings.sel_val_patient)\n",
    "        self.X_val, self.mask_val, self.img_val = MUDI_cglVNN.get_patient(  self.settings,\n",
    "                                                            self.settings.sel_val_patient)\n",
    "\n",
    "    # Functionality called upon the End of a Training Epoch\n",
    "    def on_epoch_end(self, epoch, logs = None):\n",
    "\n",
    "        # Epoch Update for Losses & Training Image Reconstruction\n",
    "        tt_plot, tt_best_loss, tt_worst_loss, tv_plot, tv_best_loss, tv_worst_loss = self.reconstruct(  self.trainset, self.X_train,\n",
    "                                                                                                        self.mask_train, self.img_train,\n",
    "                                                                                                        sel_slice = 25, epoch = epoch)\n",
    "        vt_plot, vt_best_loss, vt_worst_loss, vv_plot, vv_best_loss, vv_worst_loss = self.reconstruct(  self.valset, self.X_val,\n",
    "                                                                                                        self.mask_val, self.img_val,\n",
    "                                                                                                        sel_slice = 25, epoch = epoch)\n",
    "        \n",
    "        # TensorBoard Logger Model Visualizer, Update for Image Visualizer\n",
    "        self.train_logger.experiment.add_scalar(\"Best Reconstruction Loss | Training\", tt_best_loss, epoch)\n",
    "        self.train_logger.experiment.add_scalar(\"Worst Reconstruction Loss | Training\", tt_worst_loss, epoch)\n",
    "        self.train_logger.experiment.add_scalar(\"Best Reconstruction Loss | Validation\", tv_best_loss, epoch)\n",
    "        self.train_logger.experiment.add_scalar(\"Worst Reconstruction Loss | Validation\", tv_worst_loss, epoch)\n",
    "        self.train_logger.experiment.add_figure(\"Training Image Reconstruction\", tt_plot, epoch)\n",
    "        self.train_logger.experiment.add_figure(\"Validation Image Reconstruction\", tv_plot, epoch)\n",
    "\n",
    "        self.val_logger.experiment.add_scalar(\"Best Reconstruction Loss | Training\", vt_best_loss, epoch)\n",
    "        self.val_logger.experiment.add_scalar(\"Worst Reconstruction Loss | Training\", vt_worst_loss, epoch)\n",
    "        self.val_logger.experiment.add_scalar(\"Best Reconstruction Loss | Validation\", vv_best_loss, epoch)\n",
    "        self.val_logger.experiment.add_scalar(\"Worst Reconstruction Loss | Validation\", vv_worst_loss, epoch)\n",
    "        self.val_logger.experiment.add_figure(\"Training Image Reconstruction\", vt_plot, epoch)\n",
    "        self.val_logger.experiment.add_figure(\"Validation Image Reconstruction\", vv_plot, epoch)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **cVNP**\n",
    "\n",
    "### *Voxel-Wise* Conditional Neural Process\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Keras** *Version*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data** *Reader*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Major Scale**: A *Training Batch* is repeated only for *num_recon * num_train_params* times\n",
    "\n",
    "**Medium Scale**: A *Training Parameter* is repeated for *num_recon* times, every *num_train_params* interval\n",
    "\n",
    "**Minor Scale**: A *Target Parameter* is not repeated, and will happen every *num_recon* interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D MUDI Dataset Initialization Class\n",
    "class MUDI_cVNP(keras.utils.Sequence):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,\n",
    "        subject: int or list,\n",
    "        training: bool = True\n",
    "    ):\n",
    "        \n",
    "        # Parameter & Patient Index Value Access\n",
    "        super(MUDI_cVNP).__init__()\n",
    "        self.settings = settings\n",
    "\n",
    "        # Vertical Splitting (Patient Selection)\n",
    "        self.idxv = pd.read_csv(self.settings.info_filepath,            # List of Index Values ...\n",
    "                                index_col = 0).to_numpy()               # ... pertaining to each Patient\n",
    "        self.idxv = self.idxv[np.isin(self.idxv[:, 1], subject), 0]     # Patient-Specific Index Values\n",
    "        self.idxv_set = np.arange(len(self.idxv))\n",
    "\n",
    "        # Horizontal Splitting (Parameter Selection)\n",
    "        idxh_train_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Training Labels (V{self.settings.data_version}).txt\")    # Filepath for Selected Training Labels\n",
    "        idxh_val_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Validation Labels (V{self.settings.data_version}).txt\")    # Filepath for Selected Validation Labels\n",
    "        self.idxh_train = np.sort(np.loadtxt(idxh_train_filepath)).astype(int); self.num_train_params = len(self.idxh_train)\n",
    "        self.idxh_val = np.sort(np.loadtxt(idxh_val_filepath)).astype(int); self.num_val_params = len(self.idxh_val)\n",
    "        assert(self.num_train_params == self.settings.num_train_params), \"ERROR: Model wrongly Built!\"\n",
    "        #self.msk = np.logical_not(np.isin(np.arange(1344), self.idxh_train))\n",
    "        \n",
    "        # Parameter Value Initialization & Selection\n",
    "        self.params = pd.read_excel(self.settings.param_filepath)                                       # List of Dataset's Parameters\n",
    "        self.num_labels = self.settings.num_labels\n",
    "        if self.settings.gradient_coord:\n",
    "            self.params = self.params.drop(columns = ['Gradient theta', 'Gradient phi'])                # Choosing of Gradient Orientation\n",
    "        else: self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])      # from 3D Cartesian or Polar Referential\n",
    "        assert(self.params.shape[1] == self.num_labels), \"ERROR: Labels wrongly Deleted!\"\n",
    "        if self.settings.label_norm:                                                                    # Control Boolean Value for the Normalization of Labels\n",
    "            self.scaler = StandardScaler()\n",
    "            self.params = pd.DataFrame( self.scaler.fit_transform(self.params),\n",
    "                                        columns = self.params.columns)\n",
    "        \n",
    "        # Label Normalizer / Scaler Saving\n",
    "        scaler_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "        if not scaler_filepath.exists(): torch.save(self.scaler, scaler_filepath)\n",
    "        \n",
    "        # Random Selection of Parameters for Training Loop Reconstruction\n",
    "        if training:\n",
    "            self.param_recon = self.settings.param_recon_train\n",
    "            self.batch_size = self.settings.batch_size\n",
    "        else:\n",
    "            self.param_recon = self.settings.param_recon_full\n",
    "            self.batch_size = len(self.idxv)\n",
    "        self.num_train_recon = int((self.param_recon * self.num_train_params) / 100)\n",
    "        self.num_val_recon = int((self.param_recon * self.num_val_params) / 100)\n",
    "        self.num_recon = self.num_train_recon + self.num_val_recon\n",
    "        #self.batch_size = self.settings.batch_size * self.num_recon\n",
    "        self.idxh_recon = np.hstack((   self.idxh_train[np.sort(np.random.choice(self.num_train_params,\n",
    "                                                                self.num_train_recon, replace = False))],\n",
    "                                        self.idxh_val[np.sort(np.random.choice(self.num_val_params,\n",
    "                                                                self.num_val_recon, replace = False))]))\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # DataLoader Length / No. Batches Computation Functionality\n",
    "    def __len__(self): return int(np.ceil(len(self.idxv) / self.batch_size)) * self.num_recon * self.settings.num_train_params\n",
    "\n",
    "    # Single-Batch Generation Functionality\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # Batch Vertical/Patient Indexing\n",
    "        idxv = int(idx // (self.num_recon * self.settings.num_train_params))\n",
    "        idxv = self.idxv_set[   idxv * self.batch_size :\n",
    "                                (idxv + 1) * self.batch_size]\n",
    "        idxv = [self.idxv[k] for k in idxv]\n",
    "\n",
    "        # Batch Horizontal/Parameter Indexing\n",
    "        idxh_train = int((idx // self.num_recon) % self.settings.num_train_params)\n",
    "        idxh_target = int(idx % self.num_recon)\n",
    "        #input, X_target = self.get_data(idxv, idxh_train, idxh_target)\n",
    "        X_train, y_train, y_target, X_target = self.get_data(idxv, idxh_train, idxh_target)\n",
    "        return [X_train, y_train, y_target], [X_target]\n",
    "    \n",
    "    # Label Scaler Download & Reverse Transformation\n",
    "    def label_unscale(\n",
    "        self,\n",
    "        y: np.array or pd.DataFrame\n",
    "    ):\n",
    "\n",
    "        # Label Scaler Download & Reverse Usage\n",
    "        try: self.scaler\n",
    "        except AttributeError:\n",
    "            scaler = torch.load(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "        return scaler.inverse_transform(y.reshape(1, -1))\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # End of Epoch Shuffling Functionality\n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        # Batch Shuffling\n",
    "        self.idxv_set = np.arange(len(self.idxv))\n",
    "        if self.settings.sample_shuffle: np.random.shuffle(self.idxv_set)\n",
    "\n",
    "        # Reconstruction Parameter Shuffling\n",
    "        if self.settings.param_shuffle:\n",
    "            self.idxh_recon = np.hstack((   self.idxh_train[np.sort(np.random.choice(self.num_train_params,\n",
    "                                            int((self.param_recon * self.num_train_params) / 100), replace = False))],\n",
    "                                            self.idxh_val[np.sort(np.random.choice(self.num_val_params,\n",
    "                                            int((self.param_recon * self.num_val_params) / 100), replace = False))]))\n",
    "\n",
    "    # Batch Data Generation Functionality\n",
    "    def get_data(self, idxv, idxh_train, idxh_target):\n",
    "\n",
    "        # Data Access\n",
    "        data = h5py.File(self.settings.data_filepath, 'r').get('data1')\n",
    "        X_train = data[idxv, :][:, self.idxh_train[idxh_train]].reshape((len(idxv), 1))                             # [batch_size,  1] Training Data\n",
    "        y_train = self.params.iloc[self.idxh_train[idxh_train]].values.reshape((1, self.settings.num_labels))       # [1,           num_labels] Training Parameters\n",
    "        y_target = self.params.iloc[self.idxh_recon[idxh_target]].values.reshape((1, self.settings.num_labels))     # [1,           num_labels] Target Parameters\n",
    "        y_train = y_train.repeat(len(idxv), 0); y_target = y_target.repeat(len(idxv), 0);                           # [batch_size,  num_labels] Training & Target Parameters\n",
    "        X_target = data[idxv, :][:, self.idxh_recon[idxh_target]].reshape((len(idxv), 1))                           # [batch_size,  1] GT Target Data\n",
    "        #input = tf.keras.layers.concatenate([X_train, y_train, y_target], axis = 1)                                 # [batch_size,  1 + (2 * num_labels)] Input\n",
    "        #return input, X_target\n",
    "        return X_train, y_train, y_target, X_target\n",
    "    \n",
    "    # Patient Data Generation Functionality\n",
    "    def get_patient(settings, num_patient: int):\n",
    "\n",
    "        # Patient Data Access\n",
    "        data = h5py.File(settings.data_filepath, 'r').get('data1')\n",
    "        idxv = pd.read_csv( settings.info_filepath,             # List of Index Values ...\n",
    "                            index_col = 0).to_numpy()           # ... pertaining to each Patient\n",
    "        idxv = idxv[np.isin(idxv[:, 1], num_patient), 0]        # Patient-Specific Index Values\n",
    "        X = data[idxv, :]\n",
    "\n",
    "        # Patient Mask Access\n",
    "        mask_filepath = Path(f\"{settings.mask_folderpath}/p{num_patient}.nii\")\n",
    "        assert(mask_filepath.exists()), f\"ERROR: Patient {num_patient}'s Mask not Found!\"\n",
    "        mask = load_img(mask_filepath)\n",
    "        img = unmask(X.T, mask).get_fdata().T\n",
    "        return X, mask, img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset DataLoader Creation\n",
    "trainset = MUDI_cVNP(settings, #training = False,\n",
    "                        subject = [11])\n",
    "#X, mask, img = MUDI_fcglVNN.get_patient(settings, 11)\n",
    "#X_fake = model.predict_generator(trainset)\n",
    "\n",
    "# Build Testing\n",
    "#for i in range(trainset.num_recon):\n",
    "#    assert(np.all(trainset.__getitem__(i)[0][:, -5::] == trainset.__getitem__(i + trainset.num_recon)[0][:, -5::])), f\"{i}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Model* **Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cVNP Encoder Layer Class\n",
    "class cVNP_Encoder(tf.keras.layers.Layer):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,\n",
    "    ):\n",
    "        \n",
    "        # Class Variable Logging\n",
    "        super().__init__()\n",
    "        self.settings = settings\n",
    "        self.encoder = Sequential()\n",
    "\n",
    "        # Encoder Architecture Definition\n",
    "        for i in reversed(range(self.settings.num_hidden + 1)):\n",
    "            if i != 0: out_neuron = int(self.settings.var_hidden / (2 ** (i - 1)))\n",
    "            if i == self.settings.num_hidden:\n",
    "                self.encoder.add(Dense(     input_dim = 1 + self.settings.num_labels,\n",
    "                                            units = out_neuron))\n",
    "            else:\n",
    "                self.encoder.add(Dense(     units = out_neuron))\n",
    "            self.encoder.add(   LeakyReLU(  alpha = 0.2))\n",
    "    \n",
    "    # Build Configuration Functionalities\n",
    "    #def build(self, input_shape): super(cVNP_Encoder, self).build([(6,)])\n",
    "    #def get_config(self): return super(cVNP_Encoder, self).get_config()\n",
    "\n",
    "    # Neural Network Application Function\n",
    "    def call(self, input: tf.Tensor): return self.encoder(input)\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional Voxel-Wise Neural Process Model Class\n",
    "class cVNP(tf.keras.Model):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,\n",
    "        #num_labels: int = 5,                    # Number of Training Parameters / Input Channels\n",
    "        #num_hidden: int = 3,                    # Number of NN Hidden Layers\n",
    "        #var_hidden: int = 128                   # Deviance / Expansion of Hidden Layers\n",
    "    ):\n",
    "        \n",
    "        # Class Variable Logging\n",
    "        super().__init__(); self.settings = settings\n",
    "        self.encoder = cVNP_Encoder(self.settings)\n",
    "        self.decoder = Sequential()\n",
    "        self.agregg = Dense(input_dim = self.settings.var_hidden,\n",
    "                            units = self.settings.var_hidden)\n",
    "\n",
    "            \n",
    "        # Decoder Architecture Definition\n",
    "        for i in range(self.settings.num_hidden + 2):\n",
    "            if i != 0: out_neuron = int(self.settings.var_hidden / (2 ** (i - 1)))\n",
    "            if i == self.settings.num_hidden + 1: out_neuron = 1\n",
    "            if i == 0: self.decoder.add(Dense(  input_dim = self.settings.var_hidden + self.settings.num_labels,\n",
    "                                                units = self.settings.var_hidden))\n",
    "            else: self.decoder.add(Dense(       units = out_neuron))\n",
    "            if i != self.settings.num_hidden + 1:\n",
    "                self.decoder.add(   LeakyReLU(  alpha = 0.2))\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Build Configuration Functionalities\n",
    "    #def build(self, input_shape): super(cVNP, self).build([(1,),\n",
    "    #    (self.settings.num_labels,), (self.settings.num_labels,)])\n",
    "    #def get_config(self): return super(cVNP, self).get_config()\n",
    "\n",
    "    # Neural Network Application Function\n",
    "    def call(\n",
    "        self,\n",
    "        input: list,\n",
    "        training = None\n",
    "        #X_train: np.ndarray or tf.Tensor,\n",
    "        #y_train: np.ndarray or tf.Tensor,\n",
    "        #y_target: np.ndarray or tf.Tensor\n",
    "    ):\n",
    "        \n",
    "        # Neural Network Feed Forward Process\n",
    "        X_train, y_train, y_target = input\n",
    "        print(X_train.shape); print(y_train.shape); print(y_target.shape)\n",
    "        print(tf.keras.layers.concatenate([X_train, y_train], axis = -1).shape)\n",
    "        h = self.encoder(tf.keras.layers.concatenate([X_train, y_train], axis = -1))    # Encoded Latent Space Representation\n",
    "        print(h.shape)\n",
    "        h = self.agregg(tf.reduce_mean(h, axis = 0, keepdims = True))                   # Encoded Representation Aggregation ...\n",
    "        print(h.shape)\n",
    "        h = tf.repeat(h, y_target.shape[0], axis = 0)                                   # ... Repeated for every Target\n",
    "        print(h.shape)\n",
    "        out = self.decoder(tf.keras.layers.concatenate([h, y_target], axis = -1))\n",
    "        print(out.shape)\n",
    "        return out      # Decoded Output for Target Parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Initialization Example\n",
    "model = cVNP(settings)\n",
    "#print(model.encoder.summary())\n",
    "\n",
    "# Data Parameter Access\n",
    "#X_real = tf.random.uniform([10, 1])\n",
    "#y_train = tf.random.uniform([10, 5])\n",
    "#y_target = tf.random.uniform([10, 5])\n",
    "trainset = MUDI_cVNP(   settings, training = False,\n",
    "                        subject = [11])\n",
    "# Model Usage Example\n",
    "model.compile(  optimizer = Adam(learning_rate = settings.base_lr),\n",
    "                loss =      'mean_squared_error')\n",
    "model.fit(  trainset, epochs = 1,\n",
    "            use_multiprocessing = False)\n",
    "#X_fake = model.predict(trainset)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Performance* **Callbacks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction Callback Class\n",
    "class ReconCallback(keras.callbacks.Callback):\n",
    "       \n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,              # Model Settings & Parametrizations\n",
    "    ):\n",
    "\n",
    "        # Class Variable Logging\n",
    "        super().__init__()\n",
    "        self.settings = settings; self.criterion = nn.MSELoss()\n",
    "\n",
    "        # TensorBoard Logger Initialization\n",
    "        self.train_logger = TensorBoardLogger(f'{self.settings.modelsave_folderpath}/V{self.settings.model_version}', 'train')\n",
    "        self.val_logger = TensorBoardLogger(f'{self.settings.modelsave_folderpath}/V{self.settings.model_version}', 'validation')\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Patient Image Reconstruction Functionality\n",
    "    def reconstruct(\n",
    "        self,\n",
    "        set: MUDI_fcglVNN,                  # Keras MUDI DataLoader\n",
    "        X: np.ndarray,                      # Selected Patient Data\n",
    "        mask: nib.nifti1.Nifti1Image,       # Selected Patient's Mask\n",
    "        img: np.ndarray,                    # Selected Patient Image\n",
    "        sel_slice: int = 25,                # Selected Reconstruction Slice\n",
    "        epoch: int = 0                      # Epoch Number\n",
    "    ):\n",
    "        \n",
    "        # Reconstruction Loop from all Training Parameters\n",
    "        with alive_bar( self.settings.num_train_params * len(set.idxh_recon),\n",
    "                        title = f'Epoch {epoch} |' +\n",
    "                        'Patient Reconstruction Callback',\n",
    "                        force_tty = True) as progress_bar:\n",
    "            for idx_train, param_train in enumerate(set.idxh_train):\n",
    "\n",
    "                # Reconstruction Loop for all Selected Target Parameters\n",
    "                for idx_target, param_target in range(set.idxh_recon):\n",
    "\n",
    "                    # Training -> Target Parameter Image Reconstruction\n",
    "                    X_param = self.model.predict_generator(set.__getitem__())\n",
    "\n",
    "                    gc.collect(); torch.cuda.empty_cache()\n",
    "                    time.sleep(0.01); progress_bar()\n",
    "        \n",
    "\n",
    "        \"\"\"\n",
    "        # Patient Image Reconstruction\n",
    "        X_fake = self.model.predict_generator(set)\n",
    "        best_train_loss = torch.ones(1, dtype = torch.float64) * 1000\n",
    "        worst_train_loss = torch.zeros(1, dtype = torch.float64)\n",
    "        best_val_loss = torch.ones(1, dtype = torch.float64) * 1000\n",
    "        worst_val_loss = torch.zeros(1, dtype = torch.float64)\n",
    "        \n",
    "        # Voxel Reconstruction Loop for all Selected Target Parameters\n",
    "        with alive_bar( len(set.idxh_recon),\n",
    "                        title = f'Epoch {epoch} |' +\n",
    "                        'Training Patient Reconstruction',\n",
    "                        force_tty = True) as progress_bar:\n",
    "            for i, param in enumerate(set.idxh_recon):\n",
    "\n",
    "                # Selected Target Parameter Image Reconstruction\n",
    "                X_param = X_fake[np.where(np.arange(len(X_fake)) % set.num_recon == i)[0]]\n",
    "                X_gt = X[:, param].T.reshape((len(X_param), 1))\n",
    "                loss = self.criterion(torch.Tensor(X_param), torch.Tensor(X_gt)); del X_gt\n",
    "                \n",
    "                # Loss Computation for Training Parameter\n",
    "                if param in set.idxh_train:\n",
    "                    if loss < best_train_loss:\n",
    "                        best_train_loss = loss\n",
    "                        best_train_idx = param\n",
    "                        X_train_best = X_param\n",
    "                    if loss > worst_train_loss:\n",
    "                        worst_train_loss = loss\n",
    "                        worst_train_idx = param\n",
    "                        X_train_worst = X_param\n",
    "\n",
    "                # Loss Computation for Validation Parameter\n",
    "                elif param in set.idxh_val:\n",
    "                    if loss < best_val_loss:\n",
    "                        best_val_loss = loss\n",
    "                        best_val_idx = param\n",
    "                        X_val_best = X_param\n",
    "                    if loss > worst_val_loss:\n",
    "                        worst_val_loss = loss\n",
    "                        worst_val_idx = param\n",
    "                        X_val_worst = X_param\n",
    "                \n",
    "                else: print(\"ERROR: Reconstruction Parameter not Found!\")\n",
    "                gc.collect(); torch.cuda.empty_cache()\n",
    "                time.sleep(0.01); progress_bar()\n",
    "        \n",
    "        # --------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Training Image Unmasking of Original & Reconstructed Results\n",
    "        X_train_best = unmask(X_train_best.T, mask).get_fdata().T\n",
    "        X_train_worst = unmask(X_train_worst.T, mask).get_fdata().T\n",
    "\n",
    "        # Training Example Original & Best Reconstructed Image Subplots\n",
    "        train_figure = plt.figure(figsize = (20, 20))\n",
    "        plt.xticks([]); plt.yticks([]); plt.grid(False); plt.tight_layout()\n",
    "        plt.subplot(2, 2, 1, title = f'Target Image (Parameter #{best_train_idx})')\n",
    "        plt.imshow(img[best_train_idx, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        plt.subplot(2, 2, 2, title = f'Best Reconstruction (Parameter #{best_train_idx})')\n",
    "        plt.imshow(X_train_best[0, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        del best_train_idx, X_train_best\n",
    "        \n",
    "        # Training Example Original & Worst Reconstructed Image Subplots\n",
    "        plt.subplot(2, 2, 3, title = f'Target Image (Parameter #{worst_train_idx})')\n",
    "        plt.imshow(img[worst_train_idx, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        plt.subplot(2, 2, 4, title = f'Worst Reconstruction (Parameter #{worst_train_idx})')\n",
    "        plt.imshow(X_train_worst[0, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        del worst_train_idx, X_train_worst\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Training Image Unmasking of Original & Reconstructed Results\n",
    "        X_val_best = unmask(X_val_best.T, mask).get_fdata().T\n",
    "        X_val_worst = unmask(X_val_worst.T, mask).get_fdata().T\n",
    "\n",
    "        # Training Example Original & Best Reconstructed Image Subplots\n",
    "        val_figure = plt.figure(figsize = (20, 20))\n",
    "        plt.xticks([]); plt.yticks([]); plt.grid(False); plt.tight_layout()\n",
    "        plt.subplot(2, 2, 1, title = f'Target Image (Parameter #{best_val_idx})')\n",
    "        plt.imshow(img[best_val_idx, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        plt.subplot(2, 2, 2, title = f'Best Reconstruction (Parameter #{best_val_idx})')\n",
    "        plt.imshow(X_val_best[0, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        del best_val_idx, X_val_best\n",
    "        \n",
    "        # Training Example Original & Worst Reconstructed Image Subplots\n",
    "        plt.subplot(2, 2, 3, title = f'Target Image (Parameter #{worst_val_idx})')\n",
    "        plt.imshow(img[worst_val_idx, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        plt.subplot(2, 2, 4, title = f'Worst Reconstruction (Parameter #{worst_val_idx})')\n",
    "        plt.imshow(X_val_worst[0, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "        del worst_val_idx, X_val_worst\n",
    "        return train_figure, best_train_loss, worst_train_loss, val_figure, best_val_loss, worst_val_loss\n",
    "        \"\"\"\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Functionality called upon the Start of Training\n",
    "    def on_train_begin(self, logs = None):\n",
    "\n",
    "        # Example Training Patient Download\n",
    "        self.trainset = MUDI_cVNP(  self.settings, training = False,\n",
    "                                    subject = self.settings.sel_train_patient)\n",
    "        self.X_train, self.mask_train, self.img_train = MUDI_cVNP.get_patient(  self.settings,\n",
    "                                                                self.settings.sel_train_patient)\n",
    "\n",
    "        # Example Validation Patient Download\n",
    "        self.valset = MUDI_cVNP(    self.settings, training = False,\n",
    "                                    subject = self.settings.sel_val_patient)\n",
    "        self.X_val, self.mask_val, self.img_val = MUDI_cVNP.get_patient(    self.settings,\n",
    "                                                            self.settings.sel_val_patient)\n",
    "\n",
    "    # Functionality called upon the End of a Training Epoch\n",
    "    def on_epoch_end(self, epoch, logs = None):\n",
    "\n",
    "        # Epoch Update for Losses & Training Image Reconstruction\n",
    "        tt_plot, tt_best_loss, tt_worst_loss, tv_plot, tv_best_loss, tv_worst_loss = self.reconstruct(  self.trainset, self.X_train,\n",
    "                                                                                                        self.mask_train, self.img_train,\n",
    "                                                                                                        sel_slice = 25, epoch = epoch)\n",
    "        vt_plot, vt_best_loss, vt_worst_loss, vv_plot, vv_best_loss, vv_worst_loss = self.reconstruct(  self.valset, self.X_val,\n",
    "                                                                                                        self.mask_val, self.img_val,\n",
    "                                                                                                        sel_slice = 25, epoch = epoch)\n",
    "        \n",
    "        # TensorBoard Logger Model Visualizer, Update for Image Visualizer\n",
    "        self.train_logger.experiment.add_scalar(\"Best Reconstruction Loss | Training\", tt_best_loss, epoch)\n",
    "        self.train_logger.experiment.add_scalar(\"Worst Reconstruction Loss | Training\", tt_worst_loss, epoch)\n",
    "        self.train_logger.experiment.add_scalar(\"Best Reconstruction Loss | Validation\", tv_best_loss, epoch)\n",
    "        self.train_logger.experiment.add_scalar(\"Worst Reconstruction Loss | Validation\", tv_worst_loss, epoch)\n",
    "        self.train_logger.experiment.add_figure(\"Training Image Reconstruction\", tt_plot, epoch)\n",
    "        self.train_logger.experiment.add_figure(\"Validation Image Reconstruction\", tv_plot, epoch)\n",
    "\n",
    "        self.val_logger.experiment.add_scalar(\"Best Reconstruction Loss | Training\", vt_best_loss, epoch)\n",
    "        self.val_logger.experiment.add_scalar(\"Worst Reconstruction Loss | Training\", vt_worst_loss, epoch)\n",
    "        self.val_logger.experiment.add_scalar(\"Best Reconstruction Loss | Validation\", vv_best_loss, epoch)\n",
    "        self.val_logger.experiment.add_scalar(\"Worst Reconstruction Loss | Validation\", vv_worst_loss, epoch)\n",
    "        self.val_logger.experiment.add_figure(\"Training Image Reconstruction\", vt_plot, epoch)\n",
    "        self.val_logger.experiment.add_figure(\"Validation Image Reconstruction\", vv_plot, epoch)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pytorch** *Version*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data** *Reader*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cVNP MUDI Dataset Initialization Class (V-2)\n",
    "class MUDI_cVNP(Dataset):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,\n",
    "        subject: int or list,\n",
    "        param_from: int or float = 100,\n",
    "        param_to: int or float = 100\n",
    "    ):\n",
    "        \n",
    "        # Parameter & Patient Index Value Access\n",
    "        super(MUDI_cVNP).__init__()\n",
    "        self.settings = settings; self.param_from = param_from; self.param_to = param_to\n",
    "        self.data = h5py.File(self.settings.data_filepath, 'r').get('data1')\n",
    "\n",
    "        # Vertical Splitting (Patient Selection)\n",
    "        self.idxv = pd.read_csv(self.settings.info_filepath,            # List of Index Values ...\n",
    "                                index_col = 0).to_numpy()               # ... pertaining to each Patient\n",
    "        self.idxv = self.idxv[np.isin(self.idxv[:, 1], subject), 0]     # Patient-Specific Index Values\n",
    "\n",
    "        # Horizontal Splitting (Parameter Selection)\n",
    "        idxh_train_filepath = Path(f\"{self.settings.datasave_folderpath}\" +\\\n",
    "                f\"/1D Training Labels (V{self.settings.data_version}).txt\")\n",
    "        idxh_val_filepath = Path(f\"{self.settings.datasave_folderpath}\" +\\\n",
    "                f\"/1D Validation Labels (V{self.settings.data_version}).txt\")\n",
    "        self.idxh_train = np.sort(np.loadtxt(idxh_train_filepath)).astype(int)\n",
    "        self.idxh_val = np.sort(np.loadtxt(idxh_val_filepath)).astype(int)\n",
    "        self.num_train_params = len(self.idxh_train); self.num_val_params = len(self.idxh_val)\n",
    "        assert(self.num_train_params == self.settings.num_train_params), \"ERROR: Dataset wrongly Built!\"\n",
    "        #self.msk = np.logical_not(np.isin(np.arange(1344), self.idxh_train))\n",
    "        \n",
    "        # Parameter Value Initialization & Selection\n",
    "        self.params = pd.read_excel(self.settings.param_filepath)                                       # List of Dataset's Parameters\n",
    "        self.num_labels = self.settings.num_labels\n",
    "        if self.settings.gradient_coord:\n",
    "            self.params = self.params.drop(columns = ['Gradient theta', 'Gradient phi'])                # Choosing of Gradient Orientation\n",
    "        else: self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])      # from 3D Cartesian or Polar Ref.\n",
    "\n",
    "        # Label Normalization / Scaling\n",
    "        if self.settings.label_norm == 'auto':\n",
    "            print(\"Automatic Normalization of Parameter Values\")\n",
    "            self.scaler = StandardScaler()\n",
    "            self.params = pd.DataFrame( self.scaler.fit_transform(self.params),\n",
    "                                        columns = self.params.columns)\n",
    "            scaler_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "            if not scaler_filepath.exists(): torch.save(self.scaler, scaler_filepath)\n",
    "        \n",
    "        # Label Manual Normalization\n",
    "        elif self.settings.label_norm == 'manual':\n",
    "            print(\"Manual Normalization of Parameter Values\")\n",
    "            self.params[['Gradient theta', 'Gradient phi']] = self.cart2polar(self.params[['Gradient x', 'Gradient y', 'Gradient z']].values)\n",
    "            self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])\n",
    "            self.params['b Value'] = self.params['b Value'] / 10000\n",
    "            self.params['TI'] = self.params['TI'] / 10000\n",
    "            self.params['TE'] = (self.params['TE'] - 80) / 200\n",
    "        else: print(\"No Normalization of Parameter Values\")\n",
    "        assert(self.params.shape[1] == self.num_labels), \"ERROR: Labels wrongly Deleted!\"\n",
    "\n",
    "        # Random Selection of Parameters for Training Loop Reconstruction\n",
    "        self.num_param_from = int((self.param_from * self.num_train_params) / 100)\n",
    "        self.num_param_to = int((self.param_to * self.num_val_params) / 100)\n",
    "        self.num_recon = self.num_param_from * self.num_param_to\n",
    "        self.idxh_from = self.idxh_train[np.sort(np.random.choice(self.num_train_params,\n",
    "                                                self.num_param_from, replace = False))]\n",
    "        self.idxh_to = self.idxh_val[np.sort(   np.random.choice(self.num_val_params,\n",
    "                                                self.num_param_to, replace = False))]\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # DataLoader Length / No. Batches Computation Functionality\n",
    "    def __len__(self): return int(len(self.idxv) * self.num_recon)\n",
    "\n",
    "    # Single-Batch Generation Functionality\n",
    "    def __getitem__(self, idx) -> tuple[np.ndarray, np.float32]:\n",
    "        \n",
    "        # Each Voxel Intensity Value 'X_train' will have its corresponding Training Parameter\n",
    "        # 'y_train' and be mapped to one of the 'num_param_to' the Target Parameter 'y_target'.\n",
    "        # This means that each voxel position will see all the 'num_param_from' Parameters in it\n",
    "        # be mapped to the 'num_param_to' Parameters in the Validation Set\n",
    "\n",
    "        # [Destination -> Origin -> Voxel] Batch Vertical/Patient & Horizontal/Parameter Indexing\n",
    "        idxv = idx % len(self.idxv)                                     # Batch's Vertical Index for X_train\n",
    "        idxh_train = (idx // len(self.idxv)) % self.num_param_from      # Batch's Horizontal Index for y_train\n",
    "        idxh_target = idx // (len(self.idxv) * self.num_param_from)     # Batch's Horizontal Index for y_target\n",
    "\n",
    "        # [Voxel -> Origin -> Destination] Batch Vertical/Patient & Horizontal/Parameter Indexing\n",
    "        #idxv = idx // (self.num_param_from * self.num_param_to)         # Batch's Vertical Index for X_train\n",
    "        #idxh_train = (idx // self.num_param_to) % self.num_param_from   # Batch's Horizontal Index for y_train\n",
    "        #idxh_target = idx % self.num_param_to                           # Batch's Horizontal Index for y_target\n",
    "        #print(f\"idxv = {idxv} | idxh_train = {idxh_train} | idxh_target = {idxh_target}\")\n",
    "        \n",
    "        # Batch Data Generation\n",
    "        X_train = self.data[self.idxv[idxv], :][self.idxh_from[idxh_train]]     # [    1    ] Training Data\n",
    "        y_train = self.params.iloc[self.idxh_from[idxh_train]].values           # [num_labels] Training Parameters\n",
    "        y_target = self.params.iloc[self.idxh_to[idxh_target]].values           # [num_labels] Target Parameters\n",
    "        X_target = self.data[self.idxv[idxv], :][self.idxh_to[idxh_target]]     # [    1    ] GT Target Data\n",
    "        #input = np.hstack((X_train, y_target)).astype(np.float32)               # [num_train_params + num_labels] Encoder Input\n",
    "        return {'X_train': np.array(X_train), 'y_train': y_train,\n",
    "                'y_target': y_target, 'X_target': np.array(X_target)}\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # End of Epoch Reconstruction Parameter Shuffling Functionality\n",
    "    def on_epoch_end(\n",
    "        self,\n",
    "        idxh_from: np.array = None,\n",
    "        idxh_to: np.array = None\n",
    "    ):\n",
    "        \n",
    "        # Batch Shuffling\n",
    "        self.idxv_set = np.arange(len(self.idxv))\n",
    "        if self.settings.sample_shuffle: np.random.shuffle(self.idxv_set)\n",
    "\n",
    "        # Origin & Destination Reconstruction Parameter Shuffling\n",
    "        if self.settings.param_shuffle:\n",
    "            self.idxh_from = self.idxh_train[np.sort(np.random.choice(self.num_train_params,\n",
    "                                            self.num_param_from, replace = False))]\n",
    "            self.idxh_to = self.idxh_val[np.sort(   np.random.choice(self.num_val_params,\n",
    "                                                    self.num_param_to, replace = False))]\n",
    "        if idxh_from is not None: self.idxh_from = idxh_from\n",
    "        if idxh_to is not None: self.idxh_to = idxh_to  \n",
    "    \n",
    "    # Label Scaler Download & Reverse Transformation\n",
    "    def label_unscale(\n",
    "        self,\n",
    "        y: np.array or pd.DataFrame\n",
    "    ):\n",
    "\n",
    "        # Label Scaler Download & Reverse Usage\n",
    "        try: self.scaler\n",
    "        except AttributeError:\n",
    "            scaler = torch.load(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "        return scaler.inverse_transform(y.reshape(1, -1))\n",
    "\n",
    "    # Cartesian to Polar Coordinate Conversion Functionality\n",
    "    def cart2polar(self, y: np.array):\n",
    "\n",
    "        # Cartesian to Polar Coordinates Conversion\n",
    "        phi = np.arccos(y[:, 2]).astype(np.float32); theta = np.arctan2(y[:, 1], y[:, 0])\n",
    "        theta = np.where(theta < 0, 2 * np.pi - np.abs(theta), theta).astype(np.float32)\n",
    "        theta = np.expand_dims(theta, axis = 1); phi = np.expand_dims(phi, axis = 1)\n",
    "        return pd.DataFrame(data = np.concatenate((theta, phi), axis = 1),\n",
    "                            columns = ['Gradient theta', 'Gradient phi'])\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Patient Data Generation Functionality\n",
    "    def get_patient(settings, num_patient: int):\n",
    "\n",
    "        # Patient Data Access\n",
    "        data = h5py.File(settings.data_filepath, 'r').get('data1')\n",
    "        idxv = pd.read_csv( settings.info_filepath,             # List of Index Values ...\n",
    "                            index_col = 0).to_numpy()           # ... pertaining to each Patient\n",
    "        idxv = idxv[np.isin(idxv[:, 1], num_patient), 0]        # Patient-Specific Index Values\n",
    "        X = torch.Tensor(data[idxv, :])\n",
    "\n",
    "        # Patient Mask Access\n",
    "        mask = MUDI_fcglVNN.get_mask(settings, num_patient = num_patient)\n",
    "        img = unmask(X.T, mask).get_fdata().T\n",
    "        return X, mask, torch.Tensor(img)\n",
    "\n",
    "    # Patient Mask Retrieval Functionality\n",
    "    def get_mask(settings, num_patient: int):\n",
    "        mask_filepath = Path(f\"{settings.mask_folderpath}/p{num_patient}.nii\")\n",
    "        assert(mask_filepath.exists()), f\"ERROR: Patient {num_patient}'s Mask not Found!\"\n",
    "        #return torch.Tensor(np.array(load_img(mask_filepath).dataobj, dtype = np.float32))\n",
    "        return load_img(mask_filepath)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cVNP MUDI Dataset Initialization Class (V0)\n",
    "class MUDI_cVNP(Dataset):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,\n",
    "        subject: int or list,\n",
    "        mode: str = 'Target',\n",
    "        source_param: int or float = 100,\n",
    "        target_param: int or float = 100,\n",
    "        target_voxel: int or float = 100\n",
    "    ):\n",
    "        \n",
    "        # Parameter & Patient Index Value Access\n",
    "        super(MUDI_cVNP).__init__()\n",
    "        self.settings = settings; self.source_param = source_param\n",
    "        self.target_param = target_param; self.target_voxel = target_voxel\n",
    "        self.data = h5py.File(self.settings.data_filepath, 'r').get('data1')\n",
    "        self.params = pd.read_excel(self.settings.param_filepath)\n",
    "\n",
    "        # Vertical Splitting (Patient Selection)\n",
    "        self.idxv = pd.read_csv(self.settings.info_filepath,            # List of Index Values ...\n",
    "                                index_col = 0).to_numpy()               # ... pertaining to each Patient\n",
    "        self.idxv = self.idxv[np.isin(self.idxv[:, 1], subject), 0]     # Patient-Specific Index Values\n",
    "\n",
    "        # Horizontal Splitting (Parameter Selection)\n",
    "        idxh_source_filepath = Path(f\"{self.settings.datasave_folderpath}/Training Labels (V{self.settings.data_version}).txt\")\n",
    "        idxh_target_filepath = Path(f\"{self.settings.datasave_folderpath}/{mode} Labels (V{self.settings.data_version}).txt\")\n",
    "        self.idxh_source_base = np.sort(np.loadtxt(idxh_source_filepath)).astype(int)\n",
    "        if not idxh_target_filepath.exists(): self.label_gen()\n",
    "        self.idxh_target_base = np.sort(np.loadtxt(idxh_target_filepath)).astype(int)\n",
    "\n",
    "        # Vertical & Horizontal Sub-Sectioning & Shuffling\n",
    "        self.h_source = int((self.source_param * len(self.idxh_source_base)) / 100)\n",
    "        self.h_target = int((self.target_param * len(self.idxh_target_base)) / 100)\n",
    "        self.v_target = int((self.target_voxel * len(self.idxv)) / 100); self.shuffle(init = True)\n",
    "        print(f\"     > Utilizing {self.h_source} \\ {len(self.idxh_source_base)} of the Training Parameters\")\n",
    "        print(f\"     > Utilizing {self.h_target} \\ {len(self.idxh_target_base)} of the Target Parameters\")\n",
    "        print(f\"     > Utilizing {self.v_target} \\ {len(self.idxv)} of the Training Voxels\")\n",
    "\n",
    "        # Parameter Selection & Value Normalization / Scaling\n",
    "        if self.settings.gradient_coord:\n",
    "            self.params = self.params.drop(columns = ['Gradient theta', 'Gradient phi'])\n",
    "        else: self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])\n",
    "        if self.settings.label_norm == 'auto':\n",
    "            print(f\"     > Automatic Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "            self.scaler = StandardScaler()\n",
    "            self.params = pd.DataFrame( self.scaler.fit_transform(self.params),\n",
    "                                        columns = self.params.columns)\n",
    "            scaler_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "            if not scaler_filepath.exists(): torch.save(self.scaler, scaler_filepath)\n",
    "        elif self.settings.label_norm == 'manual':\n",
    "            print(f\"     > Manual Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "            self.params[['Gradient theta', 'Gradient phi']] = self.cart2polar(self.params[['Gradient x', 'Gradient y', 'Gradient z']].values)\n",
    "            self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])\n",
    "            self.params['b Value'] = self.params['b Value'] / 10000\n",
    "            self.params['TI'] = self.params['TI'] / 10000\n",
    "            self.params['TE'] = (self.params['TE'] - 80) / 200\n",
    "        else: print(f\"     > No Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "        assert(self.params.shape[1] == self.settings.num_labels), \"ERROR: Labels wrongly Deleted!\"\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # DataLoader Length / No. Batches Computation Functionality\n",
    "    def __len__(self): return self.v_target * self.h_source * self.h_target\n",
    "\n",
    "    # Single-Batch Generation Functionality\n",
    "    def __getitem__(self, idx) -> tuple[np.ndarray, np.float32]:\n",
    "\n",
    "        # Each Voxel Intensity Value 'X_train' will have its corresponding Training Parameter\n",
    "        # 'y_train' and be mapped to one of the 'num_param_to' the Target Parameter 'y_target'.\n",
    "        # This means that each voxel position will see all the 'num_param_from' Parameters in it\n",
    "        # be mapped to the 'num_param_to' Parameters in the Validation Set\n",
    "\n",
    "        # The order goes from a Minor to a Major Scale, meaning it will use all Voxels of the same Image\n",
    "        # cosecutively, and then select one Target Parameter to map to, and iterate through all Source\n",
    "        # Parameters, only changing the Target when these all these are exhausted\n",
    "\n",
    "        # [Destination -> Origin -> Voxel] Batch Vertical/Patient & Horizontal/Parameter Indexing\n",
    "        idxv = idx % self.v_target                               # Batch's Vertical Index for X_train\n",
    "        idxh_source = (idx // self.v_target) % self.h_source     # Batch's Horizontal Index for y_train\n",
    "        idxh_target = idx // (self.v_target * self.h_source)     # Batch's Horizontal Index for y_target\n",
    "        \n",
    "        # Batch Data Generation\n",
    "        X_train = self.data[self.idxv_target[idxv], :][self.idxh_source[idxh_source]]       # [    1    ] Training Data\n",
    "        y_train = self.params.iloc[self.idxh_source[idxh_source]].values                    # [num_labels] Training Parameters\n",
    "        y_target = self.params.iloc[self.idxh_target[idxh_target]].values                   # [num_labels] Target Parameters\n",
    "        X_target = self.data[self.idxv_target[idxv], :][self.idxh_target[idxh_target]]      # [    1    ] GT Target Data\n",
    "        return {'X_train': np.array(X_train),\n",
    "                'X_target': np.array(X_target),\n",
    "                'idxv': self.idxv_target[idxv],\n",
    "                'y_train': y_train.astype(np.float32),\n",
    "                'param_source': self.idxh_source[idxh_source],\n",
    "                'idxh_source': idxh_source,\n",
    "                'y_target': y_target.astype(np.float32),\n",
    "                'param_target': self.idxh_target[idxh_target],\n",
    "                'idxh_target': idxh_target}\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Source Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def source_param_shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxh_source: np.array = None\n",
    "    ):\n",
    "        if idxh_source is not None: self.idxh_source = idxh_source\n",
    "        else:\n",
    "            if self.settings.param_shuffle or init:\n",
    "                self.idxh_source = self.idxh_source_base[   np.sort(np.random.choice(len(self.idxh_source_base),\n",
    "                                                            self.h_source, replace = False))]\n",
    "                \n",
    "    # Target Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def target_param_shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxh_target: np.array = None\n",
    "    ):\n",
    "        if idxh_target is not None: self.idxh_target = idxh_target\n",
    "        else:\n",
    "            if self.settings.param_shuffle or init:\n",
    "                self.idxh_target = self.idxh_target_base[   np.sort(np.random.choice(len(self.idxh_target_base),\n",
    "                                                            self.h_target, replace = False))]\n",
    "                \n",
    "    # Target Voxel Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def voxel_shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxv_target: np.array = None\n",
    "    ):  \n",
    "        if idxv_target is not None: self.idxv_target = idxv_target\n",
    "        else:\n",
    "            if self.settings.voxel_shuffle or init:\n",
    "                self.idxv_target = self.idxv[   np.sort(np.random.choice(len(self.idxv),\n",
    "                                                self.v_target, replace = False))]\n",
    "    \n",
    "    # All Selected Voxel & Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxh_source: np.array = None,\n",
    "        idxh_target: np.array = None,\n",
    "        idxv_target: np.array = None\n",
    "    ):\n",
    "        self.source_param_shuffle(init, idxh_source)\n",
    "        self.target_param_shuffle(init, idxh_target)\n",
    "        self.voxel_shuffle(init, idxv_target)\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Random Target Parameter for Training & Test Sets Generation Functionality\n",
    "    def label_gen(self):\n",
    "\n",
    "        # Target & Test Label Index File Generation\n",
    "        idxh_train = np.delete(np.arange(self.params.shape[0]), self.idxh_train)\n",
    "        if self.settings.test_target_param != 0:\n",
    "            idxh_test = idxh_train[np.sort(np.random.choice(len(idxh_train),\n",
    "                                    self.settings.test_target_param, replace = False))]\n",
    "            idxh_train = np.delete(idxh_train, np.where(np.in1d(idxh_train, idxh_test)))\n",
    "            for i in range(settings.test_target_param): assert(idxh_test[i] not in idxh_train\n",
    "                ), f\"ERROR: Target Parameter #{i} for Training & Test Sets not mutually Exclusive\"\n",
    "            \n",
    "            # Target & Test Label Index File Saving\n",
    "            print(f\">     Saving File Target Parameters for Training ({len(idxh_train)}) & Test {len(idxh_test)} Set's\")\n",
    "            np.savetxt(Path(f\"{self.settings.datasave_folderpath}/Test Labels (V{self.settings.data_version}).txt\"), idxh_test)\n",
    "            np.savetxt(Path(f\"{self.settings.datasave_folderpath}/Target Labels (V{self.settings.data_version}).txt\"), idxh_train)\n",
    " \n",
    "    # Label Scaler Download & Reverse Transformation\n",
    "    def label_unscale(\n",
    "        self,\n",
    "        y: np.array or pd.DataFrame\n",
    "    ):\n",
    "\n",
    "        # Label Scaler Download & Reverse Usage\n",
    "        try: self.scaler\n",
    "        except AttributeError:\n",
    "            scaler = torch.load(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "        return scaler.inverse_transform(y.reshape(1, -1))\n",
    "\n",
    "    # Cartesian to Polar Coordinate Conversion Functionality\n",
    "    def cart2polar(self, y: np.array):\n",
    "\n",
    "        # Cartesian to Polar Coordinates Conversion\n",
    "        phi = np.arccos(y[:, 2]).astype(np.float32); theta = np.arctan2(y[:, 1], y[:, 0])\n",
    "        theta = np.where(theta < 0, 2 * np.pi - np.abs(theta), theta).astype(np.float32)\n",
    "        theta = np.expand_dims(theta, axis = 1); phi = np.expand_dims(phi, axis = 1)\n",
    "        return pd.DataFrame(data = np.concatenate((theta, phi), axis = 1),\n",
    "                            columns = ['Gradient theta', 'Gradient phi'])\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Patient Data Generation Functionality\n",
    "    def get_img(settings, num_patient: int):\n",
    "\n",
    "        # Patient Data Access\n",
    "        data = h5py.File(settings.data_filepath, 'r').get('data1')\n",
    "        idxv = pd.read_csv( settings.info_filepath,             # List of Index Values ...\n",
    "                            index_col = 0).to_numpy()           # ... pertaining to each Patient\n",
    "        idxv = idxv[np.isin(idxv[:, 1], num_patient), 0]        # Patient-Specific Index Values\n",
    "        X = torch.Tensor(data[idxv, :])\n",
    "\n",
    "        # Patient Mask Access\n",
    "        mask = MUDI_fcglVNN.get_mask(settings, num_patient = num_patient)\n",
    "        img = unmask(X.T, mask).get_fdata().T\n",
    "        return torch.Tensor(img)\n",
    "\n",
    "    # Patient Mask Retrieval Functionality\n",
    "    def get_mask(settings, num_patient: int):\n",
    "        mask_filepath = Path(f\"{settings.mask_folderpath}/p{num_patient}.nii\")\n",
    "        assert(mask_filepath.exists()), f\"ERROR: Patient {num_patient}'s Mask not Found!\"\n",
    "        #return torch.Tensor(np.array(load_img(mask_filepath).dataobj, dtype = np.float32))\n",
    "        return load_img(mask_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cVNP MUDI Dataset Initialization Class (V1)\n",
    "class MUDI_cVNP(Dataset):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,\n",
    "        subject: int or list,\n",
    "        mode: str = 'Target',\n",
    "        source_param: int or float = 100,\n",
    "        target_param: int or float = 100,\n",
    "        target_voxel: int or float = 100,\n",
    "        sample_size: int = 0,\n",
    "    ):\n",
    "        \n",
    "        # Parameter & Patient Index Value Access\n",
    "        super(MUDI_cVNP).__init__()\n",
    "        self.settings = settings; self.source_param = source_param\n",
    "        self.target_param = target_param; self.target_voxel = target_voxel\n",
    "        self.data = h5py.File(self.settings.data_filepath, 'r').get('data1')\n",
    "        self.params = pd.read_excel(self.settings.param_filepath)\n",
    "\n",
    "        # Vertical Splitting (Patient Selection)\n",
    "        self.idxv = pd.read_csv(self.settings.info_filepath,            # List of Index Values ...\n",
    "                                index_col = 0).to_numpy()               # ... pertaining to each Patient\n",
    "        self.idxv = self.idxv[np.isin(self.idxv[:, 1], subject), 0]     # Patient-Specific Index Values\n",
    "\n",
    "        # Horizontal Splitting (Parameter Selection)\n",
    "        idxh_source_filepath = Path(f\"{self.settings.datasave_folderpath}/Training Labels (V{self.settings.data_version}).txt\")\n",
    "        idxh_target_filepath = Path(f\"{self.settings.datasave_folderpath}/{mode} Labels (V{self.settings.data_version}).txt\")\n",
    "        self.idxh_source_base = np.sort(np.loadtxt(idxh_source_filepath)).astype(int)\n",
    "        if not idxh_target_filepath.exists(): self.label_gen()\n",
    "        self.idxh_target_base = np.sort(np.loadtxt(idxh_target_filepath)).astype(int)\n",
    "\n",
    "        # Vertical & Horizontal Sub-Sectioning & Shuffling\n",
    "        self.h_source = int((self.source_param * len(self.idxh_source_base)) / 100)\n",
    "        print(f\"     > Utilizing {self.h_source} \\ {len(self.idxh_source_base)} of the Training Parameters\")\n",
    "        self.h_target = int((self.target_param * len(self.idxh_target_base)) / 100)\n",
    "        print(f\"     > Utilizing {self.h_target} \\ {len(self.idxh_target_base)} of the Target Parameters\")\n",
    "        self.v_target = int((self.target_voxel * len(self.idxv)) / 100); self.shuffle(init = True)\n",
    "        \n",
    "        # Voxel Grouping Functionality (for Loader Step Reduction)\n",
    "        # https://discuss.pytorch.org/t/data-loader-process-killed/120181\n",
    "        if sample_size == 0: self.sample_size = self.v_target               # Automatic Sample Grouping Size \n",
    "        else: self.sample_size = sample_size\n",
    "        print(f\"     > Utilizing {self.v_target} \\ {len(self.idxv)} of the Training Samples in Groupings of {self.sample_size}\")\n",
    "        self.g_target = int(np.ceil(self.v_target / self.sample_size))      # Number of Sample Groupings in a Full Image\n",
    "\n",
    "        # Parameter Selection & Value Normalization / Scaling\n",
    "        if self.settings.gradient_coord:\n",
    "            self.params = self.params.drop(columns = ['Gradient theta', 'Gradient phi'])\n",
    "        else: self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])\n",
    "        if self.settings.label_norm == 'auto':\n",
    "            print(f\"     > Automatic Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "            self.scaler = StandardScaler()\n",
    "            self.params = pd.DataFrame( self.scaler.fit_transform(self.params),\n",
    "                                        columns = self.params.columns)\n",
    "            scaler_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "            if not scaler_filepath.exists(): torch.save(self.scaler, scaler_filepath)\n",
    "        elif self.settings.label_norm == 'manual':\n",
    "            print(f\"     > Manual Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "            self.params[['Gradient theta', 'Gradient phi']] = self.cart2polar(self.params[['Gradient x', 'Gradient y', 'Gradient z']].values)\n",
    "            self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])\n",
    "            self.params['b Value'] = self.params['b Value'] / 10000\n",
    "            self.params['TI'] = self.params['TI'] / 10000\n",
    "            self.params['TE'] = (self.params['TE'] - 80) / 200\n",
    "        else: print(f\"     > No Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "        assert(self.params.shape[1] == self.settings.num_labels), \"ERROR: Labels wrongly Deleted!\"\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # DataLoader Length / No. Batches Computation Functionality\n",
    "    def __len__(self): return int(self.g_target * self.h_source * self.h_target)\n",
    "\n",
    "    # Single-Batch Generation Functionality\n",
    "    def __getitem__(self, idx) -> tuple[np.ndarray, np.float32]:\n",
    "\n",
    "        # Each Voxel Intensity Value 'X_train' will have its corresponding Training Parameter\n",
    "        # 'y_train' and be mapped to one of the 'num_param_to' the Target Parameter 'y_target'.\n",
    "        # This means that each voxel position will see all the 'num_param_from' Parameters in it\n",
    "        # be mapped to the 'num_param_to' Parameters in the Validation Set\n",
    "\n",
    "        # The order goes from a Minor to a Major Scale, meaning it will use all Voxels of the same Image\n",
    "        # consecutively, and then select one Target Parameter to map to, and iterate through all Source\n",
    "        # Parameters, only changing the Target when these all these are exhausted\n",
    "\n",
    "        # [Destination -> Origin -> Voxel] Batch Vertical/Patient & Horizontal/Parameter Indexing\n",
    "        idxg = idx % self.g_target                                      # Batch's Sample Grouping Index\n",
    "        idxh_source = (idx // self.g_target) % self.h_source            # Batch's Horizontal Index for y_train\n",
    "        idxh_target = idx // (self.g_target * self.h_source)            # Batch's Horizontal Index for y_target\n",
    "        if idxg == self.g_target - 1: idxv = self.idxv_target[idxg * self.sample_size ::]\n",
    "        else: idxv = self.idxv_target[idxg * self.sample_size : (idxg + 1) * self.sample_size]\n",
    "\n",
    "        # Batch Data Generation\n",
    "        X_train = self.data[idxv, :][:, self.idxh_source[idxh_source]]          # [    1                   ] Training Data\n",
    "        y_train = self.params.iloc[self.idxh_source[idxh_source]].values        # [num_labels              ] Training Parameters\n",
    "        y_train = np.repeat(y_train.reshape(1, -1), len(idxv), axis = 0)        # [num_labels * sample_size] Training Parameters\n",
    "        y_target = self.params.iloc[self.idxh_target[idxh_target]].values       # [num_labels              ] Target Parameters\n",
    "        y_target = np.repeat(y_target.reshape(1, -1), len(idxv), axis = 0)      # [num_labels * sample_size] Target Parameters\n",
    "        X_target = self.data[idxv, :][:, self.idxh_target[idxh_target]]         # [    1                   ] GT Target Data\n",
    "        return {'X_train': np.array(X_train),\n",
    "                'X_target': np.array(X_target),\n",
    "                'idxv': idxv, 'idxg': idxg, 'g_size': len(idxv),\n",
    "                'y_train': np.ravel(y_train).astype(np.float32),\n",
    "                'param_source': self.idxh_source[idxh_source],\n",
    "                'idxh_source': idxh_source,\n",
    "                'y_target': np.ravel(y_target).astype(np.float32),\n",
    "                'param_target': self.idxh_target[idxh_target],\n",
    "                'idxh_target': idxh_target}\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Source Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def source_param_shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxh_source: np.array = None\n",
    "    ):\n",
    "        if idxh_source is not None: self.idxh_source = idxh_source\n",
    "        else:\n",
    "            if self.settings.param_shuffle or init:\n",
    "                self.idxh_source = self.idxh_source_base[   np.sort(np.random.choice(len(self.idxh_source_base),\n",
    "                                                            self.h_source, replace = False))]\n",
    "                \n",
    "    # Target Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def target_param_shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxh_target: np.array = None\n",
    "    ):\n",
    "        if idxh_target is not None: self.idxh_target = idxh_target\n",
    "        else:\n",
    "            if self.settings.param_shuffle or init:\n",
    "                self.idxh_target = self.idxh_target_base[   np.sort(np.random.choice(len(self.idxh_target_base),\n",
    "                                                            self.h_target, replace = False))]\n",
    "                \n",
    "    # Target Voxel Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def voxel_shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxv_target: np.array = None\n",
    "    ):  \n",
    "        if idxv_target is not None: self.idxv_target = idxv_target\n",
    "        else:\n",
    "            if self.settings.voxel_shuffle or init:\n",
    "                self.idxv_target = self.idxv[   np.sort(np.random.choice(len(self.idxv),\n",
    "                                                self.v_target, replace = False))]\n",
    "    \n",
    "    # All Selected Voxel & Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxh_source: np.array = None,\n",
    "        idxh_target: np.array = None,\n",
    "        idxv_target: np.array = None\n",
    "    ):\n",
    "        self.source_param_shuffle(init, idxh_source)\n",
    "        self.target_param_shuffle(init, idxh_target)\n",
    "        self.voxel_shuffle(init, idxv_target)\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Random Target Parameter for Training & Test Sets Generation Functionality\n",
    "    def label_gen(self):\n",
    "\n",
    "        # Target & Test Label Index File Generation\n",
    "        idxh_train = np.delete(np.arange(self.params.shape[0]), self.idxh_train)\n",
    "        if self.settings.test_target_param != 0:\n",
    "            idxh_test = idxh_train[np.sort(np.random.choice(len(idxh_train),\n",
    "                                    self.settings.test_target_param, replace = False))]\n",
    "            idxh_train = np.delete(idxh_train, np.where(np.in1d(idxh_train, idxh_test)))\n",
    "            for i in range(self.settings.test_target_param): assert(idxh_test[i] not in idxh_train\n",
    "                ), f\"ERROR: Target Parameter #{i} for Training & Test Sets not mutually Exclusive\"\n",
    "            \n",
    "            # Target & Test Label Index File Saving\n",
    "            print(f\">     Saving File Target Parameters for Training ({len(idxh_train)}) & Test {len(idxh_test)} Set's\")\n",
    "            np.savetxt(Path(f\"{self.settings.datasave_folderpath}/Test Labels (V{self.settings.data_version}).txt\"), idxh_test)\n",
    "            np.savetxt(Path(f\"{self.settings.datasave_folderpath}/Target Labels (V{self.settings.data_version}).txt\"), idxh_train)\n",
    " \n",
    "    # Label Scaler Download & Reverse Transformation\n",
    "    def label_unscale(\n",
    "        self,\n",
    "        y: np.array or pd.DataFrame\n",
    "    ):\n",
    "\n",
    "        # Label Scaler Download & Reverse Usage\n",
    "        try: self.scaler\n",
    "        except AttributeError:\n",
    "            scaler = torch.load(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "        return scaler.inverse_transform(y.reshape(1, -1))\n",
    "\n",
    "    # Cartesian to Polar Coordinate Conversion Functionality\n",
    "    def cart2polar(self, y: np.array):\n",
    "\n",
    "        # Cartesian to Polar Coordinates Conversion\n",
    "        phi = np.arccos(y[:, 2]).astype(np.float32); theta = np.arctan2(y[:, 1], y[:, 0])\n",
    "        theta = np.where(theta < 0, 2 * np.pi - np.abs(theta), theta).astype(np.float32)\n",
    "        theta = np.expand_dims(theta, axis = 1); phi = np.expand_dims(phi, axis = 1)\n",
    "        return pd.DataFrame(data = np.concatenate((theta, phi), axis = 1),\n",
    "                            columns = ['Gradient theta', 'Gradient phi'])\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Patient Data Generation Functionality\n",
    "    def get_img(settings, num_patient: int):\n",
    "\n",
    "        # Patient Data Access\n",
    "        data = h5py.File(settings.data_filepath, 'r').get('data1')\n",
    "        idxv = pd.read_csv( settings.info_filepath,             # List of Index Values ...\n",
    "                            index_col = 0).to_numpy()           # ... pertaining to each Patient\n",
    "        idxv = idxv[np.isin(idxv[:, 1], num_patient), 0]        # Patient-Specific Index Values\n",
    "        X = torch.Tensor(data[idxv, :])\n",
    "\n",
    "        # Patient Mask Access\n",
    "        mask = MUDI_cVNP.get_mask(settings, num_patient = num_patient)\n",
    "        img = unmask(X.T, mask).get_fdata().T\n",
    "        return torch.Tensor(img)\n",
    "\n",
    "    # Patient Mask Retrieval Functionality\n",
    "    def get_mask(settings, num_patient: int):\n",
    "        mask_filepath = Path(f\"{settings.mask_folderpath}/p{num_patient}.nii\")\n",
    "        assert(mask_filepath.exists()), f\"ERROR: Patient {num_patient}'s Mask not Found!\"\n",
    "        #return torch.Tensor(np.array(load_img(mask_filepath).dataobj, dtype = np.float32))\n",
    "        return load_img(mask_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cVNP MUDI Dataset Initialization Class (Random)\n",
    "class MUDI_cVNP(Dataset):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,\n",
    "        subject: int or list,\n",
    "        mode: str = 'Target',\n",
    "        source_param: int or float = 100,\n",
    "        target_param: int or float = 100,\n",
    "        target_voxel: int or float = 100,\n",
    "        param_loop: int or float = 100\n",
    "    ):\n",
    "        \n",
    "        # Parameter & Patient Index Value Access\n",
    "        super(MUDI_cVNP).__init__()\n",
    "        self.settings = settings; self.source_param = source_param\n",
    "        self.target_param = target_param; self.target_voxel = target_voxel\n",
    "        self.data = h5py.File(self.settings.data_filepath, 'r').get('data1')\n",
    "        self.params = pd.read_excel(self.settings.param_filepath)\n",
    "\n",
    "        # Vertical Splitting (Patient Selection)\n",
    "        self.idxv = pd.read_csv(self.settings.info_filepath,            # List of Index Values ...\n",
    "                                index_col = 0).to_numpy()               # ... pertaining to each Patient\n",
    "        self.idxv = self.idxv[np.isin(self.idxv[:, 1], subject), 0]     # Patient-Specific Index Values\n",
    "\n",
    "        # Horizontal Splitting (Parameter Selection)\n",
    "        idxh_source_filepath = Path(f\"{self.settings.datasave_folderpath}/Training Labels (V{self.settings.data_version}).txt\")\n",
    "        idxh_target_filepath = Path(f\"{self.settings.datasave_folderpath}/{mode} Labels (V{self.settings.data_version}).txt\")\n",
    "        self.idxh_source_base = np.sort(np.loadtxt(idxh_source_filepath)).astype(int)\n",
    "        if not idxh_target_filepath.exists(): self.label_gen()\n",
    "        self.idxh_target_base = np.sort(np.loadtxt(idxh_target_filepath)).astype(int)\n",
    "\n",
    "        # Vertical & Horizontal Sub-Sectioning & Shuffling\n",
    "        self.h_source = int((self.source_param * len(self.idxh_source_base)) / 100)\n",
    "        self.h_target = int((self.target_param * len(self.idxh_target_base)) / 100)\n",
    "        self.v_target = int((self.target_voxel * len(self.idxv)) / 100); self.shuffle(init = True)\n",
    "        self.num_loop = int((param_loop * (self.h_source * self.h_target)) / 100)\n",
    "        print(f\"     > Utilizing {self.h_source} \\ {len(self.idxh_source_base)} of the Training Parameters\")\n",
    "        print(f\"     > Utilizing {self.h_target} \\ {len(self.idxh_target_base)} of the Target Parameters\")\n",
    "        print(f\"     > Utilizing {self.v_target} \\ {len(self.idxv)} of the Training Voxels\")\n",
    "        print(f\"     > Looping through {self.num_loop} of the the Possible {self.h_source * self.h_target} Source/Target Parameter Combos\")\n",
    "\n",
    "        # Parameter Selection & Value Normalization / Scaling\n",
    "        if self.settings.gradient_coord:\n",
    "            self.params = self.params.drop(columns = ['Gradient theta', 'Gradient phi'])\n",
    "        else: self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])\n",
    "        if self.settings.label_norm == 'auto':\n",
    "            print(f\"     > Automatic Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "            self.scaler = StandardScaler()\n",
    "            self.params = pd.DataFrame( self.scaler.fit_transform(self.params),\n",
    "                                        columns = self.params.columns)\n",
    "            scaler_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "            if not scaler_filepath.exists(): torch.save(self.scaler, scaler_filepath)\n",
    "        elif self.settings.label_norm == 'manual':\n",
    "            print(f\"     > Manual Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "            self.params[['Gradient theta', 'Gradient phi']] = self.cart2polar(self.params[['Gradient x', 'Gradient y', 'Gradient z']].values)\n",
    "            self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])\n",
    "            self.params['b Value'] = self.params['b Value'] / 10000\n",
    "            self.params['TI'] = self.params['TI'] / 10000\n",
    "            self.params['TE'] = (self.params['TE'] - 80) / 200\n",
    "        else: print(f\"     > No Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "        assert(self.params.shape[1] == self.settings.num_labels), \"ERROR: Labels wrongly Deleted!\"\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # DataLoader Length / No. Batches Computation Functionality\n",
    "    def __len__(self): return self.v_target * self.num_loop\n",
    "\n",
    "    # Single-Batch Generation Functionality\n",
    "    def __getitem__(self, idx) -> tuple[np.ndarray, np.float32]:\n",
    "\n",
    "        # Each Voxel Intensity Value 'X_train' will have its corresponding Training Parameter\n",
    "        # 'y_train' and be mapped to one of the 'num_param_to' the Target Parameter 'y_target'.\n",
    "        # This means that each voxel position will see all the 'num_param_from' Parameters in it\n",
    "        # be mapped to the 'num_param_to' Parameters in the Validation Set\n",
    "\n",
    "        # The order goes from a Minor to a Major Scale, meaning it will use all Voxels of the same Image\n",
    "        # cosecutively, and then select one Target Parameter to map to, and iterate through all Source\n",
    "        # Parameters, only changing the Target when these all these are exhausted\n",
    "\n",
    "        # [Destination -> Origin -> Voxel] Batch Vertical/Patient & Horizontal/Parameter Indexing\n",
    "        idxv = idx % self.v_target                                  # Batch's Vertical Index for X_train\n",
    "        idxh_loop = (idx // self.v_target) % self.num_loop          # Batch's Horizontal Index for Loop Combo\n",
    "        idxh_source = random.randrange(self.h_source)               # Batch's Horizontal Index for y_train\n",
    "        idxh_target = random.randrange(self.h_target)               # Batch's Horizontal Index for y_target\n",
    "        \n",
    "        # Batch Data Generation\n",
    "        X_train = self.data[self.idxv_target[idxv], :][self.idxh_source[idxh_source]]       # [    1    ] Training Data\n",
    "        y_train = self.params.iloc[self.idxh_source[idxh_source]].values                    # [num_labels] Training Parameters\n",
    "        y_target = self.params.iloc[self.idxh_target[idxh_target]].values                   # [num_labels] Target Parameters\n",
    "        X_target = self.data[self.idxv_target[idxv], :][self.idxh_target[idxh_target]]      # [    1    ] GT Target Data\n",
    "        return {'X_train': np.array(X_train),\n",
    "                'X_target': np.array(X_target),\n",
    "                'idxv': self.idxv_target[idxv],\n",
    "                'idxh_loop': idxh_loop,\n",
    "                'y_train': y_train.astype(np.float32),\n",
    "                'param_source': self.idxh_source[idxh_source],\n",
    "                'idxh_source': idxh_source,\n",
    "                'y_target': y_target.astype(np.float32),\n",
    "                'param_target': self.idxh_target[idxh_target],\n",
    "                'idxh_target': idxh_target}\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Source Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def source_param_shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxh_source: np.array = None\n",
    "    ):\n",
    "        if idxh_source is not None: self.idxh_source = idxh_source\n",
    "        else:\n",
    "            if self.settings.param_shuffle or init:\n",
    "                self.idxh_source = self.idxh_source_base[   np.sort(np.random.choice(len(self.idxh_source_base),\n",
    "                                                            self.h_source, replace = False))]\n",
    "                \n",
    "    # Target Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def target_param_shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxh_target: np.array = None\n",
    "    ):\n",
    "        if idxh_target is not None: self.idxh_target = idxh_target\n",
    "        else:\n",
    "            if self.settings.param_shuffle or init:\n",
    "                self.idxh_target = self.idxh_target_base[   np.sort(np.random.choice(len(self.idxh_target_base),\n",
    "                                                            self.h_target, replace = False))]\n",
    "                \n",
    "    # Target Voxel Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def voxel_shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxv_target: np.array = None\n",
    "    ):  \n",
    "        if idxv_target is not None: self.idxv_target = idxv_target\n",
    "        else:\n",
    "            if self.settings.voxel_shuffle or init:\n",
    "                self.idxv_target = self.idxv[   np.sort(np.random.choice(len(self.idxv),\n",
    "                                                self.v_target, replace = False))]\n",
    "    \n",
    "    # All Selected Voxel & Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxh_source: np.array = None,\n",
    "        idxh_target: np.array = None,\n",
    "        idxv_target: np.array = None\n",
    "    ):\n",
    "        self.source_param_shuffle(init, idxh_source)\n",
    "        self.target_param_shuffle(init, idxh_target)\n",
    "        self.voxel_shuffle(init, idxv_target)\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Random Target Parameter for Training & Test Sets Generation Functionality\n",
    "    def label_gen(self):\n",
    "\n",
    "        # Target & Test Label Index File Generation\n",
    "        idxh_train = np.delete(np.arange(self.params.shape[0]), self.idxh_train)\n",
    "        if self.settings.test_target_param != 0:\n",
    "            idxh_test = idxh_train[np.sort(np.random.choice(len(idxh_train),\n",
    "                                    self.settings.test_target_param, replace = False))]\n",
    "            idxh_train = np.delete(idxh_train, np.where(np.in1d(idxh_train, idxh_test)))\n",
    "            for i in range(self.settings.test_target_param): assert(idxh_test[i] not in idxh_train\n",
    "                ), f\"ERROR: Target Parameter #{i} for Training & Test Sets not mutually Exclusive\"\n",
    "            \n",
    "            # Target & Test Label Index File Saving\n",
    "            print(f\">     Saving File Target Parameters for Training ({len(idxh_train)}) & Test {len(idxh_test)} Set's\")\n",
    "            np.savetxt(Path(f\"{self.settings.datasave_folderpath}/Test Labels (V{self.settings.data_version}).txt\"), idxh_test)\n",
    "            np.savetxt(Path(f\"{self.settings.datasave_folderpath}/Target Labels (V{self.settings.data_version}).txt\"), idxh_train)\n",
    " \n",
    "    # Label Scaler Download & Reverse Transformation\n",
    "    def label_unscale(\n",
    "        self,\n",
    "        y: np.array or pd.DataFrame\n",
    "    ):\n",
    "\n",
    "        # Label Scaler Download & Reverse Usage\n",
    "        try: self.scaler\n",
    "        except AttributeError:\n",
    "            scaler = torch.load(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "        return scaler.inverse_transform(y.reshape(1, -1))\n",
    "\n",
    "    # Cartesian to Polar Coordinate Conversion Functionality\n",
    "    def cart2polar(self, y: np.array):\n",
    "\n",
    "        # Cartesian to Polar Coordinates Conversion\n",
    "        phi = np.arccos(y[:, 2]).astype(np.float32); theta = np.arctan2(y[:, 1], y[:, 0])\n",
    "        theta = np.where(theta < 0, 2 * np.pi - np.abs(theta), theta).astype(np.float32)\n",
    "        theta = np.expand_dims(theta, axis = 1); phi = np.expand_dims(phi, axis = 1)\n",
    "        return pd.DataFrame(data = np.concatenate((theta, phi), axis = 1),\n",
    "                            columns = ['Gradient theta', 'Gradient phi'])\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Patient Data Generation Functionality\n",
    "    def get_img(settings, num_patient: int):\n",
    "\n",
    "        # Patient Data Access\n",
    "        data = h5py.File(settings.data_filepath, 'r').get('data1')\n",
    "        idxv = pd.read_csv( settings.info_filepath,             # List of Index Values ...\n",
    "                            index_col = 0).to_numpy()           # ... pertaining to each Patient\n",
    "        idxv = idxv[np.isin(idxv[:, 1], num_patient), 0]        # Patient-Specific Index Values\n",
    "        X = torch.Tensor(data[idxv, :])\n",
    "\n",
    "        # Patient Mask Access\n",
    "        mask = MUDI_cVNP.get_mask(settings, num_patient = num_patient)\n",
    "        img = unmask(X.T, mask).get_fdata().T\n",
    "        return torch.Tensor(img)\n",
    "\n",
    "    # Patient Mask Retrieval Functionality\n",
    "    def get_mask(settings, num_patient: int):\n",
    "        mask_filepath = Path(f\"{settings.mask_folderpath}/p{num_patient}.nii\")\n",
    "        assert(mask_filepath.exists()), f\"ERROR: Patient {num_patient}'s Mask not Found!\"\n",
    "        #return torch.Tensor(np.array(load_img(mask_filepath).dataobj, dtype = np.float32))\n",
    "        return load_img(mask_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cVNP MUDI Dataset Initialization Class (Final)\n",
    "class MUDI_cVNP(Dataset):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,\n",
    "        subject: int or list,\n",
    "        mode: str = 'Target', random: bool = True,\n",
    "        source_param: int or float = 100,\n",
    "        target_param: int or float = 100,\n",
    "        target_voxel: int or float = 100,\n",
    "        param_loop: int or float = 100\n",
    "    ):\n",
    "        \n",
    "        # Parameter & Patient Index Value Access\n",
    "        super(MUDI_cVNP).__init__(); self.random = random\n",
    "        self.settings = settings; self.source_param = source_param\n",
    "        self.target_param = target_param; self.target_voxel = target_voxel\n",
    "        self.data = np.array(h5py.File(self.settings.data_filepath, 'r').get('data1')).T\n",
    "        self.params = pd.read_excel(self.settings.param_filepath)\n",
    "\n",
    "        # Vertical Splitting (Patient Selection)\n",
    "        self.idxv = pd.read_csv(self.settings.info_filepath,            # List of Index Values ...\n",
    "                                index_col = 0).to_numpy()               # ... pertaining to each Patient\n",
    "        self.idxv = self.idxv[np.isin(self.idxv[:, 1], subject), 0]     # Patient-Specific Index Values\n",
    "\n",
    "        # Horizontal Splitting (Parameter Selection)\n",
    "        idxh_source_filepath = Path(f\"{self.settings.datasave_folderpath}/Training Labels (V{self.settings.data_version}).txt\")\n",
    "        idxh_target_filepath = Path(f\"{self.settings.datasave_folderpath}/{mode} Labels (V{self.settings.data_version}).txt\")\n",
    "        self.idxh_source_base = np.sort(np.loadtxt(idxh_source_filepath)).astype(int)\n",
    "        if not idxh_target_filepath.exists(): self.label_gen()\n",
    "        self.idxh_target_base = np.sort(np.loadtxt(idxh_target_filepath)).astype(int)\n",
    "\n",
    "        # Vertical & Horizontal Sub-Sectioning & Shuffling\n",
    "        self.h_source = int((self.source_param * len(self.idxh_source_base)) / 100)\n",
    "        self.h_target = int((self.target_param * len(self.idxh_target_base)) / 100)\n",
    "        self.v_target = int((self.target_voxel * len(self.idxv)) / 100)\n",
    "        self.num_loop = int((param_loop * (self.h_source * self.h_target)) / 100); self.shuffle(init = True)\n",
    "        print(f\"     > Utilizing {self.h_source} \\ {len(self.idxh_source_base)} of the Training Parameters\")\n",
    "        print(f\"     > Utilizing {self.h_target} \\ {len(self.idxh_target_base)} of the Target Parameters\")\n",
    "        print(f\"     > Utilizing {self.v_target} \\ {len(self.idxv)} of the Training Voxels\")\n",
    "        print(f\"     > Looping through {self.num_loop} of the Possible {self.h_source * self.h_target} Source/Target Parameter Combos\")\n",
    "\n",
    "        # Parameter Selection & Value Normalization / Scaling\n",
    "        if self.settings.gradient_coord:\n",
    "            self.params = self.params.drop(columns = ['Gradient theta', 'Gradient phi'])\n",
    "        else: self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])\n",
    "        if self.settings.label_norm == 'auto':\n",
    "            print(f\"     > Automatic Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "            self.scaler = StandardScaler()\n",
    "            self.params = pd.DataFrame( self.scaler.fit_transform(self.params),\n",
    "                                        columns = self.params.columns)\n",
    "            scaler_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "            if not scaler_filepath.exists(): torch.save(self.scaler, scaler_filepath)\n",
    "        elif self.settings.label_norm == 'manual':\n",
    "            print(f\"     > Manual Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "            self.params[['Gradient theta', 'Gradient phi']] = self.cart2polar(self.params[['Gradient x', 'Gradient y', 'Gradient z']].values)\n",
    "            self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])\n",
    "            self.params['b Value'] = self.params['b Value'] / 10000\n",
    "            self.params['TI'] = self.params['TI'] / 10000\n",
    "            self.params['TE'] = (self.params['TE'] - 80) / 200\n",
    "        else: print(f\"     > No Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "        assert(self.params.shape[1] == self.settings.num_labels), \"ERROR: Labels wrongly Deleted!\"\n",
    "        self.params = self.params.values\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # DataLoader Length / No. Batches Computation Functionality\n",
    "    def __len__(self): return self.v_target * self.num_loop\n",
    "\n",
    "    # Single-Batch Generation Functionality\n",
    "    def __getitem__(self, idx) -> tuple[np.ndarray, np.float32]:\n",
    "\n",
    "        # Each Voxel Intensity Value 'X_train' will have its corresponding Training Parameter\n",
    "        # 'y_train' and be mapped to one of the 'num_param_to' the Target Parameter 'y_target'.\n",
    "        # This means that each voxel position will see all the 'num_param_from' Parameters in it\n",
    "        # be mapped to the 'num_param_to' Parameters in the Validation Set\n",
    "\n",
    "        # The order goes from a Minor to a Major Scale, meaning it will use all Voxels of the same Image\n",
    "        # cosecutively, and then select one Target Parameter to map to, and iterate through all Source\n",
    "        # Parameters, only changing the Target when these all these are exhausted\n",
    "\n",
    "        # No Sample Shuffling in the Validation Set allows the Reader to iterate over a set of Fixed\n",
    "        # Source / Target Parameter Combos, previously set, so as to allow the Visualization of Full\n",
    "        # 1-to-1 Transformations of Images, from the Source to the Target\n",
    "\n",
    "        # [Destination -> Origin -> Voxel] Batch Vertical/Patient & Horizontal/Parameter Indexing\n",
    "        idxv = idx % self.v_target                                      # Batch's Vertical Index for X_train\n",
    "        idxh_loop = (idx // self.v_target) % self.num_loop              # Batch's Horizontal Index for Loop Combo\n",
    "        if self.random:\n",
    "            idxh_source = random.randrange(self.h_source)               # Random Batch's Horizontal Index for y_train\n",
    "            idxh_target = random.randrange(self.h_target)               # Random Batch's Horizontal Index for y_target\n",
    "        else:\n",
    "            idxh_source = int(np.where(self.idxh_source == self.idxh_combo[idxh_loop][0])[0])   # Fixed Batch's Horizontal Index for y_train\n",
    "            idxh_target = int(np.where(self.idxh_target == self.idxh_combo[idxh_loop][1])[0])   # Fixed Batch's Horizontal Index for y_target\n",
    "\n",
    "        # Batch Data Generation\n",
    "        X_train = self.data[self.idxh_source[idxh_source], :][self.idxv_target[idxv]]       # [    1    ] Training Data\n",
    "        y_train = self.params[self.idxh_source[idxh_source]]                                # [num_labels] Training Parameters\n",
    "        y_target = self.params[self.idxh_target[idxh_target]]                               # [num_labels] Target Parameters\n",
    "        X_target = self.data[self.idxh_target[idxh_target], :][self.idxv_target[idxv]]      # [    1    ] GT Target Data\n",
    "\n",
    "        return {'X_train': np.array(X_train),\n",
    "                'X_target': np.array(X_target),\n",
    "                'idxv': self.idxv_target[idxv],\n",
    "                'idxh_loop': idxh_loop,\n",
    "                'y_train': y_train.astype(np.float32),\n",
    "                'param_source': self.idxh_source[idxh_source],\n",
    "                'idxh_source': idxh_source,\n",
    "                'y_target': y_target.astype(np.float32),\n",
    "                'param_target': self.idxh_target[idxh_target],\n",
    "                'idxh_target': idxh_target}\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Source Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def source_param_shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxh_source: np.array = None\n",
    "    ):\n",
    "        if idxh_source is not None: self.idxh_source = idxh_source\n",
    "        else:\n",
    "            if self.settings.param_shuffle or init:\n",
    "                self.idxh_source = self.idxh_source_base[   np.sort(np.random.choice(len(self.idxh_source_base),\n",
    "                                                            self.h_source, replace = False))]\n",
    "                \n",
    "    # Target Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def target_param_shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxh_target: np.array = None\n",
    "    ):\n",
    "        if idxh_target is not None: self.idxh_target = idxh_target\n",
    "        else:\n",
    "            if self.settings.param_shuffle or init:\n",
    "                self.idxh_target = self.idxh_target_base[   np.sort(np.random.choice(len(self.idxh_target_base),\n",
    "                                                            self.h_target, replace = False))]\n",
    "    \n",
    "    # Target Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def combo_shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxh_combo: np.array = None\n",
    "    ):\n",
    "        if idxh_combo is not None: self.idxh_combo = idxh_combo\n",
    "        else:\n",
    "            if self.settings.param_shuffle or init:\n",
    "                self.idxh_combo = []\n",
    "                for i in range(self.num_loop):\n",
    "                    self.idxh_combo.append(np.array([self.idxh_source[random.randrange(self.h_source)],\n",
    "                                                    self.idxh_target[random.randrange(self.h_target)]]))\n",
    "                \n",
    "    # Target Voxel Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def voxel_shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxv_target: np.array = None\n",
    "    ):  \n",
    "        if idxv_target is not None: self.idxv_target = idxv_target\n",
    "        else:\n",
    "            if self.settings.voxel_shuffle or init:\n",
    "                self.idxv_target = self.idxv[   np.sort(np.random.choice(len(self.idxv),\n",
    "                                                self.v_target, replace = False))]\n",
    "    \n",
    "    # All Selected Voxel & Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def shuffle(\n",
    "        self,\n",
    "        idxh_source: np.array = None,\n",
    "        idxh_target: np.array = None,\n",
    "        idxh_combo: np.array = None,\n",
    "        idxv_target: np.array = None,\n",
    "        init: bool = False\n",
    "    ):\n",
    "        self.source_param_shuffle(init, idxh_source)\n",
    "        self.target_param_shuffle(init, idxh_target)\n",
    "        self.combo_shuffle(init, idxh_combo)\n",
    "        self.voxel_shuffle(init, idxv_target)\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Random Target Parameter for Training & Test Sets Generation Functionality\n",
    "    def label_gen(self):\n",
    "\n",
    "        # Target & Test Label Index File Generation\n",
    "        idxh_train = np.delete(np.arange(self.params.shape[0]), self.idxh_train)\n",
    "        if self.settings.test_target_param != 0:\n",
    "            idxh_test = idxh_train[np.sort(np.random.choice(len(idxh_train),\n",
    "                                    self.settings.test_target_param, replace = False))]\n",
    "            idxh_train = np.delete(idxh_train, np.where(np.in1d(idxh_train, idxh_test)))\n",
    "            for i in range(self.settings.test_target_param): assert(idxh_test[i] not in idxh_train\n",
    "                ), f\"ERROR: Target Parameter #{i} for Training & Test Sets not mutually Exclusive\"\n",
    "            \n",
    "            # Target & Test Label Index File Saving\n",
    "            print(f\">     Saving File Target Parameters for Training ({len(idxh_train)}) & Test {len(idxh_test)} Set's\")\n",
    "            np.savetxt(Path(f\"{self.settings.datasave_folderpath}/Test Labels (V{self.settings.data_version}).txt\"), idxh_test)\n",
    "            np.savetxt(Path(f\"{self.settings.datasave_folderpath}/Target Labels (V{self.settings.data_version}).txt\"), idxh_train)\n",
    " \n",
    "    # Label Scaler Download & Reverse Transformation\n",
    "    def label_unscale(\n",
    "        self,\n",
    "        y: np.array or pd.DataFrame\n",
    "    ):\n",
    "\n",
    "        # Label Scaler Download & Reverse Usage\n",
    "        try: self.scaler\n",
    "        except AttributeError:\n",
    "            scaler = torch.load(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "        return scaler.inverse_transform(y.reshape(1, -1))\n",
    "\n",
    "    # Cartesian to Polar Coordinate Conversion Functionality\n",
    "    def cart2polar(self, y: np.array):\n",
    "\n",
    "        # Cartesian to Polar Coordinates Conversion\n",
    "        phi = np.arccos(y[:, 2]).astype(np.float32); theta = np.arctan2(y[:, 1], y[:, 0])\n",
    "        theta = np.where(theta < 0, 2 * np.pi - np.abs(theta), theta).astype(np.float32)\n",
    "        theta = np.expand_dims(theta, axis = 1); phi = np.expand_dims(phi, axis = 1)\n",
    "        return pd.DataFrame(data = np.concatenate((theta, phi), axis = 1),\n",
    "                            columns = ['Gradient theta', 'Gradient phi'])\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Patient Data Generation Functionality\n",
    "    def get_img(settings, num_patient: int):\n",
    "\n",
    "        # Patient Data Access\n",
    "        data = h5py.File(settings.data_filepath, 'r').get('data1')\n",
    "        idxv = pd.read_csv( settings.info_filepath,             # List of Index Values ...\n",
    "                            index_col = 0).to_numpy()           # ... pertaining to each Patient\n",
    "        idxv = idxv[np.isin(idxv[:, 1], num_patient), 0]        # Patient-Specific Index Values\n",
    "        X = torch.Tensor(data[idxv, :])\n",
    "\n",
    "        # Patient Mask Access\n",
    "        mask = MUDI_cVNP.get_mask(settings, num_patient = num_patient)\n",
    "        img = unmask(X.T, mask).get_fdata().T\n",
    "        return torch.Tensor(img)\n",
    "\n",
    "    # Patient Mask Retrieval Functionality\n",
    "    def get_mask(settings, num_patient: int):\n",
    "        mask_filepath = Path(f\"{settings.mask_folderpath}/p{num_patient}.nii\")\n",
    "        assert(mask_filepath.exists()), f\"ERROR: Patient {num_patient}'s Mask not Found!\"\n",
    "        #return torch.Tensor(np.array(load_img(mask_filepath).dataobj, dtype = np.float32))\n",
    "        return load_img(mask_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cVNP MUDI Dataset Initialization Class (Final)\n",
    "class MUDI_cVNP(Dataset):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,\n",
    "        subject: int or list,\n",
    "        mode: str = 'Target', random: bool = True,\n",
    "        source_param: int or float = 100,\n",
    "        target_param: int or float = 100,\n",
    "        target_voxel: int or float = 100,\n",
    "        param_loop: int or float = 100\n",
    "    ):\n",
    "        \n",
    "        # Parameter & Patient Index Value Access\n",
    "        super(MUDI_cVNP).__init__(); self.random = random\n",
    "        self.settings = settings; self.source_param = source_param\n",
    "        self.target_param = target_param; self.target_voxel = target_voxel\n",
    "        self.data = np.array(h5py.File(self.settings.data_filepath, 'r').get('data1')).T\n",
    "        self.params = pd.read_excel(self.settings.param_filepath)\n",
    "\n",
    "        # Vertical Splitting (Patient Selection)\n",
    "        self.idxv = pd.read_csv(self.settings.info_filepath,            # List of Index Values ...\n",
    "                                index_col = 0).to_numpy()               # ... pertaining to each Patient\n",
    "        self.idxv = self.idxv[np.isin(self.idxv[:, 1], subject), 0]     # Patient-Specific Index Values\n",
    "\n",
    "        # Horizontal Splitting (Parameter Selection)\n",
    "        idxh_source_filepath = Path(f\"{self.settings.datasave_folderpath}/Training Labels (V{self.settings.data_version}).txt\")\n",
    "        idxh_target_filepath = Path(f\"{self.settings.datasave_folderpath}/{mode} Labels (V{self.settings.data_version}).txt\")\n",
    "        self.idxh_source_base = np.sort(np.loadtxt(idxh_source_filepath)).astype(int)\n",
    "        if not idxh_target_filepath.exists(): self.label_gen()\n",
    "        self.idxh_target_base = np.sort(np.loadtxt(idxh_target_filepath)).astype(int)\n",
    "\n",
    "        # Vertical & Horizontal Sub-Sectioning & Shuffling\n",
    "        self.h_source = int((self.source_param * len(self.idxh_source_base)) / 100)\n",
    "        self.h_target = int((self.target_param * len(self.idxh_target_base)) / 100)\n",
    "        self.v_target = int((self.target_voxel * len(self.idxv)) / 100)\n",
    "        self.num_loop = int((param_loop * (self.h_source * self.h_target)) / 100); self.shuffle(init = True)\n",
    "        print(f\"     > Utilizing {self.h_source} \\ {len(self.idxh_source_base)} of the Training Parameters\")\n",
    "        print(f\"     > Utilizing {self.h_target} \\ {len(self.idxh_target_base)} of the Target Parameters\")\n",
    "        print(f\"     > Utilizing {self.v_target} \\ {len(self.idxv)} of the Training Voxels\")\n",
    "        print(f\"     > Looping through {self.num_loop} of the Possible {self.h_source * self.h_target} Source/Target Parameter Combos\")\n",
    "\n",
    "        # Parameter Selection & Value Normalization / Scaling\n",
    "        if self.settings.gradient_coord:\n",
    "            self.params = self.params.drop(columns = ['Gradient theta', 'Gradient phi'])\n",
    "        else: self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])\n",
    "        if self.settings.label_norm == 'auto':\n",
    "            print(f\"     > Automatic Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "            self.scaler = StandardScaler()\n",
    "            self.params = pd.DataFrame( self.scaler.fit_transform(self.params),\n",
    "                                        columns = self.params.columns)\n",
    "            scaler_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "            if not scaler_filepath.exists(): torch.save(self.scaler, scaler_filepath)\n",
    "        elif self.settings.label_norm == 'manual':\n",
    "            print(f\"     > Manual Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "            self.params[['Gradient theta', 'Gradient phi']] = self.cart2polar(self.params[['Gradient x', 'Gradient y', 'Gradient z']].values)\n",
    "            self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])\n",
    "            self.params['b Value'] = self.params['b Value'] / 10000\n",
    "            self.params['TI'] = self.params['TI'] / 10000\n",
    "            self.params['TE'] = (self.params['TE'] - 80) / 200\n",
    "        else: print(f\"     > No Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "        assert(self.params.shape[1] == self.settings.num_labels), \"ERROR: Labels wrongly Deleted!\"\n",
    "        self.params = self.params.values\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # DataLoader Length / No. Batches Computation Functionality\n",
    "    def __len__(self): return self.v_target * self.num_loop\n",
    "\n",
    "    # Single-Batch Generation Functionality\n",
    "    def __getitem__(self, idx) -> tuple[np.ndarray, np.float32]:\n",
    "\n",
    "        # Each Voxel Intensity Value 'X_train' will have its corresponding Training Parameter\n",
    "        # 'y_train' and be mapped to one of the 'num_param_to' the Target Parameter 'y_target'.\n",
    "        # This means that each voxel position will see all the 'num_param_from' Parameters in it\n",
    "        # be mapped to the 'num_param_to' Parameters in the Validation Set\n",
    "\n",
    "        # The order goes from a Minor to a Major Scale, meaning it will use all Voxels of the same Image\n",
    "        # cosecutively, and then select one Target Parameter to map to, and iterate through all Source\n",
    "        # Parameters, only changing the Target when these all these are exhausted\n",
    "\n",
    "        # No Sample Shuffling in the Validation Set allows the Reader to iterate over a set of Fixed\n",
    "        # Source / Target Parameter Combos, previously set, so as to allow the Visualization of Full\n",
    "        # 1-to-1 Transformations of Images, from the Source to the Target\n",
    "\n",
    "        # [Destination -> Origin -> Voxel] Batch Vertical/Patient & Horizontal/Parameter Indexing\n",
    "        idxv = idx % self.v_target                                      # Batch's Vertical Index for X_train\n",
    "        idxh_loop = (idx // self.v_target) % self.num_loop              # Batch's Horizontal Index for Loop Combo\n",
    "        if self.random:\n",
    "            idxh_source = random.randrange(self.h_source)               # Random Batch's Horizontal Index for y_train\n",
    "            idxh_target = random.randrange(self.h_target)               # Random Batch's Horizontal Index for y_target\n",
    "            while(idxh_source == idxh_target): idxh_target = random.randrange(self.h_target)\n",
    "        else:\n",
    "            idxh_source = int(np.where(self.idxh_source == self.idxh_combo[idxh_loop][0])[0])   # Fixed Batch's Horizontal Index for y_train\n",
    "            idxh_target = int(np.where(self.idxh_target == self.idxh_combo[idxh_loop][1])[0])   # Fixed Batch's Horizontal Index for y_target\n",
    "        if self.num_loop == self.h_source * self.h_target:\n",
    "            idxh_source = (idx // self.v_target) % self.h_source        # Batch's Horizontal Index for y_train\n",
    "            idxh_target = idx // (self.v_target * self.h_source)        # Batch's Horizontal Index for y_target\n",
    "\n",
    "        # Batch Data Generation\n",
    "        X_train = self.data[self.idxh_source[idxh_source], :][self.idxv_target[idxv]]       # [    1    ] Training Data\n",
    "        y_train = self.params[self.idxh_source[idxh_source]]                                # [num_labels] Training Parameters\n",
    "        y_target = self.params[self.idxh_target[idxh_target]]                               # [num_labels] Target Parameters\n",
    "        X_target = self.data[self.idxh_target[idxh_target], :][self.idxv_target[idxv]]      # [    1    ] GT Target Data\n",
    "\n",
    "        return {'X_train': np.array(X_train),\n",
    "                'X_target': np.array(X_target),\n",
    "                'idxv': self.idxv_target[idxv],\n",
    "                'idxh_loop': idxh_loop,\n",
    "                'y_train': y_train.astype(np.float32),\n",
    "                'param_source': self.idxh_source[idxh_source],\n",
    "                'idxh_source': idxh_source,\n",
    "                'y_target': y_target.astype(np.float32),\n",
    "                'param_target': self.idxh_target[idxh_target],\n",
    "                'idxh_target': idxh_target}\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Source Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def source_param_shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxh_source: np.array = None\n",
    "    ):\n",
    "        if idxh_source is not None: self.idxh_source = idxh_source\n",
    "        else:\n",
    "            if self.settings.param_shuffle or init:\n",
    "                self.idxh_source = self.idxh_source_base[   np.sort(np.random.choice(len(self.idxh_source_base),\n",
    "                                                            self.h_source, replace = False))]\n",
    "                \n",
    "    # Target Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def target_param_shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxh_target: np.array = None\n",
    "    ):\n",
    "        if idxh_target is not None: self.idxh_target = idxh_target\n",
    "        else:\n",
    "            if self.settings.param_shuffle or init:\n",
    "                self.idxh_target = self.idxh_target_base[   np.sort(np.random.choice(len(self.idxh_target_base),\n",
    "                                                            self.h_target, replace = False))]\n",
    "    \n",
    "    # Target Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def combo_shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxh_combo: np.array = None\n",
    "    ):\n",
    "        if idxh_combo is not None: self.idxh_combo = idxh_combo\n",
    "        else:\n",
    "            if self.settings.param_shuffle or init:\n",
    "                self.idxh_combo = []\n",
    "                for i in range(self.num_loop):\n",
    "                    self.idxh_combo.append(np.array([self.idxh_source[random.randrange(self.h_source)],\n",
    "                                                    self.idxh_target[random.randrange(self.h_target)]]))\n",
    "                \n",
    "    # Target Voxel Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def voxel_shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxv_target: np.array = None\n",
    "    ):  \n",
    "        if idxv_target is not None: self.idxv_target = idxv_target\n",
    "        else:\n",
    "            if self.settings.voxel_shuffle or init:\n",
    "                self.idxv_target = self.idxv[   np.sort(np.random.choice(len(self.idxv),\n",
    "                                                self.v_target, replace = False))]\n",
    "    \n",
    "    # All Selected Voxel & Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def shuffle(\n",
    "        self,\n",
    "        idxh_source: np.array = None,\n",
    "        idxh_target: np.array = None,\n",
    "        idxh_combo: np.array = None,\n",
    "        idxv_target: np.array = None,\n",
    "        init: bool = False\n",
    "    ):\n",
    "        self.source_param_shuffle(init, idxh_source)\n",
    "        self.target_param_shuffle(init, idxh_target)\n",
    "        self.combo_shuffle(init, idxh_combo)\n",
    "        self.voxel_shuffle(init, idxv_target)\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Random Target Parameter for Training & Test Sets Generation Functionality\n",
    "    def label_gen(self):\n",
    "\n",
    "        # Target & Test Label Index File Generation\n",
    "        idxh_train = np.delete(np.arange(self.params.shape[0]), self.idxh_train)\n",
    "        if self.settings.test_target_param != 0:\n",
    "            idxh_test = idxh_train[np.sort(np.random.choice(len(idxh_train),\n",
    "                                    self.settings.test_target_param, replace = False))]\n",
    "            idxh_train = np.delete(idxh_train, np.where(np.in1d(idxh_train, idxh_test)))\n",
    "            for i in range(self.settings.test_target_param): assert(idxh_test[i] not in idxh_train\n",
    "                ), f\"ERROR: Target Parameter #{i} for Training & Test Sets not mutually Exclusive\"\n",
    "            \n",
    "            # Target & Test Label Index File Saving\n",
    "            print(f\">     Saving File Target Parameters for Training ({len(idxh_train)}) & Test {len(idxh_test)} Set's\")\n",
    "            np.savetxt(Path(f\"{self.settings.datasave_folderpath}/Test Labels (V{self.settings.data_version}).txt\"), idxh_test)\n",
    "            np.savetxt(Path(f\"{self.settings.datasave_folderpath}/Target Labels (V{self.settings.data_version}).txt\"), idxh_train)\n",
    " \n",
    "    # Label Scaler Download & Reverse Transformation\n",
    "    def label_unscale(\n",
    "        self,\n",
    "        y: np.array or pd.DataFrame\n",
    "    ):\n",
    "\n",
    "        # Label Scaler Download & Reverse Usage\n",
    "        try: self.scaler\n",
    "        except AttributeError:\n",
    "            scaler = torch.load(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "        return scaler.inverse_transform(y.reshape(1, -1))\n",
    "\n",
    "    # Cartesian to Polar Coordinate Conversion Functionality\n",
    "    def cart2polar(self, y: np.array):\n",
    "\n",
    "        # Cartesian to Polar Coordinates Conversion\n",
    "        phi = np.arccos(y[:, 2]).astype(np.float32); theta = np.arctan2(y[:, 1], y[:, 0])\n",
    "        theta = np.where(theta < 0, 2 * np.pi - np.abs(theta), theta).astype(np.float32)\n",
    "        theta = np.expand_dims(theta, axis = 1); phi = np.expand_dims(phi, axis = 1)\n",
    "        return pd.DataFrame(data = np.concatenate((theta, phi), axis = 1),\n",
    "                            columns = ['Gradient theta', 'Gradient phi'])\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Patient Data Generation Functionality\n",
    "    def get_img(settings, num_patient: int):\n",
    "\n",
    "        # Patient Data Access\n",
    "        data = h5py.File(settings.data_filepath, 'r').get('data1')\n",
    "        idxv = pd.read_csv( settings.info_filepath,             # List of Index Values ...\n",
    "                            index_col = 0).to_numpy()           # ... pertaining to each Patient\n",
    "        idxv = idxv[np.isin(idxv[:, 1], num_patient), 0]        # Patient-Specific Index Values\n",
    "        X = torch.Tensor(data[idxv, :])\n",
    "\n",
    "        # Patient Mask Access\n",
    "        mask = MUDI_cVNP.get_mask(settings, num_patient = num_patient)\n",
    "        img = unmask(X.T, mask).get_fdata().T\n",
    "        return torch.Tensor(img)\n",
    "\n",
    "    # Patient Mask Retrieval Functionality\n",
    "    def get_mask(settings, num_patient: int):\n",
    "        mask_filepath = Path(f\"{settings.mask_folderpath}/p{num_patient}.nii\")\n",
    "        assert(mask_filepath.exists()), f\"ERROR: Patient {num_patient}'s Mask not Found!\"\n",
    "        #return torch.Tensor(np.array(load_img(mask_filepath).dataobj, dtype = np.float32))\n",
    "        return load_img(mask_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     > Utilizing 1344 \\ 1344 of the Training Parameters\n",
      "     > Utilizing 1244 \\ 1344 of the Target Parameters\n",
      "     > Utilizing 32490 \\ 108300 of the Training Voxels\n",
      "     > Looping through 83596 of the Possible 1671936 Source/Target Parameter Combos\n",
      "     > Manual Normalization of all 5 Parameter Values\n",
      "1299\n",
      "830\n",
      "291\n",
      "1\n",
      "2\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# DataLoader Testing\\ntrain_iter = iter(trainloader)\\nfor i in range(2):#len(trainloader)):\\n    batch = next(train_iter)\\n    #assert(np.all(np.round(np.array(batch[0][0, -5::]), 5) == np.round(trainset.params.iloc[trainset.idxh_to[i]].values, 5).astype('float32')))\\n    img_target = unmask(batch['X_target'].reshape((1, len(trainset.idxv_target))), mask).get_fdata().T\\n    img_source = unmask(batch['X_train'].reshape((1, len(trainset.idxv_target))), mask).get_fdata().T\\n    plt.subplot(2, 2, 1); plt.imshow(img_target[0, 25, :, :], cmap = plt.cm.binary)\\n    plt.subplot(2, 2, 2); plt.imshow(img[trainset.idxh_target[i], 25, :, :], cmap = plt.cm.binary)\\n    plt.subplot(2, 2, 3); plt.imshow(img_source[0, 25, :, :], cmap = plt.cm.binary)\\n    plt.subplot(2, 2, 4); plt.imshow(img[trainset.idxh_source[i], 25, :, :], cmap = plt.cm.binary)\\n    plt.grid(False); plt.show(); time.sleep(5)\\n\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset DataLoader Creation\n",
    "trainset = MUDI_cVNP(       settings, subject = [11], random = True,\n",
    "                            source_param = settings.train_source_param,\n",
    "                            target_param = 92.56, #settings.train_target_param,\n",
    "                            target_voxel = settings.train_target_voxel,\n",
    "                            param_loop = settings.train_param_loop)\n",
    "                            #sample_size = settings.sample_size)\n",
    "trainloader = DataLoader(   dataset = trainset,\n",
    "                            shuffle = settings.val_sample_shuffle,\n",
    "                            num_workers = 0,#settings.num_workers,\n",
    "                            batch_size = 500000,#settings.batch_size,#len(trainset.idxv_target),\n",
    "                            pin_memory = False)\n",
    "#mask = MUDI_fcglVNN.get_mask(settings, num_patient = 11)\n",
    "#img = MUDI_fcglVNN.get_img(settings, num_patient = 11)\n",
    "\n",
    "i = 64980\n",
    "print(trainset.__getitem__(i)['idxh_source'])\n",
    "print(trainset.__getitem__(i)['param_source'])\n",
    "print(trainset.__getitem__(i)['idxh_target'])\n",
    "print(trainset.__getitem__(i)['param_target'])\n",
    "print(trainset.__getitem__(i)['idxv'])\n",
    "print(trainset.__getitem__(i)['idxh_loop'])\n",
    "\n",
    "\"\"\"\n",
    "# DataLoader Testing\n",
    "train_iter = iter(trainloader)\n",
    "for i in range(2):#len(trainloader)):\n",
    "    batch = next(train_iter)\n",
    "    #assert(np.all(np.round(np.array(batch[0][0, -5::]), 5) == np.round(trainset.params.iloc[trainset.idxh_to[i]].values, 5).astype('float32')))\n",
    "    img_target = unmask(batch['X_target'].reshape((1, len(trainset.idxv_target))), mask).get_fdata().T\n",
    "    img_source = unmask(batch['X_train'].reshape((1, len(trainset.idxv_target))), mask).get_fdata().T\n",
    "    plt.subplot(2, 2, 1); plt.imshow(img_target[0, 25, :, :], cmap = plt.cm.binary)\n",
    "    plt.subplot(2, 2, 2); plt.imshow(img[trainset.idxh_target[i], 25, :, :], cmap = plt.cm.binary)\n",
    "    plt.subplot(2, 2, 3); plt.imshow(img_source[0, 25, :, :], cmap = plt.cm.binary)\n",
    "    plt.subplot(2, 2, 4); plt.imshow(img[trainset.idxh_source[i], 25, :, :], cmap = plt.cm.binary)\n",
    "    plt.grid(False); plt.show(); time.sleep(5)\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Model* **Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed Conditional Generative Linear Voxel Net Model Class\n",
    "class cVNP(nn.Module):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser\n",
    "    ):\n",
    "        \n",
    "        # Class Variable Logging\n",
    "        super().__init__(); self.settings = settings\n",
    "        self.encoder = []; self.decoder = []; self.arch = []\n",
    "        self.arch.insert(0, 1 + self.settings.num_labels)\n",
    "\n",
    "        # Encoder Architecture Definition\n",
    "        for i in range(self.settings.num_hidden):\n",
    "            self.arch.insert(i + 1, int(self.settings.var_hidden /\\\n",
    "                            (2 ** (self.settings.num_hidden - i - 1))))\n",
    "            self.encoder.append(nn.Sequential(\n",
    "                            nn.Linear(      in_features = self.arch[i],\n",
    "                                            out_features = self.arch[i + 1]),\n",
    "                            nn.BatchNorm1d( num_features = self.arch[i + 1]),\n",
    "                            nn.ReLU()))\n",
    "        self.encoder = nn.Sequential(*self.encoder)\n",
    "        \n",
    "        # --------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # Decoder Architecture Definition\n",
    "        self.arch.insert(len(self.arch), self.settings.var_hidden + self.settings.num_labels)\n",
    "        for i in range(self.settings.num_hidden):\n",
    "            i += self.settings.num_hidden + 1\n",
    "            self.arch.insert(i + 1, int(self.settings.var_hidden /\\\n",
    "                            (2 ** (i - self.settings.num_hidden - 1))))\n",
    "            self.decoder.append(nn.Sequential(\n",
    "                            nn.Linear(      in_features = self.arch[i],\n",
    "                                            out_features = self.arch[i + 1]),\n",
    "                            nn.BatchNorm1d( num_features = self.arch[i + 1]),\n",
    "                            nn.ReLU()))\n",
    "        self.decoder.append(nn.Linear(  in_features = self.arch[-1],\n",
    "                                        out_features = 1))\n",
    "        self.decoder = nn.Sequential(*self.decoder)            \n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Neural Network Application Function\n",
    "    def forward(\n",
    "        self,\n",
    "        X_train: np.ndarray or torch.Tensor,\n",
    "        y_train: np.ndarray or torch.Tensor,\n",
    "        y_target: np.ndarray or torch.Tensor\n",
    "    ):  \n",
    "        \n",
    "        # Batch Data Handling\n",
    "        #X_train = X_train.reshape(X_train.shape[0], 1).to(torch.float32)\n",
    "        #y_train = y_train.to(torch.float32)\n",
    "        #y_target = y_target.to(torch.float32)\n",
    "\n",
    "        # Model Network Application\n",
    "        X_train = X_train.reshape(X_train.shape[0], 1)\n",
    "        z = self.encoder(torch.cat((X_train, y_train), dim = 1))    # Encoder Feedthrough\n",
    "        #z = z.repeat(y_target.shape[0], 1)                         # Aggregation\n",
    "        return self.decoder(torch.cat((z, y_target), dim = 1))      # Decoder Feedthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed Conditional Generative Linear Voxel Net Model Class\n",
    "class cVNP(nn.Module):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser\n",
    "    ):\n",
    "        \n",
    "        # Class Variable Logging\n",
    "        super().__init__(); self.settings = settings; self.net = []\n",
    "        self.net.append(nn.Sequential(\n",
    "                            nn.Linear(      in_features = 1 + (2 * self.settings.num_labels),\n",
    "                                            out_features = 8),\n",
    "                            nn.BatchNorm1d( num_features = 8),\n",
    "                            nn.ReLU()))\n",
    "        self.net.append(    nn.Linear(  in_features = 8,\n",
    "                                        out_features = 1))\n",
    "        self.net = nn.Sequential(*self.net)\n",
    "     \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Neural Network Application Function\n",
    "    def forward(\n",
    "        self,\n",
    "        X_train: np.ndarray or torch.Tensor,\n",
    "        y_train: np.ndarray or torch.Tensor,\n",
    "        y_target: np.ndarray or torch.Tensor\n",
    "    ):  \n",
    "        \n",
    "        # Model Network Application\n",
    "        X_train = X_train.reshape(X_train.shape[0], 1)\n",
    "        return self.net(torch.cat((X_train, y_train, y_target), dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cVNP(\n",
      "  (encoder): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=6, out_features=32, bias=True)\n",
      "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=69, out_features=64, bias=True)\n",
      "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=32, bias=True)\n",
      "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'MUDI_cVNP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pfernan2\\Desktop\\dMRI-Studio\\Experiments\\Autoencoders\\Autoencoders.ipynb Cell 116\u001b[0m in \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Y200sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(model)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Y200sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Dataset DataLoader Creation\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Y200sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m trainset \u001b[39m=\u001b[39m MUDI_cVNP(       settings, subject \u001b[39m=\u001b[39m [\u001b[39m11\u001b[39m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Y200sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                             source_param \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtrain_source_param,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Y200sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                             target_param \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtrain_target_param,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Y200sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                             target_voxel \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtrain_target_voxel)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Y200sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m trainloader \u001b[39m=\u001b[39m DataLoader(   dataset \u001b[39m=\u001b[39m trainset,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Y200sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                             shuffle \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\u001b[39m#settings.val_sample_shuffle,\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Y200sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                             num_workers \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\u001b[39m#settings.num_workers,\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Y200sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m                             batch_size \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m,\u001b[39m#len(trainset.idxv_target)#settings.batch_size,\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Y200sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m                             pin_memory \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Y200sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Model Usage Example\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Y200sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m#X_train = tf.random.uniform([10, 1])\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Y200sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m#y_train = tf.random.uniform([10, 5])\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Y200sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m#y_target = tf.random.uniform([10, 5])\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MUDI_cVNP' is not defined"
     ]
    }
   ],
   "source": [
    "# Model Initialization Example\n",
    "model = cVNP(settings)\n",
    "print(model)\n",
    "\n",
    "# Dataset DataLoader Creation\n",
    "trainset = MUDI_cVNP(       settings, subject = [11],\n",
    "                            source_param = settings.train_source_param,\n",
    "                            target_param = settings.train_target_param,\n",
    "                            target_voxel = settings.train_target_voxel)\n",
    "trainloader = DataLoader(   dataset = trainset,\n",
    "                            shuffle = False,#settings.val_sample_shuffle,\n",
    "                            num_workers = 0,#settings.num_workers,\n",
    "                            batch_size = 10,#len(trainset.idxv_target)#settings.batch_size,\n",
    "                            pin_memory = False)\n",
    "\n",
    "# Model Usage Example\n",
    "#X_train = tf.random.uniform([10, 1])\n",
    "#y_train = tf.random.uniform([10, 5])\n",
    "#y_target = tf.random.uniform([10, 5])\n",
    "batch = next(iter(trainloader))\n",
    "X_target = model(batch['X_train'], batch['y_train'], batch['y_target'])\n",
    "print(X_target.shape)\n",
    "#print(model(trainset.__getitem__(0)[0]).shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training** *Script*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result Plotting Functionality (V0)\n",
    "def plot_results(\n",
    "    logger: TensorBoardLogger, loss_: str,\n",
    "    best_loss: torch.Tensor or np.float,\n",
    "    worst_loss: torch.Tensor or np.float,\n",
    "    best_source_idx: int, best_target_idx: int,\n",
    "    worst_source_idx: int, worst_target_idx: int,\n",
    "    img_best_gt, img_best_fake, img_worst_gt, img_worst_fake,\n",
    "    patient_id: int = 14, sel_slice: int = 25, epoch = 0\n",
    "):\n",
    "\n",
    "    # Set Example Reconstruction Results Image Plotting\n",
    "    plot = plt.figure(figsize = (20, 22))\n",
    "    plt.xticks([]); plt.yticks([]); plt.grid(False); plt.tight_layout()\n",
    "    plt.suptitle(f'Validation Patient {patient_id} | Parameter Results | {loss_} Loss')\n",
    "    if type(best_loss) == torch.Tensor: best_loss = best_loss.item(); worst_loss= worst_loss.item()\n",
    "\n",
    "    # Set Example Original & Best Loss Reconstructed Image Subplots\n",
    "    plt.subplot(2, 2, 1, title = f'Best {loss_} | Original | Parameter #{best_source_idx} -> {best_target_idx}')\n",
    "    plt.imshow(img_best_gt[0, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "    plt.subplot(2, 2, 2, title = f'Best {loss_} | Fake | {loss_}: {np.round(best_loss, 5)}')\n",
    "    plt.imshow(img_best_fake[0, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "    \n",
    "    # Set Example Original & Worst Loss Reconstructed Image Subplots\n",
    "    plt.subplot(2, 2, 3, title = f'Worst {loss_} | Original | Parameter #{worst_source_idx} -> {worst_target_idx}')\n",
    "    plt.imshow(img_worst_gt[0, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "    plt.subplot(2, 2, 4, title = f'Worst {loss_} | Fake | {loss_}: {np.round(worst_loss, 5)}')\n",
    "    plt.imshow(img_worst_fake[0, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "\n",
    "    # Tensorboard Reconstruction Callback\n",
    "    logger.experiment.add_figure(f\"{loss_} Results\", plot, epoch)\n",
    "    logger.experiment.add_scalar(f\"Best {loss_}\", best_loss, epoch)\n",
    "    logger.experiment.add_scalar(f\"Worst {loss_}\", worst_loss, epoch)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fcglVNN Model Training Script (V0)\n",
    "def cVNP_train(\n",
    "    settings,\n",
    "):\n",
    "\n",
    "    # Seed Random State for Reproducibility\n",
    "    torch.manual_seed(settings.seed)\n",
    "    np.random.seed(settings.seed)\n",
    "    random.seed(settings.seed)\n",
    "\n",
    "    # Experiment Logs Directories Initialization\n",
    "    checkpoint_folderpath = os.path.join(f'{settings.modelsave_folderpath}/V{settings.model_version}', 'logs')\n",
    "    train_logger = TensorBoardLogger(checkpoint_folderpath, 'train')\n",
    "    val_logger = TensorBoardLogger(checkpoint_folderpath, 'validation')\n",
    "\n",
    "    # Training & Validation DataLoaders Initialization\n",
    "    train_set = []; val_set = []; viz_logger = []\n",
    "    train_loader = []; val_loader = []; save_epoch = -1\n",
    "    for p, patient_id in enumerate(settings.patient_list):\n",
    "\n",
    "        # Patient Set & DataLoader Initialization\n",
    "        if patient_id in settings.train_patient_list:\n",
    "            print(f\"Patient #{patient_id} | Training Set:\")\n",
    "            train_set.append(   MUDI_cVNP(      settings, subject = [patient_id],\n",
    "                                                source_param = settings.train_source_param,\n",
    "                                                target_param = settings.train_target_param,\n",
    "                                                target_voxel = settings.train_target_voxel))\n",
    "            train_loader.append(DataLoader(     dataset = train_set[-1], pin_memory = True,\n",
    "                                                shuffle = settings.train_sample_shuffle,\n",
    "                                                num_workers = 0,#settings.num_workers,\n",
    "                                                batch_size = settings.batch_size))\n",
    "           \n",
    "        elif patient_id in settings.val_patient_list:\n",
    "            print(f\"Patient #{patient_id} | Validation Set:\")\n",
    "            val_set.append(     MUDI_cVNP(      settings, subject = [patient_id],\n",
    "                                                source_param = settings.val_source_param,\n",
    "                                                target_param = settings.val_target_param,\n",
    "                                                target_voxel = settings.val_target_voxel))\n",
    "            val_loader.append(  DataLoader(     dataset = val_set[-1], pin_memory = True,\n",
    "                                                shuffle = settings.val_sample_shuffle,\n",
    "                                                num_workers = 0,#settings.num_workers,\n",
    "                                                batch_size = len(val_set[-1].idxv_target)))\n",
    "            viz_logger.append(  TensorBoardLogger(checkpoint_folderpath, f'validation/p{patient_id}'))\n",
    "        else: print(f\"Patient #{patient_id} | Test Set:     > Not Included\")\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Model & Optimizer Setup\n",
    "    print(f\"Running\\n     > Training cVNP Model with {torch.cuda.device_count()} GPUs!\")\n",
    "    model = nn.DataParallel(cVNP(settings), device_ids = settings.device_ids).to(settings.device)\n",
    "    optimizer = torch.optim.AdamW(  model.parameters(), lr = settings.base_lr,\n",
    "                                    weight_decay = settings.weight_decay)\n",
    "\n",
    "    # Model Checkpoint Loading\n",
    "    model_filepath = Path(f\"{settings.modelsave_folderpath}/V{settings.model_version}/Best cVNP.pt\")\n",
    "    if model_filepath.exists():\n",
    "        checkpoint = torch.load(model_filepath, map_location = settings.device)\n",
    "        model.load_state_dict(checkpoint['Model']); optimizer.load_state_dict(checkpoint['Optimizer'])\n",
    "        save_epoch = checkpoint['Current Epoch']; torch.set_rng_state(checkpoint['RNG State'])\n",
    "        print(f\"     > Loading cVNP Model for {settings.model_version}: {save_epoch} Past Epochs\")\n",
    "        del checkpoint\n",
    "\n",
    "    # Criterion & Early Stopping Setup\n",
    "    mse_criterion = nn.MSELoss(reduction = 'mean')\n",
    "    earlyStopping = EarlyStopping(settings)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Epoch Iteration Loop\n",
    "    train_iter = 0; val_iter = 0\n",
    "    for epoch in range(save_epoch + 1, settings.num_epochs):\n",
    "\n",
    "        # Training Patient Loop\n",
    "        train_mse_loss = []; print(f\"Training Epoch #{epoch}:\")\n",
    "        for p, patient_id in enumerate(settings.train_patient_list):\n",
    "\n",
    "            # Training Iteration Loop\n",
    "            mask = MUDI_cVNP.get_mask(settings, num_patient = patient_id)\n",
    "            train_bar = tqdm(   enumerate(train_loader[p]), total = len(train_loader[p]),\n",
    "                desc = f'Epoch #{epoch} | Training Patient {patient_id}', unit = 'Batches')\n",
    "            for batch_idx, batch in train_bar:\n",
    "\n",
    "                # Forward Propagation\n",
    "                model.train(); model.zero_grad(); optimizer.zero_grad()\n",
    "                X_fake = model( batch['X_train'].to(settings.device),\n",
    "                                batch['y_train'].to(settings.device),\n",
    "                                batch['y_target'].to(settings.device))\n",
    "                X_fake = torch.squeeze(X_fake, dim = 1)\n",
    "                gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "                # Backward Propagation\n",
    "                mse_loss = mse_criterion(X_fake, batch['X_target'].to(settings.device))\n",
    "                mse_loss.backward(); optimizer.step(); del batch, X_fake\n",
    "                train_logger.experiment.add_scalar(\"MSE Loss\", mse_loss.item(), train_iter)\n",
    "                train_mse_loss.append(mse_loss.item()); train_iter += 1\n",
    "\n",
    "            # Inter-Patient Reconstruction Parameter Sharing Functionality\n",
    "            if settings.interpatient_sharing:\n",
    "                if p == 0:\n",
    "                    train_set[p].shuffle()\n",
    "                    idxh_target_train = train_set[p].idxh_target\n",
    "                    idxh_source_train = train_set[p].idxh_source\n",
    "                else:\n",
    "                    train_set[p].shuffle(   idxh_target = idxh_target_train,\n",
    "                                            idxh_source= idxh_source_train)\n",
    "                    assert(np.all(  train_set[p].idxh_source == train_set[0].idxh_source)\n",
    "                                    ), f\"     > ERROR: Parameter Sharing incorrectly setup!\"\n",
    "                    assert(np.all(  train_set[p].idxh_target == train_set[0].idxh_target)\n",
    "                                    ), f\"     > ERROR: Parameter Sharing incorrectly setup!\"\n",
    "            else: train_set[p].shuffle()\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Validation Set Reconstruction Loss Checkpoints\n",
    "        best_mse = 1000; worst_mse = 0\n",
    "        best_ssim = 0; worst_ssim = 1000\n",
    "\n",
    "        # Validation Patient Loop\n",
    "        with torch.no_grad():\n",
    "            model.eval(); val_ssim_loss = []; val_mse_loss = []\n",
    "            for p, patient_id in enumerate(settings.val_patient_list):\n",
    "            \n",
    "                # Training Iteration Loop\n",
    "                mask = MUDI_cVNP.get_mask(settings, num_patient = patient_id)\n",
    "                val_bar = tqdm(   enumerate(val_loader[p]), total = len(val_loader[p]),\n",
    "                    desc = f'Epoch #{epoch} | Validation Patient {patient_id}', unit = 'Batches')\n",
    "                for batch_idx, batch in val_bar:\n",
    "            \n",
    "                    # Batch Handling\n",
    "                    idxh_source = batch['param_source'][0]\n",
    "                    idxh_target = batch['param_target'][0]\n",
    "                    img_gt = torch.Tensor(unmask(batch['X_target'].reshape((1,\n",
    "                                len(batch['X_target']))), mask).get_fdata().T)\n",
    "\n",
    "                    # Forward Propagation\n",
    "                    X_fake = model( batch['X_train'].to(settings.device),\n",
    "                                    batch['y_train'].to(settings.device),\n",
    "                                    batch['y_target'].to(settings.device))\n",
    "                    X_fake = torch.squeeze(X_fake, dim = 1)\n",
    "                    img_fake = torch.Tensor(unmask(X_fake.detach().cpu().reshape((1,\n",
    "                                    len(batch['X_target']))), mask).get_fdata().T)\n",
    "                    gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "                    # Loss Computation\n",
    "                    mse_loss = mse_criterion(X_fake, batch['X_target'].to(settings.device)).detach().cpu().numpy()\n",
    "                    ssim_loss, ssim_img = ssim( img_gt[0].cpu().numpy().astype(np.float32), \n",
    "                                                img_fake[0].cpu().numpy().astype(np.float32), full = True,\n",
    "                                        data_range = (torch.max(img_gt) - torch.min(img_gt)).cpu().numpy())\n",
    "                    ssim_loss = np.mean(ssim_loss); del ssim_img, batch, X_fake\n",
    "\n",
    "                    # Loss Appending \n",
    "                    val_logger.experiment.add_scalar(\"MSE Loss\", mse_loss.item(), val_iter)\n",
    "                    val_logger.experiment.add_scalar(\"SSIM Index\", ssim_loss, val_iter)\n",
    "                    val_mse_loss.append(mse_loss.item()); val_ssim_loss.append(ssim_loss); val_iter += 1\n",
    "\n",
    "                    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "                    # MSE & SSIM Loss Assignation for Parameters\n",
    "                    if mse_loss < best_mse:\n",
    "                        best_mse = mse_loss\n",
    "                        best_mse_source_idx = idxh_source\n",
    "                        best_mse_target_idx = idxh_target\n",
    "                        img_fake_best_mse = img_fake.detach().cpu()\n",
    "                        img_gt_best_mse = img_gt.detach().cpu()\n",
    "                    if mse_loss > worst_mse:\n",
    "                        worst_mse = mse_loss\n",
    "                        worst_mse_source_idx = idxh_source\n",
    "                        worst_mse_target_idx = idxh_target\n",
    "                        img_fake_worst_mse = img_fake.detach().cpu()\n",
    "                        img_gt_worst_mse = img_gt.detach().cpu()\n",
    "                    if ssim_loss > best_ssim:\n",
    "                        best_ssim = ssim_loss\n",
    "                        best_ssim_source_idx = idxh_source\n",
    "                        best_ssim_target_idx = idxh_target\n",
    "                        img_fake_best_ssim = img_fake.detach().cpu()\n",
    "                        img_gt_best_ssim = img_gt.detach().cpu()\n",
    "                    if ssim_loss < worst_ssim:\n",
    "                        worst_ssim = ssim_loss\n",
    "                        worst_ssim_source_idx = idxh_source\n",
    "                        worst_ssim_target_idx = idxh_target\n",
    "                        img_fake_worst_ssim = img_fake.detach().cpu()\n",
    "                        img_gt_worst_ssim = img_gt.detach().cpu()\n",
    "                    gc.collect(); torch.cuda.empty_cache(); del img_gt, img_fake\n",
    "\n",
    "                # Inter-Patient Reconstruction Parameter Sharing Functionality\n",
    "                if settings.interpatient_sharing:\n",
    "                    if p == 0:\n",
    "                        val_set[p].shuffle()\n",
    "                        idxh_target_train = val_set[p].idxh_target\n",
    "                        idxh_source_train = val_set[p].idxh_source\n",
    "                    else:\n",
    "                        val_set[p].shuffle( idxh_target = idxh_target_train,\n",
    "                                            idxh_source= idxh_source_train)\n",
    "                        assert(np.all(  val_set[p].idxh_source == val_set[0].idxh_source)\n",
    "                                        ), f\"     > ERROR: Parameter Sharing incorrectly setup!\"\n",
    "                        assert(np.all(  val_set[p].idxh_target == val_set[0].idxh_target)\n",
    "                                        ), f\"     > ERROR: Parameter Sharing incorrectly setup!\"\n",
    "                else: val_set[p].shuffle()\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "\n",
    "                # MSE Epoch Results\n",
    "                viz_logger[p] = plot_results(   epoch = epoch, loss_ = 'MSE Loss', logger = viz_logger[p],\n",
    "                                                sel_slice = settings.sel_slice, best_loss = best_mse, worst_loss = worst_mse,\n",
    "                                                best_source_idx = best_mse_source_idx, best_target_idx = best_mse_target_idx,\n",
    "                                                worst_source_idx = worst_mse_target_idx, worst_target_idx = worst_mse_source_idx,\n",
    "                                                img_best_gt = img_gt_best_mse, img_best_fake = img_fake_best_mse,\n",
    "                                                img_worst_gt = img_gt_worst_mse, img_worst_fake = img_fake_worst_mse)\n",
    "                del best_mse_source_idx, best_mse_target_idx, img_gt_best_mse, img_fake_best_mse, best_mse,\\\n",
    "                    worst_mse_target_idx, worst_mse_source_idx, img_gt_worst_mse, img_fake_worst_mse, worst_mse\n",
    "\n",
    "                # SSIM Epoch Results\n",
    "                viz_logger[p] = plot_results(   epoch = epoch, loss_ = 'SSIM Index', logger = viz_logger[p],\n",
    "                                                sel_slice = settings.sel_slice, best_loss = best_ssim, worst_loss = worst_ssim,\n",
    "                                                best_source_idx = best_ssim_source_idx, best_target_idx = best_ssim_target_idx,\n",
    "                                                worst_source_idx = worst_ssim_source_idx, worst_target_idx = worst_ssim_target_idx,\n",
    "                                                img_best_gt = img_gt_best_ssim, img_best_fake = img_fake_best_ssim,\n",
    "                                                img_worst_gt = img_gt_worst_ssim, img_worst_fake = img_fake_worst_ssim)\n",
    "                del best_ssim_source_idx, best_ssim_target_idx, img_gt_best_ssim, img_fake_best_ssim, best_ssim,\\\n",
    "                    worst_ssim_source_idx, worst_ssim_target_idx, img_gt_worst_ssim, img_fake_worst_ssim, worst_ssim\n",
    "                \n",
    "        # End of Epoch Mean Loss Writing\n",
    "        train_mse_loss = np.mean(np.array(train_mse_loss))\n",
    "        val_mse_loss = np.mean(np.array(val_mse_loss))\n",
    "        val_ssim_loss = np.mean(np.array(val_ssim_loss))\n",
    "        train_logger.experiment.add_scalar(\"Mean MSE Loss\", train_mse_loss, epoch)\n",
    "        val_logger.experiment.add_scalar(\"Mean MSE Loss\", val_mse_loss, epoch)        \n",
    "        val_logger.experiment.add_scalar(\"Mean SSIM Index\", val_ssim_loss, epoch)\n",
    "        \n",
    "        # --------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Early Stopping Callback Application\n",
    "        early_stop = earlyStopping( loss = val_mse_loss, epoch = epoch,\n",
    "                                    model = model, optimizer = optimizer)\n",
    "        if early_stop: print(f'     > Training Finished at Epoch #{epoch}'); return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fcglVNN Model Training Script (V1)\n",
    "def cVNP_train(\n",
    "    settings,\n",
    "):\n",
    "\n",
    "    # Seed Random State for Reproducibility\n",
    "    torch.manual_seed(settings.seed)\n",
    "    np.random.seed(settings.seed)\n",
    "    random.seed(settings.seed)\n",
    "\n",
    "    # Experiment Logs Directories Initialization\n",
    "    checkpoint_folderpath = os.path.join(f'{settings.modelsave_folderpath}/V{settings.model_version}', 'logs')\n",
    "    train_logger = TensorBoardLogger(checkpoint_folderpath, 'train')\n",
    "    val_logger = TensorBoardLogger(checkpoint_folderpath, 'validation')\n",
    "\n",
    "    # Training & Validation DataLoaders Initialization\n",
    "    train_set = []; val_set = []; viz_logger = []\n",
    "    train_loader = []; val_loader = []; save_epoch = -1\n",
    "    for p, patient_id in enumerate(settings.patient_list):\n",
    "\n",
    "        # Patient Set & DataLoader Initialization\n",
    "        if patient_id in settings.train_patient_list:\n",
    "            print(f\"Patient #{patient_id} | Training Set:\")\n",
    "            train_set.append(   MUDI_cVNP(      settings, subject = [patient_id],\n",
    "                                                source_param = settings.train_source_param,\n",
    "                                                target_param = settings.train_target_param,\n",
    "                                                target_voxel = settings.train_target_voxel,\n",
    "                                                sample_size = settings.sample_size))\n",
    "            train_loader.append(DataLoader(     dataset = train_set[-1], pin_memory = True,\n",
    "                                                shuffle = settings.train_sample_shuffle,\n",
    "                                                num_workers = settings.num_workers,\n",
    "                                                batch_size = settings.batch_size))\n",
    "           \n",
    "        elif patient_id in settings.val_patient_list:\n",
    "            print(f\"Patient #{patient_id} | Validation Set:\")\n",
    "            val_set.append(     MUDI_cVNP(      settings, subject = [patient_id],\n",
    "                                                source_param = settings.val_source_param,\n",
    "                                                target_param = settings.val_target_param,\n",
    "                                                target_voxel = settings.val_target_voxel,\n",
    "                                                sample_size = 0))\n",
    "            val_loader.append(  DataLoader(     dataset = val_set[-1], pin_memory = True,\n",
    "                                                shuffle = settings.val_sample_shuffle,\n",
    "                                                num_workers = settings.num_workers,\n",
    "                                                batch_size = 1))#len(val_set[-1].idxv_target)))\n",
    "            viz_logger.append(  TensorBoardLogger(checkpoint_folderpath, f'validation/p{patient_id}'))\n",
    "        else: print(f\"Patient #{patient_id} | Test Set:     > Not Included\")\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Model & Optimizer Setup\n",
    "    print(f\"Running\\n     > Training cVNP Model with {torch.cuda.device_count()} GPUs!\")\n",
    "    model = nn.DataParallel(cVNP(settings), device_ids = settings.device_ids).to(settings.device)\n",
    "    optimizer = torch.optim.AdamW(  model.parameters(), lr = settings.base_lr,\n",
    "                                    weight_decay = settings.weight_decay)\n",
    "\n",
    "    # Model Checkpoint Loading\n",
    "    model_filepath = Path(f\"{settings.modelsave_folderpath}/V{settings.model_version}/Best cVNP.pt\")\n",
    "    if model_filepath.exists():\n",
    "        checkpoint = torch.load(model_filepath, map_location = settings.device)\n",
    "        model.load_state_dict(checkpoint['Model']); optimizer.load_state_dict(checkpoint['Optimizer'])\n",
    "        save_epoch = checkpoint['Current Epoch']; torch.set_rng_state(checkpoint['RNG State'])\n",
    "        print(f\"     > Loading cVNP Model for {settings.model_version}: {save_epoch} Past Epochs\")\n",
    "        del checkpoint\n",
    "\n",
    "    # Criterion & Early Stopping Setup\n",
    "    mse_criterion = nn.MSELoss(reduction = 'mean')\n",
    "    earlyStopping = EarlyStopping(settings)\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Epoch Iteration Loop\n",
    "    train_iter = 0; val_iter = 0\n",
    "    for epoch in range(save_epoch + 1, settings.num_epochs):\n",
    "\n",
    "        # Training Patient Loop\n",
    "        train_mse_loss = []; print(f\"Training Epoch #{epoch}:\")\n",
    "        for p, patient_id in enumerate(settings.train_patient_list):\n",
    "\n",
    "            # Training Iteration Loop\n",
    "            mask = MUDI_cVNP.get_mask(settings, num_patient = patient_id)\n",
    "            train_bar = tqdm(   enumerate(train_loader[p]), total = len(train_loader[p]),\n",
    "                desc = f'Epoch #{epoch} | Training Patient {patient_id}', unit = 'Batches')\n",
    "            for batch_idx, batch in train_bar:\n",
    "\n",
    "                # Forward Propagation\n",
    "                model.train(); model.zero_grad(); optimizer.zero_grad()\n",
    "                g_size = batch['g_size']; batch_size = len(batch['idxh_source'])\n",
    "                X_fake = model( batch['X_train'].ravel().to(settings.device),\n",
    "                                batch['y_train'].reshape((g_size * batch_size, 5)).to(settings.device),\n",
    "                                batch['y_target'].reshape((g_size * batch_size, 5)).to(settings.device))\n",
    "                X_fake = torch.squeeze(X_fake, dim = 1); gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "                # Backward Propagation\n",
    "                mse_loss = mse_criterion(X_fake, batch['X_target'].ravel().to(settings.device))\n",
    "                mse_loss.backward(); optimizer.step(); del batch, X_fake\n",
    "                train_logger.experiment.add_scalar(\"MSE Loss\", mse_loss.item(), train_iter)\n",
    "                train_mse_loss.append(mse_loss.item()); train_iter += 1\n",
    "\n",
    "            # Inter-Patient Reconstruction Parameter Sharing Functionality\n",
    "            if settings.interpatient_sharing:\n",
    "                if p == 0:\n",
    "                    train_set[p].shuffle()\n",
    "                    idxh_target_train = train_set[p].idxh_target\n",
    "                    idxh_source_train = train_set[p].idxh_source\n",
    "                else:\n",
    "                    train_set[p].shuffle(   idxh_target = idxh_target_train,\n",
    "                                            idxh_source= idxh_source_train)\n",
    "                    assert(np.all(  train_set[p].idxh_source == train_set[0].idxh_source)\n",
    "                                    ), f\"     > ERROR: Parameter Sharing incorrectly setup!\"\n",
    "                    assert(np.all(  train_set[p].idxh_target == train_set[0].idxh_target)\n",
    "                                    ), f\"     > ERROR: Parameter Sharing incorrectly setup!\"\n",
    "            else: train_set[p].shuffle()\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Validation Set Reconstruction Loss Checkpoints\n",
    "        best_mse = 1000; worst_mse = 0\n",
    "        best_ssim = 0; worst_ssim = 1000\n",
    "\n",
    "        # Validation Patient Loop\n",
    "        with torch.no_grad():\n",
    "            model.eval(); val_ssim_loss = []; val_mse_loss = []\n",
    "            for p, patient_id in enumerate(settings.val_patient_list):\n",
    "            \n",
    "                # Training Iteration Loop\n",
    "                mask = MUDI_cVNP.get_mask(settings, num_patient = patient_id)\n",
    "                val_bar = tqdm(   enumerate(val_loader[p]), total = len(val_loader[p]),\n",
    "                    desc = f'Epoch #{epoch} | Validation Patient {patient_id}', unit = 'Batches')\n",
    "                for batch_idx, batch in val_bar:\n",
    "            \n",
    "                    # Batch Handling\n",
    "                    idxh_source = batch['param_source'][0]; idxh_target = batch['param_target'][0]\n",
    "                    g_size = batch['g_size']; batch_size = len(batch['idxh_source'])\n",
    "                    img_gt = torch.Tensor(unmask(batch['X_target'].ravel().reshape((1,\n",
    "                                g_size * batch_size)), mask).get_fdata().T)\n",
    "\n",
    "                    # Forward Propagation\n",
    "                    X_fake = model( batch['X_train'].ravel().to(settings.device),\n",
    "                                    batch['y_train'].reshape((g_size * batch_size, 5)).to(settings.device),\n",
    "                                    batch['y_target'].reshape((g_size * batch_size, 5)).to(settings.device))\n",
    "                    X_fake = model( batch['X_train'].to(settings.device),\n",
    "                                    batch['y_train'].to(settings.device),\n",
    "                                    batch['y_target'].to(settings.device))\n",
    "                    X_fake = torch.squeeze(X_fake, dim = 1)\n",
    "                    img_fake = torch.Tensor(unmask(X_fake.detach().cpu().reshape((1,\n",
    "                                    g_size * batch_size)), mask).get_fdata().T)\n",
    "                    gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "                    # Loss Computation\n",
    "                    mse_loss = mse_criterion(X_fake, batch['X_target'].ravel().to(settings.device)).detach().cpu().numpy()\n",
    "                    ssim_loss, ssim_img = ssim( img_gt[0].cpu().numpy().astype(np.float32), \n",
    "                                                img_fake[0].cpu().numpy().astype(np.float32), full = True,\n",
    "                                        data_range = (torch.max(img_gt) - torch.min(img_gt)).cpu().numpy())\n",
    "                    ssim_loss = np.mean(ssim_loss); del ssim_img, batch, X_fake\n",
    "\n",
    "                    # Loss Appending \n",
    "                    val_logger.experiment.add_scalar(\"MSE Loss\", mse_loss.item(), val_iter)\n",
    "                    val_logger.experiment.add_scalar(\"SSIM Index\", ssim_loss, val_iter)\n",
    "                    val_mse_loss.append(mse_loss.item()); val_ssim_loss.append(ssim_loss); val_iter += 1\n",
    "\n",
    "                    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "                    # MSE & SSIM Loss Assignation for Parameters\n",
    "                    if mse_loss < best_mse:\n",
    "                        best_mse = mse_loss\n",
    "                        best_mse_source_idx = idxh_source\n",
    "                        best_mse_target_idx = idxh_target\n",
    "                        img_fake_best_mse = img_fake.detach().cpu()\n",
    "                        img_gt_best_mse = img_gt.detach().cpu()\n",
    "                    if mse_loss > worst_mse:\n",
    "                        worst_mse = mse_loss\n",
    "                        worst_mse_source_idx = idxh_source\n",
    "                        worst_mse_target_idx = idxh_target\n",
    "                        img_fake_worst_mse = img_fake.detach().cpu()\n",
    "                        img_gt_worst_mse = img_gt.detach().cpu()\n",
    "                    if ssim_loss > best_ssim:\n",
    "                        best_ssim = ssim_loss\n",
    "                        best_ssim_source_idx = idxh_source\n",
    "                        best_ssim_target_idx = idxh_target\n",
    "                        img_fake_best_ssim = img_fake.detach().cpu()\n",
    "                        img_gt_best_ssim = img_gt.detach().cpu()\n",
    "                    if ssim_loss < worst_ssim:\n",
    "                        worst_ssim = ssim_loss\n",
    "                        worst_ssim_source_idx = idxh_source\n",
    "                        worst_ssim_target_idx = idxh_target\n",
    "                        img_fake_worst_ssim = img_fake.detach().cpu()\n",
    "                        img_gt_worst_ssim = img_gt.detach().cpu()\n",
    "                    gc.collect(); torch.cuda.empty_cache(); del img_gt, img_fake\n",
    "\n",
    "                # Inter-Patient Reconstruction Parameter Sharing Functionality\n",
    "                if settings.interpatient_sharing:\n",
    "                    if p == 0:\n",
    "                        val_set[p].shuffle()\n",
    "                        idxh_target_train = val_set[p].idxh_target\n",
    "                        idxh_source_train = val_set[p].idxh_source\n",
    "                    else:\n",
    "                        val_set[p].shuffle( idxh_target = idxh_target_train,\n",
    "                                            idxh_source= idxh_source_train)\n",
    "                        assert(np.all(  val_set[p].idxh_source == val_set[0].idxh_source)\n",
    "                                        ), f\"     > ERROR: Parameter Sharing incorrectly setup!\"\n",
    "                        assert(np.all(  val_set[p].idxh_target == val_set[0].idxh_target)\n",
    "                                        ), f\"     > ERROR: Parameter Sharing incorrectly setup!\"\n",
    "                else: val_set[p].shuffle()\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "\n",
    "                # MSE Epoch Results\n",
    "                viz_logger[p] = plot_results(   epoch = epoch, loss_ = 'MSE Loss', logger = viz_logger[p],\n",
    "                                                sel_slice = settings.sel_slice, best_loss = best_mse, worst_loss = worst_mse,\n",
    "                                                best_source_idx = best_mse_source_idx, best_target_idx = best_mse_target_idx,\n",
    "                                                worst_source_idx = worst_mse_target_idx, worst_target_idx = worst_mse_source_idx,\n",
    "                                                img_best_gt = img_gt_best_mse, img_best_fake = img_fake_best_mse,\n",
    "                                                img_worst_gt = img_gt_worst_mse, img_worst_fake = img_fake_worst_mse)\n",
    "                del best_mse_source_idx, best_mse_target_idx, img_gt_best_mse, img_fake_best_mse, best_mse,\\\n",
    "                    worst_mse_target_idx, worst_mse_source_idx, img_gt_worst_mse, img_fake_worst_mse, worst_mse\n",
    "\n",
    "                # SSIM Epoch Results\n",
    "                viz_logger[p] = plot_results(   epoch = epoch, loss_ = 'SSIM Index', logger = viz_logger[p],\n",
    "                                                sel_slice = settings.sel_slice, best_loss = best_ssim, worst_loss = worst_ssim,\n",
    "                                                best_source_idx = best_ssim_source_idx, best_target_idx = best_ssim_target_idx,\n",
    "                                                worst_source_idx = worst_ssim_source_idx, worst_target_idx = worst_ssim_target_idx,\n",
    "                                                img_best_gt = img_gt_best_ssim, img_best_fake = img_fake_best_ssim,\n",
    "                                                img_worst_gt = img_gt_worst_ssim, img_worst_fake = img_fake_worst_ssim)\n",
    "                del best_ssim_source_idx, best_ssim_target_idx, img_gt_best_ssim, img_fake_best_ssim, best_ssim,\\\n",
    "                    worst_ssim_source_idx, worst_ssim_target_idx, img_gt_worst_ssim, img_fake_worst_ssim, worst_ssim\n",
    "                \n",
    "        # End of Epoch Mean Loss Writing\n",
    "        train_mse_loss = np.mean(np.array(train_mse_loss))\n",
    "        val_mse_loss = np.mean(np.array(val_mse_loss))\n",
    "        val_ssim_loss = np.mean(np.array(val_ssim_loss))\n",
    "        train_logger.experiment.add_scalar(\"Mean MSE Loss\", train_mse_loss, epoch)\n",
    "        val_logger.experiment.add_scalar(\"Mean MSE Loss\", val_mse_loss, epoch)        \n",
    "        val_logger.experiment.add_scalar(\"Mean SSIM Index\", val_ssim_loss, epoch)\n",
    "        \n",
    "        # --------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Early Stopping Callback Application\n",
    "        early_stop = earlyStopping( loss = val_mse_loss, epoch = epoch,\n",
    "                                    model = model, optimizer = optimizer)\n",
    "        if early_stop: print(f'     > Training Finished at Epoch #{epoch}'); return\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Performance* **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result Plotting Functionality (V0)\n",
    "def ResultCallback(\n",
    "    logger: TensorBoardLogger,\n",
    "    best_info: dict,\n",
    "    worst_info: dict,\n",
    "    epoch: int = 0,\n",
    "    num_slice: int = 25,\n",
    "    mode: str = 'Test',\n",
    "    loss: str = 'MSE Loss',\n",
    "):\n",
    "\n",
    "    # Set Example Reconstruction Results Image Plotting\n",
    "    plot = plt.figure(figsize = (30, 25)); plt.suptitle(f\"Overall {mode} | {loss}\")\n",
    "    plt.xticks([]); plt.yticks([]); plt.grid(False); plt.tight_layout()\n",
    "\n",
    "    # Set Example Original & Best Loss Reconstructed Image Subplots\n",
    "    plt.subplot(2, 3, 1, title =        f\"Best | Source Parameter #{best_info['idxh_source']}\")\n",
    "    plt.imshow(best_info['img_source'][ num_slice, :, :], cmap = plt.cm.binary)\n",
    "    plt.subplot(2, 3, 2, title =        f\"Best | Target Parameter #{best_info['idxh_target']}\")\n",
    "    plt.imshow(best_info['img_target'][ num_slice, :, :], cmap = plt.cm.binary)\n",
    "    plt.subplot(2, 3, 3, title =        f\"Best | Reconstruction | {loss}: {np.round(best_info['loss'], 5)}\")\n",
    "    plt.imshow(best_info['img_fake'][   0, num_slice, :, :], cmap = plt.cm.binary)\n",
    "\n",
    "    # Set Example Original & Worst Loss Reconstructed Image Subplots\n",
    "    plt.subplot(2, 3, 4, title =        f\"Worst | Source Parameter #{worst_info['idxh_source']}\")\n",
    "    plt.imshow(worst_info['img_source'][num_slice, :, :], cmap = plt.cm.binary)\n",
    "    plt.subplot(2, 3, 5, title =        f\"Worst | Target Parameter #{worst_info['idxh_target']}\")\n",
    "    plt.imshow(worst_info['img_target'][num_slice, :, :], cmap = plt.cm.binary)\n",
    "    plt.subplot(2, 3, 6, title =        f\"Worst | Reconstruction | {loss}: {np.round(worst_info['loss'], 5)}\")\n",
    "    plt.imshow(worst_info['img_fake'][  0, num_slice, :, :], cmap = plt.cm.binary)\n",
    "\n",
    "    # Tensorboard Reconstruction Callback\n",
    "    logger.experiment.add_figure(f\"{mode} Image Results\", plot, epoch)\n",
    "    logger.experiment.add_scalar(\"Best Loss\", best_info['loss'], epoch)\n",
    "    logger.experiment.add_scalar(\"Worst Loss\", worst_info['loss'], epoch)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cVNP Model Testing Script (V0)\n",
    "def cVNP_test(\n",
    "    settings,\n",
    "    patient_id: int = 15\n",
    "):\n",
    "        \n",
    "    # Seed Random State for Reproducibility\n",
    "    torch.manual_seed(settings.seed)\n",
    "    np.random.seed(settings.seed)\n",
    "    random.seed(settings.seed)\n",
    "\n",
    "    # cVNP Model Loading\n",
    "    print(f\"Evaluation\\n     > Testing cVNP Model with {torch.cuda.device_count()} GPUs!\")\n",
    "    model = nn.DataParallel(cVNP(settings)).to(settings.device)\n",
    "    model_filepath = Path(f\"cVNP/{settings.modelsave_folderpath}/V{settings.model_version}/Best cVNP.pt\")\n",
    "    assert(model_filepath.exists()), f\"ERROR: cVNP Model (V{settings.model_version}) not Found!\"\n",
    "    checkpoint = torch.load(model_filepath, map_location = settings.device)\n",
    "    model.load_state_dict(checkpoint['Model'])\n",
    "    #optimizer.load_state_dict(checkpoint['Optimizer'])\n",
    "    save_epoch = checkpoint['Current Epoch']\n",
    "    torch.set_rng_state(checkpoint['RNG State'])\n",
    "    mse_criterion = nn.MSELoss(reduction = 'mean'); del checkpoint\n",
    "\n",
    "    # Experiment Logs Directories Initialization\n",
    "    checkpoint_folderpath = os.path.join(f'{settings.modelsave_folderpath}/V{settings.model_version}', 'logs')\n",
    "    mse_logger = TensorBoardLogger(checkpoint_folderpath, f'test/epoch{save_epoch}/p{patient_id}/mse')\n",
    "    ssim_logger = TensorBoardLogger(checkpoint_folderpath, f'test/epoch{save_epoch}/p{patient_id}/ssim')\n",
    "    print(f\"     > Evaluating fcglVNN Model for Version #{settings.model_version}: {save_epoch} Past Epochs\")\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Test Set Initialization\n",
    "    mask = MUDI_cVNP.get_mask(settings, num_patient = 14)\n",
    "    testset = MUDI_cVNP(    settings, subject = [14], random = False,\n",
    "                            source_param = 100, target_param = 100,\n",
    "                            target_voxel = 100, param_loop = 100)\n",
    "    testloader = DataLoader(dataset = testset, shuffle = False,\n",
    "                            num_workers = 0, pin_memory = False,\n",
    "                            batch_size = len(testset.idxv_target))\n",
    "\n",
    "    # Loss Value Initialization\n",
    "    test_mse = []; test_ssim = []; test_iter = 0\n",
    "    best_mse = 1000; worst_mse = 0\n",
    "    best_ssim = 0; worst_ssim = 1000\n",
    "    \n",
    "    # Batch Iteration Loop\n",
    "    with torch.no_grad():\n",
    "        test_bar = tqdm(   enumerate(testloader), total = len(testloader),\n",
    "            desc = f'Test Patient {patient_id}', unit = 'Batches'); model.eval()\n",
    "        for batch_idx, batch in test_bar:\n",
    "\n",
    "            # Forward Propagation\n",
    "            idxh_source = batch['param_source']; idxh_target = batch['param_target']\n",
    "            X_fake = model( batch['X_train'].to(settings.device),\n",
    "                            batch['y_train'].to(settings.device),\n",
    "                            batch['y_target'].to(settings.device))\n",
    "\n",
    "            # Image Handling\n",
    "            img_fake = torch.Tensor(unmask(X_fake.detach().cpu().T, mask).get_fdata().T)\n",
    "            img_source = torch.Tensor(unmask(batch['X_train'], mask).get_fdata().T)\n",
    "            img_target = torch.Tensor(unmask(batch['X_target'], mask).get_fdata().T)\n",
    "\n",
    "            # Loss Computation\n",
    "            mse_loss = mse_criterion(X_fake.T[0], batch['X_target'])\n",
    "            ssim_loss, ssim_img = ssim( img_target.detach().cpu().numpy().astype(np.float32), \n",
    "                                        img_fake[0].cpu().numpy().astype(np.float32), full = True,\n",
    "                                        data_range = (torch.max(img_target) - torch.min(img_target)).cpu().numpy())\n",
    "            ssim_loss = np.mean(ssim_loss); del ssim_img, X_fake, batch\n",
    "\n",
    "            # Loss Appending\n",
    "            test_mse.append(mse_loss.item()); test_ssim.append(ssim_loss)\n",
    "            mse_logger.experiment.add_scalar(\"Batch Loss\", mse_loss.item(), test_iter)\n",
    "            ssim_logger.experiment.add_scalar(\"Batch Loss\", ssim_loss, test_iter); test_iter += 1\n",
    "            \n",
    "            # --------------------------------------------------------------------------------------------\n",
    "\n",
    "            # MSE & SSIM Loss Assignation for Parameters\n",
    "            if mse_loss.item() < best_mse:\n",
    "                best_mse = mse_loss.item()\n",
    "                best_mse = {    'loss': mse_loss.item(), 'img_fake': img_fake,\n",
    "                                'idxh_source': idxh_source, 'idxh_target': idxh_target,\n",
    "                                'img_source': img_source, 'img_target': img_target}\n",
    "            if mse_loss.item() > worst_mse:\n",
    "                worst_mse = mse_loss.item()\n",
    "                worst_mse = {   'loss': mse_loss.item(), 'img_fake': img_fake,\n",
    "                                'idxh_source': idxh_source, 'idxh_target': idxh_target,\n",
    "                                'img_source': img_source, 'img_target': img_target}\n",
    "            if ssim_loss > best_ssim:\n",
    "                best_ssim = ssim_loss\n",
    "                best_ssim = {   'loss': ssim_loss, 'img_fake': img_fake,\n",
    "                                'idxh_source': idxh_source, 'idxh_target': idxh_target,\n",
    "                                'img_source': img_source, 'img_target': img_target}\n",
    "            if ssim_loss < worst_ssim:\n",
    "                worst_ssim = ssim_loss\n",
    "                worst_ssim = {  'loss': ssim_loss, 'img_fake': img_fake,\n",
    "                                'idxh_source': idxh_source, 'idxh_target': idxh_target,\n",
    "                                'img_source': img_source, 'img_target': img_target}\n",
    "            gc.collect(); torch.cuda.empty_cache()\n",
    "            del img_source, img_target, img_fake, idxh_source, idxh_target\n",
    "\n",
    "            # --------------------------------------------------------------------------------------------\n",
    "\n",
    "            # Source Parameter Based Result Appending\n",
    "            if batch_idx % testset.h_target == 0:\n",
    "\n",
    "                # End of Source Parameter Image Result Writing\n",
    "                mse_logger = ResultCallback(    logger = mse_logger, mode = 'Test', loss = 'MSE Loss',\n",
    "                                                epoch = batch_idx // testset.h_target,\n",
    "                                                best_info = best_mse, worst_info = worst_mse)\n",
    "                ssim_logger = ResultCallback(   logger = ssim_logger, mode = 'Test', loss = 'SSIM Index',\n",
    "                                                epoch = batch_idx // testset.h_target,\n",
    "                                                best_info = best_ssim, worst_info = worst_ssim)\n",
    "                del best_mse, worst_mse, best_ssim, worst_ssim\n",
    "\n",
    "                # Loss Value Re-Initialization\n",
    "                mse_logger.experiment.add_scalar(\"Mean Loss\", np.mean(test_mse), batch_idx // testset.h_target)\n",
    "                ssim_logger.experiment.add_scalar(\"Mean Loss\", np.mean(test_ssim), batch_idx // testset.h_target)\n",
    "                test_mse = []; test_ssim = []; best_mse = 1000; worst_mse = 0; best_ssim = 0; worst_ssim = 1000\n",
    "    \n",
    "    \"\"\"\n",
    "    # Result Image Saving\n",
    "    img_fake = nib.Nifti1Image(img_fake.T, affine = np.eye(4)); img_fake.header.get_xyzt_units()\n",
    "    img_mse = nib.Nifti1Image(img_mse.T, affine = np.eye(4)); img_mse.header.get_xyzt_units()\n",
    "    img_ssim = nib.Nifti1Image(img_ssim.T, affine = np.eye(4)); img_ssim.header.get_xyzt_units()\n",
    "    nib.save(img_fake, Path(f\"{checkpoint_folderpath}/test/epoch{save_epoch}/p{patient_id}/img_fake.nii.gz\"))\n",
    "    nib.save(img_mse, Path(f\"{checkpoint_folderpath}/test/epoch{save_epoch}/p{patient_id}/img_mse.nii.gz\"))\n",
    "    nib.save(img_ssim, Path(f\"{checkpoint_folderpath}/test/epoch{save_epoch}/p{patient_id}/img_ssim.nii.gz\"))\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MUDI_cVNP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pfernan2\\Desktop\\dMRI-Studio\\Experiments\\Autoencoders\\Autoencoders.ipynb Cell 111\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Z1051sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Test Set Initialization\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Z1051sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m mask \u001b[39m=\u001b[39m MUDI_cVNP\u001b[39m.\u001b[39mget_mask(settings, num_patient \u001b[39m=\u001b[39m \u001b[39m14\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Z1051sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m testset \u001b[39m=\u001b[39m MUDI_cVNP(    settings, subject \u001b[39m=\u001b[39m [\u001b[39m14\u001b[39m], random \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Z1051sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                         source_param \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m, target_param \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Z1051sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                         target_voxel \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m, param_loop \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m \u001b[39m/\u001b[39m (\u001b[39m500\u001b[39m \u001b[39m*\u001b[39m \u001b[39m844\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Z1051sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m testloader \u001b[39m=\u001b[39m DataLoader(dataset \u001b[39m=\u001b[39m testset, shuffle \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Z1051sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                         num_workers \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, pin_memory \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Z1051sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                         batch_size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(testset\u001b[39m.\u001b[39midxv_target))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MUDI_cVNP' is not defined"
     ]
    }
   ],
   "source": [
    "# Test Set Initialization\n",
    "mask = MUDI_cVNP.get_mask(settings, num_patient = 14)\n",
    "testset = MUDI_cVNP(    settings, subject = [14], random = False,\n",
    "                        source_param = 100, target_param = 100,\n",
    "                        target_voxel = 100, param_loop = 100 / (500 * 844))\n",
    "testloader = DataLoader(dataset = testset, shuffle = False,\n",
    "                        num_workers = 0, pin_memory = False,\n",
    "                        batch_size = len(testset.idxv_target))\n",
    "\n",
    "# cVNP Model Loading\n",
    "print(f\"Evaluation\\n     > Testing cVNP Model with {torch.cuda.device_count()} GPUs!\")\n",
    "model = nn.DataParallel(cVNP(settings)).to(settings.device)\n",
    "model_filepath = Path(f\"cVNP/{settings.modelsave_folderpath}/V{settings.model_version}/Best cVNP.pt\")\n",
    "assert(model_filepath.exists()), f\"ERROR: cVNP Model (V{settings.model_version}) not Found!\"\n",
    "checkpoint = torch.load(model_filepath, map_location = settings.device)\n",
    "model.load_state_dict(checkpoint['Model'])\n",
    "#optimizer.load_state_dict(checkpoint['Optimizer'])\n",
    "save_epoch = checkpoint['Current Epoch']\n",
    "torch.set_rng_state(checkpoint['RNG State'])\n",
    "mse_criterion = nn.MSELoss(reduction = 'mean'); del checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Reconstruction Plot Functionality\n",
    "def recon_plot(\n",
    "    idxh_source: int = 0,\n",
    "    idxh_target: int = 0,\n",
    "    num_slice: int = 0\n",
    "):\n",
    "\n",
    "    # Forward Propagation\n",
    "    with torch.no_grad():\n",
    "        idxh_combo = [np.array([testset.idxh_source[idxh_source],\n",
    "                                testset.idxh_target[idxh_target]])]\n",
    "        testset.combo_shuffle(idxh_combo = idxh_combo)\n",
    "        batch = next(iter(testloader)); model.eval()\n",
    "        X_fake = model( batch['X_train'].to(settings.device),\n",
    "                        batch['y_train'].to(settings.device),\n",
    "                        batch['y_target'].to(settings.device))\n",
    "\n",
    "    # Image Handling\n",
    "    img_fake = torch.Tensor(unmask(X_fake.detach().cpu().T, mask).get_fdata().T)\n",
    "    img_source = torch.Tensor(unmask(batch['X_train'], mask).get_fdata().T)\n",
    "    img_target = torch.Tensor(unmask(batch['X_target'], mask).get_fdata().T)\n",
    "\n",
    "    # Loss Computation\n",
    "    mse_loss = mse_criterion(X_fake.T[0], batch['X_target'])\n",
    "    ssim_loss, ssim_img = ssim( img_target.detach().cpu().numpy().astype(np.float32), \n",
    "                                img_fake[0].cpu().numpy().astype(np.float32), full = True,\n",
    "                                data_range = (torch.max(img_target) - torch.min(img_target)).cpu().numpy())\n",
    "    ssim_loss = np.mean(ssim_loss); del ssim_img, batch, X_fake\n",
    "    \n",
    "    # Original Training Example Image Subplot\n",
    "    figure = plt.figure(figsize = (15, 5))\n",
    "    plt.suptitle(f'Test Patient #{settings.test_patient_list[0]} | Slice #{num_slice}' +\n",
    "                 f'\\nMSE: {round(mse_loss.item(), 5)} | SSIM: {round(ssim_loss.item(), 5)}\\n')\n",
    "    plt.xticks([]); plt.yticks([]); plt.grid(False); plt.tight_layout()\n",
    "    \n",
    "    # Source Parameter Image Scan Subplot\n",
    "    plt.subplot(1, 3, 1, title = f'Source Parameter #{idxh_combo[0][0]}')\n",
    "    plt.imshow(img_source[num_slice, :, :], cmap = plt.cm.binary)\n",
    "\n",
    "    # Target Parameter Image Scan Subplot\n",
    "    plt.subplot(1, 3, 2, title = f'Target Parameter #{idxh_combo[0][1]}')\n",
    "    plt.imshow(img_target[num_slice, :, :], cmap = plt.cm.binary)\n",
    "\n",
    "    # Source Parameter Image Scan Subplot\n",
    "    plt.subplot(1, 3, 3, title = f'Generated Scan')\n",
    "    plt.imshow(img_fake[0, num_slice, :, :], cmap = plt.cm.binary)\n",
    "\n",
    "# Image Interactive Construction\n",
    "source_slider = IntSlider(  value = 0, min = 0, max = len(testset.idxh_source) - 1,\n",
    "                            description = 'Source Parameter', continuous_update = False)\n",
    "target_slider = IntSlider(  value = 0, min = 0, max = len(testset.idxh_target) - 1,\n",
    "                            description = 'Parameter', continuous_update = False)\n",
    "slice_slider = IntSlider(   value = 0, min = 0, max = 56 - 1,\n",
    "                            description = 'Slice', continuous_update = False)\n",
    "#interactive(recon_plot, idxh_source = source_slider,\n",
    "#            idxh_target = target_slider, num_slice = slice_slider)\n",
    "recon_plot(idxh_source = 0, idxh_target = 0, num_slice = 25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **2D CVAE-GAN**\n",
    "\n",
    "### *2D Conditional Variational AutoEncoder + Generative Adversarial Network* \n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data** *Reader*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D MUDI Dataset Initialization Class (Linear)\n",
    "class MUDI_CVAE_GAN_2D(Dataset):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,\n",
    "        subject: int or list,\n",
    "        mode: str = 'Target',\n",
    "        source_param: int or float = 100,\n",
    "        target_param: int or float = 100,\n",
    "        target_slice: int or float = 100\n",
    "    ):\n",
    "        \n",
    "        # Parameter & Patient Index Value Access\n",
    "        super(MUDI_CVAE_GAN_2D).__init__(); self.mode = mode\n",
    "        self.settings = settings; self.source_param = source_param\n",
    "        self.target_param = target_param; self.target_slice = target_slice\n",
    "        self.data = h5py.File(self.settings.data_filepath, 'r').get('data1')\n",
    "        self.params = pd.read_excel(self.settings.param_filepath)\n",
    "\n",
    "        # Vertical Splitting (Patient & Slice Selection)\n",
    "        self.idxv = pd.read_csv(self.settings.info_filepath,                    # List of Index Values ...\n",
    "                                index_col = 0).to_numpy()                       # ... pertaining to each Patient\n",
    "        self.idxv = self.idxv[np.isin(self.idxv[:, 1], subject), 0]             # Patient-Specific Index Values\n",
    "        self.mask = MUDI_CVAE_GAN_2D.get_mask(self.settings, subject[0])        # Patient-Specific Mask Download\n",
    "        self.data = unmask(self.data[self.idxv, :].T, self.mask).get_fdata().T  # Patient-Specific Image Unmasking\n",
    "        self.data = MUDI_CVAE_GAN_2D.zero_padding(self.data, self.settings.img_shape)   # Image Pre-Processing: Zero Padding\n",
    "        self.idxv_slice_full = np.arange(self.mask.shape[-1])                   # Full List of Available Image Slices\n",
    "\n",
    "        # Horizontal Splitting (Source & Target Parameter Selection)\n",
    "        idxh_source_filepath = Path(f\"{self.settings.datasave_folderpath}/Training Labels (V{self.settings.data_version}).txt\")\n",
    "        idxh_target_filepath = Path(f\"{self.settings.datasave_folderpath}/{self.mode} Labels (V{self.settings.data_version}).txt\")\n",
    "        self.idxh_source_full = np.sort(np.loadtxt(idxh_source_filepath)).astype(int)\n",
    "        if not idxh_target_filepath.exists(): self.idxh_target_full = self.label_gen()\n",
    "        else: self.idxh_target_full = np.sort(np.loadtxt(idxh_target_filepath)).astype(int)\n",
    "\n",
    "        # Vertical & Horizontal Sub-Sectioning & Shuffling\n",
    "        self.s_target = int((self.target_slice * len(self.idxv_slice_full)) / 100)\n",
    "        print(f\"     > Utilizing {self.s_target} \\ {len(self.idxv_slice_full)} of the Available Slices\")\n",
    "        self.h_source = int((self.source_param * len(self.idxh_source_full)) / 100)\n",
    "        self.h_target = int((self.target_param * len(self.idxh_target_full)) / 100); self.shuffle(True)\n",
    "        print(f\"     > Utilizing {self.h_source} \\ {len(self.idxh_source_full)} of the Training Parameters\")\n",
    "        print(f\"     > Utilizing {self.h_target} \\ {len(self.idxh_target_full)} of the Target Parameters\")\n",
    "        print(f\"     > Pre-Processing Images to be of Square Shape of {self.settings.img_shape}\")\n",
    "\n",
    "        # Parameter Selection & Value Normalization / Scaling\n",
    "        if self.settings.gradient_coord:\n",
    "            self.params = self.params.drop(columns = ['Gradient theta', 'Gradient phi'])                # Choosing of Gradient Orientation\n",
    "        else: self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])\n",
    "        if self.settings.label_norm == 'auto':\n",
    "            print(f\"     > Automatic Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "            self.scaler = StandardScaler()\n",
    "            self.params = pd.DataFrame( self.scaler.fit_transform(self.params),\n",
    "                                        columns = self.params.columns)\n",
    "            scaler_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "            if not scaler_filepath.exists(): torch.save(self.scaler, scaler_filepath)\n",
    "        elif self.settings.label_norm == 'manual':\n",
    "            print(f\"     > Manual Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "            self.params[['Gradient theta', 'Gradient phi']] = self.cart2polar(self.params[['Gradient x', 'Gradient y', 'Gradient z']].values)\n",
    "            self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])\n",
    "            self.params['b Value'] = self.params['b Value'] / 10000\n",
    "            self.params['TI'] = self.params['TI'] / 10000\n",
    "            self.params['TE'] = (self.params['TE'] - 80) / 200\n",
    "        else: print(f\"     > No Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "        assert(self.params.shape[1] == self.settings.num_labels), \"ERROR: Labels wrongly Deleted!\"\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # DataLoader Length / No. Batches Computation Functionality\n",
    "    def __len__(self): return self.s_target * self.h_source * self.h_target\n",
    "\n",
    "    # Image Zero-Padding Pre-Processing Method Functionality\n",
    "    def zero_padding(\n",
    "        data: np.array or torch.Tensor,\n",
    "        img_shape: int\n",
    "    ):\n",
    "\n",
    "        # Input Data Assertions\n",
    "        assert(data.ndim >= 3), \"ERROR: Pre-Processing Input Data has the Wrong Dimmensions\"\n",
    "        assert(img_shape >= int(data.shape[-2]) and img_shape >= int(data.shape[-1])\n",
    "        ), \"ERROR: Pre-Processed Output Data Shape is Larget than Input one!\"\n",
    "\n",
    "        # Zero-Padding Implementation\n",
    "        padding = np.array([0, 0, (img_shape - data.shape[-2]) / 2, (img_shape - data.shape[-1]) / 2])\n",
    "        padding = padding.reshape((1, -1)).T + np.array([0, 0])\n",
    "        padding[:, -1] = np.ceil(padding[:, -1]); padding[:, -2] = np.floor(padding[:, -2])\n",
    "        return np.pad(data, padding.astype(np.int32), 'constant')\n",
    "        \n",
    "    # Single-Batch Generation Functionality\n",
    "    def __getitem__(self, idx) -> tuple[np.ndarray, np.float32]:\n",
    "        \n",
    "        # Batch Vertical/Slice & Horizontal/Parameter Indexing\n",
    "        idxv_slice = idx % self.s_target                        # Batch's Vertical Index for X_train\n",
    "        idxh_source = (idx // self.s_target) % self.h_source    # Batch's Horizontal Index for y_train\n",
    "        idxh_target = idx // (self.s_target * self.h_source)    # Batch's Horizontal Index for y_target\n",
    "        #print(f\"Item #{idx} | Slice #{idxv_slice} | Source Parameter #{self.idxh_source[idxh_source]} | Target Parameter #{self.idxh_target[idxh_target]}\")\n",
    "\n",
    "        # Batch Data Generation\n",
    "        X_train = self.data[self.idxh_source[idxh_source], self.idxv_slice[idxv_slice], :, :]           # [1, 1, :, :] Training Image Slice Data\n",
    "        y_train = self.params.iloc[self.idxh_source[idxh_source]].values                                # [num_labels] Training Image Parameter Values\n",
    "        X_target = self.data[self.idxh_target[idxh_target], self.idxv_slice[idxv_slice], :, :]          # [1, 1, :, :] GT Target Image Slice Data\n",
    "        y_target = self.params.iloc[self.idxh_target[idxh_target]].values                               # [num_labels] Target Image Parameter Values\n",
    "        return {'X_train': np.array(X_train).reshape((1, X_train.shape[0], X_train.shape[1])).astype(np.float32),\n",
    "                'X_target': np.array(X_target).reshape((1, X_target.shape[0], X_target.shape[1])).astype(np.float32),\n",
    "                'y_train': np.ravel(y_train).astype(np.float32), 'y_target': np.ravel(y_target).astype(np.float32),\n",
    "                'idxv_slice': idxv_slice, 'slice_target': self.idxv_slice[idxv_slice],\n",
    "                'idxh_source': idxh_source, 'param_source': self.idxh_source[idxh_source],\n",
    "                'idxh_target': idxh_target, 'param_target': self.idxh_target[idxh_target]}\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Source Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def source_param_shuffle(\n",
    "        self,\n",
    "        begin: bool = False,\n",
    "        idxh_source: np.array = None\n",
    "    ):\n",
    "        if idxh_source is not None: self.idxh_source = idxh_source\n",
    "        else:\n",
    "            if self.settings.param_shuffle or begin:\n",
    "                self.idxh_source = self.idxh_source_full[   np.sort(np.random.choice(len(self.idxh_source_full),\n",
    "                                                            self.h_source, replace = False))]\n",
    "\n",
    "    # Target Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def target_param_shuffle(\n",
    "        self,\n",
    "        begin: bool = False,\n",
    "        idxh_target: np.array = None\n",
    "    ):\n",
    "        if idxh_target is not None: self.idxh_target = idxh_target\n",
    "        else:\n",
    "            if self.settings.param_shuffle or begin:\n",
    "                self.idxh_target = self.idxh_target_full[   np.sort(np.random.choice(len(self.idxh_target_full),\n",
    "                                                            self.h_target, replace = False))]\n",
    "                \n",
    "    # Target Slice Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def slice_shuffle(\n",
    "        self,\n",
    "        begin: bool = False,\n",
    "        idxv_slice: np.array = None\n",
    "    ):  \n",
    "        if idxv_slice is not None: self.idxv_slice = idxv_slice\n",
    "        else:\n",
    "            if self.settings.slice_shuffle or begin:\n",
    "                self.idxv_slice = self.idxv_slice_full[     np.sort(np.random.choice(len(self.idxv_slice_full),\n",
    "                                                            self.s_target, replace = False))]\n",
    "    \n",
    "    # Target Voxel & Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def shuffle(\n",
    "        self,\n",
    "        begin: bool = False,\n",
    "        idxh_source: np.array = None,\n",
    "        idxh_target: np.array = None,\n",
    "        idxv_slice: np.array = None\n",
    "    ):\n",
    "        self.source_param_shuffle(begin, idxh_source)\n",
    "        self.target_param_shuffle(begin, idxh_target)\n",
    "        self.slice_shuffle(begin, idxv_slice)\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Random Target Parameter for Training & Test Sets Generation Functionality\n",
    "    def label_gen(self):\n",
    "\n",
    "        # Target & Test Label Index File Generation\n",
    "        idxh_target = np.delete(np.arange(self.params.shape[0]), self.idxh_train)\n",
    "        if self.settings.test_target_param != 0:\n",
    "            idxh_test = idxh_target[np.sort(np.random.choice(len(idxh_target),\n",
    "                                    self.settings.test_target_param, replace = False))]\n",
    "            idxh_target = np.delete(idxh_target, np.where(np.in1d(idxh_target, idxh_test)))\n",
    "            for i in range(self.settings.test_target_param): assert(idxh_test[i] not in idxh_target\n",
    "                ), f\"ERROR: Target Parameter #{i} for Training & Test Sets not mutually Exclusive\"\n",
    "            \n",
    "            # Target & Test Label Index File Saving\n",
    "            print(f\">     Saving File Target Parameters for Training ({len(idxh_target)}) & Test {len(idxh_test)} Set's\")\n",
    "            np.savetxt(Path(f\"{self.settings.datasave_folderpath}/Test Labels (V{self.settings.data_version}).txt\"), idxh_test)\n",
    "            np.savetxt(Path(f\"{self.settings.datasave_folderpath}/Target Labels (V{self.settings.data_version}).txt\"), idxh_target)\n",
    "        if self.mode == 'Target': return idxh_target\n",
    "        else: return idxh_test\n",
    "        \n",
    "    # Label Scaler Download & Reverse Transformation\n",
    "    def label_unscale(\n",
    "        self,\n",
    "        y: np.array or pd.DataFrame\n",
    "    ):\n",
    "\n",
    "        # Label Scaler Download & Reverse Usage\n",
    "        try: self.scaler\n",
    "        except AttributeError:\n",
    "            scaler = torch.load(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "        return scaler.inverse_transform(y.reshape(1, -1))\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Cartesian to Polar Coordinate Conversion Functionality\n",
    "    def cart2polar(self, y: np.array):\n",
    "\n",
    "        # Cartesian to Polar Coordinates Conversion\n",
    "        phi = np.arccos(y[:, 2]).astype(np.float32); theta = np.arctan2(y[:, 1], y[:, 0])\n",
    "        theta = np.where(theta < 0, 2 * np.pi - np.abs(theta), theta).astype(np.float32)\n",
    "        theta = np.expand_dims(theta, axis = 1); phi = np.expand_dims(phi, axis = 1)\n",
    "        return pd.DataFrame(data = np.concatenate((theta, phi), axis = 1),\n",
    "                            columns = ['Gradient theta', 'Gradient phi'])\n",
    "\n",
    "    # Patient Mask Retrieval Functionality\n",
    "    def get_mask(settings, patient_id: int):\n",
    "        mask_filepath = Path(f\"{settings.mask_folderpath}/p{patient_id}.nii\")\n",
    "        assert(mask_filepath.exists()), f\"ERROR: Patient {patient_id}'s Mask not Found!\"\n",
    "        return load_img(mask_filepath)\n",
    "    \n",
    "    # Data Retrieval Functionality\n",
    "    def get_data(\n",
    "        settings,\n",
    "        patient_id: int,\n",
    "        idxv: int or np.array = None,\n",
    "        idxh_source: int or np.array = None,\n",
    "        idxh_target: int or np.array = None\n",
    "    ):\n",
    "        \n",
    "        # Dataset Download & Patient-Wise Splitting\n",
    "        data = h5py.File(settings.data_filepath, 'r').get('data1')\n",
    "        idxv_full = pd.read_csv(settings.info_filepath, index_col = 0).to_numpy()\n",
    "        idxv_full = idxv_full[np.isin(idxv_full[:, 1], patient_id), 0]                  # Patient-Specific Index Values\n",
    "        mask = MUDI_CVAE_GAN_2D.get_mask(settings, patient_id)                          # Patient-Specific Mask Download\n",
    "        \n",
    "        # Dataset Source Horizontal / Parameter & Vertical / Slice Indexing\n",
    "        if idxh_source is not None:\n",
    "            X_train = unmask(data[idxv_full, :][:, idxh_source].T, mask).get_fdata().T\n",
    "            if type(idxh_source) is int: X_train = np.expand_dims(X_train, axis = 0)\n",
    "            X_train = MUDI_CVAE_GAN_2D.zero_padding(X_train, settings.img_shape)\n",
    "            if type(idxh_source) is int: X_train = np.expand_dims(X_train[0, idxv, :, :], axis = 0)\n",
    "            else: X_train = X_train[:, idxv, :, :]\n",
    "        if idxh_target is None: return torch.Tensor(X_train)\n",
    "\n",
    "        # Dataset Target Horizontal / Parameter & Vertical / Slice Indexing\n",
    "        else:\n",
    "            X_target = unmask(data[idxv_full, :][:, idxh_target].T, mask).get_fdata().T\n",
    "            if type(idxh_target) is int: X_target = np.expand_dims(X_target, axis = 0)\n",
    "            X_target = MUDI_CVAE_GAN_2D.zero_padding(X_target, settings.img_shape)\n",
    "            if type(idxh_target) is int: X_target = np.expand_dims(X_target[0, idxv, :, :], axis = 0)\n",
    "            else: X_target = X_target[:, idxv, :, :]\n",
    "        return torch.Tensor(X_train), torch.Tensor(X_target)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D MUDI Dataset Initialization Class (Linear)\n",
    "class MUDI_CVAE_GAN_2D(Dataset):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,\n",
    "        subject: int or list,\n",
    "        mode: str = 'Target',\n",
    "        source_param: int or float = 100,\n",
    "        target_param: int or float = 100,\n",
    "        target_slice: int or float = 100\n",
    "    ):\n",
    "        \n",
    "        # Parameter & Patient Index Value Access\n",
    "        super(MUDI_CVAE_GAN_2D).__init__(); self.mode = mode\n",
    "        self.settings = settings; self.source_param = source_param\n",
    "        self.target_param = target_param; self.target_slice = target_slice\n",
    "        self.data = h5py.File(self.settings.data_filepath, 'r').get('data1')\n",
    "        self.params = pd.read_excel(self.settings.param_filepath)\n",
    "\n",
    "        # Vertical Splitting (Patient & Slice Selection)\n",
    "        self.idxv = pd.read_csv(self.settings.info_filepath,                    # List of Index Values ...\n",
    "                                index_col = 0).to_numpy()                       # ... pertaining to each Patient\n",
    "        self.idxv = self.idxv[np.isin(self.idxv[:, 1], subject), 0]             # Patient-Specific Index Values\n",
    "        self.mask = MUDI_CVAE_GAN_2D.get_mask(self.settings, subject[0])        # Patient-Specific Mask Download\n",
    "        self.data = unmask(self.data[self.idxv, :].T, self.mask).get_fdata().T  # Patient-Specific Image Unmasking\n",
    "        self.data = MUDI_CVAE_GAN_2D.zero_padding(self.data, self.settings.img_shape)   # Image Pre-Processing: Zero Padding\n",
    "        self.idxv_slice_full = np.arange(self.mask.shape[-1])                   # Full List of Available Image Slices\n",
    "\n",
    "        # Horizontal Splitting (Source & Target Parameter Selection)\n",
    "        idxh_source_filepath = Path(f\"{self.settings.datasave_folderpath}/Training Labels (V{self.settings.data_version}).txt\")\n",
    "        idxh_target_filepath = Path(f\"{self.settings.datasave_folderpath}/{self.mode} Labels (V{self.settings.data_version}).txt\")\n",
    "        self.idxh_source_full = np.sort(np.loadtxt(idxh_source_filepath)).astype(int)\n",
    "        if not idxh_target_filepath.exists(): self.idxh_target_full = self.label_gen()\n",
    "        else: self.idxh_target_full = np.sort(np.loadtxt(idxh_target_filepath)).astype(int)\n",
    "\n",
    "        # Vertical & Horizontal Sub-Sectioning & Shuffling\n",
    "        self.s_target = int((self.target_slice * len(self.idxv_slice_full)) / 100)\n",
    "        print(f\"     > Utilizing {self.s_target} \\ {len(self.idxv_slice_full)} of the Available Slices\")\n",
    "        self.h_source = int((self.source_param * len(self.idxh_source_full)) / 100)\n",
    "        self.h_target = int((self.target_param * len(self.idxh_target_full)) / 100); self.shuffle(True)\n",
    "        print(f\"     > Utilizing {self.h_source} \\ {len(self.idxh_source_full)} of the Training Parameters\")\n",
    "        print(f\"     > Utilizing {self.h_target} \\ {len(self.idxh_target_full)} of the Target Parameters\")\n",
    "        print(f\"     > Pre-Processing Images to be of Square Shape of {self.settings.img_shape}\")\n",
    "\n",
    "        # Parameter Selection & Value Normalization / Scaling\n",
    "        if self.settings.gradient_coord:\n",
    "            self.params = self.params.drop(columns = ['Gradient theta', 'Gradient phi'])                # Choosing of Gradient Orientation\n",
    "        else: self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])\n",
    "        if self.settings.label_norm == 'auto':\n",
    "            print(f\"     > Automatic Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "            self.scaler = StandardScaler()\n",
    "            self.params = pd.DataFrame( self.scaler.fit_transform(self.params),\n",
    "                                        columns = self.params.columns)\n",
    "            scaler_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "            if not scaler_filepath.exists(): torch.save(self.scaler, scaler_filepath)\n",
    "        elif self.settings.label_norm == 'manual':\n",
    "            print(f\"     > Manual Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "            self.params[['Gradient theta', 'Gradient phi']] = self.cart2polar(self.params[['Gradient x', 'Gradient y', 'Gradient z']].values)\n",
    "            self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])\n",
    "            self.params['b Value'] = self.params['b Value'] / 10000\n",
    "            self.params['TI'] = self.params['TI'] / 10000\n",
    "            self.params['TE'] = (self.params['TE'] - 80) / 200\n",
    "        else: print(f\"     > No Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "        assert(self.params.shape[1] == self.settings.num_labels), \"ERROR: Labels wrongly Deleted!\"\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # DataLoader Length / No. Batches Computation Functionality\n",
    "    def __len__(self): return self.s_target * self.h_source * self.h_target\n",
    "\n",
    "    # Image Zero-Padding Pre-Processing Method Functionality\n",
    "    def zero_padding(\n",
    "        data: np.array or torch.Tensor,\n",
    "        img_shape: int\n",
    "    ):\n",
    "\n",
    "        # Input Data Assertions\n",
    "        assert(data.ndim >= 3), \"ERROR: Pre-Processing Input Data has the Wrong Dimmensions\"\n",
    "        assert(img_shape >= int(data.shape[-2]) and img_shape >= int(data.shape[-1])\n",
    "        ), \"ERROR: Pre-Processed Output Data Shape is Larget than Input one!\"\n",
    "\n",
    "        # Zero-Padding Implementation\n",
    "        padding = np.array([0, 0, (img_shape - data.shape[-2]) / 2, (img_shape - data.shape[-1]) / 2])\n",
    "        padding = padding.reshape((1, -1)).T + np.array([0, 0])\n",
    "        padding[:, -1] = np.ceil(padding[:, -1]); padding[:, -2] = np.floor(padding[:, -2])\n",
    "        return np.pad(data, padding.astype(np.int32), 'constant')\n",
    "        \n",
    "    # Single-Batch Generation Functionality\n",
    "    def __getitem__(self, idx) -> tuple[np.ndarray, np.float32]:\n",
    "        \n",
    "        # Batch Vertical/Slice & Horizontal/Parameter Indexing\n",
    "        idxv_slice = idx % self.s_target                        # Batch's Vertical Index for X_train\n",
    "        idxh_source = (idx // self.s_target) % self.h_source    # Batch's Horizontal Index for y_train\n",
    "        idxh_target = idx // (self.s_target * self.h_source)    # Batch's Horizontal Index for y_target\n",
    "        #print(f\"Item #{idx} | Slice #{idxv_slice} | Source Parameter #{self.idxh_source[idxh_source]} | Target Parameter #{self.idxh_target[idxh_target]}\")\n",
    "\n",
    "        # Batch Data Generation\n",
    "        X_train = self.data[self.idxh_source[idxh_source], self.idxv_slice[idxv_slice], :, :]           # [1, 1, :, :] Training Image Slice Data\n",
    "        y_train = self.params.iloc[self.idxh_source[idxh_source]].values                                # [num_labels] Training Image Parameter Values\n",
    "        X_target = self.data[self.idxh_target[idxh_target], self.idxv_slice[idxv_slice], :, :]          # [1, 1, :, :] GT Target Image Slice Data\n",
    "        y_target = self.params.iloc[self.idxh_target[idxh_target]].values                               # [num_labels] Target Image Parameter Values\n",
    "        return {'X_train': np.array(X_train).reshape((1, X_train.shape[0], X_train.shape[1])).astype(np.float32),\n",
    "                'X_target': np.array(X_target).reshape((1, X_target.shape[0], X_target.shape[1])).astype(np.float32),\n",
    "                'y_train': np.ravel(y_train).astype(np.float32), 'y_target': np.ravel(y_target).astype(np.float32),\n",
    "                'idxv_slice': idxv_slice, 'slice_target': self.idxv_slice[idxv_slice],\n",
    "                'idxh_source': idxh_source, 'param_source': self.idxh_source[idxh_source],\n",
    "                'idxh_target': idxh_target, 'param_target': self.idxh_target[idxh_target]}\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Source Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def source_param_shuffle(\n",
    "        self,\n",
    "        begin: bool = False,\n",
    "        idxh_source: np.array = None\n",
    "    ):\n",
    "        if idxh_source is not None: self.idxh_source = idxh_source\n",
    "        else:\n",
    "            if self.settings.param_shuffle or begin:\n",
    "                self.idxh_source = self.idxh_source_full[   np.sort(np.random.choice(len(self.idxh_source_full),\n",
    "                                                            self.h_source, replace = False))]\n",
    "\n",
    "    # Target Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def target_param_shuffle(\n",
    "        self,\n",
    "        begin: bool = False,\n",
    "        idxh_target: np.array = None\n",
    "    ):\n",
    "        if idxh_target is not None: self.idxh_target = idxh_target\n",
    "        else:\n",
    "            if self.settings.param_shuffle or begin:\n",
    "                self.idxh_target = self.idxh_target_full[   np.sort(np.random.choice(len(self.idxh_target_full),\n",
    "                                                            self.h_target, replace = False))]\n",
    "                \n",
    "    # Target Slice Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def slice_shuffle(\n",
    "        self,\n",
    "        begin: bool = False,\n",
    "        idxv_slice: np.array = None\n",
    "    ):  \n",
    "        if idxv_slice is not None: self.idxv_slice = idxv_slice\n",
    "        else:\n",
    "            if self.settings.slice_shuffle or begin:\n",
    "                self.idxv_slice = self.idxv_slice_full[     np.sort(np.random.choice(len(self.idxv_slice_full),\n",
    "                                                            self.s_target, replace = False))]\n",
    "    \n",
    "    # Target Voxel & Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def shuffle(\n",
    "        self,\n",
    "        begin: bool = False,\n",
    "        idxh_source: np.array = None,\n",
    "        idxh_target: np.array = None,\n",
    "        idxv_slice: np.array = None\n",
    "    ):\n",
    "        self.source_param_shuffle(begin, idxh_source)\n",
    "        self.target_param_shuffle(begin, idxh_target)\n",
    "        self.slice_shuffle(begin, idxv_slice)\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Random Target Parameter for Training & Test Sets Generation Functionality\n",
    "    def label_gen(self):\n",
    "\n",
    "        # Target & Test Label Index File Generation\n",
    "        idxh_target = np.delete(np.arange(self.params.shape[0]), self.idxh_train)\n",
    "        if self.settings.test_target_param != 0:\n",
    "            idxh_test = idxh_target[np.sort(np.random.choice(len(idxh_target),\n",
    "                                    self.settings.test_target_param, replace = False))]\n",
    "            idxh_target = np.delete(idxh_target, np.where(np.in1d(idxh_target, idxh_test)))\n",
    "            for i in range(self.settings.test_target_param): assert(idxh_test[i] not in idxh_target\n",
    "                ), f\"ERROR: Target Parameter #{i} for Training & Test Sets not mutually Exclusive\"\n",
    "            \n",
    "            # Target & Test Label Index File Saving\n",
    "            print(f\">     Saving File Target Parameters for Training ({len(idxh_target)}) & Test {len(idxh_test)} Set's\")\n",
    "            np.savetxt(Path(f\"{self.settings.datasave_folderpath}/Test Labels (V{self.settings.data_version}).txt\"), idxh_test)\n",
    "            np.savetxt(Path(f\"{self.settings.datasave_folderpath}/Target Labels (V{self.settings.data_version}).txt\"), idxh_target)\n",
    "        if self.mode == 'Target': return idxh_target\n",
    "        else: return idxh_test\n",
    "        \n",
    "    # Label Scaler Download & Reverse Transformation\n",
    "    def label_unscale(\n",
    "        self,\n",
    "        y: np.array or pd.DataFrame\n",
    "    ):\n",
    "\n",
    "        # Label Scaler Download & Reverse Usage\n",
    "        try: self.scaler\n",
    "        except AttributeError:\n",
    "            scaler = torch.load(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "        return scaler.inverse_transform(y.reshape(1, -1))\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Cartesian to Polar Coordinate Conversion Functionality\n",
    "    def cart2polar(self, y: np.array):\n",
    "\n",
    "        # Cartesian to Polar Coordinates Conversion\n",
    "        phi = np.arccos(y[:, 2]).astype(np.float32); theta = np.arctan2(y[:, 1], y[:, 0])\n",
    "        theta = np.where(theta < 0, 2 * np.pi - np.abs(theta), theta).astype(np.float32)\n",
    "        theta = np.expand_dims(theta, axis = 1); phi = np.expand_dims(phi, axis = 1)\n",
    "        return pd.DataFrame(data = np.concatenate((theta, phi), axis = 1),\n",
    "                            columns = ['Gradient theta', 'Gradient phi'])\n",
    "\n",
    "    # Patient Mask Retrieval Functionality\n",
    "    def get_mask(settings, patient_id: int):\n",
    "        mask_filepath = Path(f\"{settings.mask_folderpath}/p{patient_id}.nii\")\n",
    "        assert(mask_filepath.exists()), f\"ERROR: Patient {patient_id}'s Mask not Found!\"\n",
    "        return load_img(mask_filepath)\n",
    "    \n",
    "    # Data Retrieval Functionality\n",
    "    def get_data(\n",
    "        settings,\n",
    "        patient_id: int,\n",
    "        idxv: int or np.array = None,\n",
    "        idxh_source: int or np.array = None,\n",
    "        idxh_target: int or np.array = None\n",
    "    ):\n",
    "        \n",
    "        # Dataset Download & Patient-Wise Splitting\n",
    "        data = h5py.File(settings.data_filepath, 'r').get('data1')\n",
    "        idxv_full = pd.read_csv(settings.info_filepath, index_col = 0).to_numpy()\n",
    "        idxv_full = idxv_full[np.isin(idxv_full[:, 1], patient_id), 0]                  # Patient-Specific Index Values\n",
    "        mask = MUDI_CVAE_GAN_2D.get_mask(settings, patient_id)                          # Patient-Specific Mask Download\n",
    "        \n",
    "        # Dataset Source Horizontal / Parameter & Vertical / Slice Indexing\n",
    "        if idxh_source is not None:\n",
    "            X_train = unmask(data[idxv_full, :][:, idxh_source].T, mask).get_fdata().T\n",
    "            if type(idxh_source) is int: X_train = np.expand_dims(X_train, axis = 0)\n",
    "            X_train = MUDI_CVAE_GAN_2D.zero_padding(X_train, settings.img_shape)\n",
    "            if type(idxh_source) is int: X_train = np.expand_dims(X_train[0, idxv, :, :], axis = 0)\n",
    "            else: X_train = X_train[:, idxv, :, :]\n",
    "        if idxh_target is None: return torch.Tensor(X_train)\n",
    "\n",
    "        # Dataset Target Horizontal / Parameter & Vertical / Slice Indexing\n",
    "        else:\n",
    "            X_target = unmask(data[idxv_full, :][:, idxh_target].T, mask).get_fdata().T\n",
    "            if type(idxh_target) is int: X_target = np.expand_dims(X_target, axis = 0)\n",
    "            X_target = MUDI_CVAE_GAN_2D.zero_padding(X_target, settings.img_shape)\n",
    "            if type(idxh_target) is int: X_target = np.expand_dims(X_target[0, idxv, :, :], axis = 0)\n",
    "            else: X_target = X_target[:, idxv, :, :]\n",
    "        return torch.Tensor(X_train), torch.Tensor(X_target)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     > Pre-Processing Images to be of Square Shape of 96\n",
      "     > Utilizing 33 \\ 56 of the Available Slices\n",
      "     > Utilizing 500 \\ 500 of the Training Parameters\n",
      "     > Utilizing 844 \\ 844 of the Target Parameters\n",
      "     > Manual Normalization of all 5 Parameter Values\n"
     ]
    }
   ],
   "source": [
    "# Dataset & DataLoader Initialization\n",
    "trainset = MUDI_CVAE_GAN_2D(settings, subject = [11],\n",
    "                            source_param = settings.train_source_param,\n",
    "                            target_param = settings.train_target_param,\n",
    "                            target_slice = settings.train_target_slice)\n",
    "trainloader = DataLoader(   dataset = trainset, pin_memory = False,\n",
    "                            shuffle = True,#settings.val_sample_shuffle,\n",
    "                            num_workers = 0,#settings.num_workers,\n",
    "                            batch_size = 100)#len(trainset.idxv_target),#settings.batch_size,\n",
    "\n",
    "# Image Example Subplotting\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Model* **Architecture**\n",
    "\n",
    "https://github.com/Ram81/AC-VAEGAN-PyTorch/blob/master/model.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CVAE** (*Conditional Variational AutoEncoder*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CVAE Encoder Main Block Class\n",
    "class EncoderBlock(nn.Module):\n",
    "\n",
    "    # Block Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int = 3,\n",
    "        stride: int = 2,\n",
    "        padding: int = 1,\n",
    "        momentum: float = 0.9\n",
    "    ):\n",
    "\n",
    "        # Class Variable Logging\n",
    "        super().__init__()\n",
    "        self.block_conv = nn.Conv2d(in_channels = in_channels, out_channels = out_channels,\n",
    "                                    kernel_size = kernel_size, stride = stride, padding = padding)\n",
    "        self.block_rest = nn.Sequential(\n",
    "                    nn.BatchNorm2d( num_features = out_channels, momentum = momentum),\n",
    "                    nn.ReLU(        inplace = False))\n",
    "\n",
    "    # Block Application Function\n",
    "    def forward(self, X, recon: bool = False):\n",
    "        layer_rep = self.block_conv(X)\n",
    "        out = self.block_rest(layer_rep)\n",
    "        if recon: return out, layer_rep\n",
    "        else: return out\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# CVAE Encoder Model Class\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser\n",
    "    ):\n",
    "        \n",
    "        # CVAE Encoder Convolutional Architecture Definition\n",
    "        super().__init__(); self.settings = settings; encoder_conv = []\n",
    "        in_channels = 1; out_channels = int(self.settings.dim_latent / 2)\n",
    "        for i in range(self.settings.num_hidden):\n",
    "            #print(f\"{in_channels} -> {out_channels}\")\n",
    "            encoder_conv.append(EncoderBlock(   in_channels = in_channels,\n",
    "                                                out_channels = out_channels,\n",
    "                                                kernel_size = self.settings.kernel_size,\n",
    "                                                padding = self.settings.padding))\n",
    "            in_channels = out_channels; out_channels *= 2\n",
    "        self.encoder_conv = nn.Sequential(*encoder_conv)\n",
    "\n",
    "        # CVAE Encoder Linear Architecture Definition\n",
    "        img_shape = np.ceil(self.settings.img_shape / (2 ** (self.settings.num_hidden)))\n",
    "        in_channels = int(in_channels * (img_shape ** 2))\n",
    "        self.encoder_fc = nn.Sequential(\n",
    "                                nn.Linear(      in_features = in_channels,\n",
    "                                                out_features = self.settings.dim_hidden, bias = False),\n",
    "                                nn.BatchNorm1d( num_features = self.settings.dim_hidden, momentum = 0.9),\n",
    "                                nn.ReLU(        inplace = True))\n",
    "        self.encoder_mu = nn.Linear(            in_features = self.settings.dim_hidden + self.settings.num_labels,\n",
    "                                                out_features = self.settings.dim_latent)\n",
    "        self.encoder_logvar = nn.Linear(        in_features = self.settings.dim_hidden + self.settings.num_labels,\n",
    "                                                out_features = self.settings.dim_latent)\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # CVAE Encoder Application Function\n",
    "    def forward(\n",
    "        self,\n",
    "        X_train: np.ndarray or torch.Tensor,\n",
    "        y_train: np.ndarray or torch.Tensor\n",
    "    ): \n",
    "        out = self.encoder_conv(X_train)            # Convolutional Section Application\n",
    "        out = out.view(len(out), -1)                # Output Linearization\n",
    "        out = self.encoder_fc(out)                  # Linear Section Application\n",
    "        out = torch.cat((out, y_train), dim = 1)    # Inclusion of Training Labels\n",
    "        mu = self.encoder_mu(out)                   # Mean Computation\n",
    "        logvar = self.encoder_logvar(out)           # Log Variance Computation\n",
    "        return mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CVAE Decoder Main Block Class\n",
    "class DecoderBlock(nn.Module):\n",
    "\n",
    "    # Block Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int = 3,\n",
    "        stride: int = 2,\n",
    "        padding: int = 1,\n",
    "        momentum: float = 0.9\n",
    "    ):\n",
    "\n",
    "        # Class Variable Logging\n",
    "        super().__init__(); block = []\n",
    "        block.append(nn.Sequential(\n",
    "                        nn.ConvTranspose2d( in_channels = in_channels, out_channels = out_channels,\n",
    "                                            kernel_size = kernel_size, stride = stride,\n",
    "                                            padding = padding, output_padding = 1, bias = False),\n",
    "                        nn.BatchNorm2d(     num_features = out_channels, momentum = momentum), nn.ReLU()))\n",
    "        self.block = nn.Sequential(*block)\n",
    "\n",
    "    # Block Application Function\n",
    "    def forward(self, X): return self.block(X)\n",
    "                            \n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# CVAE Decoder Model Class\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser\n",
    "    ):\n",
    "\n",
    "        # CVAE Decoder Linear Architecture Definition\n",
    "        super().__init__(); self.settings = settings\n",
    "        self.img_shape = int(np.ceil(self.settings.img_shape / (2 ** (self.settings.num_hidden))))\n",
    "        out_channels = int((self.settings.dim_latent / 2) * (2 ** (self.settings.num_hidden - 1)) * (self.img_shape ** 2))\n",
    "        self.decoder_fc = nn.Sequential(\n",
    "                                nn.Linear(      in_features = self.settings.dim_latent + self.settings.num_labels,\n",
    "                                                out_features = out_channels, bias = False),\n",
    "                                nn.BatchNorm1d( num_features = out_channels, momentum = 0.9),\n",
    "                                nn.ReLU(inplace = True))\n",
    "\n",
    "        # CVAE Decoder Convolutional Architecture Definition\n",
    "        in_channels = int(out_channels / (self.img_shape ** 2))\n",
    "        decoder_conv = []; out_channels = self.settings.dim_latent * 2\n",
    "        for i in range(self.settings.num_hidden):\n",
    "            #print(f\"{in_channels} -> {out_channels}\")\n",
    "            decoder_conv.append(DecoderBlock(   in_channels = in_channels,\n",
    "                                                out_channels = out_channels,\n",
    "                                                kernel_size = self.settings.kernel_size,\n",
    "                                                padding = self.settings.padding))\n",
    "            in_channels = out_channels; out_channels = int(out_channels / 2)\n",
    "        decoder_conv.append(nn.Sequential(\n",
    "                                    nn.Conv2d(  in_channels = in_channels, out_channels = 1,\n",
    "                                                kernel_size = self.settings.kernel_size,\n",
    "                                                padding = self.settings.padding), nn.Tanh()))\n",
    "        self.decoder_conv = nn.Sequential(*decoder_conv)\n",
    "                \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Reparametrization Trick Functionality\n",
    "    def reparam(mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + (eps * std)\n",
    "    \n",
    "    # Kullback-Leibler Divergence Computation Functionality\n",
    "    def kl_loss(mu, logvar):\n",
    "        return -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # CVAE Decoder Application Function\n",
    "    def forward(\n",
    "        self,\n",
    "        z: np.ndarray or torch.Tensor,\n",
    "        y_target: np.ndarray or torch.Tensor\n",
    "    ): \n",
    "        out = torch.cat((z, y_target), dim = 1)     # Inclusion of Target Labels\n",
    "        out = self.decoder_fc(out)                  # Linear Section Application\n",
    "        out = out.view( len(out), -1,\n",
    "                        self.img_shape,\n",
    "                        self.img_shape)             # Output Dimensionalization\n",
    "        return self.decoder_conv(out)               # Convolutional Section Application\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CVAE Model Class\n",
    "class CVAE(nn.Module):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser\n",
    "    ):\n",
    "        super().__init__(); self.settings = settings\n",
    "        self.encoder = Encoder(self.settings)\n",
    "        self.decoder = Decoder(self.settings)\n",
    "\n",
    "    # CVAE Model Application Function\n",
    "    def forward(\n",
    "        self,\n",
    "        X_train: np.ndarray or torch.Tensor,\n",
    "        y_train: np.ndarray or torch.Tensor,\n",
    "        y_target: np.ndarray or torch.Tensor\n",
    "    ):\n",
    "        mu, logvar = self.encoder(X_train, y_train)     # Encoder Model Application\n",
    "        z = self.reparam(mu, logvar)                    # Reparametrization Trick\n",
    "        kl = CVAE.kl_loss(mu, logvar)                   # Kullback-Leibler Loss Computation\n",
    "        return self.decoder(z, y_target)                # Decoder Model Application\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Reparametrization Trick Functionality\n",
    "    def reparam(mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + (eps * std)\n",
    "    \n",
    "    # Kullback-Leibler Divergence Computation Functionality\n",
    "    def kl_loss(mu, logvar):\n",
    "        return -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Initialization\n",
    "X_train = torch.rand((  10, 1, settings.img_shape,\n",
    "                        settings.img_shape))\n",
    "y_train = torch.rand((10, 5))\n",
    "y_target = torch.rand((10, 5))\n",
    "\n",
    "# Segmented CVAE Model Usage Example\n",
    "encoder = Encoder(settings)\n",
    "mu, logvar = encoder(X_train, y_train)\n",
    "z = torch.rand((10, settings.dim_latent))\n",
    "decoder = Decoder(settings)\n",
    "X_target1 = decoder(z, y_target)\n",
    "\n",
    "# Full CVAE Model Usage Example\n",
    "model = CVAE(settings); print(model)\n",
    "X_target = model(X_train, y_train, y_target)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **GAN** (*Generative Adversarial Network*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN Discriminator Model Class\n",
    "class Discriminator(nn.Module):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser\n",
    "    ):\n",
    "        \n",
    "        # GAN Discriminator Convolutional Architecture Definition #1\n",
    "        super().__init__(); self.settings = settings\n",
    "        self.discriminator_conv = nn.ModuleList()\n",
    "        out_channels = self.settings.dim_latent // 4\n",
    "        self.discriminator_conv.append(nn.Sequential(\n",
    "                    nn.Conv2d(  in_channels = 1, out_channels = out_channels,\n",
    "                                kernel_size = self.settings.kernel_size,\n",
    "                                padding = self.settings.padding),\n",
    "                    nn.ReLU(    inplace = True)))\n",
    "\n",
    "        # GAN Discriminator Convolutional Architecture Definition #2\n",
    "        for i in range(self.settings.num_hidden):\n",
    "            #print(f\"{in_channels} -> {out_channels}\")\n",
    "            in_channels = out_channels\n",
    "            if i == 0: out_channels *= 4\n",
    "            else: out_channels *= 2\n",
    "            if i == self.settings.num_hidden - 1: out_channels //= 2\n",
    "            self.discriminator_conv.append(\n",
    "                EncoderBlock(   in_channels = in_channels,\n",
    "                                out_channels = out_channels,\n",
    "                                kernel_size = self.settings.kernel_size,\n",
    "                                padding = self.settings.padding))\n",
    "            \n",
    "        # GAN Discriminator Linear Architecture Definition\n",
    "        self.img_shape = int(np.ceil(self.settings.img_shape / (2 ** (self.settings.num_hidden))))\n",
    "        self.discriminator_fc = nn.Sequential(\n",
    "                nn.Linear(      in_features = out_channels * (self.img_shape ** 2),\n",
    "                                out_features = self.settings.dim_hidden // 2, bias = False),\n",
    "                nn.BatchNorm1d( num_features = self.settings.dim_hidden // 2,\n",
    "                                momentum = 0.9), nn.ReLU(inplace = True))\n",
    "        self.discriminator_pred = nn.Sequential(\n",
    "                    nn.Linear(  in_features = self.settings.dim_hidden // 2,\n",
    "                                out_features = 1), nn.Sigmoid())\n",
    "        self.discriminator_label = nn.Sequential(\n",
    "                    nn.Linear(  in_features = self.settings.dim_hidden // 2,\n",
    "                                out_features = self.settings.num_labels), nn.LogSoftmax())\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # GAN Discriminator Model Application Function\n",
    "    def forward(\n",
    "        self,\n",
    "        X_train: np.ndarray or torch.Tensor,\n",
    "        X_target: np.ndarray or torch.Tensor,\n",
    "        recon: bool = False\n",
    "    ):\n",
    "\n",
    "        # GAN Discriminator Convolutional Architecture Application\n",
    "        input = torch.cat((X_train, X_target), dim = 0)\n",
    "        if recon:\n",
    "            for i, layer in enumerate(self.discriminator_conv):\n",
    "                if i != self.settings.recon_level: input = layer(input)\n",
    "                else:\n",
    "                    input, recon_pred = layer(input, recon = True)          # Layer Representations Output\n",
    "                    return recon_pred.view(len(recon_pred), -1)             # for both Input & Reconstructed Image\n",
    "        else:\n",
    "            for i, layer in enumerate(self.discriminator_conv): input = layer(input)\n",
    "        \n",
    "        # GAN Discriminator Linear Architecture Application\n",
    "        out = input.view(len(input), -1)\n",
    "        out = self.discriminator_fc(out)\n",
    "        auth_pred = self.discriminator_pred(out)        # Real vs Fake Prediction\n",
    "        #label_pred = self.discriminator_label(out)      # Label Value Prediction\n",
    "        return auth_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D CVAE-GAN Model Class\n",
    "class CVAE_GAN_2D(nn.Module):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser\n",
    "    ):\n",
    "        \n",
    "        # CVAE-GAN Architecture Definition\n",
    "        super().__init__(); self.settings = settings\n",
    "        self.encoder = Encoder(self.settings)\n",
    "        self.decoder = Decoder(self.settings)\n",
    "        self.discriminator = Discriminator(self.settings)\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Reparametrization Trick Functionality\n",
    "    def reparam(mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + (eps * std)\n",
    "    \n",
    "    # Kullback-Leibler Divergence Computation Functionality\n",
    "    def kl_loss(mu, logvar):\n",
    "        return -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # CVAE-GAN Model Application Function\n",
    "    def forward(\n",
    "        self,\n",
    "        X_train: np.ndarray or torch.Tensor,\n",
    "        y_train: np.ndarray or torch.Tensor,\n",
    "        y_target: np.ndarray or torch.Tensor,\n",
    "    ):\n",
    "\n",
    "        # CVAE-GAN Application\n",
    "        mu, logvar = self.encoder(X_train, y_train)         # Encoder Model Application\n",
    "        z = CVAE_GAN_2D.reparam(mu, logvar)                 # Reparametrization Trick\n",
    "        kl_loss = CVAE_GAN_2D.kl_loss(mu, logvar)           # Kullback-Leibler Loss Computation\n",
    "        X_target = self.decoder(z, y_target)                # Decoder Model Application\n",
    "        auth_pred = self.discriminator(X_train, X_target)   # Discriminator Model Application\n",
    "        return X_target, auth_pred, kl_loss\n",
    "\n",
    "        # GAN Application\n",
    "        #layer_rep = self.discriminator(X_target, X_train, True)     # Discriminator for Reconstruction\n",
    "        #z_gauss = torch.randn_like(logvar)                          # Gaussian Distribution Noise\n",
    "        #X_fake = self.decoder(z_gauss, y_target)                    # Decoder for Generation\n",
    "        #auth_pred, label_pred = self.discriminator(X_train, X_fake) # Discriminator for Authenticity Prediction\n",
    "        #return X_target, X_fake, auth_pred, label_pred, layer_rep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Initialization\n",
    "X_train = torch.rand((  10, 1, settings.img_shape,\n",
    "                        settings.img_shape))\n",
    "y_train = torch.rand((10, 5))\n",
    "X_target = torch.rand(( 10, 1, settings.img_shape,\n",
    "                        settings.img_shape))\n",
    "y_target = torch.rand((10, 5))\n",
    "\n",
    "# GAN Discriminator Model Usage Example\n",
    "discriminator = Discriminator(settings)\n",
    "auth_pred1 = discriminator(X_train, X_target)\n",
    "\n",
    "# Full CVAE-GAN Model Usage Example\n",
    "model = CVAE_GAN_2D(settings)\n",
    "X_target, auth_pred, kl_loss = model(X_train, y_train, y_target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training** *Script*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D CVAE-GAN Model Training Script (V0)\n",
    "def CVAE_GAN_2D_train(\n",
    "    settings,\n",
    "):\n",
    "\n",
    "    ##############################################################################################\n",
    "    # ------------------------------------ Setup | DataLoader ------------------------------------\n",
    "    ##############################################################################################\n",
    "\n",
    "    # Seed Random State for Reproducibility\n",
    "    torch.manual_seed(settings.seed)\n",
    "    np.random.seed(settings.seed)\n",
    "    random.seed(settings.seed)\n",
    "\n",
    "    # Experiment Logs Directories Initialization\n",
    "    checkpoint_folderpath = os.path.join(f'{settings.modelsave_folderpath}/V{settings.model_version}', 'logs')\n",
    "    train_enc_logger = TensorBoardLogger(checkpoint_folderpath, 'train/encoder'); val_enc_logger = TensorBoardLogger(checkpoint_folderpath, 'validation/encoder')\n",
    "    train_dec_logger = TensorBoardLogger(checkpoint_folderpath, 'train/decoder'); val_dec_logger = TensorBoardLogger(checkpoint_folderpath, 'validation/decoder')\n",
    "    train_gan_logger = TensorBoardLogger(checkpoint_folderpath, 'train/discriminator'); val_gan_logger = TensorBoardLogger(checkpoint_folderpath, 'validation/discriminator')\n",
    "\n",
    "    # Training & Validation DataLoaders Initialization\n",
    "    train_set = []; val_set = []; viz_logger = []\n",
    "    train_loader = []; val_loader = []\n",
    "    for p, patient_id in enumerate(settings.patient_list):\n",
    "\n",
    "        # Patient Set & DataLoader Initialization\n",
    "        if patient_id in settings.train_patient_list:\n",
    "            print(f\"Patient #{patient_id} | Training Set:\")\n",
    "            train_set.append(   MUDI_CVAE_GAN_2D(   settings, subject = [patient_id],\n",
    "                                                    source_param = settings.train_source_param,\n",
    "                                                    target_param = settings.train_target_param,\n",
    "                                                    target_slice = settings.train_target_slice))\n",
    "            train_loader.append(DataLoader(         dataset = train_set[-1], pin_memory = True,\n",
    "                                                    shuffle = settings.train_sample_shuffle,\n",
    "                                                    num_workers = settings.num_workers,\n",
    "                                                    batch_size = settings.batch_size))\n",
    "            \n",
    "        elif patient_id in settings.val_patient_list:\n",
    "            print(f\"Patient #{patient_id} | Validation Set:\")\n",
    "            val_set.append(     MUDI_CVAE_GAN_2D(   settings, subject = [patient_id],\n",
    "                                                    source_param = settings.train_source_param,\n",
    "                                                    target_param = settings.train_target_param,\n",
    "                                                    target_slice = settings.train_target_slice))\n",
    "            val_loader.append(  DataLoader(         dataset = val_set[-1], pin_memory = True,\n",
    "                                                    shuffle = settings.val_sample_shuffle,\n",
    "                                                    num_workers = settings.num_workers,\n",
    "                                                    batch_size = val_set[-1].s_target))\n",
    "            viz_logger.append(  TensorBoardLogger(checkpoint_folderpath, f'validation/p{patient_id}'))\n",
    "            \n",
    "        else: print(f\"Patient #{patient_id} | Test Set:     > Not Included\")\n",
    "    \n",
    "    ##############################################################################################\n",
    "    # -------------------------------- Setup | Models & Optimizers -------------------------------\n",
    "    ##############################################################################################\n",
    "\n",
    "    # Model Initialization\n",
    "    print(f\"Running\\n     > Training 2D CVAE-GAN Model with {torch.cuda.device_count()} GPUs!\")\n",
    "    enc_model = nn.DataParallel(Encoder(settings), device_ids = settings.device_ids).to(settings.device)\n",
    "    dec_model = nn.DataParallel(Decoder(settings), device_ids = settings.device_ids).to(settings.device)\n",
    "    gan_model = nn.DataParallel(Discriminator(settings), device_ids = settings.device_ids).to(settings.device)\n",
    "\n",
    "    # Optimizer Initialization\n",
    "    enc_optimizer = torch.optim.AdamW(  enc_model.parameters(), lr = settings.base_lr,\n",
    "                                        weight_decay = settings.weight_decay)\n",
    "    dec_optimizer = torch.optim.AdamW(  dec_model.parameters(), lr = settings.base_lr,\n",
    "                                        weight_decay = settings.weight_decay)\n",
    "    gan_optimizer = torch.optim.AdamW(  gan_model.parameters(), lr = settings.base_lr,\n",
    "                                        weight_decay = settings.weight_decay)\n",
    "\n",
    "    # Learning Rate Scheduling\n",
    "    gan_equilibrium = settings.base_equilibrium; gan_margin = settings.base_margin\n",
    "    #enc_lr = ExponentialLR(enc_optimizer, gamma = settings.decay_lr)\n",
    "    #dec_lr = ExponentialLR(dec_optimizer, gamma = settings.decay_lr)\n",
    "    #gan_lr = ExponentialLR(gan_optimizer, gamma = settings.decay_lr)\n",
    "\n",
    "    # Criterion & Early Stopping Setup\n",
    "    mse_criterion = nn.MSELoss(reduction = 'mean')\n",
    "    bce_criterion = nn.BCELoss(reduction = 'mean')\n",
    "    ssim_criterion = SSIM(window_size = settings.kernel_size)\n",
    "    earlyStopping = EarlyStopping(settings); train_iter = 0; val_iter = 0\n",
    "\n",
    "    # Model Checkpoint Loading\n",
    "    model_filepath = Path(f\"{settings.modelsave_folderpath}/V{settings.model_version}/Best 2D CVAE-GAN.pt\")\n",
    "    if model_filepath.exists():\n",
    "        checkpoint = torch.load(model_filepath, map_location = settings.device)\n",
    "        enc_model.load_state_dict(checkpoint['Encoder Model']); enc_optimizer.load_state_dict(checkpoint['Encoder Optimizer'])\n",
    "        dec_model.load_state_dict(checkpoint['Decoder Model']); dec_optimizer.load_state_dict(checkpoint['Decoder Optimizer'])\n",
    "        gan_model.load_state_dict(checkpoint['Discriminator Model']); gan_optimizer.load_state_dict(checkpoint['Discriminator Optimizer'])\n",
    "        train_iter = checkpoint['Current Iteration']; val_iter = checkpoint['Current Validation Iteration']\n",
    "        save_epoch = checkpoint['Current Epoch']; torch.set_rng_state(checkpoint['RNG State'])\n",
    "        print(f\"     > Loading 2D CVAE-GAN Model for {settings.model_version}: {save_epoch} Past Epochs\"); del checkpoint\n",
    "    else: save_epoch = -1\n",
    "    \n",
    "    # Epoch Iteration Loop\n",
    "    for epoch in range(save_epoch + 1, settings.num_epochs):\n",
    "\n",
    "        ##############################################################################################\n",
    "        # ----------------------------------- Training | Iteration -----------------------------------\n",
    "        ##############################################################################################\n",
    "\n",
    "        # Result Value Initialization\n",
    "        best_train_enc_mse = 1000; worst_train_enc_mse = 0\n",
    "        best_train_dec_ssim = 0; worst_train_dec_ssim = 1000\n",
    "        best_train_dec_mse = 1000; worst_train_dec_mse = 0\n",
    "        train_enc_mse = []; train_enc_loss = []; train_dec_ssim = []\n",
    "        train_dec_kld = []; train_dec_mse = []; train_dec_nle = []; train_dec_bce = []\n",
    "        train_dec_loss = []; train_gan_bce = []; train_gan_loss = []\n",
    "\n",
    "        # Training Patient Loop\n",
    "        print(f\"Training Epoch #{epoch}:\")\n",
    "        for p, patient_id in enumerate(settings.train_patient_list):\n",
    "\n",
    "            # Training Iteration Loop\n",
    "            mask = MUDI_CVAE_GAN_2D.get_mask(settings, num_patient = patient_id)\n",
    "            train_bar = tqdm(   enumerate(train_loader[p]), total = len(train_loader[p]),\n",
    "                desc = f'Epoch #{epoch} | Training Patient {patient_id}', unit = 'Batches')\n",
    "            for batch_idx, batch in train_bar:\n",
    "\n",
    "                # --------------------------------------------------------------------------------------------\n",
    "\n",
    "                # Model & Optimizer Setup\n",
    "                enc_model.train(); enc_model.zero_grad(); enc_optimizer.zero_grad()\n",
    "                dec_model.train(); dec_model.zero_grad(); dec_optimizer.zero_grad()\n",
    "                gan_model.train(); gan_model.zero_grad(); gan_optimizer.zero_grad()\n",
    "\n",
    "                # Forward Propagation\n",
    "                mu, logvar = enc_model(  batch['X_train'].to(settings.device),\n",
    "                                            batch['y_train'].to(settings.device))       # Encoder Model Application\n",
    "                z = Decoder.reparam(mu, logvar)                                         # Reparametrization Trick\n",
    "                X_target = dec_model(z, batch['y_target'].to(settings.device))          # Decoder Model Application\n",
    "                dec_pred = gan_model(  batch['X_train'].to(settings.device),            # Discriminator Model Application for Image Reconstruction Authentication\n",
    "                                                batch['X_target'].to(settings.device), recon = True)\n",
    "                dec_train = dec_pred[:len(dec_pred) // 2]; dec_target = dec_pred[len(dec_pred) // 2:]\n",
    "                gan_pred = gan_model(  batch['X_train'].to(settings.device),            # Discriminator Model Application for Target Image Authentication\n",
    "                                                batch['X_target'].to(settings.device))\n",
    "                gan_train = gan_pred[:len(gan_pred) // 2]; gan_target = gan_pred[len(gan_pred) // 2:]\n",
    "                gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "                # --------------------------------------------------------------------------------------------\n",
    "\n",
    "                # CVAE Model Loss Computation\n",
    "                mse_enc = mse_criterion(dec_train, dec_target)                                      # Mean Squared Error Loss (Encoder)\n",
    "                ssim_loss = ssim_criterion(X_target.detach().cpu().numpy(), batch['X_target'])      # Structural Similarity Index (Decoder)\n",
    "                ssim_loss = np.mean(ssim_loss); del ssim_img                                        # Structural Similarity Index (Decoder)\n",
    "                kld_loss = Decoder.kl_loss(mu, logvar); del mu, logvar, z                           # Kullback-Leibler Divergence Loss\n",
    "                enc_loss = torch.sum(kld_loss) + torch.sum(mse_enc)                                 # Full CVAE Encoder Loss\n",
    "\n",
    "                # GAN Model Loss Computation\n",
    "                mse_dec = mse_criterion(X_target, batch['X_target'].to(settings.device))            # Mean Squared Error Loss (Decoder)\n",
    "                nle_loss = - X_target.view((len(X_target), -1)) ** 2 + 0.5 *\\\n",
    "                    (batch['X_target'].to(settings.device).view(len(batch['X_target']), -1))        # Normal Loss Expectancy\n",
    "                bce_dec_train = -torch.log(1 - dec_train); bce_dec_target = -torch.log(dec_target)  # Binary Cross Entropy (Decoder)\n",
    "                bce_gan_train = -torch.log(gan_train); bce_gan_target = -torch.log(1 - gan_target)  # Binary Cross Entropy (Discriminator)\n",
    "                gan_loss = torch.sum(bce_dec_train) + torch.sum(bce_dec_target)                     # Full GAN Discriminator Loss\n",
    "                dec_loss = torch.sum(settings.lambda_mse * mse_dec) - gan_loss                      # Full CVAE Decoder Loss\n",
    "\n",
    "                # --------------------------------------------------------------------------------------------\n",
    "                            \n",
    "                # Adversarial Training\n",
    "                gan_train = True; dec_train = True\n",
    "                if torch.mean(bce_gan_train).data < gan_equilibrium - gan_margin or\\\n",
    "                    torch.mean(bce_gan_target).data < gan_equilibrium - gan_margin: gan_train = False\n",
    "                if torch.mean(bce_gan_train).data > gan_equilibrium + gan_margin or\\\n",
    "                    torch.mean(bce_gan_target).data > gan_equilibrium + gan_margin: dec_train = False\n",
    "                if gan_train is False and dec_train is False: gan_train = True; dec_train = True\n",
    "                \n",
    "                # Backward Propagation\n",
    "                enc_loss.backward(retain_graph = True); enc_optimizer.step()\n",
    "                if dec_train:\n",
    "                    dec_loss.backward(retain_graph = True)\n",
    "                    dec_optimizer.step(); gan_model.zero_grad()\n",
    "                if gan_train: gan_loss.backward(); gan_optimizer.step()\n",
    "\n",
    "                # --------------------------------------------------------------------------------------------\n",
    "\n",
    "                # Loss Appending (Encoder Model)\n",
    "                train_enc_mse.append(mse_enc.item()); train_enc_loss.append(enc_loss.item())\n",
    "                train_enc_logger.experiment.add_scalar(\"MSE Loss\", mse_enc.item(), train_iter)\n",
    "                train_enc_logger.experiment.add_scalar(\"Backprop Loss\", enc_loss.item(), train_iter)\n",
    "\n",
    "                # Loss Appending (Decoder Model)\n",
    "                train_dec_ssim.append(ssim_loss); train_dec_kld.append(kld_loss.item())\n",
    "                train_dec_mse.append(mse_dec.item()); train_dec_nle.append(nle_loss)\n",
    "                train_dec_bce.append(bce_dec_train); train_dec_loss.append(dec_loss.item())\n",
    "                train_dec_logger.experiment.add_scalar(\"SSIM Index\", ssim_loss, train_iter)\n",
    "                train_dec_logger.experiment.add_scalar(\"KL Divergence\", kld_loss.item(), train_iter)\n",
    "                train_dec_logger.experiment.add_scalar(\"MSE Loss\", mse_dec.item(), train_iter)\n",
    "                train_dec_logger.experiment.add_scalar(\"NLE Loss\", nle_loss, train_iter)\n",
    "                train_dec_logger.experiment.add_scalar(\"BCE Loss\", bce_dec_train, train_iter)\n",
    "                train_dec_logger.experiment.add_scalar(\"Backprop Loss\", dec_loss.item(), train_iter)\n",
    "                train_dec_logger.experiment.add_scalar(\"Adversarial Training\", int(dec_train == True), train_iter)\n",
    "\n",
    "                # Loss Appending (Discriminator Model)\n",
    "                train_gan_bce.append(bce_gan_train); train_gan_loss.append(gan_loss.item())\n",
    "                train_gan_logger.experiment.add_scalar(\"BCE Loss\", bce_gan_train, train_iter)\n",
    "                train_gan_logger.experiment.add_scalar(\"Backprop Loss\", gan_loss.item(), train_iter)\n",
    "                train_gan_logger.experiment.add_scalar(\"Adversarial Training\", int(gan_train == True), train_iter)\n",
    "                train_iter += 1                \n",
    "\n",
    "                # --------------------------------------------------------------------------------------------\n",
    "\n",
    "                # Result Saving (Encoder MSE Loss)\n",
    "                if mse_enc.item() < best_train_enc_mse:\n",
    "                    best_train_enc_mse = mse_enc.item()\n",
    "                    X_gt_best_train_enc_mse = dec_train.detach().cpu()\n",
    "                    X_target_best_train_enc_mse = dec_target.detach().cpu()\n",
    "                if mse_enc.item() > worst_train_enc_mse:\n",
    "                    worst_train_enc_mse = mse_enc.item()\n",
    "                    X_gt_worst_train_enc_mse = dec_train.detach().cpu()\n",
    "                    X_target_worst_train_enc_mse = dec_target.detach().cpu()\n",
    "\n",
    "                # Result Saving (Decoder SSIM Index)\n",
    "                if ssim_loss > best_train_dec_ssim:\n",
    "                    best_train_dec_ssim = ssim_loss\n",
    "                    X_gt_best_train_dec_ssim = batch['X_target'].detach().cpu()\n",
    "                    X_target_best_train_dec_ssim = X_target.detach().cpu()\n",
    "                if ssim_loss < worst_train_dec_ssim:\n",
    "                    worst_train_dec_ssim = ssim_loss\n",
    "                    X_gt_worst_train_dec_ssim = batch['X_target'].detach().cpu()\n",
    "                    X_target_worst_train_dec_ssim = X_target.detach().cpu()\n",
    "                \n",
    "                # Result Saving (Decoder MSE Loss)\n",
    "                if mse_dec.item() < best_train_dec_mse:\n",
    "                    best_train_dec_mse = mse_dec.item()\n",
    "                    X_gt_best_train_dec_mse = batch['X_target'].detach().cpu()\n",
    "                    X_gt_best_train_dec_mse = X_target.detach().cpu()\n",
    "                if mse_dec.item() > worst_train_dec_mse:\n",
    "                    worst_train_dec_mse = mse_dec.item()\n",
    "                    X_gt_worst_train_dec_mse = batch['X_target'].detach().cpu()\n",
    "                    X_gt_worst_train_dec_mse = X_target.detach().cpu()\n",
    "                gc.collect(); torch.cuda.empty_cache()\n",
    "                del dec_train, dec_target, X_target,\n",
    "\n",
    "        ##############################################################################################\n",
    "        # ------------------------------------ Training | Results ------------------------------------\n",
    "        ##############################################################################################\n",
    "\n",
    "            # Inter-Patient Reconstruction Parameter Sharing Functionality\n",
    "            if settings.interpatient_sharing:\n",
    "                if p == 0: train_set[p].shuffle(); idxh_target_train = train_set[p].idxh_target\n",
    "                else:\n",
    "                    train_set[p].shuffle(idxh_target = idxh_target_train)\n",
    "                    assert(np.all(  train_set[p].idxh_target == train_set[0].idxh_target)\n",
    "                                    ), f\"     > ERROR: Parameter Sharing incorrectly setup!\"\n",
    "            else: train_set[p].shuffle()\n",
    "\n",
    "        # Learning Rate & GAN Settings Update\n",
    "        #enc_lr.step(); dec_lr.step(); gan_lr.step()\n",
    "        gan_equilibrium *= settings.equilibrium_decay\n",
    "        gan_margin *= settings.margin_decay\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # End of Training Epoch Mean Loss Writing\n",
    "        #train_mse_loss = np.mean(np.array(train_enc_mse))\n",
    "        #train_logger.experiment.add_scalar(\"Mean MSE Loss\", train_mse_loss, epoch)\n",
    "\n",
    "        # End of Training Epoch Image Result Writing\n",
    "        #\n",
    "\n",
    "        ##############################################################################################\n",
    "        # ---------------------------------- Validation | Iteration ----------------------------------\n",
    "        ##############################################################################################\n",
    "\n",
    "        \"\"\"\n",
    "        # Validation Set Reconstruction Loss Checkpoints\n",
    "        best_mse = 1000; worst_mse = 0\n",
    "        best_ssim = 0; worst_ssim = 1000\n",
    "\n",
    "        # Validation Patient Loop\n",
    "        with torch.no_grad():\n",
    "            model.eval(); val_ssim_loss = []; val_mse_loss = []\n",
    "            for p, patient_id in enumerate(settings.val_patient_list):\n",
    "            \n",
    "                # Training Iteration Loop\n",
    "                mask = MUDI_fcglVNN.get_mask(settings, num_patient = patient_id)\n",
    "                val_bar = tqdm(   enumerate(val_loader[p]), total = len(val_loader[p]),\n",
    "                    desc = f'Epoch #{epoch} | Validation Patient {patient_id}', unit = 'Batches')\n",
    "                for batch_idx, batch in val_bar:\n",
    "            \n",
    "                    # Batch Handling\n",
    "                    img_gt = torch.Tensor(unmask(batch[1].reshape((1,\n",
    "                        len(batch[1]))), mask).get_fdata().T).to(settings.device)\n",
    "\n",
    "                    # Forward Propagation\n",
    "                    X_fake = torch.squeeze(model(batch[0].to(settings.device)), dim = 1)\n",
    "                    img_fake = torch.Tensor(unmask(X_fake.detach().cpu().reshape((1,\n",
    "                                            len(batch[1]))), mask).get_fdata().T)\n",
    "                    gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "                    # Loss Computation\n",
    "                    mse_loss = mse_criterion(X_fake, batch[1].to(settings.device)).detach().cpu().numpy()\n",
    "                    ssim_loss, ssim_img = ssim( img_gt[0].cpu().numpy().astype(np.float32), \n",
    "                                                img_fake[0].cpu().numpy().astype(np.float32), full = True,\n",
    "                                        data_range = (torch.max(img_gt) - torch.min(img_gt)).cpu().numpy())\n",
    "                    ssim_loss = np.mean(ssim_loss); del ssim_img, batch, X_fake\n",
    "\n",
    "                    # Loss Appending \n",
    "                    val_logger.experiment.add_scalar(\"MSE Loss\", mse_loss.item(), val_iter)\n",
    "                    val_logger.experiment.add_scalar(\"SSIM Index\", ssim_loss, val_iter)\n",
    "                    val_mse_loss.append(mse_loss.item()); val_ssim_loss.append(ssim_loss); val_iter += 1\n",
    "\n",
    "                    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "                    # MSE & SSIM Loss Assignation for Parameters\n",
    "                    param_idx = batch_idx % val_set[p].h_target\n",
    "                    if mse_loss < best_mse:\n",
    "                        best_mse = mse_loss\n",
    "                        best_mse_idx = val_set[p].idxh_target[param_idx]\n",
    "                        img_fake_best_mse = img_fake.detach().cpu()\n",
    "                        img_gt_best_mse = img_gt.detach().cpu()\n",
    "                    if mse_loss > worst_mse:\n",
    "                        worst_mse = mse_loss\n",
    "                        worst_mse_idx = val_set[p].idxh_target[param_idx]\n",
    "                        img_fake_worst_mse = img_fake.detach().cpu()\n",
    "                        img_gt_worst_mse = img_gt.detach().cpu()\n",
    "                    if ssim_loss > best_ssim:\n",
    "                        best_ssim = ssim_loss\n",
    "                        best_ssim_idx = val_set[p].idxh_target[param_idx]\n",
    "                        img_fake_best_ssim = img_fake.detach().cpu()\n",
    "                        img_gt_best_ssim = img_gt.detach().cpu()\n",
    "                    if ssim_loss < worst_ssim:\n",
    "                        worst_ssim = ssim_loss\n",
    "                        worst_ssim_idx = val_set[p].idxh_target[param_idx]\n",
    "                        img_fake_worst_ssim = img_fake.detach().cpu()\n",
    "                        img_gt_worst_ssim = img_gt.detach().cpu()\n",
    "                    gc.collect(); torch.cuda.empty_cache(); del img_gt, img_fake\n",
    "\n",
    "                # Inter-Patient Reconstruction Parameter Sharing Functionality\n",
    "                if settings.interpatient_sharing:\n",
    "                    if p == 0: val_set[p].shuffle(); idxh_target_val = val_set[p].idxh_target\n",
    "                    else:\n",
    "                        val_set[p].shuffle(idxh_target = idxh_target_val)\n",
    "                        assert(np.all(  val_set[p].idxh_target == val_set[0].idxh_target)\n",
    "                                        ), f\"     > ERROR: Parameter Sharing incorrectly setup!\"\n",
    "                else: val_set[p].shuffle()\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "\n",
    "                # MSE Epoch Results\n",
    "                viz_logger[p] = plot_results(   epoch = epoch, loss_ = 'MSE',\n",
    "                                                logger = viz_logger[p], sel_slice = settings.sel_slice,\n",
    "                                                best_idx = best_mse_idx, worst_idx = worst_mse_idx,\n",
    "                                                best_loss = best_mse, worst_loss = worst_mse,\n",
    "                                                img_best_gt = img_gt_best_mse, img_best_fake = img_fake_best_mse,\n",
    "                                                img_worst_gt = img_gt_worst_mse, img_worst_fake = img_fake_worst_mse)\n",
    "                del best_mse_idx, img_gt_best_mse, img_fake_best_mse, best_mse,\\\n",
    "                    worst_mse_idx, img_gt_worst_mse, img_fake_worst_mse, worst_mse\n",
    "\n",
    "                # SSIM Epoch Results\n",
    "                viz_logger[p] = plot_results(   epoch = epoch, loss_ = 'SSIM',\n",
    "                                                logger = viz_logger[p], sel_slice = settings.sel_slice,\n",
    "                                                best_idx = best_ssim_idx, worst_idx = worst_ssim_idx,\n",
    "                                                best_loss = best_ssim, worst_loss = worst_ssim,\n",
    "                                                img_best_gt = img_gt_best_ssim, img_best_fake = img_fake_best_ssim,\n",
    "                                                img_worst_gt = img_gt_worst_ssim, img_worst_fake = img_fake_worst_ssim)\n",
    "                del best_ssim_idx, img_gt_best_ssim, img_fake_best_ssim, best_ssim,\\\n",
    "                    worst_ssim_idx, img_gt_worst_ssim, img_fake_worst_ssim, worst_ssim\n",
    "                \n",
    "        # End of Validation Epoch Mean Loss Writing\n",
    "        #val_mse_loss = np.mean(np.array(val_mse_loss))\n",
    "        #val_ssim_loss = np.mean(np.array(val_ssim_loss))\n",
    "        #val_logger.experiment.add_scalar(\"Mean MSE Loss\", val_mse_loss, epoch)        \n",
    "        #val_logger.experiment.add_scalar(\"Mean SSIM Index\", val_ssim_loss, epoch)\n",
    "        \n",
    "        # --------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Early Stopping Callback Application\n",
    "        #early_stop = earlyStopping( loss = val_mse_loss, epoch = epoch,\n",
    "        #                            model = model, optimizer = optimizer)\n",
    "        #if early_stop: print(f'     > Training Finished at Epoch #{epoch}'); return\n",
    "        \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D CVAE-GAN Model Training Script (V1)\n",
    "def CVAE_GAN_2D_train(\n",
    "    settings,\n",
    "):\n",
    "\n",
    "    ##############################################################################################\n",
    "    # ------------------------------------ Setup | DataLoader ------------------------------------\n",
    "    ##############################################################################################\n",
    "\n",
    "    # Seed Random State for Reproducibility\n",
    "    torch.manual_seed(settings.seed)\n",
    "    np.random.seed(settings.seed)\n",
    "    random.seed(settings.seed)\n",
    "\n",
    "    # Experiment Logs Directories Initialization\n",
    "    checkpoint_folderpath = os.path.join(f'{settings.modelsave_folderpath}/V{settings.model_version}', 'logs')\n",
    "    train_enc_logger = TensorBoardLogger(checkpoint_folderpath, 'train/encoder'); val_enc_logger = TensorBoardLogger(checkpoint_folderpath, 'validation/encoder')\n",
    "    train_dec_logger = TensorBoardLogger(checkpoint_folderpath, 'train/decoder'); val_dec_logger = TensorBoardLogger(checkpoint_folderpath, 'validation/decoder')\n",
    "    train_gan_logger = TensorBoardLogger(checkpoint_folderpath, 'train/discriminator'); val_gan_logger = TensorBoardLogger(checkpoint_folderpath, 'validation/discriminator')\n",
    "\n",
    "    # Training & Validation DataLoaders Initialization\n",
    "    train_set = []; val_set = []; viz_logger = []\n",
    "    train_loader = []; val_loader = []\n",
    "    for p, patient_id in enumerate(settings.patient_list):\n",
    "\n",
    "        # Patient Set & DataLoader Initialization\n",
    "        if patient_id in settings.train_patient_list:\n",
    "            print(f\"Patient #{patient_id} | Training Set:\")\n",
    "            train_set.append(   MUDI_CVAE_GAN_2D(   settings, subject = [patient_id],\n",
    "                                                    source_param = settings.train_source_param,\n",
    "                                                    target_param = settings.train_target_param,\n",
    "                                                    target_slice = settings.train_target_slice))\n",
    "            train_loader.append(DataLoader(         dataset = train_set[-1], pin_memory = True,\n",
    "                                                    shuffle = settings.train_sample_shuffle,\n",
    "                                                    num_workers = settings.num_workers,\n",
    "                                                    batch_size = settings.batch_size))\n",
    "            \n",
    "        elif patient_id in settings.val_patient_list:\n",
    "            print(f\"Patient #{patient_id} | Validation Set:\")\n",
    "            val_set.append(     MUDI_CVAE_GAN_2D(   settings, subject = [patient_id],\n",
    "                                                    source_param = settings.train_source_param,\n",
    "                                                    target_param = settings.train_target_param,\n",
    "                                                    target_slice = settings.train_target_slice))\n",
    "            val_loader.append(  DataLoader(         dataset = val_set[-1], pin_memory = True,\n",
    "                                                    shuffle = settings.val_sample_shuffle,\n",
    "                                                    num_workers = settings.num_workers,\n",
    "                                                    batch_size = val_set[-1].s_target))\n",
    "            viz_logger.append(  TensorBoardLogger(checkpoint_folderpath, f'validation/p{patient_id}'))\n",
    "            \n",
    "        else: print(f\"Patient #{patient_id} | Test Set:     > Not Included\")\n",
    "    \n",
    "    ##############################################################################################\n",
    "    # -------------------------------- Setup | Models & Optimizers -------------------------------\n",
    "    ##############################################################################################\n",
    "\n",
    "    # Model Initialization\n",
    "    print(f\"Running\\n     > Training 2D CVAE-GAN Model with {torch.cuda.device_count()} GPUs!\")\n",
    "    enc_model = nn.DataParallel(Encoder(settings), device_ids = settings.device_ids).to(settings.device)\n",
    "    dec_model = nn.DataParallel(Decoder(settings), device_ids = settings.device_ids).to(settings.device)\n",
    "    gan_model = nn.DataParallel(Discriminator(settings), device_ids = settings.device_ids).to(settings.device)\n",
    "\n",
    "    # Optimizer Initialization\n",
    "    enc_optimizer = torch.optim.AdamW(  enc_model.parameters(), lr = settings.base_lr,\n",
    "                                        weight_decay = settings.weight_decay)\n",
    "    dec_optimizer = torch.optim.AdamW(  dec_model.parameters(), lr = settings.base_lr,\n",
    "                                        weight_decay = settings.weight_decay)\n",
    "    gan_optimizer = torch.optim.AdamW(  gan_model.parameters(), lr = settings.base_lr,\n",
    "                                        weight_decay = settings.weight_decay)\n",
    "\n",
    "    # Learning Rate Scheduling\n",
    "    gan_equilibrium = settings.base_equilibrium\n",
    "    gan_margin = settings.base_margin\n",
    "    dec_lambda = settings.base_lambda\n",
    "    #enc_lr = ExponentialLR(enc_optimizer, gamma = settings.decay_lr)\n",
    "    #dec_lr = ExponentialLR(dec_optimizer, gamma = settings.decay_lr)\n",
    "    #gan_lr = ExponentialLR(gan_optimizer, gamma = settings.decay_lr)\n",
    "\n",
    "    # Criterion & Early Stopping Setup\n",
    "    mse_criterion = nn.MSELoss(reduction = 'mean')\n",
    "    ssim_criterion = SSIM(window_size = settings.kernel_size)\n",
    "    bce_criterion = nn.BCELoss(reduction = 'mean')\n",
    "    earlyStopping = EarlyStopping(settings); train_iter = 0; val_iter = 0\n",
    "\n",
    "    # Model Checkpoint Loading\n",
    "    model_filepath = Path(f\"{settings.modelsave_folderpath}/V{settings.model_version}/Best 2D CVAE-GAN.pt\")\n",
    "    if model_filepath.exists():\n",
    "        checkpoint = torch.load(model_filepath, map_location = settings.device)\n",
    "        enc_model.load_state_dict(checkpoint['Encoder Model']); enc_optimizer.load_state_dict(checkpoint['Encoder Optimizer'])\n",
    "        dec_model.load_state_dict(checkpoint['Decoder Model']); dec_optimizer.load_state_dict(checkpoint['Decoder Optimizer'])\n",
    "        gan_model.load_state_dict(checkpoint['Discriminator Model']); gan_optimizer.load_state_dict(checkpoint['Discriminator Optimizer'])\n",
    "        train_iter = checkpoint['Current Iteration']; val_iter = checkpoint['Current Validation Iteration']\n",
    "        save_epoch = checkpoint['Current Epoch']; torch.set_rng_state(checkpoint['RNG State'])\n",
    "        print(f\"     > Loading 2D CVAE-GAN Model for {settings.model_version}: {save_epoch} Past Epochs\"); del checkpoint\n",
    "    else: save_epoch = -1\n",
    "    \n",
    "    # Epoch Iteration Loop\n",
    "    for epoch in range(save_epoch + 1, settings.num_epochs):\n",
    "\n",
    "        ##############################################################################################\n",
    "        # ----------------------------------- Training | Iteration -----------------------------------\n",
    "        ##############################################################################################\n",
    "\n",
    "        # Result Value Initialization\n",
    "        best_train_enc_mse = 1000; worst_train_enc_mse = 0\n",
    "        best_train_dec_ssim = 0; worst_train_dec_ssim = 1000\n",
    "        best_train_dec_mse = 1000; worst_train_dec_mse = 0\n",
    "        train_enc_mse = []; train_enc_loss = []; train_dec_ssim = []\n",
    "        train_enc_kld = []; train_dec_mse = []; train_dec_nle = []; train_dec_bce = []\n",
    "        train_dec_loss = []; train_gan_bce = []; train_gan_loss = []\n",
    "\n",
    "        # Training Patient Loop\n",
    "        print(f\"Training Epoch #{epoch}:\")\n",
    "        for p, patient_id in enumerate(settings.train_patient_list):\n",
    "\n",
    "            # Training Iteration Loop\n",
    "            train_bar = tqdm(   enumerate(train_loader[p]), total = len(train_loader[p]),\n",
    "                desc = f'Epoch #{epoch} | Training Patient {patient_id}', unit = 'Batches')\n",
    "            for batch_idx, batch in train_bar:\n",
    "                \n",
    "                # --------------------------------------------------------------------------------------------\n",
    "\n",
    "                \"\"\"\n",
    "                # Model & Optimizer Setup\n",
    "                enc_model.train(); enc_model.zero_grad(); enc_optimizer.zero_grad()\n",
    "                dec_model.train(); dec_model.zero_grad(); dec_optimizer.zero_grad()\n",
    "                gan_model.train(); gan_model.zero_grad(); gan_optimizer.zero_grad()\n",
    "\n",
    "                # Forward Propagation\n",
    "                mu, logvar = enc_model(  batch['X_train'].to(settings.device),\n",
    "                                            batch['y_train'].to(settings.device))       # Encoder Model Application\n",
    "                z = Decoder.reparam(mu, logvar)                                         # Reparametrization Trick\n",
    "                X_target = dec_model(z, batch['y_target'].to(settings.device))          # Decoder Model Application\n",
    "                auth_pred = gan_model(  batch['X_train'].to(settings.device),            # Discriminator Model Application for Image Reconstruction Authentication\n",
    "                                                batch['X_target'].to(settings.device), recon = True)\n",
    "                dec_train = auth_pred[:len(auth_pred) // 2]; dec_target = auth_pred[len(auth_pred) // 2:]\n",
    "                gan_pred = gan_model(  batch['X_train'].to(settings.device),            # Discriminator Model Application for Target Image Authentication\n",
    "                                                batch['X_target'].to(settings.device))\n",
    "                gan_train = gan_pred[:len(gan_pred) // 2]; gan_target = gan_pred[len(gan_pred) // 2:]\n",
    "                gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "                # --------------------------------------------------------------------------------------------\n",
    "\n",
    "                # CVAE Model Loss Computation\n",
    "                mse_enc = mse_criterion(dec_train, dec_target)                                          # Mean Squared Error Loss (Encoder)\n",
    "                ssim_loss = ssim_criterion(X_target.detach().cpu(), torch.Tensor(batch['X_target']))    # Structural Similarity Index (Decoder)\n",
    "                kld_loss = Decoder.kl_loss(mu, logvar); del mu, logvar, z                               # Kullback-Leibler Divergence Loss\n",
    "                bce_dec = bce_criterion(dec_train, dec_target)                                          # Binary Cross Entropy (Decoder)\n",
    "                #bce_dec_train = -torch.log(1 - dec_train); bce_dec_target = -torch.log(dec_target)      # Binary Cross Entropy (Decoder)\n",
    "                #bce_dec = torch.sum(bce_dec_train) + torch.sum(bce_dec_target)\n",
    "                enc_loss = torch.sum(kld_loss) + torch.sum(mse_enc)                                     # Full CVAE Encoder Loss\n",
    "\n",
    "                # GAN Model Loss Computation\n",
    "                print(torch.min(batch['X_target'])); print(type(batch['X_target']))\n",
    "                mse_dec = mse_criterion(torch.clip(X_target, 0.0, settings.img_range),                  # Mean Squared Error Loss (Decoder)\n",
    "                                        torch.clip(batch['X_target'], 0.0, settings.img_range).to(settings.device))\n",
    "                nle_loss = torch.mean(- X_target.view((len(X_target), -1)) ** 2 + 0.5 *\\\n",
    "                    (batch['X_target'].to(settings.device).view(len(batch['X_target']), -1)))           # Normal Loss Expectancy\n",
    "                #bce_gan = bce_criterion(gan_train, gan_target)                                          # Binary Cross Entropy (Discriminator)\n",
    "                bce_gan_train = -torch.log(gan_train); bce_gan_target = -torch.log(1 - gan_target)      # Binary Cross Entropy (Discriminator)\n",
    "                bce_gan = torch.sum(bce_gan_train) + torch.sum(bce_gan_target)\n",
    "                gan_loss = bce_gan#torch.sum(bce_gan)                                                   # Full GAN Discriminator Loss\n",
    "                dec_loss = torch.sum(dec_lambda * mse_dec) - gan_loss                                   # Full CVAE Decoder Loss\n",
    "                \n",
    "                print(bce_dec); print(bce_dec.shape); print(bce_gan); print(bce_gan.shape); print(mse_dec)\n",
    "                \"\"\"\n",
    "\n",
    "                # Model & Optimizer Setup\n",
    "                enc_model.train(); enc_model.zero_grad(); enc_optimizer.zero_grad()\n",
    "                dec_model.train(); dec_model.zero_grad(); dec_optimizer.zero_grad()\n",
    "                gan_model.train(); gan_model.zero_grad(); gan_optimizer.zero_grad()\n",
    "\n",
    "                # CVAE Model Forward Propagation\n",
    "                mu, logvar = enc_model( batch['X_train'].to(settings.device),\n",
    "                                        batch['y_train'].to(settings.device))               # Encoder Model Application\n",
    "                z = Decoder.reparam(mu, logvar)                                             # Reparametrization Trick\n",
    "                X_target = dec_model(z, batch['y_target'].to(settings.device))              # Decoder Model Application for Target Image Generation\n",
    "                X_fake = dec_model(torch.randn_like(logvar).to(settings.device),            # Decoder Model Application for Fake Image Generation\n",
    "                                   batch['y_target'].to(settings.device))\n",
    "\n",
    "                # GAN Model Forward Propagation\n",
    "                auth_dec_pred = gan_model(batch['X_target'].to(settings.device),            # Discriminator Model Application for\n",
    "                #auth_dec_pred = gan_model(batch['X_train'].to(settings.device),             # Discriminator Model Application for\n",
    "                                          X_target, recon = True)                           # Intermediate Layer Representation Authentication\n",
    "                auth_dec_train = auth_dec_pred[:len(auth_dec_pred) // 2]; auth_dec_target = auth_dec_pred[len(auth_dec_pred) // 2:]\n",
    "                auth_gan_pred = gan_model(batch['X_target'].to(settings.device),            # Discriminator Model Application\n",
    "                                          X_fake)#X_target)                                 # for Generated Target Image Authentication\n",
    "                auth_gan_train = auth_gan_pred[:len(auth_gan_pred) // 2]; auth_gan_target = auth_gan_pred[len(auth_gan_pred) // 2:]\n",
    "                gc.collect(); torch.cuda.empty_cache(); del auth_dec_pred, auth_gan_pred, X_fake\n",
    "\n",
    "                # --------------------------------------------------------------------------------------------\n",
    "\n",
    "                # CVAE Model Loss Computation\n",
    "                mse_enc = mse_criterion(auth_dec_train, auth_dec_target)                                    # Mean Squared Error Loss (Encoder)\n",
    "                ssim_loss = ssim_criterion(X_target.detach().cpu(), torch.Tensor(batch['X_target']))        # Structural Similarity Index (Decoder)\n",
    "                kld_loss = Decoder.kl_loss(mu, logvar); del mu, logvar, z                                   # Kullback-Leibler Divergence Loss\n",
    "                enc_loss = torch.sum(kld_loss) + torch.sum(mse_enc)                                         # Full CVAE Encoder Loss\n",
    "\n",
    "                # Model Cross Entropy Loss Computation\n",
    "                bce_dec_train = -torch.log(1 - auth_dec_train); bce_dec_target = -torch.log(auth_dec_target)\n",
    "                bce_dec = torch.sum(bce_dec_train) + torch.sum(bce_dec_target)\n",
    "                bce_dec_mean = bce_criterion(auth_dec_train, auth_dec_target)\n",
    "                bce_gan_train = -torch.log(auth_gan_train); bce_gan_target = -torch.log(1 - auth_gan_target)\n",
    "                bce_gan = torch.sum(bce_gan_train) + torch.sum(bce_gan_target)\n",
    "                bce_gan_mean = bce_criterion(auth_gan_train, auth_gan_target)\n",
    "\n",
    "                # GAN Model Loss Computation\n",
    "                mse_dec = mse_criterion(X_target.detach().cpu(), batch['X_target'])                    # Mean Squared Error Loss (Decoder)\n",
    "                nle_loss = torch.mean(- X_target.view((len(X_target), -1)) ** 2 + 0.5 *\\\n",
    "                    (batch['X_target'].to(settings.device).view(len(batch['X_target']), -1)))               # Normal Loss Expectancy\n",
    "                gan_loss = torch.sum(bce_gan_train) + torch.sum(bce_gan_target)                             # Full GAN Discriminator Loss\n",
    "                #dec_loss = torch.sum(dec_lambda * mse_dec) - gan_loss                                       # Full CVAE Decoder Loss\n",
    "                dec_loss = torch.sum(dec_lambda * mse_dec) - gan_loss; del batch                            # Full CVAE Decoder Loss\n",
    "\n",
    "                # --------------------------------------------------------------------------------------------\n",
    "                            \n",
    "                # Adversarial Training\n",
    "                gan_train = True; dec_train = True\n",
    "                if torch.mean(bce_gan_train).data < gan_equilibrium - gan_margin or\\\n",
    "                    torch.mean(bce_gan_target).data < gan_equilibrium - gan_margin: gan_train = False\n",
    "                if torch.mean(bce_gan_train).data > gan_equilibrium + gan_margin or\\\n",
    "                    torch.mean(bce_gan_target).data > gan_equilibrium + gan_margin: dec_train = False\n",
    "                if gan_train is False and dec_train is False: gan_train = True; dec_train = True\n",
    "                del bce_dec_train, bce_dec_target, bce_gan_train, bce_gan_target\n",
    "                \n",
    "                # Backward Propagation\n",
    "                enc_loss.backward(retain_graph = True); enc_optimizer.step()\n",
    "                if dec_train:\n",
    "                    dec_loss.backward(retain_graph = True)\n",
    "                    dec_optimizer.step(); gan_model.zero_grad()\n",
    "                if gan_train: gan_loss.backward(); gan_optimizer.step()\n",
    "                gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "                # --------------------------------------------------------------------------------------------\n",
    "\n",
    "                # Loss Appending (CVAE Model)\n",
    "                #train_enc_mse.append(mse_enc.item()); train_dec_ssim.append(ssim_loss)\n",
    "                #train_enc_kld.append(kld_loss.item()); train_dec_bce.append(bce_dec); train_enc_loss.append(enc_loss.item())\n",
    "                train_enc_logger.experiment.add_scalar(\"MSE Loss\", mse_enc.item(), train_iter)\n",
    "                train_dec_logger.experiment.add_scalar(\"SSIM Index\", ssim_loss, train_iter)\n",
    "                train_enc_logger.experiment.add_scalar(\"KL Divergence\", kld_loss.item(), train_iter)\n",
    "                train_dec_logger.experiment.add_scalar(\"BCE Loss\", bce_dec_mean, train_iter)\n",
    "                train_enc_logger.experiment.add_scalar(\"Backprop Loss\", enc_loss.item(), train_iter)\n",
    "                train_dec_logger.experiment.add_scalar(\"Adversarial Training\", int(dec_train == True), train_iter)\n",
    "\n",
    "                # Loss Appending (GAN Model)\n",
    "                #train_dec_mse.append(mse_dec.item()); train_dec_nle.append(nle_loss)\n",
    "                #train_gan_bce.append(bce_gan_train); train_dec_loss.append(dec_loss.item()); train_gan_loss.append(gan_loss.item())\n",
    "                train_dec_logger.experiment.add_scalar(\"MSE Loss\", mse_dec.item(), train_iter)\n",
    "                train_dec_logger.experiment.add_scalar(\"NLE Loss\", nle_loss, train_iter)\n",
    "                train_gan_logger.experiment.add_scalar(\"BCE Loss\", bce_gan_mean, train_iter)\n",
    "                train_dec_logger.experiment.add_scalar(\"Backprop Loss\", dec_loss.item(), train_iter)\n",
    "                train_gan_logger.experiment.add_scalar(\"Backprop Loss\", gan_loss.item(), train_iter)\n",
    "                train_gan_logger.experiment.add_scalar(\"Adversarial Training\", int(gan_train == True), train_iter)\n",
    "                train_iter += 1; del auth_dec_train, auth_dec_target, auth_gan_train, auth_gan_target, X_target\n",
    "\n",
    "                # --------------------------------------------------------------------------------------------\n",
    "\n",
    "                \"\"\"\n",
    "                # Result Saving (Encoder MSE Loss)\n",
    "                if mse_enc.item() < best_train_enc_mse:\n",
    "                    best_train_enc_mse = mse_enc.item()\n",
    "                    auth_gt_best_train_enc_mse = auth_train\n",
    "                    auth_target_best_train_enc_mse = auth_target\n",
    "                    # Save Source & Target Parameters, as well as Slice Numbers,\n",
    "                    # so you can check which slice is actually the best, or which one\n",
    "                    # is the worst, by doing slice per slice MSE computation and then\n",
    "                    # we will be able to show that single one and all its attributes\n",
    "                if mse_enc.item() > worst_train_enc_mse:\n",
    "                    worst_train_enc_mse = mse_enc.item()\n",
    "                    X_gt_worst_train_enc_mse = dec_train.detach().cpu()\n",
    "                    X_target_worst_train_enc_mse = dec_target.detach().cpu()\n",
    "\n",
    "                # Result Saving (Decoder SSIM Index)\n",
    "                if ssim_loss > best_train_dec_ssim:\n",
    "                    best_train_dec_ssim = ssim_loss\n",
    "                    X_gt_best_train_dec_ssim = batch['X_target'].detach().cpu()\n",
    "                    X_target_best_train_dec_ssim = X_target.detach().cpu()\n",
    "                if ssim_loss < worst_train_dec_ssim:\n",
    "                    worst_train_dec_ssim = ssim_loss\n",
    "                    X_gt_worst_train_dec_ssim = batch['X_target'].detach().cpu()\n",
    "                    X_target_worst_train_dec_ssim = X_target.detach().cpu()\n",
    "                \n",
    "                # Result Saving (Decoder MSE Loss)\n",
    "                if mse_dec.item() < best_train_dec_mse:\n",
    "                    best_train_dec_mse = mse_dec.item()\n",
    "                    X_gt_best_train_dec_mse = batch['X_target'].detach().cpu()\n",
    "                    X_gt_best_train_dec_mse = X_target.detach().cpu()\n",
    "                if mse_dec.item() > worst_train_dec_mse:\n",
    "                    worst_train_dec_mse = mse_dec.item()\n",
    "                    X_gt_worst_train_dec_mse = batch['X_target'].detach().cpu()\n",
    "                    X_gt_worst_train_dec_mse = X_target.detach().cpu()\n",
    "                gc.collect(); torch.cuda.empty_cache()\n",
    "                del dec_train, dec_target, X_target,\n",
    "                \"\"\"\n",
    "\n",
    "        ##############################################################################################\n",
    "        # ------------------------------------ Training | Results ------------------------------------\n",
    "        ##############################################################################################\n",
    "\n",
    "            # Inter-Patient Reconstruction Parameter Sharing Functionality\n",
    "            if settings.interpatient_sharing:\n",
    "                if p == 0: train_set[p].shuffle(); idxh_target_train = train_set[p].idxh_target\n",
    "                else:\n",
    "                    train_set[p].shuffle(idxh_target = idxh_target_train)\n",
    "                    assert(np.all(  train_set[p].idxh_target == train_set[0].idxh_target)\n",
    "                                    ), f\"     > ERROR: Parameter Sharing incorrectly setup!\"\n",
    "            else: train_set[p].shuffle()\n",
    "\n",
    "        # Learning Rate & GAN Settings Update\n",
    "        #enc_lr.step(); dec_lr.step(); gan_lr.step()\n",
    "        gan_equilibrium *= settings.equilibrium_decay\n",
    "        gan_margin *= settings.margin_decay\n",
    "        dec_lambda *= settings.lambda_decay\n",
    "        if gan_margin > gan_equilibrium: gan_equilibrium = gan_margin\n",
    "        if dec_lambda > 1: dec_lambda = 1\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # End of Training Epoch Mean Loss Writing\n",
    "        #train_mse_loss = np.mean(np.array(train_enc_mse))\n",
    "        #train_logger.experiment.add_scalar(\"Mean MSE Loss\", train_mse_loss, epoch)\n",
    "\n",
    "        # End of Training Epoch Image Result Writing\n",
    "        #\n",
    "\n",
    "        ##############################################################################################\n",
    "        # ---------------------------------- Validation | Iteration ----------------------------------\n",
    "        ##############################################################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training** *Callbacks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping Callback Functionality\n",
    "class EarlyStopping:\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings\n",
    "    ):\n",
    "        self.best_path = Path(f\"{settings.modelsave_folderpath}/V{settings.model_version}/Best fcglVNN.pt\")\n",
    "        self.local_path = Path(f\"{settings.modelsave_folderpath}/V{settings.model_version}/fcglVNN.pt\")\n",
    "        self.patience = settings.es_patience; self.delta = settings.es_delta; self.early_stop = False\n",
    "        self.counter = 0; self.best_score = -np.inf; self.local_score = -np.inf; self.local_loss = np.Inf; self.best_loss = np.inf\n",
    "    \n",
    "    # Callback Application Function\n",
    "    def __call__(\n",
    "        self,\n",
    "        loss,\n",
    "        model,\n",
    "        optimizer,\n",
    "        epoch: int = 0\n",
    "    ):  \n",
    "\n",
    "        # Best / First Local Result Checkpoint Saving\n",
    "        if -loss > self.local_score + self.delta or self.local_score is None:\n",
    "            self.save_checkpoint(loss, model, optimizer, epoch, best = False)\n",
    "            self.local_score = -loss; self.counter = 0\n",
    "        \n",
    "        # Checkpoint Counter Startup\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            print(f'     > EarlyStopping Counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience: self.early_stop = True\n",
    "        \n",
    "        # Best / First Overall Result Checkpoint Saving\n",
    "        if -loss > self.best_score or self.best_score is None:\n",
    "            self.save_checkpoint(loss, model, optimizer, epoch, best = True)\n",
    "            self.best_score = -loss\n",
    "        return self.early_stop\n",
    "\n",
    "    # Model Saving Functionality\n",
    "    def save_checkpoint(\n",
    "        self,\n",
    "        loss,\n",
    "        model,\n",
    "        optimizer,\n",
    "        epoch: int = 0,\n",
    "        best: bool = False\n",
    "    ):\n",
    "        if best: path = self.best_path\n",
    "        else: path = self.local_path\n",
    "        if best: print(f\"     > Loss Decreased ({self.best_loss:.6f} --> {loss:.6f})\\n     > Saving Best Model\"); self.best_loss = loss\n",
    "        else: print(f\"     > Loss Decreased ({self.local_loss:.6f} --> {loss:.6f})\\n     > Saving Model\"); self.local_loss = loss\n",
    "        torch.save({'Model': model.state_dict(),\n",
    "                    'Optimizer': optimizer.state_dict(),\n",
    "                    'Current Epoch': epoch,\n",
    "                    'RNG State': torch.get_rng_state()}, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSIM Loss Callback\n",
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
    "    return gauss/gauss.sum()\n",
    "\n",
    "def create_window(window_size, channel):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
    "    return window\n",
    "\n",
    "def create_window_3D(window_size, channel):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t())\n",
    "    _3D_window = _1D_window.mm(_2D_window.reshape(1, -1)).reshape(window_size, window_size, window_size).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = Variable(_3D_window.expand(channel, 1, window_size, window_size, window_size).contiguous())\n",
    "    return window\n",
    "\n",
    "def _ssim(img1, img2, window, window_size, channel, size_average = True):\n",
    "    mu1 = F.conv2d(img1, window, padding = window_size//2, groups = channel)\n",
    "    mu2 = F.conv2d(img2, window, padding = window_size//2, groups = channel)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1*mu2\n",
    "\n",
    "    sigma1_sq = F.conv2d(img1*img1, window, padding = window_size//2, groups = channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2*img2, window, padding = window_size//2, groups = channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1*img2, window, padding = window_size//2, groups = channel) - mu1_mu2\n",
    "\n",
    "    C1 = 0.01**2\n",
    "    C2 = 0.03**2\n",
    "\n",
    "    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "    if size_average:\n",
    "        return ssim_map.mean()\n",
    "    else:\n",
    "        return ssim_map.mean(1).mean(1).mean(1)\n",
    "    \n",
    "def _ssim_3D(img1, img2, window, window_size, channel, size_average = True):\n",
    "    mu1 = F.conv3d(img1, window, padding = window_size//2, groups = channel)\n",
    "    mu2 = F.conv3d(img2, window, padding = window_size//2, groups = channel)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "\n",
    "    mu1_mu2 = mu1*mu2\n",
    "\n",
    "    sigma1_sq = F.conv3d(img1*img1, window, padding = window_size//2, groups = channel) - mu1_sq\n",
    "    sigma2_sq = F.conv3d(img2*img2, window, padding = window_size//2, groups = channel) - mu2_sq\n",
    "    sigma12 = F.conv3d(img1*img2, window, padding = window_size//2, groups = channel) - mu1_mu2\n",
    "\n",
    "    C1 = 0.01**2\n",
    "    C2 = 0.03**2\n",
    "\n",
    "    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "    if size_average:\n",
    "        return ssim_map.mean()\n",
    "    else:\n",
    "        return ssim_map.mean(1).mean(1).mean(1)\n",
    "    \n",
    "\n",
    "\n",
    "class SSIM(torch.nn.Module):\n",
    "    def __init__(self, window_size = 11, size_average = True):\n",
    "        super(SSIM, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.size_average = size_average\n",
    "        self.channel = 1\n",
    "        self.window = create_window(window_size, self.channel)\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        (_, channel, _, _) = img1.size()\n",
    "\n",
    "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
    "            window = self.window\n",
    "        else:\n",
    "            window = create_window(self.window_size, channel)\n",
    "            \n",
    "            if img1.is_cuda:\n",
    "                window = window.cuda(img1.get_device())\n",
    "            window = window.type_as(img1)\n",
    "            \n",
    "            self.window = window\n",
    "            self.channel = channel\n",
    "\n",
    "\n",
    "        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n",
    "    \n",
    "    \n",
    "class SSIM3D(torch.nn.Module):\n",
    "    def __init__(self, window_size = 11, size_average = True):\n",
    "        super(SSIM3D, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.size_average = size_average\n",
    "        self.channel = 1\n",
    "        self.window = create_window_3D(window_size, self.channel)\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        (_, channel, _, _, _) = img1.size()\n",
    "\n",
    "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
    "            window = self.window\n",
    "        else:\n",
    "            window = create_window_3D(self.window_size, channel)\n",
    "            \n",
    "            if img1.is_cuda:\n",
    "                window = window.cuda(img1.get_device())\n",
    "            window = window.type_as(img1)\n",
    "            \n",
    "            self.window = window\n",
    "            self.channel = channel\n",
    "\n",
    "\n",
    "        return _ssim_3D(img1, img2, window, self.window_size, channel, self.size_average)\n",
    "\n",
    "    \n",
    "def ssim(img1, img2, window_size = 11, size_average = True):\n",
    "    (_, channel, _, _) = img1.size()\n",
    "    window = create_window(window_size, channel)\n",
    "    \n",
    "    if img1.is_cuda:\n",
    "        window = window.cuda(img1.get_device())\n",
    "    window = window.type_as(img1)\n",
    "    \n",
    "    return _ssim(img1, img2, window, window_size, channel, size_average)\n",
    "\n",
    "def ssim3D(img1, img2, window_size = 11, size_average = True):\n",
    "    (_, channel, _, _, _) = img1.size()\n",
    "    window = create_window_3D(window_size, channel)\n",
    "    \n",
    "    if img1.is_cuda:\n",
    "        window = window.cuda(img1.get_device())\n",
    "    window = window.type_as(img1)\n",
    "    \n",
    "    return _ssim_3D(img1, img2, window, window_size, channel, size_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result Plotting Functionality (V0)\n",
    "def plot_results(\n",
    "    logger: TensorBoardLogger, mode: str = 'Train',\n",
    "    loss: str, info: list, epoch: int = 0\n",
    "):\n",
    "\n",
    "    # Set Example Reconstruction Results Image Plotting\n",
    "    plot = plt.figure(figsize = (20, 22))\n",
    "    plt.xticks([]); plt.yticks([]); plt.grid(False); plt.tight_layout()\n",
    "    plt.suptitle(f'{mode} Patient {patient_id} | Parameter Results | {loss_} Loss')\n",
    "    if type(best_loss) == torch.Tensor: best_loss = best_loss.item(); worst_loss= worst_loss.item()\n",
    "\n",
    "    # Set Example Original & Best Loss Reconstructed Image Subplots\n",
    "    plt.subplot(2, 2, 1, title = f'Best {loss_} | Original | Parameter #{best_idx}')\n",
    "    plt.imshow(img_best_gt[0, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "    plt.subplot(2, 2, 2, title = f'Best {loss_} | Fake | {loss_}: {np.round(best_loss, 4)}')\n",
    "    plt.imshow(img_best_fake[0, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "    \n",
    "    # Set Example Original & Worst Loss Reconstructed Image Subplots\n",
    "    plt.subplot(2, 2, 3, title = f'Worst {loss_} | Original | Parameter #{worst_idx}')\n",
    "    plt.imshow(img_worst_gt[0, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "    plt.subplot(2, 2, 4, title = f'Worst {loss_} | Fake | {loss_}: {np.round(worst_loss, 4)}')\n",
    "    plt.imshow(img_worst_fake[0, sel_slice, :, :], cmap = plt.cm.binary)\n",
    "\n",
    "    # Tensorboard Reconstruction Callback\n",
    "    logger.experiment.add_figure(f\"{loss_} Results\", plot, epoch)\n",
    "    logger.experiment.add_scalar(f\"Best {loss_}\", best_loss, epoch)\n",
    "    logger.experiment.add_scalar(f\"Worst {loss_}\", worst_loss, epoch)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = torch.rand((100, 1, 96, 96))\n",
    "X_gt = torch.rand((100, 1, 96, 96))\n",
    "ssim_criterion = SSIM(window_size = 5)\n",
    "ssim_loss = torch.empty(100)\n",
    "for i in range(100):\n",
    "    ssim_loss[i] = ssim_criterion(  torch.Tensor(np.expand_dims(X_pred[i], axis = 0)),\n",
    "                                    torch.Tensor(np.expand_dims(X_gt[i], axis = 0)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **2D CVAE**\n",
    "\n",
    "### *2D Conditional Variational AutoEncoder* \n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data** *Reader*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D MUDI Dataset Initialization Class (Linear)\n",
    "class MUDI_CVAE_GAN_2D(Dataset):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,\n",
    "        subject: int or list,\n",
    "        mode: str = 'Target',\n",
    "        source_param: int or float = 100,\n",
    "        target_param: int or float = 100,\n",
    "        target_slice: int or float = 100\n",
    "    ):\n",
    "        \n",
    "        # Parameter & Patient Index Value Access\n",
    "        super(MUDI_CVAE_GAN_2D).__init__(); self.mode = mode\n",
    "        self.settings = settings; self.source_param = source_param\n",
    "        self.target_param = target_param; self.target_slice = target_slice\n",
    "        self.data = h5py.File(self.settings.data_filepath, 'r').get('data1')\n",
    "        self.params = pd.read_excel(self.settings.param_filepath)\n",
    "\n",
    "        # Vertical Splitting (Patient & Slice Selection)\n",
    "        self.idxv = pd.read_csv(self.settings.info_filepath,                    # List of Index Values ...\n",
    "                                index_col = 0).to_numpy()                       # ... pertaining to each Patient\n",
    "        self.idxv = self.idxv[np.isin(self.idxv[:, 1], subject), 0]             # Patient-Specific Index Values\n",
    "        self.mask = MUDI_CVAE_GAN_2D.get_mask(self.settings, subject[0])        # Patient-Specific Mask Download\n",
    "        self.data = unmask(self.data[self.idxv, :].T, self.mask).get_fdata().T  # Patient-Specific Image Unmasking\n",
    "        self.data = MUDI_CVAE_GAN_2D.zero_padding(self.data, self.settings.img_shape)   # Image Pre-Processing: Zero Padding\n",
    "        self.idxv_slice_full = np.arange(self.mask.shape[-1])                   # Full List of Available Image Slices\n",
    "\n",
    "        # Horizontal Splitting (Source & Target Parameter Selection)\n",
    "        idxh_source_filepath = Path(f\"{self.settings.datasave_folderpath}/Training Labels (V{self.settings.data_version}).txt\")\n",
    "        idxh_target_filepath = Path(f\"{self.settings.datasave_folderpath}/{self.mode} Labels (V{self.settings.data_version}).txt\")\n",
    "        self.idxh_source_full = np.sort(np.loadtxt(idxh_source_filepath)).astype(int)\n",
    "        if not idxh_target_filepath.exists(): self.idxh_target_full = self.label_gen()\n",
    "        else: self.idxh_target_full = np.sort(np.loadtxt(idxh_target_filepath)).astype(int)\n",
    "\n",
    "        # Vertical & Horizontal Sub-Sectioning & Shuffling\n",
    "        self.s_target = int((self.target_slice * len(self.idxv_slice_full)) / 100)\n",
    "        print(f\"     > Utilizing {self.s_target} \\ {len(self.idxv_slice_full)} of the Available Slices\")\n",
    "        self.h_source = int((self.source_param * len(self.idxh_source_full)) / 100)\n",
    "        self.h_target = int((self.target_param * len(self.idxh_target_full)) / 100); self.shuffle(True)\n",
    "        print(f\"     > Utilizing {self.h_source} \\ {len(self.idxh_source_full)} of the Training Parameters\")\n",
    "        print(f\"     > Utilizing {self.h_target} \\ {len(self.idxh_target_full)} of the Target Parameters\")\n",
    "        print(f\"     > Pre-Processing Images to be of Square Shape of {self.settings.img_shape}\")\n",
    "\n",
    "        # Parameter Selection & Value Normalization / Scaling\n",
    "        if self.settings.gradient_coord:\n",
    "            self.params = self.params.drop(columns = ['Gradient theta', 'Gradient phi'])                # Choosing of Gradient Orientation\n",
    "        else: self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])\n",
    "        if self.settings.label_norm == 'auto':\n",
    "            print(f\"     > Automatic Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "            self.scaler = StandardScaler()\n",
    "            self.params = pd.DataFrame( self.scaler.fit_transform(self.params),\n",
    "                                        columns = self.params.columns)\n",
    "            scaler_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "            if not scaler_filepath.exists(): torch.save(self.scaler, scaler_filepath)\n",
    "        elif self.settings.label_norm == 'manual':\n",
    "            print(f\"     > Manual Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "            self.params[['Gradient theta', 'Gradient phi']] = self.cart2polar(self.params[['Gradient x', 'Gradient y', 'Gradient z']].values)\n",
    "            self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])\n",
    "            self.params['b Value'] = self.params['b Value'] / 10000\n",
    "            self.params['TI'] = self.params['TI'] / 10000\n",
    "            self.params['TE'] = (self.params['TE'] - 80) / 200\n",
    "        else: print(f\"     > No Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "        assert(self.params.shape[1] == self.settings.num_labels), \"ERROR: Labels wrongly Deleted!\"\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # DataLoader Length / No. Batches Computation Functionality\n",
    "    def __len__(self): return self.s_target * self.h_source * self.h_target\n",
    "\n",
    "    # Image Zero-Padding Pre-Processing Method Functionality\n",
    "    def zero_padding(\n",
    "        data: np.array or torch.Tensor,\n",
    "        img_shape: int\n",
    "    ):\n",
    "\n",
    "        # Input Data Assertions\n",
    "        assert(data.ndim >= 3), \"ERROR: Pre-Processing Input Data has the Wrong Dimmensions\"\n",
    "        assert(img_shape >= int(data.shape[-2]) and img_shape >= int(data.shape[-1])\n",
    "        ), \"ERROR: Pre-Processed Output Data Shape is Larget than Input one!\"\n",
    "\n",
    "        # Zero-Padding Implementation\n",
    "        padding = np.array([0, 0, (img_shape - data.shape[-2]) / 2, (img_shape - data.shape[-1]) / 2])\n",
    "        padding = padding.reshape((1, -1)).T + np.array([0, 0])\n",
    "        padding[:, -1] = np.ceil(padding[:, -1]); padding[:, -2] = np.floor(padding[:, -2])\n",
    "        return np.pad(data, padding.astype(np.int32), 'constant')\n",
    "        \n",
    "    # Single-Batch Generation Functionality\n",
    "    def __getitem__(self, idx) -> tuple[np.ndarray, np.float32]:\n",
    "        \n",
    "        # Batch Vertical/Slice & Horizontal/Parameter Indexing\n",
    "        idxv_slice = idx % self.s_target                        # Batch's Vertical Index for X_train\n",
    "        idxh_source = (idx // self.s_target) % self.h_source    # Batch's Horizontal Index for y_train\n",
    "        idxh_target = idx // (self.s_target * self.h_source)    # Batch's Horizontal Index for y_target\n",
    "        #print(f\"Item #{idx} | Slice #{idxv_slice} | Source Parameter #{self.idxh_source[idxh_source]} | Target Parameter #{self.idxh_target[idxh_target]}\")\n",
    "\n",
    "        # Batch Data Generation\n",
    "        X_train = self.data[self.idxh_source[idxh_source], self.idxv_slice[idxv_slice], :, :]           # [1, 1, :, :] Training Image Slice Data\n",
    "        y_train = self.params.iloc[self.idxh_source[idxh_source]].values                                # [num_labels] Training Image Parameter Values\n",
    "        X_target = self.data[self.idxh_target[idxh_target], self.idxv_slice[idxv_slice], :, :]          # [1, 1, :, :] GT Target Image Slice Data\n",
    "        y_target = self.params.iloc[self.idxh_target[idxh_target]].values                               # [num_labels] Target Image Parameter Values\n",
    "        return {'X_train': np.array(X_train).reshape((1, X_train.shape[0], X_train.shape[1])).astype(np.float32),\n",
    "                'X_target': np.array(X_target).reshape((1, X_target.shape[0], X_target.shape[1])).astype(np.float32),\n",
    "                'y_train': np.ravel(y_train).astype(np.float32), 'y_target': np.ravel(y_target).astype(np.float32),\n",
    "                'idxv_slice': idxv_slice, 'slice_target': self.idxv_slice[idxv_slice],\n",
    "                'idxh_source': idxh_source, 'param_source': self.idxh_source[idxh_source],\n",
    "                'idxh_target': idxh_target, 'param_target': self.idxh_target[idxh_target]}\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Source Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def source_param_shuffle(\n",
    "        self,\n",
    "        begin: bool = False,\n",
    "        idxh_source: np.array = None\n",
    "    ):\n",
    "        if idxh_source is not None: self.idxh_source = idxh_source\n",
    "        else:\n",
    "            if self.settings.param_shuffle or begin:\n",
    "                self.idxh_source = self.idxh_source_full[   np.sort(np.random.choice(len(self.idxh_source_full),\n",
    "                                                            self.h_source, replace = False))]\n",
    "\n",
    "    # Target Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def target_param_shuffle(\n",
    "        self,\n",
    "        begin: bool = False,\n",
    "        idxh_target: np.array = None\n",
    "    ):\n",
    "        if idxh_target is not None: self.idxh_target = idxh_target\n",
    "        else:\n",
    "            if self.settings.param_shuffle or begin:\n",
    "                self.idxh_target = self.idxh_target_full[   np.sort(np.random.choice(len(self.idxh_target_full),\n",
    "                                                            self.h_target, replace = False))]\n",
    "                \n",
    "    # Target Slice Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def slice_shuffle(\n",
    "        self,\n",
    "        begin: bool = False,\n",
    "        idxv_slice: np.array = None\n",
    "    ):  \n",
    "        if idxv_slice is not None: self.idxv_slice = idxv_slice\n",
    "        else:\n",
    "            if self.settings.slice_shuffle or begin:\n",
    "                self.idxv_slice = self.idxv_slice_full[     np.sort(np.random.choice(len(self.idxv_slice_full),\n",
    "                                                            self.s_target, replace = False))]\n",
    "    \n",
    "    # Target Voxel & Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def shuffle(\n",
    "        self,\n",
    "        begin: bool = False,\n",
    "        idxh_source: np.array = None,\n",
    "        idxh_target: np.array = None,\n",
    "        idxv_slice: np.array = None\n",
    "    ):\n",
    "        self.source_param_shuffle(begin, idxh_source)\n",
    "        self.target_param_shuffle(begin, idxh_target)\n",
    "        self.slice_shuffle(begin, idxv_slice)\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Random Target Parameter for Training & Test Sets Generation Functionality\n",
    "    def label_gen(self):\n",
    "\n",
    "        # Target & Test Label Index File Generation\n",
    "        idxh_target = np.delete(np.arange(self.params.shape[0]), self.idxh_train)\n",
    "        if self.settings.test_target_param != 0:\n",
    "            idxh_test = idxh_target[np.sort(np.random.choice(len(idxh_target),\n",
    "                                    self.settings.test_target_param, replace = False))]\n",
    "            idxh_target = np.delete(idxh_target, np.where(np.in1d(idxh_target, idxh_test)))\n",
    "            for i in range(self.settings.test_target_param): assert(idxh_test[i] not in idxh_target\n",
    "                ), f\"ERROR: Target Parameter #{i} for Training & Test Sets not mutually Exclusive\"\n",
    "            \n",
    "            # Target & Test Label Index File Saving\n",
    "            print(f\">     Saving File Target Parameters for Training ({len(idxh_target)}) & Test {len(idxh_test)} Set's\")\n",
    "            np.savetxt(Path(f\"{self.settings.datasave_folderpath}/Test Labels (V{self.settings.data_version}).txt\"), idxh_test)\n",
    "            np.savetxt(Path(f\"{self.settings.datasave_folderpath}/Target Labels (V{self.settings.data_version}).txt\"), idxh_target)\n",
    "        if self.mode == 'Target': return idxh_target\n",
    "        else: return idxh_test\n",
    "        \n",
    "    # Label Scaler Download & Reverse Transformation\n",
    "    def label_unscale(\n",
    "        self,\n",
    "        y: np.array or pd.DataFrame\n",
    "    ):\n",
    "\n",
    "        # Label Scaler Download & Reverse Usage\n",
    "        try: self.scaler\n",
    "        except AttributeError:\n",
    "            scaler = torch.load(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "        return scaler.inverse_transform(y.reshape(1, -1))\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Cartesian to Polar Coordinate Conversion Functionality\n",
    "    def cart2polar(self, y: np.array):\n",
    "\n",
    "        # Cartesian to Polar Coordinates Conversion\n",
    "        phi = np.arccos(y[:, 2]).astype(np.float32); theta = np.arctan2(y[:, 1], y[:, 0])\n",
    "        theta = np.where(theta < 0, 2 * np.pi - np.abs(theta), theta).astype(np.float32)\n",
    "        theta = np.expand_dims(theta, axis = 1); phi = np.expand_dims(phi, axis = 1)\n",
    "        return pd.DataFrame(data = np.concatenate((theta, phi), axis = 1),\n",
    "                            columns = ['Gradient theta', 'Gradient phi'])\n",
    "\n",
    "    # Patient Mask Retrieval Functionality\n",
    "    def get_mask(settings, patient_id: int):\n",
    "        mask_filepath = Path(f\"{settings.mask_folderpath}/p{patient_id}.nii\")\n",
    "        assert(mask_filepath.exists()), f\"ERROR: Patient {patient_id}'s Mask not Found!\"\n",
    "        return load_img(mask_filepath)\n",
    "    \n",
    "    # Data Retrieval Functionality\n",
    "    def get_data(\n",
    "        settings,\n",
    "        patient_id: int,\n",
    "        idxv: int or np.array = None,\n",
    "        idxh_source: int or np.array = None,\n",
    "        idxh_target: int or np.array = None\n",
    "    ):\n",
    "        \n",
    "        # Dataset Download & Patient-Wise Splitting\n",
    "        data = h5py.File(settings.data_filepath, 'r').get('data1')\n",
    "        idxv_full = pd.read_csv(settings.info_filepath, index_col = 0).to_numpy()\n",
    "        idxv_full = idxv_full[np.isin(idxv_full[:, 1], patient_id), 0]                  # Patient-Specific Index Values\n",
    "        mask = MUDI_CVAE_GAN_2D.get_mask(settings, patient_id)                          # Patient-Specific Mask Download\n",
    "        \n",
    "        # Dataset Source Horizontal / Parameter & Vertical / Slice Indexing\n",
    "        if idxh_source is not None:\n",
    "            X_train = unmask(data[idxv_full, :][:, idxh_source].T, mask).get_fdata().T\n",
    "            if type(idxh_source) is int: X_train = np.expand_dims(X_train, axis = 0)\n",
    "            X_train = MUDI_CVAE_GAN_2D.zero_padding(X_train, settings.img_shape)\n",
    "            if type(idxh_source) is int: X_train = np.expand_dims(X_train[0, idxv, :, :], axis = 0)\n",
    "            else: X_train = X_train[:, idxv, :, :]\n",
    "        if idxh_target is None: return torch.Tensor(X_train)\n",
    "\n",
    "        # Dataset Target Horizontal / Parameter & Vertical / Slice Indexing\n",
    "        else:\n",
    "            X_target = unmask(data[idxv_full, :][:, idxh_target].T, mask).get_fdata().T\n",
    "            if type(idxh_target) is int: X_target = np.expand_dims(X_target, axis = 0)\n",
    "            X_target = MUDI_CVAE_GAN_2D.zero_padding(X_target, settings.img_shape)\n",
    "            if type(idxh_target) is int: X_target = np.expand_dims(X_target[0, idxv, :, :], axis = 0)\n",
    "            else: X_target = X_target[:, idxv, :, :]\n",
    "        return torch.Tensor(X_train), torch.Tensor(X_target)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D MUDI Dataset Initialization Class (Random)\n",
    "class MUDI_CVAE_GAN_2D(Dataset):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,\n",
    "        subject: int or list,\n",
    "        random: bool = True,\n",
    "        mode: str = 'Target',\n",
    "        source_param: int or float = 100,\n",
    "        target_param: int or float = 100,\n",
    "        target_slice: int or float = 100,\n",
    "        param_loop: int or float = 100\n",
    "    ):\n",
    "        \n",
    "        # Parameter & Patient Index Value Access\n",
    "        super(MUDI_CVAE_GAN_2D).__init__(); self.settings = settings\n",
    "        self.random = random; self.mode = mode; self.source_param = source_param\n",
    "        self.target_param = target_param; self.target_slice = target_slice\n",
    "        self.data = h5py.File(self.settings.data_filepath, 'r').get('data1')\n",
    "        self.params = pd.read_excel(self.settings.param_filepath)\n",
    "\n",
    "        # Vertical Splitting (Patient & Slice Selection)\n",
    "        self.idxv = pd.read_csv(self.settings.info_filepath,                    # List of Index Values ...\n",
    "                                index_col = 0).to_numpy()                       # ... pertaining to each Patient\n",
    "        self.idxv = self.idxv[np.isin(self.idxv[:, 1], subject), 0]             # Patient-Specific Index Values\n",
    "        self.mask = MUDI_CVAE_GAN_2D.get_mask(self.settings, subject[0])        # Patient-Specific Mask Download\n",
    "        self.data = unmask(self.data[self.idxv, :].T, self.mask).get_fdata().T  # Patient-Specific Image Unmasking\n",
    "        self.data = MUDI_CVAE_GAN_2D.zero_padding(self.data, self.settings.img_shape)   # Image Pre-Processing: Zero Padding\n",
    "        self.idxv_slice_full = np.arange(self.mask.shape[-1])                   # Full List of Available Image Slices\n",
    "\n",
    "        # Horizontal Splitting (Source & Target Parameter Selection)\n",
    "        idxh_source_filepath = Path(f\"{self.settings.datasave_folderpath}/Training Labels (V{self.settings.data_version}).txt\")\n",
    "        idxh_target_filepath = Path(f\"{self.settings.datasave_folderpath}/{self.mode} Labels (V{self.settings.data_version}).txt\")\n",
    "        self.idxh_source_full = np.sort(np.loadtxt(idxh_source_filepath)).astype(int)\n",
    "        if not idxh_target_filepath.exists(): self.idxh_target_full = self.label_gen()\n",
    "        else: self.idxh_target_full = np.sort(np.loadtxt(idxh_target_filepath)).astype(int)\n",
    "\n",
    "        # Vertical & Horizontal Sub-Sectioning & Shuffling\n",
    "        self.s_target = int((self.target_slice * len(self.idxv_slice_full)) / 100)\n",
    "        self.h_source = int((self.source_param * len(self.idxh_source_full)) / 100)\n",
    "        self.h_target = int((self.target_param * len(self.idxh_target_full)) / 100)\n",
    "        self.num_combo = int((param_loop * (self.h_source * self.h_target)) / 100); self.shuffle(init = True)\n",
    "        print(f\"     > Utilizing {self.s_target} \\ {len(self.idxv_slice_full)} of the Available Slices\")\n",
    "        print(f\"     > Utilizing {self.h_source} \\ {len(self.idxh_source_full)} of the Training Parameters\")\n",
    "        print(f\"     > Utilizing {self.h_target} \\ {len(self.idxh_target_full)} of the Target Parameters\")\n",
    "        print(f\"     > Looping through {self.num_combo} \\ {self.h_source * self.h_target} Source / Target Parameter Combos\")\n",
    "        print(f\"     > Pre-Processing Images to be of Square Shape of {self.settings.img_shape}\")\n",
    "\n",
    "        # Parameter Selection & Value Normalization / Scaling\n",
    "        if self.settings.gradient_coord:\n",
    "            self.params = self.params.drop(columns = ['Gradient theta', 'Gradient phi'])                # Choosing of Gradient Orientation\n",
    "        else: self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])\n",
    "        if self.settings.label_norm == 'auto':\n",
    "            print(f\"     > Automatic Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "            self.scaler = StandardScaler()\n",
    "            self.params = pd.DataFrame( self.scaler.fit_transform(self.params),\n",
    "                                        columns = self.params.columns)\n",
    "            scaler_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "            if not scaler_filepath.exists(): torch.save(self.scaler, scaler_filepath)\n",
    "        elif self.settings.label_norm == 'manual':\n",
    "            print(f\"     > Manual Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "            self.params[['Gradient theta', 'Gradient phi']] = self.cart2polar(self.params[['Gradient x', 'Gradient y', 'Gradient z']].values)\n",
    "            self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])\n",
    "            self.params['b Value'] = self.params['b Value'] / 10000\n",
    "            self.params['TI'] = self.params['TI'] / 10000\n",
    "            self.params['TE'] = (self.params['TE'] - 80) / 200\n",
    "        else: print(f\"     > No Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "        assert(self.params.shape[1] == self.settings.num_labels), \"ERROR: Labels wrongly Deleted!\"\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # DataLoader Length / No. Batches Computation Functionality\n",
    "    def __len__(self): return self.s_target * self.h_source * self.h_target\n",
    "\n",
    "    # Image Zero-Padding Pre-Processing Method Functionality\n",
    "    def zero_padding(\n",
    "        data: np.array or torch.Tensor,\n",
    "        img_shape: int\n",
    "    ):\n",
    "\n",
    "        # Input Data Assertions\n",
    "        assert(data.ndim >= 3), \"ERROR: Pre-Processing Input Data has the Wrong Dimmensions\"\n",
    "        assert(img_shape >= int(data.shape[-2]) and img_shape >= int(data.shape[-1])\n",
    "        ), \"ERROR: Pre-Processed Output Data Shape is Larget than Input one!\"\n",
    "\n",
    "        # Zero-Padding Implementation\n",
    "        padding = np.array([0, 0, (img_shape - data.shape[-2]) / 2, (img_shape - data.shape[-1]) / 2])\n",
    "        padding = padding.reshape((1, -1)).T + np.array([0, 0])\n",
    "        padding[:, -1] = np.ceil(padding[:, -1]); padding[:, -2] = np.floor(padding[:, -2])\n",
    "        return np.pad(data, padding.astype(np.int32), 'constant')\n",
    "        \n",
    "    # Single-Batch Generation Functionality\n",
    "    def __getitem__(self, idx) -> tuple[np.ndarray, np.float32]:\n",
    "        \n",
    "        # Batch Vertical/Slice & Horizontal/Parameter Indexing\n",
    "        idxv_slice = idx % self.s_target                                # Batch's Vertical Index for X_train\n",
    "        idxh_loop = (idx // self.s_target) % self.num_combo             # Batch's Horizontal Index for Loop Combo\n",
    "        if self.random:\n",
    "            idxh_source = random.randrange(self.h_source)               # Random Batch's Horizontal Index for y_train\n",
    "            idxh_target = random.randrange(self.h_target)               # Random Batch's Horizontal Index for y_target\n",
    "        else:\n",
    "            idxh_source = int(np.where(self.idxh_source == self.idxh_combo[idxh_loop][0])[0])   # Fixed y_train Batch's Horizontal Index\n",
    "            idxh_target = int(np.where(self.idxh_target == self.idxh_combo[idxh_loop][1])[0])   # Fixed y_target Batch's Horizontal Index\n",
    "        #print(f\"Item #{idx} | Slice #{idxv_slice} | Source Parameter #{self.idxh_source[idxh_source]} | Target Parameter #{self.idxh_target[idxh_target]}\")\n",
    "\n",
    "        # Batch Data Generation\n",
    "        X_train = self.data[self.idxh_source[idxh_source], self.idxv_slice[idxv_slice], :, :]   # [1, 1, :, :] Training Image Slice Data\n",
    "        y_train = self.params.iloc[self.idxh_source[idxh_source]].values                    # [num_labels] Training Image Parameter Values\n",
    "        X_target = self.data[self.idxh_target[idxh_target], self.idxv_slice[idxv_slice], :, :]  # [1, 1, :, :] GT Target Image Slice Data\n",
    "        y_target = self.params.iloc[self.idxh_target[idxh_target]].values                   # [num_labels] Target Image Parameter Values\n",
    "        return {'X_train': np.array(X_train).reshape((1, X_train.shape[0], X_train.shape[1])).astype(np.float32),\n",
    "                'X_target': np.array(X_target).reshape((1, X_target.shape[0], X_target.shape[1])).astype(np.float32),\n",
    "                'y_train': np.ravel(y_train).astype(np.float32), 'y_target': np.ravel(y_target).astype(np.float32),\n",
    "                'idxv_slice': idxv_slice, 'slice_target': self.idxv_slice[idxv_slice],\n",
    "                'idxh_source': idxh_source, 'param_source': self.idxh_source[idxh_source],\n",
    "                'idxh_target': idxh_target, 'param_target': self.idxh_target[idxh_target]}\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Source Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def source_param_shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxh_source: np.array = None\n",
    "    ):\n",
    "        if idxh_source is not None: self.idxh_source = idxh_source\n",
    "        else:\n",
    "            if self.settings.param_shuffle or init:\n",
    "                self.idxh_source = self.idxh_source_full[   np.sort(np.random.choice(len(self.idxh_source_full),\n",
    "                                                            self.h_source, replace = False))]\n",
    "\n",
    "    # Target Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def target_param_shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxh_target: np.array = None\n",
    "    ):\n",
    "        if idxh_target is not None: self.idxh_target = idxh_target\n",
    "        else:\n",
    "            if self.settings.param_shuffle or init:\n",
    "                self.idxh_target = self.idxh_target_full[   np.sort(np.random.choice(len(self.idxh_target_full),\n",
    "                                                            self.h_target, replace = False))]\n",
    "                \n",
    "    # Target Slice Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def slice_shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxv_slice: np.array = None\n",
    "    ):  \n",
    "        if idxv_slice is not None: self.idxv_slice = idxv_slice\n",
    "        else:\n",
    "            if self.settings.slice_shuffle or init:\n",
    "                self.idxv_slice = self.idxv_slice_full[ np.sort(np.random.choice(len(self.idxv_slice_full),\n",
    "                                                        self.s_target, replace = False))]\n",
    "                \n",
    "    # Target Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def combo_shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxh_combo: np.array = None\n",
    "    ):\n",
    "        if idxh_combo is not None: self.idxh_combo = idxh_combo\n",
    "        else:\n",
    "            if self.settings.param_shuffle or init:\n",
    "                self.idxh_combo = []\n",
    "                for i in range(self.num_combo):\n",
    "                    self.idxh_combo.append(np.array([self.idxh_source[random.randrange(self.h_source)],\n",
    "                                                    self.idxh_target[random.randrange(self.h_target)]]))\n",
    "    \n",
    "    # Target Voxel & Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxh_source: np.array = None,\n",
    "        idxh_target: np.array = None,\n",
    "        idxv_slice: np.array = None,\n",
    "        idxh_combo: np.array = None\n",
    "    ):\n",
    "        self.source_param_shuffle(init, idxh_source)\n",
    "        self.target_param_shuffle(init, idxh_target)\n",
    "        self.slice_shuffle(init, idxv_slice)\n",
    "        self.combo_shuffle(init, idxh_combo)\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Random Target Parameter for Training & Test Sets Generation Functionality\n",
    "    def label_gen(self):\n",
    "\n",
    "        # Target & Test Label Index File Generation\n",
    "        idxh_target = np.delete(np.arange(self.params.shape[0]), self.idxh_train)\n",
    "        if self.settings.test_target_param != 0:\n",
    "            idxh_test = idxh_target[np.sort(np.random.choice(len(idxh_target),\n",
    "                                    self.settings.test_target_param, replace = False))]\n",
    "            idxh_target = np.delete(idxh_target, np.where(np.in1d(idxh_target, idxh_test)))\n",
    "            for i in range(self.settings.test_target_param): assert(idxh_test[i] not in idxh_target\n",
    "                ), f\"ERROR: Target Parameter #{i} for Training & Test Sets not mutually Exclusive\"\n",
    "            \n",
    "            # Target & Test Label Index File Saving\n",
    "            print(f\">     Saving File Target Parameters for Training ({len(idxh_target)}) & Test {len(idxh_test)} Set's\")\n",
    "            np.savetxt(Path(f\"{self.settings.datasave_folderpath}/Test Labels (V{self.settings.data_version}).txt\"), idxh_test)\n",
    "            np.savetxt(Path(f\"{self.settings.datasave_folderpath}/Target Labels (V{self.settings.data_version}).txt\"), idxh_target)\n",
    "        if self.mode == 'Target': return idxh_target\n",
    "        else: return idxh_test\n",
    "        \n",
    "    # Label Scaler Download & Reverse Transformation\n",
    "    def label_unscale(\n",
    "        self,\n",
    "        y: np.array or pd.DataFrame\n",
    "    ):\n",
    "\n",
    "        # Label Scaler Download & Reverse Usage\n",
    "        try: self.scaler\n",
    "        except AttributeError:\n",
    "            scaler = torch.load(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "        return scaler.inverse_transform(y.reshape(1, -1))\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Cartesian to Polar Coordinate Conversion Functionality\n",
    "    def cart2polar(self, y: np.array):\n",
    "\n",
    "        # Cartesian to Polar Coordinates Conversion\n",
    "        phi = np.arccos(y[:, 2]).astype(np.float32); theta = np.arctan2(y[:, 1], y[:, 0])\n",
    "        theta = np.where(theta < 0, 2 * np.pi - np.abs(theta), theta).astype(np.float32)\n",
    "        theta = np.expand_dims(theta, axis = 1); phi = np.expand_dims(phi, axis = 1)\n",
    "        return pd.DataFrame(data = np.concatenate((theta, phi), axis = 1),\n",
    "                            columns = ['Gradient theta', 'Gradient phi'])\n",
    "\n",
    "    # Patient Mask Retrieval Functionality\n",
    "    def get_mask(settings, patient_id: int):\n",
    "        mask_filepath = Path(f\"{settings.mask_folderpath}/p{patient_id}.nii\")\n",
    "        assert(mask_filepath.exists()), f\"ERROR: Patient {patient_id}'s Mask not Found!\"\n",
    "        return load_img(mask_filepath)\n",
    "    \n",
    "    # Data Retrieval Functionality\n",
    "    def get_data(\n",
    "        settings,\n",
    "        patient_id: int,\n",
    "        idxv: int or np.array = None,\n",
    "        idxh_source: int or np.array = None,\n",
    "        idxh_target: int or np.array = None\n",
    "    ):\n",
    "        \n",
    "        # Dataset Download & Patient-Wise Splitting\n",
    "        data = h5py.File(settings.data_filepath, 'r').get('data1')\n",
    "        idxv_full = pd.read_csv(settings.info_filepath, index_col = 0).to_numpy()\n",
    "        idxv_full = idxv_full[np.isin(idxv_full[:, 1], patient_id), 0]                  # Patient-Specific Index Values\n",
    "        mask = MUDI_CVAE_GAN_2D.get_mask(settings, patient_id)                          # Patient-Specific Mask Download\n",
    "        \n",
    "        # Dataset Source Horizontal / Parameter & Vertical / Slice Indexing\n",
    "        if idxh_source is not None:\n",
    "            X_train = unmask(data[idxv_full, :][:, idxh_source].T, mask).get_fdata().T\n",
    "            if type(idxh_source) is int: X_train = np.expand_dims(X_train, axis = 0)\n",
    "            X_train = MUDI_CVAE_GAN_2D.zero_padding(X_train, settings.img_shape)\n",
    "            if type(idxh_source) is int: X_train = np.expand_dims(X_train[0, idxv, :, :], axis = 0)\n",
    "            else: X_train = X_train[:, idxv, :, :]\n",
    "        if idxh_target is None: return torch.Tensor(X_train)\n",
    "\n",
    "        # Dataset Target Horizontal / Parameter & Vertical / Slice Indexing\n",
    "        else:\n",
    "            X_target = unmask(data[idxv_full, :][:, idxh_target].T, mask).get_fdata().T\n",
    "            if type(idxh_target) is int: X_target = np.expand_dims(X_target, axis = 0)\n",
    "            X_target = MUDI_CVAE_GAN_2D.zero_padding(X_target, settings.img_shape)\n",
    "            if type(idxh_target) is int: X_target = np.expand_dims(X_target[0, idxv, :, :], axis = 0)\n",
    "            else: X_target = X_target[:, idxv, :, :]\n",
    "        return torch.Tensor(X_train), torch.Tensor(X_target)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D MUDI Dataset Initialization Class (Random)\n",
    "class MUDI_CVAE_GAN_2D(Dataset):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,\n",
    "        subject: int or list,\n",
    "        random: bool = True,\n",
    "        mode: str = 'Target',\n",
    "        source_param: int or float = 100,\n",
    "        target_param: int or float = 100,\n",
    "        target_slice: int or float = 100,\n",
    "        param_loop: int or float = 100\n",
    "    ):\n",
    "        \n",
    "        # Parameter & Patient Index Value Access\n",
    "        super(MUDI_CVAE_GAN_2D).__init__(); self.settings = settings\n",
    "        self.random = random; self.mode = mode; self.source_param = source_param\n",
    "        self.target_param = target_param; self.target_slice = target_slice\n",
    "        self.data = h5py.File(self.settings.data_filepath, 'r').get('data1')\n",
    "        self.params = pd.read_excel(self.settings.param_filepath)\n",
    "\n",
    "        # Vertical Splitting (Patient & Slice Selection)\n",
    "        self.idxv = pd.read_csv(self.settings.info_filepath,                    # List of Index Values ...\n",
    "                                index_col = 0).to_numpy()                       # ... pertaining to each Patient\n",
    "        self.idxv = self.idxv[np.isin(self.idxv[:, 1], subject), 0]             # Patient-Specific Index Values\n",
    "        self.mask = MUDI_CVAE_GAN_2D.get_mask(self.settings, subject[0])        # Patient-Specific Mask Download\n",
    "        self.data = unmask(self.data[self.idxv, :].T, self.mask).get_fdata().T  # Patient-Specific Image Unmasking\n",
    "        self.data = MUDI_CVAE_GAN_2D.zero_padding(self.data, self.settings.img_shape)   # Image Pre-Processing: Zero Padding\n",
    "        self.idxv_slice_full = np.arange(self.mask.shape[-1])                   # Full List of Available Image Slices\n",
    "\n",
    "        # Horizontal Splitting (Source & Target Parameter Selection)\n",
    "        idxh_source_filepath = Path(f\"{self.settings.datasave_folderpath}/Training Labels (V{self.settings.data_version}).txt\")\n",
    "        idxh_target_filepath = Path(f\"{self.settings.datasave_folderpath}/{self.mode} Labels (V{self.settings.data_version}).txt\")\n",
    "        self.idxh_source_full = np.sort(np.loadtxt(idxh_source_filepath)).astype(int)\n",
    "        if not idxh_target_filepath.exists(): self.idxh_target_full = self.label_gen()\n",
    "        else: self.idxh_target_full = np.sort(np.loadtxt(idxh_target_filepath)).astype(int)\n",
    "\n",
    "        # Vertical & Horizontal Sub-Sectioning & Shuffling\n",
    "        self.s_target = int((self.target_slice * len(self.idxv_slice_full)) / 100)\n",
    "        print(f\"     > Utilizing {self.s_target} \\ {len(self.idxv_slice_full)} of the Available Slices\")\n",
    "        self.h_source = int((self.source_param * len(self.idxh_source_full)) / 100)\n",
    "        self.h_target = int((self.target_param * len(self.idxh_target_full)) / 100)\n",
    "        self.h_target = int((self.target_param * len(self.idxh_target_full)) / 100)\n",
    "        self.num_combo = int((param_loop * (self.h_source * self.h_target)) / 100); self.shuffle(init = True)\n",
    "        print(f\"     > Utilizing {self.h_source} \\ {len(self.idxh_source_full)} of the Training Parameters\")\n",
    "        print(f\"     > Utilizing {self.h_target} \\ {len(self.idxh_target_full)} of the Target Parameters\")\n",
    "        print(f\"     > Pre-Processing Images to be of Square Shape of {self.settings.img_shape}\")\n",
    "        print(f\"     > Looping through {self.num_combo} \\ {self.h_source * self.h_target} Source / Target Parameter Combos\")\n",
    "\n",
    "        # Parameter Selection & Value Normalization / Scaling\n",
    "        if self.settings.gradient_coord:\n",
    "            self.params = self.params.drop(columns = ['Gradient theta', 'Gradient phi'])                # Choosing of Gradient Orientation\n",
    "        else: self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])\n",
    "        if self.settings.label_norm == 'auto':\n",
    "            print(f\"     > Automatic Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "            self.scaler = StandardScaler()\n",
    "            self.params = pd.DataFrame( self.scaler.fit_transform(self.params),\n",
    "                                        columns = self.params.columns)\n",
    "            scaler_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "            if not scaler_filepath.exists(): torch.save(self.scaler, scaler_filepath)\n",
    "        elif self.settings.label_norm == 'manual':\n",
    "            print(f\"     > Manual Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "            self.params[['Gradient theta', 'Gradient phi']] = self.cart2polar(self.params[['Gradient x', 'Gradient y', 'Gradient z']].values)\n",
    "            self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])\n",
    "            self.params['b Value'] = self.params['b Value'] / 10000\n",
    "            self.params['TI'] = self.params['TI'] / 10000\n",
    "            self.params['TE'] = (self.params['TE'] - 80) / 200\n",
    "        else: print(f\"     > No Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "        assert(self.params.shape[1] == self.settings.num_labels), \"ERROR: Labels wrongly Deleted!\"\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # DataLoader Length / No. Batches Computation Functionality\n",
    "    def __len__(self): return self.s_target * self.num_combo\n",
    "\n",
    "    # Image Zero-Padding Pre-Processing Method Functionality\n",
    "    def zero_padding(\n",
    "        data: np.array or torch.Tensor,\n",
    "        img_shape: int\n",
    "    ):\n",
    "\n",
    "        # Input Data Assertions\n",
    "        assert(data.ndim >= 3), \"ERROR: Pre-Processing Input Data has the Wrong Dimmensions\"\n",
    "        assert(img_shape >= int(data.shape[-2]) and img_shape >= int(data.shape[-1])\n",
    "        ), \"ERROR: Pre-Processed Output Data Shape is Larget than Input one!\"\n",
    "\n",
    "        # Zero-Padding Implementation\n",
    "        padding = np.array([0, 0, (img_shape - data.shape[-2]) / 2, (img_shape - data.shape[-1]) / 2])\n",
    "        padding = padding.reshape((1, -1)).T + np.array([0, 0])\n",
    "        padding[:, -1] = np.ceil(padding[:, -1]); padding[:, -2] = np.floor(padding[:, -2])\n",
    "        return np.pad(data, padding.astype(np.int32), 'constant')\n",
    "        \n",
    "    # Single-Batch Generation Functionality\n",
    "    def __getitem__(self, idx) -> tuple[np.ndarray, np.float32]:\n",
    "        \n",
    "        # Batch Vertical/Slice & Horizontal/Parameter Indexing\n",
    "        idxv_slice = idx % self.s_target                                # Batch's Vertical Index for X_train\n",
    "        idxh_loop = (idx // self.s_target) % self.num_combo             # Batch's Horizontal Index for Loop Combo\n",
    "        if self.random:\n",
    "            idxh_source = random.randrange(self.h_source)               # Random Batch's Horizontal Index for y_train\n",
    "            idxh_target = random.randrange(self.h_target)               # Random Batch's Horizontal Index for y_target\n",
    "        else:\n",
    "            idxh_source = int(np.where(self.idxh_source == self.idxh_combo[idxh_loop][0])[0])   # Fixed y_train Batch's Horizontal Index\n",
    "            idxh_target = int(np.where(self.idxh_target == self.idxh_combo[idxh_loop][1])[0])   # Fixed y_target Batch's Horizontal Index\n",
    "        print( f\"Item #{idx} | Slice #{idxv_slice} | Source Parameter #{self.idxh_source[idxh_source]}\" +\\\n",
    "                \"| Target Parameter #{self.idxh_target[idxh_target]}\")\n",
    "\n",
    "        # Batch Data Generation\n",
    "        X_train = self.data[self.idxh_source[idxh_source], self.idxv_slice[idxv_slice], :, :]  # [1, 1, :, :] Training Image Slice Data\n",
    "        y_train = self.params.iloc[self.idxh_source[idxh_source]].values                       # [num_labels] Training Image Parameter Values\n",
    "        X_target = self.data[self.idxh_target[idxh_target], self.idxv_slice[idxv_slice], :, :] # [1, 1, :, :] GT Target Image Slice Data\n",
    "        y_target = self.params.iloc[self.idxh_target[idxh_target]].values                      # [num_labels] Target Image Parameter Values\n",
    "        return {'X_train': np.array(X_train).reshape((1, X_train.shape[0], X_train.shape[1])).astype(np.float32),\n",
    "                'X_target': np.array(X_target).reshape((1, X_target.shape[0], X_target.shape[1])).astype(np.float32),\n",
    "                'y_train': np.ravel(y_train).astype(np.float32), 'y_target': np.ravel(y_target).astype(np.float32),\n",
    "                'idxv_slice': idxv_slice, 'slice_target': self.idxv_slice[idxv_slice], 'idxh_loop': idxh_loop,\n",
    "                'idxh_source': idxh_source, 'param_source': self.idxh_source[idxh_source],\n",
    "                'idxh_target': idxh_target, 'param_target': self.idxh_target[idxh_target]}\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Source Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def source_param_shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxh_source: np.array = None\n",
    "    ):\n",
    "        if idxh_source is not None: self.idxh_source = idxh_source\n",
    "        else:\n",
    "            if self.settings.param_shuffle or init:\n",
    "                self.idxh_source = self.idxh_source_full[   np.sort(np.random.choice(len(self.idxh_source_full),\n",
    "                                                            self.h_source, replace = False))]\n",
    "\n",
    "    # Target Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def target_param_shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxh_target: np.array = None\n",
    "    ):\n",
    "        if idxh_target is not None: self.idxh_target = idxh_target\n",
    "        else:\n",
    "            if self.settings.param_shuffle or init:\n",
    "                self.idxh_target = self.idxh_target_full[   np.sort(np.random.choice(len(self.idxh_target_full),\n",
    "                                                            self.h_target, replace = False))]\n",
    "                \n",
    "    # Target Slice Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def slice_shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxv_slice: np.array = None\n",
    "    ):  \n",
    "        if idxv_slice is not None: self.idxv_slice = idxv_slice\n",
    "        else:\n",
    "            if self.settings.slice_shuffle or init:\n",
    "                self.idxv_slice = self.idxv_slice_full[     np.sort(np.random.choice(len(self.idxv_slice_full),\n",
    "                                                            self.s_target, replace = False))]\n",
    "\n",
    "    # Target Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def combo_shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxh_combo: np.array = None\n",
    "    ):\n",
    "        if idxh_combo is not None: self.idxh_combo = idxh_combo\n",
    "        else:\n",
    "            if self.settings.param_shuffle or init:\n",
    "                self.idxh_combo = []\n",
    "                for i in range(self.num_combo):\n",
    "                    self.idxh_combo.append(np.array([self.idxh_source[random.randrange(self.h_source)],\n",
    "                                                    self.idxh_target[random.randrange(self.h_target)]]))\n",
    "    \n",
    "    # Target Voxel & Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxh_source: np.array = None,\n",
    "        idxh_target: np.array = None,\n",
    "        idxv_slice: np.array = None,\n",
    "        idxh_combo: np.array = None\n",
    "    ):\n",
    "        self.source_param_shuffle(init, idxh_source)\n",
    "        self.target_param_shuffle(init, idxh_target)\n",
    "        self.slice_shuffle(init, idxv_slice)\n",
    "        self.combo_shuffle(init, idxh_combo)\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Random Target Parameter for Training & Test Sets Generation Functionality\n",
    "    def label_gen(self):\n",
    "\n",
    "        # Target & Test Label Index File Generation\n",
    "        idxh_target = np.delete(np.arange(self.params.shape[0]), self.idxh_train)\n",
    "        if self.settings.test_target_param != 0:\n",
    "            idxh_test = idxh_target[np.sort(np.random.choice(len(idxh_target),\n",
    "                                    self.settings.test_target_param, replace = False))]\n",
    "            idxh_target = np.delete(idxh_target, np.where(np.in1d(idxh_target, idxh_test)))\n",
    "            for i in range(self.settings.test_target_param): assert(idxh_test[i] not in idxh_target\n",
    "                ), f\"ERROR: Target Parameter #{i} for Training & Test Sets not mutually Exclusive\"\n",
    "            \n",
    "            # Target & Test Label Index File Saving\n",
    "            print(f\">     Saving File Target Parameters for Training ({len(idxh_target)}) & Test {len(idxh_test)} Set's\")\n",
    "            np.savetxt(Path(f\"{self.settings.datasave_folderpath}/Test Labels (V{self.settings.data_version}).txt\"), idxh_test)\n",
    "            np.savetxt(Path(f\"{self.settings.datasave_folderpath}/Target Labels (V{self.settings.data_version}).txt\"), idxh_target)\n",
    "        if self.mode == 'Target': return idxh_target\n",
    "        else: return idxh_test\n",
    "        \n",
    "    # Label Scaler Download & Reverse Transformation\n",
    "    def label_unscale(\n",
    "        self,\n",
    "        y: np.array or pd.DataFrame\n",
    "    ):\n",
    "\n",
    "        # Label Scaler Download & Reverse Usage\n",
    "        try: self.scaler\n",
    "        except AttributeError:\n",
    "            scaler = torch.load(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "        return scaler.inverse_transform(y.reshape(1, -1))\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Cartesian to Polar Coordinate Conversion Functionality\n",
    "    def cart2polar(self, y: np.array):\n",
    "\n",
    "        # Cartesian to Polar Coordinates Conversion\n",
    "        phi = np.arccos(y[:, 2]).astype(np.float32); theta = np.arctan2(y[:, 1], y[:, 0])\n",
    "        theta = np.where(theta < 0, 2 * np.pi - np.abs(theta), theta).astype(np.float32)\n",
    "        theta = np.expand_dims(theta, axis = 1); phi = np.expand_dims(phi, axis = 1)\n",
    "        return pd.DataFrame(data = np.concatenate((theta, phi), axis = 1),\n",
    "                            columns = ['Gradient theta', 'Gradient phi'])\n",
    "\n",
    "    # Patient Mask Retrieval Functionality\n",
    "    def get_mask(settings, patient_id: int):\n",
    "        mask_filepath = Path(f\"{settings.mask_folderpath}/p{patient_id}.nii\")\n",
    "        assert(mask_filepath.exists()), f\"ERROR: Patient {patient_id}'s Mask not Found!\"\n",
    "        return load_img(mask_filepath)\n",
    "    \n",
    "    # Data Retrieval Functionality\n",
    "    def get_data(\n",
    "        settings,\n",
    "        patient_id: int,\n",
    "        idxv: int or np.array = None,\n",
    "        idxh_source: int or np.array = None,\n",
    "        idxh_target: int or np.array = None\n",
    "    ):\n",
    "        \n",
    "        # Dataset Download & Patient-Wise Splitting\n",
    "        idxv = np.expand_dims(np.array(idxv), axis = 1)\n",
    "        data = h5py.File(settings.data_filepath, 'r').get('data1')\n",
    "        idxv_full = pd.read_csv(settings.info_filepath, index_col = 0).to_numpy()\n",
    "        idxv_full = idxv_full[np.isin(idxv_full[:, 1], patient_id), 0]                  # Patient-Specific Index Values\n",
    "        mask = MUDI_CVAE_GAN_2D.get_mask(settings, patient_id)                          # Patient-Specific Mask Download\n",
    "        data = unmask(data[idxv_full, :].T, mask).get_fdata().T                         # Patient-Specific Data Unmasking\n",
    "        \n",
    "        # Dataset Source Horizontal / Parameter Indexing\n",
    "        if idxh_source is not None:\n",
    "            idxh_source = np.expand_dims(np.array(idxh_source), axis = 1)\n",
    "            X_source = data[tuple(np.concatenate([idxh_source, idxv], axis = -1).T)]\n",
    "            X_source = np.expand_dims(X_source, axis = 1)\n",
    "            X_source = MUDI_CVAE_GAN_2D.zero_padding(X_source, settings.img_shape)            \n",
    "        else: X_source = None\n",
    "\n",
    "        # Dataset Target Horizontal / Parameter & Vertical / Slice Indexing\n",
    "        if idxh_target is not None:\n",
    "            idxh_target = np.expand_dims(np.array(idxh_target), axis = 1)\n",
    "            X_target = data[tuple(np.concatenate([idxh_target, idxv], axis = -1).T)]\n",
    "            X_target = np.expand_dims(X_target, axis = 1)\n",
    "            X_target = MUDI_CVAE_GAN_2D.zero_padding(X_target, settings.img_shape)   \n",
    "        else: X_target = None\n",
    "        return torch.Tensor(X_source), torch.Tensor(X_target)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     > Utilizing 5 \\ 56 of the Available Slices\n",
      "     > Utilizing 500 \\ 500 of the Training Parameters\n",
      "     > Utilizing 844 \\ 844 of the Target Parameters\n",
      "     > Pre-Processing Images to be of Square Shape of 96\n",
      "     > Looping through 42200 \\ 422000 Source / Target Parameter Combos\n",
      "     > Manual Normalization of all 5 Parameter Values\n",
      "Item #0 | Slice #0 | Source Parameter #90| Target Parameter #{self.idxh_target[idxh_target]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset & DataLoader Initialization\n",
    "trainset = MUDI_CVAE_GAN_2D(settings, subject = [11], random = False,\n",
    "                            source_param = settings.train_source_param,\n",
    "                            target_param = settings.train_target_param,\n",
    "                            target_slice = settings.train_target_slice,\n",
    "                            param_loop = settings.train_param_loop)\n",
    "trainloader = DataLoader(   dataset = trainset, pin_memory = False,\n",
    "                            shuffle = True,#settings.val_sample_shuffle,\n",
    "                            num_workers = 0,#settings.num_workers,\n",
    "                            batch_size = 100)#len(trainset.idxv_target),#settings.batch_size,\n",
    "\n",
    "# Image Example Subplotting\n",
    "trainset.__getitem__(0)['y_train'].shape\n",
    "X_source, X_target = MUDI_CVAE_GAN_2D.get_data( settings,\n",
    "                                                patient_id = 11,\n",
    "                                                idxv = [0, 25],\n",
    "                                                idxh_source = [0, 25],\n",
    "                                                idxh_target = [0, 25])\n",
    "plt.imshow(X_target[1, 0, :, :], cmap = plt.cm.binary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Model* **Architecture**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Label-Excluding** *Architecture*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CVAE Encoder Main Block Class\n",
    "class EncoderBlock(nn.Module):\n",
    "\n",
    "    # Block Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int = 3,\n",
    "        stride: int = 2,\n",
    "        padding: int = 1,\n",
    "        momentum: float = 0.9\n",
    "    ):\n",
    "\n",
    "        # Class Variable Logging\n",
    "        super().__init__(); self.block = nn.Sequential(\n",
    "                nn.Conv2d(      in_channels = in_channels, out_channels = out_channels,\n",
    "                                kernel_size = kernel_size, stride = stride, padding = padding),\n",
    "                nn.BatchNorm2d( num_features = out_channels, momentum = momentum),\n",
    "                nn.ReLU(        inplace = False))\n",
    "    \n",
    "    # Block Application Function\n",
    "    def forward(self, X): return self.block(X)\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# CVAE Encoder Model Class\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser\n",
    "    ):\n",
    "        \n",
    "        # CVAE Encoder Convolutional Architecture Definition\n",
    "        super().__init__(); self.settings = settings; self.encoder_conv = []\n",
    "        in_channels = 1; out_channels = int(self.settings.dim_latent / 2)\n",
    "        for i in range(self.settings.num_hidden):\n",
    "            self.encoder_conv.append(EncoderBlock(  in_channels = in_channels,\n",
    "                                                    out_channels = out_channels,\n",
    "                                                    kernel_size = self.settings.kernel_size,\n",
    "                                                    padding = self.settings.padding))\n",
    "            in_channels = out_channels; out_channels *= 2\n",
    "        self.encoder_conv = nn.Sequential(*self.encoder_conv)\n",
    "\n",
    "        # CVAE Encoder Linear Architecture Definition\n",
    "        img_shape = np.ceil(self.settings.img_shape / (2 ** (self.settings.num_hidden)))\n",
    "        in_channels = int(in_channels * (img_shape ** 2))\n",
    "        self.encoder_fc = nn.Sequential(nn.Linear(  in_features = in_channels, bias = False,\n",
    "                                                    out_features = self.settings.dim_hidden),\n",
    "                                    nn.BatchNorm1d( num_features = self.settings.dim_hidden, momentum = 0.9),\n",
    "                                    nn.ReLU(        inplace = True))\n",
    "        self.encoder_mu = nn.Linear(                in_features = self.settings.dim_hidden + self.settings.num_labels,\n",
    "                                                    out_features = self.settings.dim_latent)\n",
    "        self.encoder_logvar = nn.Linear(            in_features = self.settings.dim_hidden + self.settings.num_labels,\n",
    "                                                    out_features = self.settings.dim_latent)\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # CVAE Encoder Application Function\n",
    "    def forward(\n",
    "        self,\n",
    "        X_train: np.ndarray or torch.Tensor,\n",
    "        y_train: np.ndarray or torch.Tensor\n",
    "    ):\n",
    "        out = self.encoder_conv(X_train)            # Convolutional Section Application\n",
    "        out = out.view(len(out), -1)                # Output Linearization\n",
    "        out = self.encoder_fc(out)                  # Linear Section Application\n",
    "        out = torch.cat((out, y_train), dim = 1)    # Inclusion of Training Labels\n",
    "        mu = self.encoder_mu(out)                   # Mean Computation\n",
    "        logvar = self.encoder_logvar(out)           # Log Variance Computation\n",
    "        return mu, logvar\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CVAE Decoder Main Block Class\n",
    "class DecoderBlock(nn.Module):\n",
    "\n",
    "    # Block Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int = 3,\n",
    "        stride: int = 2,\n",
    "        padding: int = 1,\n",
    "        momentum: float = 0.9\n",
    "    ):\n",
    "\n",
    "        # Class Variable Logging\n",
    "        super().__init__(); block = []\n",
    "        block.append(nn.Sequential(\n",
    "                        nn.ConvTranspose2d( in_channels = in_channels, out_channels = out_channels,\n",
    "                                            kernel_size = kernel_size, stride = stride,\n",
    "                                            padding = padding, output_padding = 1, bias = False),\n",
    "                        nn.BatchNorm2d(     num_features = out_channels, momentum = momentum), nn.ReLU()))\n",
    "        self.block = nn.Sequential(*block)\n",
    "\n",
    "    # Block Application Function\n",
    "    def forward(self, X): return self.block(X)\n",
    "                            \n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# CVAE Decoder Model Class\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser\n",
    "    ):\n",
    "\n",
    "        # CVAE Decoder Linear Architecture Definition\n",
    "        super().__init__(); self.settings = settings\n",
    "        self.img_shape = int(np.ceil(self.settings.img_shape / (2 ** (self.settings.num_hidden))))\n",
    "        out_channels = int((self.settings.dim_latent / 2) * (2 ** (self.settings.num_hidden - 1)) * (self.img_shape ** 2))\n",
    "        self.decoder_fc = nn.Sequential(\n",
    "                                nn.Linear(      in_features = self.settings.dim_latent + self.settings.num_labels,\n",
    "                                                out_features = out_channels, bias = False),\n",
    "                                nn.BatchNorm1d( num_features = out_channels, momentum = 0.9),\n",
    "                                nn.ReLU(        inplace = True))\n",
    "\n",
    "        # CVAE Decoder Convolutional Architecture Definition\n",
    "        in_channels = int(out_channels / (self.img_shape ** 2))\n",
    "        decoder_conv = []; out_channels = self.settings.dim_latent * 2\n",
    "        for i in range(self.settings.num_hidden):\n",
    "            #print(f\"{in_channels} -> {out_channels}\")\n",
    "            decoder_conv.append(DecoderBlock(   in_channels = in_channels,\n",
    "                                                out_channels = out_channels,\n",
    "                                                kernel_size = self.settings.kernel_size,\n",
    "                                                padding = self.settings.padding))\n",
    "            in_channels = out_channels; out_channels = int(out_channels / 2)\n",
    "        decoder_conv.append(nn.Sequential(\n",
    "                                    nn.Conv2d(  in_channels = in_channels, out_channels = 1,\n",
    "                                                kernel_size = self.settings.kernel_size,\n",
    "                                                padding = self.settings.padding), nn.Sigmoid()))\n",
    "        self.decoder_conv = nn.Sequential(*decoder_conv)\n",
    "                \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # CVAE Decoder Application Function\n",
    "    def forward(\n",
    "        self,\n",
    "        z: np.ndarray or torch.Tensor,\n",
    "        y_target: np.ndarray or torch.Tensor\n",
    "    ): \n",
    "        out = torch.cat((z, y_target), dim = 1)     # Inclusion of Target Labels\n",
    "        out = self.decoder_fc(out)                  # Linear Section Application\n",
    "        out = out.view( len(out), -1,\n",
    "                        self.img_shape,\n",
    "                        self.img_shape)             # Output Dimensionalization\n",
    "        return self.decoder_conv(out)               # Convolutional Section Application\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CVAE Model Class\n",
    "class CVAE(nn.Module):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser\n",
    "    ):\n",
    "        super().__init__(); self.settings = settings\n",
    "        self.encoder = Encoder(self.settings)\n",
    "        self.decoder = Decoder(self.settings)\n",
    "\n",
    "    # CVAE Model Application Function\n",
    "    def forward(\n",
    "        self,\n",
    "        X_train: np.ndarray or torch.Tensor,\n",
    "        y_train: np.ndarray or torch.Tensor,\n",
    "        y_target: np.ndarray or torch.Tensor\n",
    "    ):\n",
    "        mu, logvar = self.encoder(X_train, y_train)     # Encoder Model Application\n",
    "        z = CVAE.reparam(mu, logvar)                    # Reparametrization Trick\n",
    "        kl_loss = CVAE.kl_loss(mu, logvar)              # Kullback-Leibler Loss Computation\n",
    "        return self.decoder(z, y_target),kl_loss        # Decoder Model Application\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Reparametrization Trick Functionality\n",
    "    def reparam(mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + (eps * std)\n",
    "    \n",
    "    # Kullback-Leibler Divergence Computation Functionality\n",
    "    def kl_loss(mu, logvar):\n",
    "        return -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Initialization\n",
    "X_train = torch.rand((  10, 1, settings.img_shape,\n",
    "                        settings.img_shape))\n",
    "y_train = torch.rand((10, 5))\n",
    "y_target = torch.rand((10, 5))\n",
    "\n",
    "# Segmented CVAE Model Usage Example\n",
    "encoder = Encoder(settings)\n",
    "mu, logvar = encoder(X_train, y_train)\n",
    "z = torch.rand((10, settings.dim_latent))\n",
    "decoder = Decoder(settings)\n",
    "X_target1 = decoder(z, y_target)\n",
    "\n",
    "# Full CVAE Model Usage Example\n",
    "model = CVAE(settings); print(model)\n",
    "X_target = model(X_train, y_train, y_target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Label-Including** *Architecture*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CVAE Encoder Main Block Class\n",
    "class EncoderBlock(nn.Module):\n",
    "\n",
    "    # Block Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int = 3,\n",
    "        stride: int = 2,\n",
    "        padding: int = 1,\n",
    "        momentum: float = 0.9\n",
    "    ):\n",
    "\n",
    "        # Class Variable Logging\n",
    "        super().__init__(); self.block = nn.Sequential(\n",
    "                nn.Conv2d(      in_channels = in_channels, out_channels = out_channels,\n",
    "                                kernel_size = kernel_size, stride = stride, padding = padding),\n",
    "                nn.BatchNorm2d( num_features = out_channels, momentum = momentum),\n",
    "                nn.ReLU(        inplace = False))\n",
    "    \n",
    "    # Block Application Function\n",
    "    def forward(self, X): return self.block(X)\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# CVAE Encoder Model Class\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser\n",
    "    ):\n",
    "        \n",
    "        # CVAE Encoder Convolutional Architecture Definition\n",
    "        super().__init__()\n",
    "        self.settings = settings; self.encoder_conv = []\n",
    "        in_channels = self.settings.num_labels + 1\n",
    "        out_channels = int(self.settings.dim_latent / 2)\n",
    "        for i in range(self.settings.num_hidden):\n",
    "            self.encoder_conv.append(EncoderBlock(  in_channels = in_channels,\n",
    "                                                    out_channels = out_channels,\n",
    "                                                    kernel_size = self.settings.kernel_size,\n",
    "                                                    padding = self.settings.padding))\n",
    "            in_channels = out_channels; out_channels *= 2\n",
    "        self.encoder_conv = nn.Sequential(*self.encoder_conv)\n",
    "\n",
    "        # CVAE Encoder Linear Architecture Definition\n",
    "        img_shape = np.ceil(self.settings.img_shape / (2 ** (self.settings.num_hidden)))\n",
    "        in_channels = int(in_channels * (img_shape ** 2))\n",
    "        self.encoder_fc = nn.Sequential(nn.Linear(  in_features = in_channels, bias = False,\n",
    "                                                    out_features = self.settings.dim_hidden),\n",
    "                                    nn.BatchNorm1d( num_features = self.settings.dim_hidden, momentum = 0.9),\n",
    "                                    nn.ReLU(        inplace = True))\n",
    "        self.encoder_mu = nn.Linear(                in_features = self.settings.dim_hidden,\n",
    "                                                    out_features = self.settings.dim_latent)\n",
    "        self.encoder_logvar = nn.Linear(            in_features = self.settings.dim_hidden,\n",
    "                                                    out_features = self.settings.dim_latent)\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # CVAE Encoder Application Function\n",
    "    def forward(\n",
    "        self,\n",
    "        X_train: np.ndarray or torch.Tensor,\n",
    "        y_train: np.ndarray or torch.Tensor\n",
    "    ):\n",
    "        y_train = y_train.unsqueeze(dim = 2).unsqueeze(dim = 2)\n",
    "        y_train = y_train.repeat(1, 1, self.settings.img_shape,\n",
    "                                    self.settings.img_shape)\n",
    "        out = torch.cat((X_train, y_train), dim = 1)    # Inclusion of Training Labels\n",
    "        out = self.encoder_conv(out)                    # Convolutional Section Application\n",
    "        out = out.view(len(out), -1)                    # Output Linearization\n",
    "        out = self.encoder_fc(out)                      # Linear Section Application\n",
    "        mu = self.encoder_mu(out)                       # Mean Computation\n",
    "        logvar = self.encoder_logvar(out)               # Log Variance Computation\n",
    "        return mu, logvar\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CVAE Decoder Main Block Class\n",
    "class DecoderBlock(nn.Module):\n",
    "\n",
    "    # Block Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int = 3,\n",
    "        stride: int = 2,\n",
    "        padding: int = 1,\n",
    "        momentum: float = 0.9\n",
    "    ):\n",
    "\n",
    "        # Class Variable Logging\n",
    "        super().__init__(); block = []\n",
    "        block.append(nn.Sequential(\n",
    "                        nn.ConvTranspose2d( in_channels = in_channels, out_channels = out_channels,\n",
    "                                            kernel_size = kernel_size, stride = stride,\n",
    "                                            padding = padding, output_padding = 1, bias = False),\n",
    "                        nn.BatchNorm2d(     num_features = out_channels, momentum = momentum), nn.ReLU()))\n",
    "        self.block = nn.Sequential(*block)\n",
    "\n",
    "    # Block Application Function\n",
    "    def forward(self, X): return self.block(X)\n",
    "                            \n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# CVAE Decoder Model Class\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser\n",
    "    ):\n",
    "\n",
    "        # CVAE Decoder Linear Architecture Definition\n",
    "        super().__init__(); self.settings = settings\n",
    "        self.img_shape = int(np.ceil(self.settings.img_shape / (2 ** (self.settings.num_hidden))))\n",
    "        out_channels = int((self.settings.dim_latent / 2) * (2 ** (self.settings.num_hidden - 1)) * (self.img_shape ** 2))\n",
    "        self.decoder_fc = nn.Sequential(\n",
    "                                nn.Linear(      in_features = self.settings.dim_latent + self.settings.num_labels,\n",
    "                                                out_features = out_channels, bias = False),\n",
    "                                nn.BatchNorm1d( num_features = out_channels, momentum = 0.9),\n",
    "                                nn.ReLU(        inplace = True))\n",
    "\n",
    "        # CVAE Decoder Convolutional Architecture Definition\n",
    "        in_channels = int(out_channels / (self.img_shape ** 2))\n",
    "        decoder_conv = []; out_channels = self.settings.dim_latent * 2\n",
    "        for i in range(self.settings.num_hidden):\n",
    "            #print(f\"{in_channels} -> {out_channels}\")\n",
    "            decoder_conv.append(DecoderBlock(   in_channels = in_channels,\n",
    "                                                out_channels = out_channels,\n",
    "                                                kernel_size = self.settings.kernel_size,\n",
    "                                                padding = self.settings.padding))\n",
    "            in_channels = out_channels; out_channels = int(out_channels / 2)\n",
    "        decoder_conv.append(nn.Sequential(\n",
    "                                    nn.Conv2d(  in_channels = in_channels, out_channels = 1,\n",
    "                                                kernel_size = self.settings.kernel_size,\n",
    "                                                padding = self.settings.padding), nn.Sigmoid()))\n",
    "        self.decoder_conv = nn.Sequential(*decoder_conv)\n",
    "                \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # CVAE Decoder Application Function\n",
    "    def forward(\n",
    "        self,\n",
    "        z: np.ndarray or torch.Tensor,\n",
    "        y_target: np.ndarray or torch.Tensor\n",
    "    ): \n",
    "        out = torch.cat((z, y_target), dim = 1)     # Inclusion of Target Labels\n",
    "        out = self.decoder_fc(out)                  # Linear Section Application\n",
    "        out = out.view( len(out), -1,\n",
    "                        self.img_shape,\n",
    "                        self.img_shape)             # Output Dimensionalization\n",
    "        return self.decoder_conv(out)               # Convolutional Section Application\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CVAE Model Class\n",
    "class CVAE(nn.Module):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser\n",
    "    ):\n",
    "        super().__init__(); self.settings = settings\n",
    "        self.encoder = Encoder(self.settings)\n",
    "        self.decoder = Decoder(self.settings)\n",
    "\n",
    "    # CVAE Model Application Function\n",
    "    def forward(\n",
    "        self,\n",
    "        X_train: np.ndarray or torch.Tensor,\n",
    "        y_train: np.ndarray or torch.Tensor,\n",
    "        y_target: np.ndarray or torch.Tensor\n",
    "    ):\n",
    "        mu, logvar = self.encoder(X_train, y_train)     # Encoder Model Application\n",
    "        z = CVAE.reparam(mu, logvar)                    # Reparametrization Trick\n",
    "        kl_loss = CVAE.kl_loss(mu, logvar)              # Kullback-Leibler Loss Computation\n",
    "        return self.decoder(z, y_target),kl_loss        # Decoder Model Application\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Reparametrization Trick Functionality\n",
    "    def reparam(mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + (eps * std)\n",
    "    \n",
    "    # Kullback-Leibler Divergence Computation Functionality\n",
    "    def kl_loss(mu, logvar):\n",
    "        return -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVAE(\n",
      "  (encoder): Encoder(\n",
      "    (encoder_conv): Sequential(\n",
      "      (0): EncoderBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(6, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (1): EncoderBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (2): EncoderBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (encoder_fc): Sequential(\n",
      "      (0): Linear(in_features=36864, out_features=1024, bias=False)\n",
      "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (encoder_mu): Linear(in_features=1024, out_features=128, bias=True)\n",
      "    (encoder_logvar): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (decoder_fc): Sequential(\n",
      "      (0): Linear(in_features=133, out_features=36864, bias=False)\n",
      "      (1): BatchNorm1d(36864, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (decoder_conv): Sequential(\n",
      "      (0): DecoderBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Sequential(\n",
      "            (0): ConvTranspose2d(256, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): DecoderBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Sequential(\n",
      "            (0): ConvTranspose2d(256, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): DecoderBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Sequential(\n",
      "            (0): ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): Conv2d(64, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (1): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Dataset Initialization\n",
    "X_train = torch.rand((  10, 1, settings.img_shape,\n",
    "                        settings.img_shape))\n",
    "y_train = torch.rand((10, 5))\n",
    "y_target = torch.rand((10, 5))\n",
    "\n",
    "# Segmented CVAE Model Usage Example\n",
    "encoder = Encoder(settings)\n",
    "mu, logvar = encoder(X_train, y_train)\n",
    "z = torch.rand((10, settings.dim_latent))\n",
    "decoder = Decoder(settings)\n",
    "X_target1 = decoder(z, y_target)\n",
    "\n",
    "# Full CVAE Model Usage Example\n",
    "model = CVAE(settings); print(model)\n",
    "X_target, kl_loss = model(X_train, y_train, y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 1])\n",
      "torch.Size([5, 96, 96])\n",
      "torch.Size([6, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.rand((  1, settings.img_shape,\n",
    "                        settings.img_shape))\n",
    "y_train = torch.rand((5))\n",
    "y_train = y_train.unsqueeze(dim=1).unsqueeze(dim=1)\n",
    "print(y_train.shape)\n",
    "y_train = y_train.repeat(1, settings.img_shape, settings.img_shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "merged_input = torch.cat((X_train, y_train), dim=0)\n",
    "print(merged_input.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Training* **Script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D CVAE Model Training Script (V0)\n",
    "def CVAE_2D_train(\n",
    "    settings,\n",
    "):\n",
    "\n",
    "    ##############################################################################################\n",
    "    # ------------------------------------ Setup | DataLoader ------------------------------------\n",
    "    ##############################################################################################\n",
    "\n",
    "    # Seed Random State for Reproducibility\n",
    "    torch.manual_seed(settings.seed)\n",
    "    np.random.seed(settings.seed)\n",
    "    random.seed(settings.seed)\n",
    "\n",
    "    # Experiment Logs Directories Initialization\n",
    "    checkpoint_folderpath = os.path.join(f'{settings.modelsave_folderpath}/V{settings.model_version}', 'logs')\n",
    "    train_logger = TensorBoardLogger(checkpoint_folderpath, 'train/cvae')\n",
    "    train_results_logger = TensorBoardLogger(checkpoint_folderpath, 'train/results')\n",
    "\n",
    "    # Training & Validation DataLoaders Initialization\n",
    "    train_set = []; val_set = []; viz_logger = []\n",
    "    train_loader = []; val_loader = []\n",
    "    for p, patient_id in enumerate(settings.patient_list):\n",
    "\n",
    "        # Patient Set & DataLoader Initialization (Training Set)\n",
    "        if patient_id in settings.train_patient_list:\n",
    "            print(f\"Patient #{patient_id} | Training Set:\")\n",
    "            train_set.append(   MUDI_CVAE_GAN_2D(   settings, subject = [patient_id], random = True,\n",
    "                                                    source_param = settings.train_source_param,\n",
    "                                                    target_param = settings.train_target_param,\n",
    "                                                    target_slice = settings.train_target_slice,\n",
    "                                                    param_loop = settings.train_param_loop))\n",
    "            train_loader.append(DataLoader(         dataset = train_set[-1], pin_memory = True,\n",
    "                                                    shuffle = settings.train_sample_shuffle,\n",
    "                                                    num_workers = settings.num_workers,\n",
    "                                                    batch_size = settings.batch_size))\n",
    "    \n",
    "        elif patient_id in settings.val_patient_list:\n",
    "            print(f\"Patient #{patient_id} | Validation Set:\")\n",
    "            val_set.append(     MUDI_CVAE_GAN_2D(   settings, subject = [patient_id], random = False,\n",
    "                                                    source_param = settings.val_source_param,\n",
    "                                                    target_param = settings.val_target_param,\n",
    "                                                    target_slice = settings.val_target_slice,\n",
    "                                                    param_loop = settings.val_param_loop))\n",
    "            val_loader.append(  DataLoader(         dataset = val_set[-1], pin_memory = True,\n",
    "                                                    shuffle = settings.val_sample_shuffle,\n",
    "                                                    num_workers = settings.num_workers,\n",
    "                                                    batch_size = val_set[-1].s_target))\n",
    "            viz_logger.append(  TensorBoardLogger(checkpoint_folderpath, f'validation/p{patient_id}'))\n",
    "        else: print(f\"Patient #{patient_id} | Test Set:     > Not Included\")\n",
    "    \n",
    "    ##############################################################################################\n",
    "    # -------------------------------- Setup | Models & Optimizers -------------------------------\n",
    "    ##############################################################################################\n",
    "\n",
    "    # Model & Optimizer Initialization\n",
    "    print(f\"Running\\n     > Training 2D CVAE Model with {torch.cuda.device_count()} GPUs!\")\n",
    "    model = nn.DataParallel(CVAE(settings), device_ids = settings.device_ids).to(settings.device)\n",
    "    optimizer = torch.optim.AdamW(  model.parameters(), lr = settings.base_lr,\n",
    "                                    weight_decay = settings.weight_decay)\n",
    "    lr_schedule = ExponentialLR(optimizer, gamma = settings.lr_decay)\n",
    "\n",
    "    # Criterion & Early Stopping Setup\n",
    "    mse_criterion = nn.MSELoss(reduction = 'mean')\n",
    "    ssim_criterion = SSIM(window_size = settings.kernel_size)\n",
    "    bce_criterion = nn.BCELoss(reduction = 'sum')\n",
    "    earlyStopping = EarlyStopping(settings); train_iter = 0; val_iter = 0\n",
    "\n",
    "    # Model Checkpoint Loading\n",
    "    model_filepath = Path(f\"{settings.modelsave_folderpath}/V{settings.model_version}/Best 2D CVAE.pt\")\n",
    "    if model_filepath.exists():\n",
    "        checkpoint = torch.load(model_filepath, map_location = settings.device)\n",
    "        model.load_state_dict(checkpoint['Model'])\n",
    "        optimizer.load_state_dict(checkpoint['Optimizer'])\n",
    "        train_iter = checkpoint['Current Training Iteration']\n",
    "        val_iter = checkpoint['Current Validation Iteration']\n",
    "        save_epoch = checkpoint['Current Epoch']\n",
    "        torch.set_rng_state(checkpoint['RNG State'])\n",
    "        print(f\"     > Loading 2D CVAE Model for {settings.model_version}: {save_epoch} Past Epochs\"); del checkpoint\n",
    "    else: save_epoch = -1\n",
    "    \n",
    "    # Epoch Iteration Loop\n",
    "    for epoch in range(save_epoch + 1, settings.num_epochs):\n",
    "\n",
    "        ##############################################################################################\n",
    "        # ----------------------------------- Training | Iteration -----------------------------------\n",
    "        ##############################################################################################\n",
    "\n",
    "        # Result Value Initialization\n",
    "        train_mse = []; train_kld = []; train_ssim = []\n",
    "        best_train_mse = 1000; worst_train_mse = 0\n",
    "        best_train_ssim = 0; worst_train_ssim = 1000\n",
    "\n",
    "        # Training Patient Loop\n",
    "        print(f\"Training Epoch #{epoch}:\")\n",
    "        for p, patient_id in enumerate(settings.train_patient_list):\n",
    "\n",
    "            # Training Iteration Loop\n",
    "            train_bar = tqdm(   enumerate(train_loader[p]), total = len(train_loader[p]),\n",
    "                desc = f'Epoch #{epoch} | Training Patient {patient_id}', unit = 'Batches')\n",
    "            for batch_idx, batch in train_bar:\n",
    "                \n",
    "                # --------------------------------------------------------------------------------------------\n",
    "\n",
    "                # Forward Propagation\n",
    "                model.train(); model.zero_grad(); optimizer.zero_grad()\n",
    "                X_target, kld_loss = model( batch['X_train'].to(settings.device),\n",
    "                                            batch['y_train'].to(settings.device),\n",
    "                                            batch['y_target'].to(settings.device))          # Kullback-Leibler Divergence\n",
    "                \n",
    "                # Loss Computation\n",
    "                mse_loss = mse_criterion(X_target, batch['X_target'].to(settings.device))   # Mean Squared Error Loss\n",
    "                ssim_loss = ssim_criterion(X_target,\n",
    "                    torch.Tensor(batch['X_target']).to(settings.device)).detach().cpu()     # Structural Similarity Index\n",
    "                bce_loss = bce_criterion(X_target, batch['X_target'].to(settings.device))   # Binary Cross Entropy Loss\n",
    "                \n",
    "                # Backwards Propagation\n",
    "                loss = Variable(bce_loss + kld_loss, requires_grad = True)\n",
    "                loss.backward(); optimizer.step()\n",
    "                gc.collect(); torch.cuda.empty_cache()\n",
    "                \n",
    "                # Loss Appending\n",
    "                train_mse.append(mse_loss.item()); train_ssim.append(ssim_loss.detach().cpu())\n",
    "                train_kld.append(kld_loss.item()); train_bce.append(bce_loss.detach().cpu())\n",
    "                train_logger.experiment.add_scalar(\"MSE Loss | Batch\", mse_loss.item(), train_iter)\n",
    "                train_logger.experiment.add_scalar(\"KL Divergence | Batch\", kld_loss.item(), train_iter)\n",
    "                train_logger.experiment.add_scalar(\"SSIM Index | Batch\", ssim_loss.item(), train_iter)\n",
    "                train_logger.experiment.add_scalar(\"BCE Loss | Batch\", bce_loss.detach().cpu(), train_iter)\n",
    "                train_iter += 1\n",
    "\n",
    "                # --------------------------------------------------------------------------------------------\n",
    "\n",
    "                # Result Saving (CVAE MSE Loss)\n",
    "                if mse_loss.item() < best_train_mse:\n",
    "                    best_train_mse = mse_loss.item()\n",
    "                    best_train_mse_info = { 'loss': mse_loss.item(), 'X_pred': X_target.detach().cpu(),\n",
    "                                            'patient_id': patient_id, 'idxv_slice': batch['slice_target'],\n",
    "                                            'idxh_source': batch['param_source'], 'idxh_target': batch['param_target']}\n",
    "                if mse_loss.item() > worst_train_mse:\n",
    "                    worst_train_mse = mse_loss.item()\n",
    "                    worst_train_mse_info = {'loss': mse_loss.item(), 'X_pred': X_target.detach().cpu(),\n",
    "                                            'patient_id': patient_id, 'idxv_slice': batch['slice_target'],\n",
    "                                            'idxh_source': batch['param_source'], 'idxh_target': batch['param_target']}\n",
    "                    \n",
    "                # Result Saving (CVAE SSIM Index)\n",
    "                if ssim_loss.item() > best_train_ssim:\n",
    "                    best_train_ssim = ssim_loss\n",
    "                    best_train_ssim_info = {'loss': ssim_loss.item(), 'X_pred': X_target.detach().cpu(),\n",
    "                                            'patient_id': patient_id, 'idxv_slice': batch['slice_target'],\n",
    "                                            'idxh_source': batch['param_source'], 'idxh_target': batch['param_target']}\n",
    "                if ssim_loss.item() < worst_train_ssim:\n",
    "                    worst_train_ssim = ssim_loss\n",
    "                    worst_train_ssim_info = {'loss': ssim_loss.item(), 'X_pred': X_target.detach().cpu(),\n",
    "                                             'patient_id': patient_id, 'idxv_slice': batch['slice_target'],\n",
    "                                             'idxh_source': batch['param_source'], 'idxh_target': batch['param_target']}\n",
    "\n",
    "                # Result Saving (CVAE MSE Loss)\n",
    "                if bce_loss.detach().cpu() < best_train_bce:\n",
    "                    best_train_bce = bce_loss.detach().cpu()\n",
    "                    best_train_bce_info = {'loss': bce_loss.detach().cpu(), 'X_pred': X_target.detach().cpu(),\n",
    "                                           'patient_id': patient_id, 'idxv_slice': batch['slice_target'],\n",
    "                                           'idxh_source': batch['param_source'], 'idxh_target': batch['param_target']}\n",
    "                if bce_loss.detach().cpu() > worst_train_bce:\n",
    "                    worst_train_bce = bce_loss.detach().cpu()\n",
    "                    worst_train_bce_info = {'loss': bce_loss.detach().cpu(), 'X_pred': X_target.detach().cpu(),\n",
    "                                            'patient_id': patient_id, 'idxv_slice': batch['slice_target'],\n",
    "                                            'idxh_source': batch['param_source'], 'idxh_target': batch['param_target']}\n",
    "                gc.collect(); torch.cuda.empty_cache()\n",
    "                del X_target\n",
    "\n",
    "        ##############################################################################################\n",
    "        # ------------------------------------ Training | Results ------------------------------------\n",
    "        ##############################################################################################\n",
    "\n",
    "            # Inter-Patient Reconstruction Parameter Sharing Functionality\n",
    "            if settings.interpatient_sharing:\n",
    "                if p == 0: train_set[p].shuffle(); idxh_target_train = train_set[p].idxh_target\n",
    "                else:\n",
    "                    train_set[p].shuffle(idxh_target = idxh_target_train)\n",
    "                    assert(np.all(  train_set[p].idxh_target == train_set[0].idxh_target)\n",
    "                                    ), f\"     > ERROR: Parameter Sharing incorrectly setup!\"\n",
    "            else: train_set[p].shuffle()        \n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # End of Training Epoch Mean & STD Loss Writing\n",
    "        print(lr_scheduler.get_last_lr())\n",
    "        train_logger.experiment.add_scalar(\"Learning Rate\", lr_scheduler.get_last_lr()[0], epoch); lr_scheduler.step()\n",
    "        train_results_logger.experiment.add_scalar(\"MSE Loss | Mean\", np.mean(np.array(train_mse)), epoch)\n",
    "        train_results_logger.experiment.add_scalar(\"MSE Loss | STD\", np.std(np.array(train_mse)), epoch)\n",
    "        train_results_logger.experiment.add_scalar(\"SSIM Index | Mean\", np.mean(np.array(train_ssim)), epoch)\n",
    "        train_results_logger.experiment.add_scalar(\"SSIM Index | STD\", np.std(np.array(train_ssim)), epoch)\n",
    "        train_results_logger.experiment.add_scalar(\"KL Divergence | Mean\", np.mean(np.array(train_kld)), epoch)\n",
    "        train_results_logger.experiment.add_scalar(\"KL Divergence | STD\", np.std(np.array(train_kld)), epoch)\n",
    "        train_results_logger.experiment.add_scalar(\"BCE Loss | Mean\", np.mean(np.array(train_bce)), epoch)\n",
    "        train_results_logger.experiment.add_scalar(\"BCE Loss | STD\", np.std(np.array(train_bce)), epoch)\n",
    "\n",
    "        # End of Training Epoch Image Result Writing\n",
    "        train_results_logger = ResultCallback(  settings, logger = train_results_logger, mode = 'Train', epoch = epoch,\n",
    "                                                criterion = nn.MSELoss(reduction = 'none'), loss = 'MSE Loss',\n",
    "                                                best_info = best_train_mse_info, worst_info = worst_train_mse_info)\n",
    "        train_results_logger = ResultCallback(  settings, logger = train_results_logger, mode = 'Train', epoch = epoch,\n",
    "                                                criterion = ssim_criterion, loss = 'SSIM Index',\n",
    "                                                best_info = best_train_ssim_info, worst_info = worst_train_ssim_info)\n",
    "        train_results_logger = ResultCallback(  settings, logger = train_results_logger, mode = 'Train', epoch = epoch,\n",
    "                                                criterion = nn.BCELoss(reduction = 'none'), loss = 'BCE Loss',\n",
    "                                                best_info = best_train_bce_info, worst_info = worst_train_bce_info)\n",
    "\n",
    "        ##############################################################################################\n",
    "        # ---------------------------------- Validation | Iteration ----------------------------------\n",
    "        ##############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D CVAE Model Training Script (V0)\n",
    "def CVAE_2D_train(\n",
    "    settings,\n",
    "):\n",
    "\n",
    "    ##############################################################################################\n",
    "    # ------------------------------------ Setup | DataLoader ------------------------------------\n",
    "    ##############################################################################################\n",
    "\n",
    "    # Seed Random State for Reproducibility\n",
    "    torch.manual_seed(settings.seed)\n",
    "    np.random.seed(settings.seed)\n",
    "    random.seed(settings.seed)\n",
    "\n",
    "    # Experiment Logs Directories Initialization\n",
    "    checkpoint_folderpath = os.path.join(f'{settings.modelsave_folderpath}/V{settings.model_version}', 'logs')\n",
    "    train_logger = TensorBoardLogger(checkpoint_folderpath, 'train/cvae')\n",
    "    train_results_logger = TensorBoardLogger(checkpoint_folderpath, 'train/results')\n",
    "\n",
    "    # Training & Validation DataLoaders Initialization\n",
    "    train_set = []; val_set = []; viz_logger = []\n",
    "    train_loader = []; val_loader = []\n",
    "    for p, patient_id in enumerate(settings.patient_list):\n",
    "\n",
    "        # Patient Set & DataLoader Initialization (Training Set)\n",
    "        if patient_id in settings.train_patient_list:\n",
    "            print(f\"Patient #{patient_id} | Training Set:\")\n",
    "            train_set.append(   MUDI_CVAE_GAN_2D(   settings, subject = [patient_id], random = True,\n",
    "                                                    source_param = settings.train_source_param,\n",
    "                                                    target_param = settings.train_target_param,\n",
    "                                                    target_slice = settings.train_target_slice,\n",
    "                                                    param_loop = settings.train_param_loop))\n",
    "            train_loader.append(DataLoader(         dataset = train_set[-1], pin_memory = True,\n",
    "                                                    shuffle = settings.train_sample_shuffle,\n",
    "                                                    num_workers = settings.num_workers,\n",
    "                                                    batch_size = settings.batch_size))\n",
    "    \n",
    "        elif patient_id in settings.val_patient_list:\n",
    "            print(f\"Patient #{patient_id} | Validation Set:\")\n",
    "            val_set.append(     MUDI_CVAE_GAN_2D(   settings, subject = [patient_id], random = False,\n",
    "                                                    source_param = settings.val_source_param,\n",
    "                                                    target_param = settings.val_target_param,\n",
    "                                                    target_slice = settings.val_target_slice,\n",
    "                                                    param_loop = settings.val_param_loop))\n",
    "            val_loader.append(  DataLoader(         dataset = val_set[-1], pin_memory = True,\n",
    "                                                    shuffle = settings.val_sample_shuffle,\n",
    "                                                    num_workers = settings.num_workers,\n",
    "                                                    batch_size = val_set[-1].s_target))\n",
    "            viz_logger.append(  TensorBoardLogger(checkpoint_folderpath, f'validation/p{patient_id}'))\n",
    "        else: print(f\"Patient #{patient_id} | Test Set:     > Not Included\")\n",
    "    \n",
    "    ##############################################################################################\n",
    "    # -------------------------------- Setup | Models & Optimizers -------------------------------\n",
    "    ##############################################################################################\n",
    "\n",
    "    # Model & Optimizer Initialization\n",
    "    print(f\"Running\\n     > Training 2D CVAE Model with {torch.cuda.device_count()} GPUs!\")\n",
    "    model = nn.DataParallel(CVAE(settings), device_ids = settings.device_ids).to(settings.device)\n",
    "    optimizer = torch.optim.AdamW(  model.parameters(), lr = settings.base_lr,\n",
    "                                    weight_decay = settings.weight_decay)\n",
    "    lr_scheduler = ExponentialLR(optimizer, gamma = settings.lr_decay)\n",
    "\n",
    "    # Criterion & Early Stopping Setup\n",
    "    mse_criterion = nn.MSELoss(reduction = 'mean')\n",
    "    ssim_criterion = SSIM(window_size = settings.kernel_size)\n",
    "    bce_criterion = nn.BCELoss(reduction = 'sum')\n",
    "    earlyStopping = EarlyStopping(settings); train_iter = 0; val_iter = 0\n",
    "\n",
    "    # Model Checkpoint Loading\n",
    "    model_filepath = Path(f\"{settings.modelsave_folderpath}/V{settings.model_version}/Best 2D CVAE.pt\")\n",
    "    if model_filepath.exists():\n",
    "        checkpoint = torch.load(model_filepath, map_location = settings.device)\n",
    "        model.load_state_dict(checkpoint['Model'])\n",
    "        optimizer.load_state_dict(checkpoint['Optimizer'])\n",
    "        train_iter = checkpoint['Current Training Iteration']\n",
    "        val_iter = checkpoint['Current Validation Iteration']\n",
    "        save_epoch = checkpoint['Current Epoch']\n",
    "        torch.set_rng_state(checkpoint['RNG State'])\n",
    "        print(f\"     > Loading 2D CVAE Model for {settings.model_version}: {save_epoch} Past Epochs\"); del checkpoint\n",
    "    else: save_epoch = -1\n",
    "    \n",
    "    # Epoch Iteration Loop\n",
    "    for epoch in range(save_epoch + 1, settings.num_epochs):\n",
    "\n",
    "        ##############################################################################################\n",
    "        # ----------------------------------- Training | Iteration -----------------------------------\n",
    "        ##############################################################################################\n",
    "\n",
    "        # Result Value Initialization\n",
    "        train_mse = []; train_kld = []; train_ssim = []; train_bce = []\n",
    "        best_train_mse = 1000; worst_train_mse = 0\n",
    "        best_train_ssim = 0; worst_train_ssim = 1000\n",
    "        best_train_bce = 1000; worst_train_bce = 0\n",
    "\n",
    "        # Training Patient Loop\n",
    "        print(f\"Training Epoch #{epoch}:\")\n",
    "        for p, patient_id in enumerate(settings.train_patient_list):\n",
    "\n",
    "            # Training Iteration Loop\n",
    "            train_bar = tqdm(   enumerate(train_loader[p]), total = len(train_loader[p]),\n",
    "                desc = f'Epoch #{epoch} | Training Patient {patient_id}', unit = 'Batches')\n",
    "            for batch_idx, batch in train_bar:\n",
    "                \n",
    "                # --------------------------------------------------------------------------------------------\n",
    "\n",
    "                # Forward Propagation\n",
    "                model.train(); model.zero_grad(); optimizer.zero_grad()\n",
    "                X_target, kld_loss = model( batch['X_train'].to(settings.device),\n",
    "                                            batch['y_train'].to(settings.device),\n",
    "                                            batch['y_target'].to(settings.device))          # Kullback-Leibler Divergence\n",
    "                \n",
    "                # Loss Computation\n",
    "                mse_loss = mse_criterion(X_target, batch['X_target'].to(settings.device))   # Mean Squared Error Loss\n",
    "                ssim_loss = ssim_criterion(X_target,\n",
    "                    torch.Tensor(batch['X_target']).to(settings.device)).detach().cpu()     # Structural Similarity Index\n",
    "                bce_loss = bce_criterion(X_target, batch['X_target'].to(settings.device))   # Binary Cross Entropy Loss\n",
    "                \n",
    "                # Backwards Propagation\n",
    "                loss_backprop = torch.autograd.Variable(mse_loss + kld_loss, requires_grad = True)\n",
    "                ssim_loss_backprop = torch.autograd.Variable(1 - ssim_loss, requires_grad = True)\n",
    "                loss_backprop.backward(retain_graph = True); ssim_loss_backprop.backward(); optimizer.step()\n",
    "                gc.collect(); torch.cuda.empty_cache()\n",
    "                \n",
    "                # Loss Appending\n",
    "                train_mse.append(mse_loss.item()); train_ssim.append(ssim_loss.detach().cpu())\n",
    "                train_kld.append(kld_loss.item()); train_bce.append(bce_loss.detach().cpu())\n",
    "                train_logger.experiment.add_scalar(\"MSE Loss | Batch\", mse_loss.item(), train_iter)\n",
    "                train_logger.experiment.add_scalar(\"KL Divergence | Batch\", kld_loss.item(), train_iter)\n",
    "                train_logger.experiment.add_scalar(\"SSIM Index | Batch\", ssim_loss.item(), train_iter)\n",
    "                train_logger.experiment.add_scalar(\"BCE Loss | Batch\", bce_loss.detach().cpu(), train_iter)\n",
    "                train_iter += 1\n",
    "\n",
    "                # --------------------------------------------------------------------------------------------\n",
    "\n",
    "                # Result Saving (CVAE MSE Loss)\n",
    "                if mse_loss.item() < best_train_mse:\n",
    "                    best_train_mse = mse_loss.item()\n",
    "                    best_train_mse_info = { 'loss': mse_loss.item(), 'X_pred': X_target.detach().cpu(),\n",
    "                                            'patient_id': patient_id, 'idxv_slice': batch['slice_target'],\n",
    "                                            'idxh_source': batch['param_source'], 'idxh_target': batch['param_target']}\n",
    "                if mse_loss.item() > worst_train_mse:\n",
    "                    worst_train_mse = mse_loss.item()\n",
    "                    worst_train_mse_info = {'loss': mse_loss.item(), 'X_pred': X_target.detach().cpu(),\n",
    "                                            'patient_id': patient_id, 'idxv_slice': batch['slice_target'],\n",
    "                                            'idxh_source': batch['param_source'], 'idxh_target': batch['param_target']}\n",
    "                    \n",
    "                # Result Saving (CVAE SSIM Index)\n",
    "                if ssim_loss.item() > best_train_ssim:\n",
    "                    best_train_ssim = ssim_loss\n",
    "                    best_train_ssim_info = {'loss': ssim_loss.item(), 'X_pred': X_target.detach().cpu(),\n",
    "                                            'patient_id': patient_id, 'idxv_slice': batch['slice_target'],\n",
    "                                            'idxh_source': batch['param_source'], 'idxh_target': batch['param_target']}\n",
    "                if ssim_loss.item() < worst_train_ssim:\n",
    "                    worst_train_ssim = ssim_loss\n",
    "                    worst_train_ssim_info = {'loss': ssim_loss.item(), 'X_pred': X_target.detach().cpu(),\n",
    "                                             'patient_id': patient_id, 'idxv_slice': batch['slice_target'],\n",
    "                                             'idxh_source': batch['param_source'], 'idxh_target': batch['param_target']}\n",
    "\n",
    "                # Result Saving (CVAE MSE Loss)\n",
    "                if bce_loss.detach().cpu() < best_train_bce:\n",
    "                    best_train_bce = bce_loss.detach().cpu()\n",
    "                    best_train_bce_info = {'loss': bce_loss.detach().cpu(), 'X_pred': X_target.detach().cpu(),\n",
    "                                           'patient_id': patient_id, 'idxv_slice': batch['slice_target'],\n",
    "                                           'idxh_source': batch['param_source'], 'idxh_target': batch['param_target']}\n",
    "                if bce_loss.detach().cpu() > worst_train_bce:\n",
    "                    worst_train_bce = bce_loss.detach().cpu()\n",
    "                    worst_train_bce_info = {'loss': bce_loss.detach().cpu(), 'X_pred': X_target.detach().cpu(),\n",
    "                                            'patient_id': patient_id, 'idxv_slice': batch['slice_target'],\n",
    "                                            'idxh_source': batch['param_source'], 'idxh_target': batch['param_target']}\n",
    "                gc.collect(); torch.cuda.empty_cache(); del X_target\n",
    "\n",
    "        ##############################################################################################\n",
    "        # ------------------------------------ Training | Results ------------------------------------\n",
    "        ##############################################################################################\n",
    "\n",
    "            # Inter-Patient Reconstruction Parameter Sharing Functionality\n",
    "            if settings.interpatient_sharing:\n",
    "                if p == 0: train_set[p].shuffle(); idxh_target_train = train_set[p].idxh_target\n",
    "                else:\n",
    "                    train_set[p].shuffle(idxh_target = idxh_target_train)\n",
    "                    assert(np.all(  train_set[p].idxh_target == train_set[0].idxh_target)\n",
    "                                    ), f\"     > ERROR: Parameter Sharing incorrectly setup!\"\n",
    "            else: train_set[p].shuffle()        \n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # End of Training Epoch Mean & STD Loss Writing\n",
    "        print(lr_scheduler.get_last_lr())\n",
    "        train_logger.experiment.add_scalar(\"Learning Rate\", lr_scheduler.get_last_lr()[0], epoch); lr_scheduler.step()\n",
    "        train_results_logger.experiment.add_scalar(\"MSE Loss | Mean\", np.mean(np.array(train_mse)), epoch)\n",
    "        train_results_logger.experiment.add_scalar(\"MSE Loss | STD\", np.std(np.array(train_mse)), epoch)\n",
    "        train_results_logger.experiment.add_scalar(\"SSIM Index | Mean\", np.mean(np.array(train_ssim)), epoch)\n",
    "        train_results_logger.experiment.add_scalar(\"SSIM Index | STD\", np.std(np.array(train_ssim)), epoch)\n",
    "        train_results_logger.experiment.add_scalar(\"KL Divergence | Mean\", np.mean(np.array(train_kld)), epoch)\n",
    "        train_results_logger.experiment.add_scalar(\"KL Divergence | STD\", np.std(np.array(train_kld)), epoch)\n",
    "        train_results_logger.experiment.add_scalar(\"BCE Loss | Mean\", np.mean(np.array(train_bce)), epoch)\n",
    "        train_results_logger.experiment.add_scalar(\"BCE Loss | STD\", np.std(np.array(train_bce)), epoch)\n",
    "\n",
    "        # End of Training Epoch Image Result Writing\n",
    "        train_results_logger = ResultCallback(  settings, logger = train_results_logger, mode = 'Train', epoch = epoch,\n",
    "                                                criterion = nn.MSELoss(reduction = 'none'), loss = 'MSE Loss',\n",
    "                                                best_info = best_train_mse_info, worst_info = worst_train_mse_info)\n",
    "        train_results_logger = ResultCallback(  settings, logger = train_results_logger, mode = 'Train', epoch = epoch,\n",
    "                                                criterion = ssim_criterion, loss = 'SSIM Index',\n",
    "                                                best_info = best_train_ssim_info, worst_info = worst_train_ssim_info)\n",
    "        train_results_logger = ResultCallback(  settings, logger = train_results_logger, mode = 'Train', epoch = epoch,\n",
    "                                                criterion = nn.BCELoss(reduction = 'none'), loss = 'BCE Loss',\n",
    "                                                best_info = best_train_bce_info, worst_info = worst_train_bce_info)\n",
    "\n",
    "        ##############################################################################################\n",
    "        # ---------------------------------- Validation | Iteration ----------------------------------\n",
    "        ##############################################################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Training* **Callbacks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result Plotting Functionality (V0)\n",
    "def ResultCallback(\n",
    "    settings,\n",
    "    logger: TensorBoardLogger,\n",
    "    criterion,\n",
    "    best_info: dict,\n",
    "    worst_info: dict,\n",
    "    epoch: int = 0,\n",
    "    mode: str = 'Train',\n",
    "    loss: str = 'MSE Loss',\n",
    "):\n",
    "\n",
    "    # Set Example Reconstruction Results Image Plotting\n",
    "    plot = plt.figure(figsize = (30, 25)); plt.suptitle(f\"Overall {mode} | {loss}\")\n",
    "    plt.xticks([]); plt.yticks([]); plt.grid(False); plt.tight_layout()\n",
    "    \n",
    "    # Source & GT Target Data Retrieval & Element-Wise Loss Computation\n",
    "    best_info['X_train'], best_info['X_gt'] = MUDI_CVAE_GAN_2D.get_data(    settings, idxv = best_info['idxv_slice'],\n",
    "                                                                            patient_id = best_info['patient_id'],\n",
    "                                                                            idxh_source = best_info['idxh_source'],\n",
    "                                                                            idxh_target = best_info['idxh_target'])\n",
    "    worst_info['X_train'], worst_info['X_gt'] = MUDI_CVAE_GAN_2D.get_data(  settings, idxv = worst_info['idxv_slice'],\n",
    "                                                                            patient_id = worst_info['patient_id'],\n",
    "                                                                            idxh_source = worst_info['idxh_source'],\n",
    "                                                                            idxh_target = worst_info['idxh_target'])\n",
    "    \n",
    "    # Best & Worst Loss Value Indexing\n",
    "    print(best_info['X_pred'].shape); print(best_info['X_gt'].shape)\n",
    "    print(worst_info['X_pred'].shape); print(worst_info['X_gt'].shape)\n",
    "    best_loss = torch.mean(criterion(best_info['X_pred'], best_info['X_gt']), dim = [1, 2, 3])\n",
    "    worst_loss = torch.mean(criterion(worst_info['X_pred'], worst_info['X_gt']), dim = [1, 2, 3])\n",
    "    best_idx = torch.argmax(best_loss); worst_idx = torch.argmin(worst_loss)\n",
    "\n",
    "    # Set Example Original & Best Loss Reconstructed Image Subplots\n",
    "    plt.subplot(2, 3, 1, title =    f\"Best | Source Parameter #{best_info['idxh_source'][best_idx]}\")\n",
    "    plt.imshow(best_info['X_train'][best_idx, best_idx, :, :], cmap = plt.cm.binary)\n",
    "    plt.subplot(2, 3, 2, title =    f\"Best | Target Parameter #{best_info['idxh_target'][best_idx]}\")\n",
    "    plt.imshow(best_info['X_gt'][   best_idx, best_idx, :, :], cmap = plt.cm.binary)\n",
    "    plt.subplot(2, 3, 3, title =    f\"Best | Reconstruction | {loss}: {np.round(best_loss[best_idx], 5)}\")\n",
    "    plt.imshow(best_info['X_pred'][ best_idx, 0, :, :], cmap = plt.cm.binary)\n",
    "\n",
    "    # Set Example Original & Worst Loss Reconstructed Image Subplots\n",
    "    plt.subplot(2, 3, 4, title =    f\"Best | Source Parameter #{worst_info['idxh_source'][worst_idx]}\")\n",
    "    plt.imshow(worst_info['X_train'][worst_idx, worst_idx, :, :], cmap = plt.cm.binary)\n",
    "    plt.subplot(2, 3, 5, title =    f\"Best | Target Parameter #{worst_info['idxh_target'][worst_idx]}\")\n",
    "    plt.imshow(worst_info['X_gt'][  worst_idx, worst_idx, :, :], cmap = plt.cm.binary)\n",
    "    plt.subplot(2, 3, 6, title =    f\"Best | Reconstruction | {loss}: {np.round(worst_loss[worst_idx], 5)}\")\n",
    "    plt.imshow(worst_info['X_pred'][worst_idx, 0, :, :], cmap = plt.cm.binary)\n",
    "\n",
    "    # Tensorboard Reconstruction Callback\n",
    "    logger.experiment.add_figure(f\"Overall {mode} | {loss}\", plot, epoch)\n",
    "    logger.experiment.add_scalar(f\"{loss} | Best\", best_loss[best_idx], epoch)\n",
    "    logger.experiment.add_scalar(f\"{loss} | Worst\", worst_loss[worst_idx], epoch)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSIM Loss Callback\n",
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
    "    return gauss/gauss.sum()\n",
    "\n",
    "def create_window(window_size, channel):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
    "    return window\n",
    "\n",
    "def create_window_3D(window_size, channel):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t())\n",
    "    _3D_window = _1D_window.mm(_2D_window.reshape(1, -1)).reshape(window_size, window_size, window_size).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = Variable(_3D_window.expand(channel, 1, window_size, window_size, window_size).contiguous())\n",
    "    return window\n",
    "\n",
    "def _ssim(img1, img2, window, window_size, channel, size_average = True):\n",
    "    mu1 = F.conv2d(img1, window, padding = window_size//2, groups = channel)\n",
    "    mu2 = F.conv2d(img2, window, padding = window_size//2, groups = channel)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1*mu2\n",
    "\n",
    "    sigma1_sq = F.conv2d(img1*img1, window, padding = window_size//2, groups = channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2*img2, window, padding = window_size//2, groups = channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1*img2, window, padding = window_size//2, groups = channel) - mu1_mu2\n",
    "\n",
    "    C1 = 0.01**2\n",
    "    C2 = 0.03**2\n",
    "\n",
    "    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "    if size_average:\n",
    "        return ssim_map.mean()\n",
    "    else:\n",
    "        return ssim_map.mean(1).mean(1).mean(1)\n",
    "    \n",
    "def _ssim_3D(img1, img2, window, window_size, channel, size_average = True):\n",
    "    mu1 = F.conv3d(img1, window, padding = window_size//2, groups = channel)\n",
    "    mu2 = F.conv3d(img2, window, padding = window_size//2, groups = channel)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "\n",
    "    mu1_mu2 = mu1*mu2\n",
    "\n",
    "    sigma1_sq = F.conv3d(img1*img1, window, padding = window_size//2, groups = channel) - mu1_sq\n",
    "    sigma2_sq = F.conv3d(img2*img2, window, padding = window_size//2, groups = channel) - mu2_sq\n",
    "    sigma12 = F.conv3d(img1*img2, window, padding = window_size//2, groups = channel) - mu1_mu2\n",
    "\n",
    "    C1 = 0.01**2\n",
    "    C2 = 0.03**2\n",
    "\n",
    "    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "    if size_average:\n",
    "        return ssim_map.mean()\n",
    "    else:\n",
    "        return ssim_map.mean(1).mean(1).mean(1)\n",
    "    \n",
    "\n",
    "\n",
    "class SSIM(torch.nn.Module):\n",
    "    def __init__(self, window_size = 11, size_average = True):\n",
    "        super(SSIM, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.size_average = size_average\n",
    "        self.channel = 1\n",
    "        self.window = create_window(window_size, self.channel)\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        (_, channel, _, _) = img1.size()\n",
    "\n",
    "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
    "            window = self.window\n",
    "        else:\n",
    "            window = create_window(self.window_size, channel)\n",
    "            \n",
    "            if img1.is_cuda:\n",
    "                window = window.cuda(img1.get_device())\n",
    "            window = window.type_as(img1)\n",
    "            \n",
    "            self.window = window\n",
    "            self.channel = channel\n",
    "\n",
    "\n",
    "        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n",
    "    \n",
    "    \n",
    "class SSIM3D(torch.nn.Module):\n",
    "    def __init__(self, window_size = 11, size_average = True):\n",
    "        super(SSIM3D, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.size_average = size_average\n",
    "        self.channel = 1\n",
    "        self.window = create_window_3D(window_size, self.channel)\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        (_, channel, _, _, _) = img1.size()\n",
    "\n",
    "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
    "            window = self.window\n",
    "        else:\n",
    "            window = create_window_3D(self.window_size, channel)\n",
    "            \n",
    "            if img1.is_cuda:\n",
    "                window = window.cuda(img1.get_device())\n",
    "            window = window.type_as(img1)\n",
    "            \n",
    "            self.window = window\n",
    "            self.channel = channel\n",
    "\n",
    "\n",
    "        return _ssim_3D(img1, img2, window, self.window_size, channel, self.size_average)\n",
    "\n",
    "    \n",
    "def ssim(img1, img2, window_size = 11, size_average = True):\n",
    "    (_, channel, _, _) = img1.size()\n",
    "    window = create_window(window_size, channel)\n",
    "    \n",
    "    if img1.is_cuda:\n",
    "        window = window.cuda(img1.get_device())\n",
    "    window = window.type_as(img1)\n",
    "    \n",
    "    return _ssim(img1, img2, window, window_size, channel, size_average)\n",
    "\n",
    "def ssim3D(img1, img2, window_size = 11, size_average = True):\n",
    "    (_, channel, _, _, _) = img1.size()\n",
    "    window = create_window_3D(window_size, channel)\n",
    "    \n",
    "    if img1.is_cuda:\n",
    "        window = window.cuda(img1.get_device())\n",
    "    window = window.type_as(img1)\n",
    "    \n",
    "    return _ssim_3D(img1, img2, window, window_size, channel, size_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping Callback Functionality\n",
    "class EarlyStopping:\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings\n",
    "    ):\n",
    "        self.best_path = Path(f\"{settings.modelsave_folderpath}/V{settings.model_version}/Best 2D CVAE.pt\")\n",
    "        self.local_path = Path(f\"{settings.modelsave_folderpath}/V{settings.model_version}/Local 2D CVAE.pt\")\n",
    "        self.patience = settings.es_patience; self.delta = settings.es_delta; self.early_stop = False\n",
    "        self.counter = 0; self.best_score = -np.inf; self.local_score = -np.inf; self.local_loss = np.Inf; self.best_loss = np.inf\n",
    "    \n",
    "    # Callback Application Function\n",
    "    def __call__(\n",
    "        self,\n",
    "        loss,\n",
    "        model,\n",
    "        optimizer,\n",
    "        epoch: int = 0\n",
    "    ):  \n",
    "\n",
    "        # Best / First Local Result Checkpoint Saving\n",
    "        if -loss > self.local_score + self.delta or self.local_score is None:\n",
    "            self.save_checkpoint(loss, model, optimizer, epoch, best = False)\n",
    "            self.local_score = -loss; self.counter = 0\n",
    "        \n",
    "        # Checkpoint Counter Startup\n",
    "        else:\n",
    "            self.counter += 1; self.local_score = -loss\n",
    "            print(f'     > EarlyStopping Counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience: self.early_stop = True\n",
    "        \n",
    "        # Best / First Overall Result Checkpoint Saving\n",
    "        if -loss > self.best_score or self.best_score is None:\n",
    "            self.save_checkpoint(loss, model, optimizer, epoch, best = True)\n",
    "            self.best_score = -loss\n",
    "        return self.early_stop\n",
    "\n",
    "    # Model Saving Functionality\n",
    "    def save_checkpoint(\n",
    "        self,\n",
    "        loss,\n",
    "        model,\n",
    "        optimizer,\n",
    "        epoch: int = 0,\n",
    "        best: bool = False\n",
    "    ):\n",
    "        if best: path = self.best_path\n",
    "        else: path = self.local_path\n",
    "        if best: print(f\"     > Loss Decreased ({self.best_loss:.6f} --> {loss:.6f})\\n     > Saving Best Model\"); self.best_loss = loss\n",
    "        else: print(f\"     > Loss Decreased ({self.local_loss:.6f} --> {loss:.6f})\\n     > Saving Local Model\"); self.local_loss = loss\n",
    "        torch.save({'Model': model.state_dict(),\n",
    "                    'Optimizer': optimizer.state_dict(),\n",
    "                    'Current Epoch': epoch,\n",
    "                    'RNG State': torch.get_rng_state()}, path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **2D fcgCVAE**\n",
    "\n",
    "### *2D Fixed Conditional Generative Convolutional Variational AutoEncoder* \n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data** *Reader*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D MUDI Dataset Initialization Class (Random)\n",
    "class MUDI_fcgCVAE(Dataset):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,\n",
    "        subject: int or list,\n",
    "        random: bool = False,\n",
    "        mode: str = 'Target',\n",
    "        target_param: int or float = 100,\n",
    "        target_slice: int or float = 100,\n",
    "        num_combo: int or float = 100\n",
    "    ):\n",
    "        \n",
    "        # Parameter & Patient Index Value Access\n",
    "        super(MUDI_fcgCVAE).__init__(); self.settings = settings; self.random = random\n",
    "        self.mode = mode; self.target_param = target_param; self.target_slice = target_slice\n",
    "        self.data = h5py.File(self.settings.data_filepath, 'r').get('data1')\n",
    "        self.params = pd.read_excel(self.settings.param_filepath)\n",
    "\n",
    "        # Vertical Splitting (Patient & Slice Selection)\n",
    "        self.idxv = pd.read_csv(self.settings.info_filepath,                    # List of Index Values ...\n",
    "                                index_col = 0).to_numpy()                       # ... pertaining to each Patient\n",
    "        self.idxv = self.idxv[np.isin(self.idxv[:, 1], subject), 0]             # Patient-Specific Index Values\n",
    "        self.mask = MUDI_fcgCVAE.get_mask(self.settings, subject[0])            # Patient-Specific Mask Download\n",
    "        self.data = unmask(self.data[self.idxv, :].T, self.mask).get_fdata().T  # Patient-Specific Image Unmasking\n",
    "        self.data = MUDI_fcgCVAE.zero_padding(self.data, self.settings.img_shape)   # Image Pre-Processing: Zero Padding\n",
    "        self.idxv_slice_full = np.arange(self.mask.shape[-1])                   # Full List of Available Image Slices\n",
    "\n",
    "        # Horizontal Splitting (Source & Target Parameter Selection)\n",
    "        idxh_source_filepath = Path(f\"{self.settings.datasave_folderpath}/Training Labels (V{self.settings.data_version}).txt\")\n",
    "        idxh_target_filepath = Path(f\"{self.settings.datasave_folderpath}/{self.mode} Labels (V{self.settings.data_version}).txt\")\n",
    "        self.idxh_source = np.sort(np.loadtxt(idxh_source_filepath)).astype(int)\n",
    "        if not idxh_target_filepath.exists(): self.idxh_target_full = self.label_gen()\n",
    "        else: self.idxh_target_full = np.sort(np.loadtxt(idxh_target_filepath)).astype(int)\n",
    "\n",
    "        # Vertical & Horizontal Sub-Sectioning & Shuffling\n",
    "        self.s_target = int((self.target_slice * len(self.idxv_slice_full)) / 100)\n",
    "        self.h_target = int((self.target_param * len(self.idxh_target_full)) / 100)\n",
    "        self.num_combo = int((num_combo * (self.s_target * self.h_target)) / 100); self.shuffle(init = True)\n",
    "        print(f\"     > Utilizing {self.s_target} \\ {len(self.idxv_slice_full)} of the Available Slices\")\n",
    "        print(f\"     > Utilizing {self.h_target} \\ {len(self.idxh_target_full)} of the Target Parameters\")\n",
    "        print(f\"     > Looping through {self.num_combo} \\ {self.s_target * self.h_target} Source / Target Parameter Combos\")\n",
    "        print(f\"     > Pre-Processing Images to be of Square Shape of {self.settings.img_shape}\")\n",
    "\n",
    "        # Parameter Selection & Value Normalization / Scaling\n",
    "        if self.settings.gradient_coord:\n",
    "            self.params = self.params.drop(columns = ['Gradient theta', 'Gradient phi'])                # Choosing of Gradient Orientation\n",
    "        else: self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])\n",
    "        if self.settings.label_norm == 'auto':\n",
    "            print(f\"     > Automatic Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "            self.scaler = StandardScaler()\n",
    "            self.params = pd.DataFrame( self.scaler.fit_transform(self.params),\n",
    "                                        columns = self.params.columns)\n",
    "            scaler_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "            if not scaler_filepath.exists(): torch.save(self.scaler, scaler_filepath)\n",
    "        elif self.settings.label_norm == 'manual':\n",
    "            print(f\"     > Manual Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "            self.params[['Gradient theta', 'Gradient phi']] = self.cart2polar(self.params[['Gradient x', 'Gradient y', 'Gradient z']].values)\n",
    "            self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])\n",
    "            self.params['b Value'] = self.params['b Value'] / 10000\n",
    "            self.params['TI'] = self.params['TI'] / 10000\n",
    "            self.params['TE'] = (self.params['TE'] - 80) / 200\n",
    "        else: print(f\"     > No Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "        assert(self.params.shape[1] == self.settings.num_labels), \"ERROR: Labels wrongly Deleted!\"\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # DataLoader Length / No. Batches Computation Functionality\n",
    "    def __len__(self):\n",
    "        if self.random: return self.num_combo\n",
    "        else: return self.s_target * self.h_target\n",
    "\n",
    "    # Image Zero-Padding Pre-Processing Method Functionality\n",
    "    def zero_padding(\n",
    "        data: np.array or torch.Tensor,\n",
    "        img_shape: int\n",
    "    ):\n",
    "\n",
    "        # Input Data Assertions\n",
    "        assert(data.ndim >= 3), \"ERROR: Pre-Processing Input Data has the Wrong Dimmensions\"\n",
    "        assert(img_shape >= int(data.shape[-2]) and img_shape >= int(data.shape[-1])\n",
    "        ), \"ERROR: Pre-Processed Output Data Shape is Larget than Input one!\"\n",
    "\n",
    "        # Zero-Padding Implementation\n",
    "        padding = np.array([0, 0, (img_shape - data.shape[-2]) / 2, (img_shape - data.shape[-1]) / 2])\n",
    "        padding = padding.reshape((1, -1)).T + np.array([0, 0])\n",
    "        padding[:, -1] = np.ceil(padding[:, -1]); padding[:, -2] = np.floor(padding[:, -2])\n",
    "        return np.pad(data, padding.astype(np.int32), 'constant')\n",
    "        \n",
    "    # Single-Batch Generation Functionality\n",
    "    def __getitem__(self, idx) -> tuple[np.ndarray, np.float32]:\n",
    "\n",
    "        # Batch Vertical/Slice & Horizontal/Parameter Indexing\n",
    "        if self.random:\n",
    "            if self.num_combo != self.s_target * self.h_target:\n",
    "                idx_loop = idx % self.num_combo                                                 # Fixed Batch's Indexes\n",
    "                idxv_slice = int(np.where(self.idxv_slice == self.idx_combo[idx_loop][0])[0])   # Fixed Train Batch's Horizontal Index\n",
    "                idxh_target = int(np.where(self.idxh_target == self.idx_combo[idx_loop][1])[0]) # Fixed Target Batch's Horizontal Index\n",
    "            else:\n",
    "                idxv_slice = random.randrange(self.s_target)        # Random Batch's Horizontal Index for y_train\n",
    "                idxh_target = random.randrange(self.h_target)       # Random Batch's Horizontal Index for y_target\n",
    "        else:\n",
    "            idxv_slice = idx % self.s_target                    # Batch's Vertical Index for X_train\n",
    "            idxh_target = idx // self.s_target                  # Batch's Horizontal Index for Loop Combo\n",
    "        print( f\"Item #{idx} | Slice #{self.idxv_slice[idxv_slice]} | Target Parameter #{self.idxh_target[idxh_target]}\")\n",
    "\n",
    "        # Batch Data Generation\n",
    "        X_train = self.data[self.idxh_source, self.idxv_slice[idxv_slice], :, :]                # [500, 1, :, :] Training Image Slices Data\n",
    "        X_target = self.data[self.idxh_target[idxh_target], self.idxv_slice[idxv_slice], :, :]  # [1, 1, :, :] GT Target Image Slice Data\n",
    "        y_target = self.params.iloc[self.idxh_target[idxh_target]].values                       # [num_labels] Target Image Parameter Values\n",
    "        return {'X_train': np.array(X_train).astype(np.float32), 'y_target': np.ravel(y_target).astype(np.float32),\n",
    "                'X_target': np.array(X_target).reshape((1, X_target.shape[0], X_target.shape[1])).astype(np.float32),\n",
    "                'idxv_slice': idxv_slice, 'slice_target': self.idxv_slice[idxv_slice],\n",
    "                'idxh_target': idxh_target, 'param_target': self.idxh_target[idxh_target]}\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Target Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def target_param_shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxh_target: np.array = None\n",
    "    ):\n",
    "        if idxh_target is not None: self.idxh_target = idxh_target\n",
    "        else:\n",
    "            if self.settings.param_shuffle or init:\n",
    "                self.idxh_target = self.idxh_target_full[   np.sort(np.random.choice(len(self.idxh_target_full),\n",
    "                                                            self.h_target, replace = False))]\n",
    "                \n",
    "    # Target Slice Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def slice_shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxv_slice: np.array = None\n",
    "    ):  \n",
    "        if idxv_slice is not None: self.idxv_slice = idxv_slice\n",
    "        else:\n",
    "            if self.settings.slice_shuffle or init:\n",
    "                self.idxv_slice = self.idxv_slice_full[     np.sort(np.random.choice(len(self.idxv_slice_full),\n",
    "                                                            self.s_target, replace = False))]\n",
    "    \n",
    "    # Target Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def combo_shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idx_combo: np.array = None\n",
    "    ):\n",
    "        if idx_combo is not None: self.idx_combo = idx_combo\n",
    "        else:\n",
    "            if (self.settings.param_shuffle or init) and self.num_combo != self.s_target * self.h_target:\n",
    "                self.idx_combo = []\n",
    "                for i in range(self.num_combo):\n",
    "                    self.idx_combo.append(np.array([self.idxv_slice[random.randrange(self.s_target)],\n",
    "                                                    self.idxh_target[random.randrange(self.h_target)]]))\n",
    "\n",
    "    # Target Voxel & Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxh_target: np.array = None,\n",
    "        idxv_slice: np.array = None,\n",
    "        idx_combo: np.array = None\n",
    "    ):\n",
    "        self.target_param_shuffle(init, idxh_target)\n",
    "        self.slice_shuffle(init, idxv_slice)\n",
    "        self.combo_shuffle(init, idx_combo)\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Random Target Parameter for Training & Test Sets Generation Functionality\n",
    "    def label_gen(self):\n",
    "\n",
    "        # Target & Test Label Index File Generation\n",
    "        idxh_target = np.delete(np.arange(self.params.shape[0]), self.idxh_source)\n",
    "        if self.settings.test_target_param != 0:\n",
    "            idxh_test = idxh_target[np.sort(np.random.choice(len(idxh_target),\n",
    "                                    self.settings.test_target_param, replace = False))]\n",
    "            idxh_target = np.delete(idxh_target, np.where(np.in1d(idxh_target, idxh_test)))\n",
    "            for i in range(self.settings.test_target_param): assert(idxh_test[i] not in idxh_target\n",
    "                ), f\"ERROR: Target Parameter #{i} for Training & Test Sets not mutually Exclusive\"\n",
    "            \n",
    "            # Target & Test Label Index File Saving\n",
    "            print(f\">     Saving File Target Parameters for Training ({len(idxh_target)}) & Test {len(idxh_test)} Set's\")\n",
    "            np.savetxt(Path(f\"{self.settings.datasave_folderpath}/Test Labels (V{self.settings.data_version}).txt\"), idxh_test)\n",
    "            np.savetxt(Path(f\"{self.settings.datasave_folderpath}/Target Labels (V{self.settings.data_version}).txt\"), idxh_target)\n",
    "        if self.mode == 'Target': return idxh_target\n",
    "        else: return idxh_test\n",
    "        \n",
    "    # Label Scaler Download & Reverse Transformation\n",
    "    def label_unscale(\n",
    "        self,\n",
    "        y: np.array or pd.DataFrame\n",
    "    ):\n",
    "\n",
    "        # Label Scaler Download & Reverse Usage\n",
    "        try: self.scaler\n",
    "        except AttributeError:\n",
    "            scaler = torch.load(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "        return scaler.inverse_transform(y.reshape(1, -1))\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Cartesian to Polar Coordinate Conversion Functionality\n",
    "    def cart2polar(self, y: np.array):\n",
    "\n",
    "        # Cartesian to Polar Coordinates Conversion\n",
    "        phi = np.arccos(y[:, 2]).astype(np.float32); theta = np.arctan2(y[:, 1], y[:, 0])\n",
    "        theta = np.where(theta < 0, 2 * np.pi - np.abs(theta), theta).astype(np.float32)\n",
    "        theta = np.expand_dims(theta, axis = 1); phi = np.expand_dims(phi, axis = 1)\n",
    "        return pd.DataFrame(data = np.concatenate((theta, phi), axis = 1),\n",
    "                            columns = ['Gradient theta', 'Gradient phi'])\n",
    "\n",
    "    # Patient Mask Retrieval Functionality\n",
    "    def get_mask(settings, patient_id: int):\n",
    "        mask_filepath = Path(f\"{settings.mask_folderpath}/p{patient_id}.nii\")\n",
    "        assert(mask_filepath.exists()), f\"ERROR: Patient {patient_id}'s Mask not Found!\"\n",
    "        return load_img(mask_filepath)\n",
    "    \n",
    "    # Data Retrieval Functionality\n",
    "    def get_data(\n",
    "        settings,\n",
    "        patient_id: int,\n",
    "        idxv: int or np.array = None,\n",
    "        idxh_source: int or np.array = None,\n",
    "        idxh_target: int or np.array = None\n",
    "    ):\n",
    "        \n",
    "        # Dataset Download & Patient-Wise Splitting\n",
    "        idxv = np.expand_dims(np.array(idxv), axis = 1)\n",
    "        data = h5py.File(settings.data_filepath, 'r').get('data1')\n",
    "        idxv_full = pd.read_csv(settings.info_filepath, index_col = 0).to_numpy()\n",
    "        idxv_full = idxv_full[np.isin(idxv_full[:, 1], patient_id), 0]                  # Patient-Specific Index Values\n",
    "        mask = MUDI_fcgCVAE.get_mask(settings, patient_id)                          # Patient-Specific Mask Download\n",
    "        data = unmask(data[idxv_full, :].T, mask).get_fdata().T                         # Patient-Specific Data Unmasking\n",
    "        \n",
    "        # Dataset Source Horizontal / Parameter Indexing\n",
    "        if idxh_source is not None:\n",
    "            idxh_source = np.expand_dims(np.array(idxh_source), axis = 1)\n",
    "            X_source = data[tuple(np.concatenate([idxh_source, idxv], axis = -1).T)]\n",
    "            X_source = np.expand_dims(X_source, axis = 1)\n",
    "            X_source = MUDI_fcgCVAE.zero_padding(X_source, settings.img_shape)            \n",
    "        else: X_source = None\n",
    "\n",
    "        # Dataset Target Horizontal / Parameter & Vertical / Slice Indexing\n",
    "        if idxh_target is not None:\n",
    "            idxh_target = np.expand_dims(np.array(idxh_target), axis = 1)\n",
    "            X_target = data[tuple(np.concatenate([idxh_target, idxv], axis = -1).T)]\n",
    "            X_target = np.expand_dims(X_target, axis = 1)\n",
    "            X_target = MUDI_fcgCVAE.zero_padding(X_target, settings.img_shape)   \n",
    "        else: X_target = None\n",
    "        return torch.Tensor(X_source), torch.Tensor(X_target)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D MUDI Dataset Initialization Class (Fixed / Random)\n",
    "class MUDI_fcgCVAE(Dataset):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,\n",
    "        subject: int or list,\n",
    "        random: bool = False,\n",
    "        mode: str = 'Target',\n",
    "        target_param: int or float = 100,\n",
    "        target_slice: int or float = 100,\n",
    "        target_combo: int or float = 100\n",
    "    ):\n",
    "        \n",
    "        # Parameter & Patient Index Value Access\n",
    "        super(MUDI_fcgCVAE).__init__(); self.settings = settings; self.random = random\n",
    "        self.mode = mode; self.target_param = target_param; self.target_slice = target_slice\n",
    "        self.data = h5py.File(self.settings.data_filepath, 'r').get('data1')\n",
    "        self.params = pd.read_excel(self.settings.param_filepath)\n",
    "\n",
    "        # Vertical Splitting (Patient & Slice Selection)\n",
    "        self.idxv = pd.read_csv(self.settings.info_filepath,                    # List of Index Values ...\n",
    "                                index_col = 0).to_numpy()                       # ... pertaining to each Patient\n",
    "        self.idxv = self.idxv[np.isin(self.idxv[:, 1], subject), 0]             # Patient-Specific Index Values\n",
    "        self.mask = MUDI_fcgCVAE.get_mask(self.settings, subject[0])            # Patient-Specific Mask Download\n",
    "        self.data = unmask(self.data[self.idxv, :].T, self.mask).get_fdata().T  # Patient-Specific Image Unmasking\n",
    "        self.data = MUDI_fcgCVAE.zero_padding(self.data, self.settings.img_shape)   # Image Pre-Processing: Zero Padding\n",
    "        self.idxv_slice_full = np.arange(self.mask.shape[-1])                   # Full List of Available Image Slices\n",
    "\n",
    "        # Horizontal Splitting (Source & Target Parameter Selection)\n",
    "        idxh_source_filepath = Path(f\"{self.settings.datasave_folderpath}/Training Labels (V{self.settings.data_version}).txt\")\n",
    "        idxh_target_filepath = Path(f\"{self.settings.datasave_folderpath}/{self.mode} Labels (V{self.settings.data_version}).txt\")\n",
    "        self.idxh_source = np.sort(np.loadtxt(idxh_source_filepath)).astype(int)\n",
    "        if not idxh_target_filepath.exists(): self.idxh_target_full = self.label_gen()\n",
    "        else: self.idxh_target_full = np.sort(np.loadtxt(idxh_target_filepath)).astype(int)\n",
    "\n",
    "        # Vertical & Horizontal Sub-Sectioning & Shuffling\n",
    "        self.s_target = int((self.target_slice * len(self.idxv_slice_full)) / 100)\n",
    "        self.h_target = int((self.target_param * len(self.idxh_target_full)) / 100)\n",
    "        self.target_combo = int((target_combo * (self.s_target * self.h_target)) / 100); self.shuffle(init = True)\n",
    "        print(f\"     > Utilizing {self.s_target} \\ {len(self.idxv_slice_full)} of the Available Slices\")\n",
    "        print(f\"     > Utilizing {self.h_target} \\ {len(self.idxh_target_full)} of the Target Parameters\")\n",
    "        print(f\"     > Looping through {self.target_combo} \\ {self.s_target * self.h_target} Source / Target Parameter Combos\")\n",
    "        print(f\"     > Pre-Processing Images to be of Square Shape of {self.settings.img_shape}\")\n",
    "\n",
    "        # Parameter Selection & Value Normalization / Scaling\n",
    "        if self.settings.gradient_coord:\n",
    "            self.params = self.params.drop(columns = ['Gradient theta', 'Gradient phi'])                # Choosing of Gradient Orientation\n",
    "        else: self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])\n",
    "        if self.settings.label_norm == 'auto':\n",
    "            print(f\"     > Automatic Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "            self.scaler = StandardScaler()\n",
    "            self.params = pd.DataFrame( self.scaler.fit_transform(self.params),\n",
    "                                        columns = self.params.columns)\n",
    "            scaler_filepath = Path(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "            if not scaler_filepath.exists(): torch.save(self.scaler, scaler_filepath)\n",
    "        elif self.settings.label_norm == 'manual':\n",
    "            print(f\"     > Manual Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "            self.params[['Gradient theta', 'Gradient phi']] = self.cart2polar(self.params[['Gradient x', 'Gradient y', 'Gradient z']].values)\n",
    "            self.params = self.params.drop(columns = ['Gradient x', 'Gradient y', 'Gradient z'])\n",
    "            self.params['b Value'] = self.params['b Value'] / 10000\n",
    "            self.params['TI'] = self.params['TI'] / 10000\n",
    "            self.params['TE'] = (self.params['TE'] - 80) / 200\n",
    "        else: print(f\"     > No Normalization of all {self.settings.num_labels} Parameter Values\")\n",
    "        assert(self.params.shape[1] == self.settings.num_labels), \"ERROR: Labels wrongly Deleted!\"\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # DataLoader Length / No. Batches Computation Functionality\n",
    "    def __len__(self): return self.target_combo\n",
    "\n",
    "    # Image Zero-Padding Pre-Processing Method Functionality\n",
    "    def zero_padding(\n",
    "        data: np.array or torch.Tensor,\n",
    "        img_shape: int\n",
    "    ):\n",
    "\n",
    "        # Input Data Assertions\n",
    "        assert(data.ndim >= 3), \"ERROR: Pre-Processing Input Data has the Wrong Dimmensions\"\n",
    "        assert(img_shape >= int(data.shape[-2]) and img_shape >= int(data.shape[-1])\n",
    "        ), \"ERROR: Pre-Processed Output Data Shape is Larget than Input one!\"\n",
    "\n",
    "        # Zero-Padding Implementation\n",
    "        padding = np.array([0, 0, (img_shape - data.shape[-2]) / 2, (img_shape - data.shape[-1]) / 2])\n",
    "        padding = padding.reshape((1, -1)).T + np.array([0, 0])\n",
    "        padding[:, -1] = np.ceil(padding[:, -1]); padding[:, -2] = np.floor(padding[:, -2])\n",
    "        return np.pad(data, padding.astype(np.int32), 'constant')\n",
    "        \n",
    "    # Single-Batch Generation Functionality\n",
    "    def __getitem__(self, idx) -> tuple[np.ndarray, np.float32]:\n",
    "\n",
    "        # Batch Vertical/Slice & Horizontal/Parameter Indexing\n",
    "        if self.random:\n",
    "            idxv_slice = random.randrange(self.s_target)        # Random Batch's Horizontal Index for y_train\n",
    "            idxh_target = random.randrange(self.h_target)       # Random Batch's Horizontal Index for y_target\n",
    "        else:\n",
    "            idx_loop = idx % self.target_combo                                              # Fixed Batch's Indexes\n",
    "            idxv_slice = int(np.where(self.idxv_slice == self.idx_combo[idx_loop][0])[0])   # Fixed Train Batch's Horizontal Index\n",
    "            idxh_target = int(np.where(self.idxh_target == self.idx_combo[idx_loop][1])[0]) # Fixed Target Batch's Horizontal Index\n",
    "        #print( f\"Item #{idx} | Slice #{self.idxv_slice[idxv_slice]} | Target Parameter #{self.idxh_target[idxh_target]}\")\n",
    "\n",
    "        # Batch Data Generation\n",
    "        X_train = self.data[self.idxh_source, self.idxv_slice[idxv_slice], :, :]                # [500, 1, :, :] Training Image Slices Data\n",
    "        X_target = self.data[self.idxh_target[idxh_target], self.idxv_slice[idxv_slice], :, :]  # [1, 1, :, :] GT Target Image Slice Data\n",
    "        y_target = self.params.iloc[self.idxh_target[idxh_target]].values                       # [num_labels] Target Image Parameter Values\n",
    "        return {'X_train': np.array(X_train).astype(np.float32), 'y_target': np.ravel(y_target).astype(np.float32),\n",
    "                'X_target': np.array(X_target).reshape((1, X_target.shape[0], X_target.shape[1])).astype(np.float32),\n",
    "                'idxv_slice': idxv_slice, 'slice_target': self.idxv_slice[idxv_slice],\n",
    "                'idxh_target': idxh_target, 'param_target': self.idxh_target[idxh_target]}\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Target Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def target_param_shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxh_target: np.array = None\n",
    "    ):\n",
    "        if idxh_target is not None: self.idxh_target = idxh_target\n",
    "        else:\n",
    "            if self.settings.param_shuffle or init:\n",
    "                self.idxh_target = self.idxh_target_full[   np.sort(np.random.choice(len(self.idxh_target_full),\n",
    "                                                            self.h_target, replace = False))]\n",
    "                \n",
    "    # Target Slice Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def slice_shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxv_slice: np.array = None\n",
    "    ):  \n",
    "        if idxv_slice is not None: self.idxv_slice = idxv_slice\n",
    "        else:\n",
    "            if self.settings.slice_shuffle or init:\n",
    "                self.idxv_slice = self.idxv_slice_full[     np.sort(np.random.choice(len(self.idxv_slice_full),\n",
    "                                                            self.s_target, replace = False))]\n",
    "    \n",
    "    # Target Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def combo_shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idx_combo: np.array = None\n",
    "    ):\n",
    "        if idx_combo is not None: self.idx_combo = idx_combo\n",
    "        else:\n",
    "            if self.settings.param_shuffle or init:\n",
    "                self.idx_combo = []\n",
    "                for i in range(self.target_combo):\n",
    "                    self.idx_combo.append(np.array([self.idxv_slice[random.randrange(self.s_target)],\n",
    "                                                    self.idxh_target[random.randrange(self.h_target)]]))\n",
    "\n",
    "    # Target Voxel & Parameter Shuffling Functionality (tbu at Epoch's Beggining)\n",
    "    def shuffle(\n",
    "        self,\n",
    "        init: bool = False,\n",
    "        idxh_target: np.array = None,\n",
    "        idxv_slice: np.array = None,\n",
    "        idx_combo: np.array = None\n",
    "    ):\n",
    "        self.target_param_shuffle(init, idxh_target)\n",
    "        self.slice_shuffle(init, idxv_slice)\n",
    "        self.combo_shuffle(init, idx_combo)\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Random Target Parameter for Training & Test Sets Generation Functionality\n",
    "    def label_gen(self):\n",
    "\n",
    "        # Target & Test Label Index File Generation\n",
    "        idxh_target = np.delete(np.arange(self.params.shape[0]), self.idxh_source)\n",
    "        if self.settings.test_target_param != 0:\n",
    "            idxh_test = idxh_target[np.sort(np.random.choice(len(idxh_target),\n",
    "                                    self.settings.test_target_param, replace = False))]\n",
    "            idxh_target = np.delete(idxh_target, np.where(np.in1d(idxh_target, idxh_test)))\n",
    "            for i in range(self.settings.test_target_param): assert(idxh_test[i] not in idxh_target\n",
    "                ), f\"ERROR: Target Parameter #{i} for Training & Test Sets not mutually Exclusive\"\n",
    "            \n",
    "            # Target & Test Label Index File Saving\n",
    "            print(f\">     Saving File Target Parameters for Training ({len(idxh_target)}) & Test {len(idxh_test)} Set's\")\n",
    "            np.savetxt(Path(f\"{self.settings.datasave_folderpath}/Test Labels (V{self.settings.data_version}).txt\"), idxh_test)\n",
    "            np.savetxt(Path(f\"{self.settings.datasave_folderpath}/Target Labels (V{self.settings.data_version}).txt\"), idxh_target)\n",
    "        if self.mode == 'Target': return idxh_target\n",
    "        else: return idxh_test\n",
    "        \n",
    "    # Label Scaler Download & Reverse Transformation\n",
    "    def label_unscale(\n",
    "        self,\n",
    "        y: np.array or pd.DataFrame\n",
    "    ):\n",
    "\n",
    "        # Label Scaler Download & Reverse Usage\n",
    "        try: self.scaler\n",
    "        except AttributeError:\n",
    "            scaler = torch.load(f\"{self.settings.datasave_folderpath}/1D Label Scaler (V{self.settings.data_version}).pkl\")\n",
    "        return scaler.inverse_transform(y.reshape(1, -1))\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Cartesian to Polar Coordinate Conversion Functionality\n",
    "    def cart2polar(self, y: np.array):\n",
    "\n",
    "        # Cartesian to Polar Coordinates Conversion\n",
    "        phi = np.arccos(y[:, 2]).astype(np.float32); theta = np.arctan2(y[:, 1], y[:, 0])\n",
    "        theta = np.where(theta < 0, 2 * np.pi - np.abs(theta), theta).astype(np.float32)\n",
    "        theta = np.expand_dims(theta, axis = 1); phi = np.expand_dims(phi, axis = 1)\n",
    "        return pd.DataFrame(data = np.concatenate((theta, phi), axis = 1),\n",
    "                            columns = ['Gradient theta', 'Gradient phi'])\n",
    "\n",
    "    # Patient Mask Retrieval Functionality\n",
    "    def get_mask(settings, patient_id: int):\n",
    "        mask_filepath = Path(f\"{settings.mask_folderpath}/p{patient_id}.nii\")\n",
    "        assert(mask_filepath.exists()), f\"ERROR: Patient {patient_id}'s Mask not Found!\"\n",
    "        return load_img(mask_filepath)\n",
    "    \n",
    "    # Data Retrieval Functionality\n",
    "    def get_data(\n",
    "        settings,\n",
    "        patient_id: int,\n",
    "        idxv: int or np.array = None,\n",
    "        idxh_source: int or np.array = None,\n",
    "        idxh_target: int or np.array = None\n",
    "    ):\n",
    "        \n",
    "        # Dataset Download & Patient-Wise Splitting\n",
    "        idxv = np.expand_dims(np.array(idxv), axis = 1)\n",
    "        data = h5py.File(settings.data_filepath, 'r').get('data1')\n",
    "        idxv_full = pd.read_csv(settings.info_filepath, index_col = 0).to_numpy()\n",
    "        idxv_full = idxv_full[np.isin(idxv_full[:, 1], patient_id), 0]                  # Patient-Specific Index Values\n",
    "        mask = MUDI_fcgCVAE.get_mask(settings, patient_id)                          # Patient-Specific Mask Download\n",
    "        data = unmask(data[idxv_full, :].T, mask).get_fdata().T                         # Patient-Specific Data Unmasking\n",
    "        \n",
    "        # Dataset Source Horizontal / Parameter Indexing\n",
    "        if idxh_source is not None:\n",
    "            idxh_source = np.expand_dims(np.array(idxh_source), axis = 1)\n",
    "            X_source = data[tuple(np.concatenate([idxh_source, idxv], axis = -1).T)]\n",
    "            X_source = np.expand_dims(X_source, axis = 1)\n",
    "            X_source = MUDI_fcgCVAE.zero_padding(X_source, settings.img_shape)            \n",
    "        else: X_source = None\n",
    "\n",
    "        # Dataset Target Horizontal / Parameter & Vertical / Slice Indexing\n",
    "        if idxh_target is not None:\n",
    "            idxh_target = np.expand_dims(np.array(idxh_target), axis = 1)\n",
    "            X_target = data[tuple(np.concatenate([idxh_target, idxv], axis = -1).T)]\n",
    "            X_target = np.expand_dims(X_target, axis = 1)\n",
    "            X_target = MUDI_fcgCVAE.zero_padding(X_target, settings.img_shape)   \n",
    "        else: X_target = None\n",
    "        return torch.Tensor(X_source), torch.Tensor(X_target)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     > Utilizing 56 \\ 56 of the Available Slices\n",
      "     > Utilizing 844 \\ 844 of the Target Parameters\n",
      "     > Looping through 4726 \\ 47264 Source / Target Parameter Combos\n",
      "     > Pre-Processing Images to be of Square Shape of 96\n",
      "     > Manual Normalization of all 5 Parameter Values\n"
     ]
    }
   ],
   "source": [
    "# Dataset DataLoader Creation\n",
    "trainset = MUDI_fcgCVAE(    settings, subject = [11], random = False,\n",
    "                            target_param = 100,#settings.train_target_param,\n",
    "                            target_slice = 100,#settings.train_target_slice,\n",
    "                            target_combo = 10)\n",
    "trainloader = DataLoader(   dataset = trainset,\n",
    "                            shuffle = settings.val_sample_shuffle,\n",
    "                            num_workers = 0,#settings.num_workers,\n",
    "                            batch_size = 2,#trainset.s_target,#settings.batch_size,\n",
    "                            pin_memory = False)\n",
    "mask = MUDI_fcgCVAE.get_mask(settings, patient_id = 11)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Model* **Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fcgCVAE Encoder Main Block Class\n",
    "class EncoderBlock(nn.Module):\n",
    "\n",
    "    # Block Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int = 3,\n",
    "        stride: int = 2,\n",
    "        padding: int = 1,\n",
    "        momentum: float = 0.9\n",
    "    ):\n",
    "\n",
    "        # Class Variable Logging\n",
    "        super().__init__(); self.block = nn.Sequential(\n",
    "                nn.Conv2d(      in_channels = in_channels, out_channels = out_channels,\n",
    "                                kernel_size = kernel_size, stride = stride, padding = padding),\n",
    "                nn.BatchNorm2d( num_features = out_channels, momentum = momentum),\n",
    "                nn.ReLU(        inplace = False))\n",
    "    \n",
    "    # Block Application Function\n",
    "    def forward(self, X): return self.block(X)\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# fcgCVAE Encoder Model Class\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser\n",
    "    ):\n",
    "        \n",
    "        # fcgCVAE Encoder Convolutional Architecture Definition\n",
    "        super().__init__()\n",
    "        self.settings = settings; self.encoder_conv = []\n",
    "        in_channels = self.settings.in_channels\n",
    "        out_channels = int(self.settings.dim_latent / 2)\n",
    "        for i in range(self.settings.num_hidden):\n",
    "            self.encoder_conv.append(EncoderBlock(  in_channels = in_channels,\n",
    "                                                    out_channels = out_channels,\n",
    "                                                    kernel_size = self.settings.kernel_size,\n",
    "                                                    padding = self.settings.padding))\n",
    "            in_channels = out_channels; out_channels *= 2\n",
    "        self.encoder_conv = nn.Sequential(*self.encoder_conv)\n",
    "\n",
    "        # CVAE Encoder Linear Architecture Definition\n",
    "        img_shape = np.ceil(self.settings.img_shape / (2 ** (self.settings.num_hidden)))\n",
    "        in_channels = int(in_channels * (img_shape ** 2))\n",
    "        self.encoder_fc = nn.Sequential(nn.Linear(  in_features = in_channels, bias = False,\n",
    "                                                    out_features = self.settings.dim_hidden),\n",
    "                                    nn.BatchNorm1d( num_features = self.settings.dim_hidden, momentum = 0.9),\n",
    "                                    nn.ReLU(        inplace = True))\n",
    "        self.encoder_mu = nn.Linear(                in_features = self.settings.dim_hidden,\n",
    "                                                    out_features = self.settings.dim_latent)\n",
    "        self.encoder_logvar = nn.Linear(            in_features = self.settings.dim_hidden,\n",
    "                                                    out_features = self.settings.dim_latent)\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # fcgCVAE Encoder Application Function\n",
    "    def forward(\n",
    "        self,\n",
    "        X_train: np.ndarray or torch.Tensor,\n",
    "    ):\n",
    "        out = self.encoder_conv(X_train)                # Convolutional Section Application\n",
    "        out = out.view(len(out), -1)                    # Output Linearization\n",
    "        out = self.encoder_fc(out)                      # Linear Section Application\n",
    "        mu = self.encoder_mu(out)                       # Mean Computation\n",
    "        logvar = self.encoder_logvar(out)               # Log Variance Computation\n",
    "        return mu, logvar\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fcgCVAE Decoder Main Block Class\n",
    "class DecoderBlock(nn.Module):\n",
    "\n",
    "    # Block Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int = 3,\n",
    "        stride: int = 2,\n",
    "        padding: int = 1,\n",
    "        momentum: float = 0.9\n",
    "    ):\n",
    "\n",
    "        # Class Variable Logging\n",
    "        super().__init__(); block = []\n",
    "        block.append(nn.Sequential(\n",
    "                        nn.ConvTranspose2d( in_channels = in_channels, out_channels = out_channels,\n",
    "                                            kernel_size = kernel_size, stride = stride,\n",
    "                                            padding = padding, output_padding = 1, bias = False),\n",
    "                        nn.BatchNorm2d(     num_features = out_channels, momentum = momentum), nn.ReLU()))\n",
    "        self.block = nn.Sequential(*block)\n",
    "\n",
    "    # Block Application Function\n",
    "    def forward(self, X): return self.block(X)\n",
    "                            \n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# fcgCVAE Decoder Model Class\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser\n",
    "    ):\n",
    "\n",
    "        # fcgCVAE Decoder Linear Architecture Definition\n",
    "        super().__init__(); self.settings = settings\n",
    "        self.img_shape = int(np.ceil(self.settings.img_shape / (2 ** (self.settings.num_hidden))))\n",
    "        out_channels = int((self.settings.dim_latent / 2) * (2 ** (self.settings.num_hidden - 1)) * (self.img_shape ** 2))\n",
    "        self.decoder_fc = nn.Sequential(\n",
    "                                nn.Linear(      in_features = self.settings.dim_latent + self.settings.num_labels,\n",
    "                                                out_features = out_channels, bias = False),\n",
    "                                nn.BatchNorm1d( num_features = out_channels, momentum = 0.9),\n",
    "                                nn.ReLU(        inplace = True))\n",
    "\n",
    "        # fcgCVAE Decoder Convolutional Architecture Definition\n",
    "        in_channels = int(out_channels / (self.img_shape ** 2))\n",
    "        decoder_conv = []; out_channels = self.settings.dim_latent * 2\n",
    "        for i in range(self.settings.num_hidden):\n",
    "            #print(f\"{in_channels} -> {out_channels}\")\n",
    "            decoder_conv.append(DecoderBlock(   in_channels = in_channels,\n",
    "                                                out_channels = out_channels,\n",
    "                                                kernel_size = self.settings.kernel_size,\n",
    "                                                padding = self.settings.padding))\n",
    "            in_channels = out_channels; out_channels = int(out_channels / 2)\n",
    "        decoder_conv.append(nn.Sequential(\n",
    "                                    nn.Conv2d(  in_channels = in_channels, out_channels = 1,\n",
    "                                                kernel_size = self.settings.kernel_size,\n",
    "                                                padding = self.settings.padding), nn.Sigmoid()))\n",
    "        self.decoder_conv = nn.Sequential(*decoder_conv)\n",
    "                \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # fcgCVAE Decoder Application Function\n",
    "    def forward(\n",
    "        self,\n",
    "        z: np.ndarray or torch.Tensor,\n",
    "        y_target: np.ndarray or torch.Tensor\n",
    "    ): \n",
    "        out = torch.cat((z, y_target), dim = 1)     # Inclusion of Target Labels\n",
    "        out = self.decoder_fc(out)                  # Linear Section Application\n",
    "        out = out.view( len(out), -1,\n",
    "                        self.img_shape,\n",
    "                        self.img_shape)             # Output Dimensionalization\n",
    "        return self.decoder_conv(out)               # Convolutional Section Application\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fcgCVAE Model Class\n",
    "class fcgCVAE(nn.Module):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser\n",
    "    ):\n",
    "        super().__init__(); self.settings = settings\n",
    "        self.encoder = Encoder(self.settings)\n",
    "        self.decoder = Decoder(self.settings)\n",
    "\n",
    "    # CVAE Model Application Function\n",
    "    def forward(\n",
    "        self,\n",
    "        X_train: np.ndarray or torch.Tensor,\n",
    "        y_target: np.ndarray or torch.Tensor\n",
    "    ):\n",
    "        mu, logvar = self.encoder(X_train)              # Encoder Model Application\n",
    "        z = fcgCVAE.reparam(mu, logvar)                 # Reparametrization Trick\n",
    "        kl_loss = fcgCVAE.kl_loss(mu, logvar)           # Kullback-Leibler Loss Computation\n",
    "        return self.decoder(z, y_target),kl_loss        # Decoder Model Application\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Reparametrization Trick Functionality\n",
    "    def reparam(mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + (eps * std)\n",
    "    \n",
    "    # Kullback-Leibler Divergence Computation Functionality\n",
    "    def kl_loss(mu, logvar):\n",
    "        return -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Concatenation operation is not implemented for NumPy arrays, use np.concatenate() instead. Please do not rely on this error; it may not be given on all Python implementations.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pfernan2\\Desktop\\dMRI-Studio\\Experiments\\Autoencoders\\Autoencoders.ipynb Cell 182\u001b[0m in \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Z1230sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m X_train \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand((  \u001b[39m10\u001b[39m, settings\u001b[39m.\u001b[39min_channels,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Z1230sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                             settings\u001b[39m.\u001b[39mimg_shape,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Z1230sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                             settings\u001b[39m.\u001b[39mimg_shape))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Z1230sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m X_target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand(( \u001b[39m10\u001b[39m, settings\u001b[39m.\u001b[39min_channels,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Z1230sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                             settings\u001b[39m.\u001b[39mimg_shape,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Z1230sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                             settings\u001b[39m.\u001b[39mimg_shape))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Z1230sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m ssim_loss, ssim_img \u001b[39m=\u001b[39m ssim( X_train\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Z1230sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                             X_target\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32), full \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Z1230sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                         data_range \u001b[39m=\u001b[39m (torch\u001b[39m.\u001b[39mmax(X_train) \u001b[39m-\u001b[39m torch\u001b[39m.\u001b[39mmin(X_train)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pfernan2/Desktop/dMRI-Studio/Experiments/Autoencoders/Autoencoders.ipynb#Z1230sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m ssim_loss \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(ssim_loss)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\skimage\\metrics\\_structural_similarity.py:246\u001b[0m, in \u001b[0;36mstructural_similarity\u001b[1;34m(im1, im2, win_size, gradient, data_range, channel_axis, gaussian_weights, full, **kwargs)\u001b[0m\n\u001b[0;32m    243\u001b[0m C1 \u001b[39m=\u001b[39m (K1 \u001b[39m*\u001b[39m R) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m    244\u001b[0m C2 \u001b[39m=\u001b[39m (K2 \u001b[39m*\u001b[39m R) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m--> 246\u001b[0m A1, A2, B1, B2 \u001b[39m=\u001b[39m ((\u001b[39m2\u001b[39;49m \u001b[39m*\u001b[39;49m ux \u001b[39m*\u001b[39;49m uy \u001b[39m+\u001b[39;49m C1,\n\u001b[0;32m    247\u001b[0m                    \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m vxy \u001b[39m+\u001b[39m C2,\n\u001b[0;32m    248\u001b[0m                    ux \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m \u001b[39m+\u001b[39m uy \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m \u001b[39m+\u001b[39m C1,\n\u001b[0;32m    249\u001b[0m                    vx \u001b[39m+\u001b[39m vy \u001b[39m+\u001b[39m C2))\n\u001b[0;32m    250\u001b[0m D \u001b[39m=\u001b[39m B1 \u001b[39m*\u001b[39m B2\n\u001b[0;32m    251\u001b[0m S \u001b[39m=\u001b[39m (A1 \u001b[39m*\u001b[39m A2) \u001b[39m/\u001b[39m D\n",
      "\u001b[1;31mTypeError\u001b[0m: Concatenation operation is not implemented for NumPy arrays, use np.concatenate() instead. Please do not rely on this error; it may not be given on all Python implementations."
     ]
    }
   ],
   "source": [
    "X_train = torch.rand((  10, settings.in_channels,\n",
    "                            settings.img_shape,\n",
    "                            settings.img_shape))\n",
    "X_target = torch.rand(( 10, settings.in_channels,\n",
    "                            settings.img_shape,\n",
    "                            settings.img_shape))\n",
    "ssim_loss, ssim_img = ssim( X_train.numpy().astype(np.float32),\n",
    "                            X_target.numpy().astype(np.float32), full = True,\n",
    "                        data_range = (torch.max(X_train) - torch.min(X_train)))\n",
    "ssim_loss = np.mean(ssim_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item #0 | Slice #29 | Target Parameter #665\n",
      "Item #1 | Slice #13 | Target Parameter #589\n",
      "CVAE(\n",
      "  (encoder): Encoder(\n",
      "    (encoder_conv): Sequential(\n",
      "      (0): EncoderBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(500, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (1): EncoderBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (2): EncoderBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (encoder_fc): Sequential(\n",
      "      (0): Linear(in_features=36864, out_features=1024, bias=False)\n",
      "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (encoder_mu): Linear(in_features=1024, out_features=128, bias=True)\n",
      "    (encoder_logvar): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (decoder_fc): Sequential(\n",
      "      (0): Linear(in_features=133, out_features=36864, bias=False)\n",
      "      (1): BatchNorm1d(36864, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (decoder_conv): Sequential(\n",
      "      (0): DecoderBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Sequential(\n",
      "            (0): ConvTranspose2d(256, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): DecoderBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Sequential(\n",
      "            (0): ConvTranspose2d(256, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): DecoderBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Sequential(\n",
      "            (0): ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): Conv2d(64, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (1): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Dataset Initialization\n",
    "\"\"\"\n",
    "X_train = torch.rand((  10, settings.in_channels,\n",
    "                            settings.img_shape,\n",
    "                            settings.img_shape))\n",
    "y_target = torch.rand((10, 5))\n",
    "\"\"\"\n",
    "batch = next(iter(trainloader))\n",
    "X_train = batch['X_train']; y_target = batch['y_target']\n",
    "\n",
    "# Segmented CVAE Model Usage Example\n",
    "encoder = Encoder(settings)\n",
    "mu, logvar = encoder(X_train)\n",
    "z = torch.rand((2, settings.dim_latent))\n",
    "decoder = Decoder(settings)\n",
    "X_target1 = decoder(z, y_target)\n",
    "\n",
    "# Full CVAE Model Usage Example\n",
    "model = fcgCVAE(settings); print(model)\n",
    "X_target, kl_loss = model(X_train, y_target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training** *Script*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result Plotting Functionality (V0)\n",
    "def ResultCallback(\n",
    "    settings,\n",
    "    logger: TensorBoardLogger,\n",
    "    best_info: dict,\n",
    "    worst_info: dict,\n",
    "    epoch: int = 0,\n",
    "    mode: str = 'Train',\n",
    "    loss: str = 'MSE Loss'\n",
    "):\n",
    "\n",
    "    # Set Example Reconstruction Results Image Plotting\n",
    "    plot = plt.figure(figsize = (30, 25)); plt.suptitle(f\"Overall {mode} | {loss}\")\n",
    "    plt.xticks([]); plt.yticks([]); plt.grid(False); plt.tight_layout()\n",
    "    \n",
    "    # Best Loss Value Indexing\n",
    "    best_loss = torch.empty(best_info['X_gt'].shape[0])\n",
    "    for i in range(best_info['X_gt'].shape[0]):\n",
    "        if loss == 'SSIM Index':\n",
    "            ssim_loss, ssim_img = ssim( best_info['X_gt'].cpu().numpy().astype(np.float32),\n",
    "                                        best_info['X_fake'].cpu().numpy().astype(np.float32), full = True,\n",
    "                    data_range = (torch.max(best_info['X_gt']) - torch.min(best_info['X_gt'])).cpu().numpy())\n",
    "            best_loss[i] = np.mean(ssim_loss); del ssim_img\n",
    "        elif loss == 'MSE Loss':\n",
    "            best_loss[i] = nn.MSELoss(reduction = 'mean')(best_info['X_gt'], best_info['X_fake'].cpu().numpy())\n",
    "        else: return 0\n",
    "    best_idx = torch.argmax(best_loss)\n",
    "\n",
    "    # Worst Loss Value Indexing\n",
    "    worst_loss = torch.empty(worst_info['X_gt'].shape[0])\n",
    "    for i in range(best_info['X_gt'].shape[0]):\n",
    "        if loss == 'SSIM Index':\n",
    "            ssim_loss, ssim_img = ssim( worst_info['X_gt'].cpu().numpy().astype(np.float32),\n",
    "                                        worst_info['X_fake'].cpu().numpy().astype(np.float32), full = True,\n",
    "                    data_range = (torch.max(worst_info['X_gt']) - torch.min(worst_info['X_gt'])).cpu().numpy())\n",
    "            worst_loss[i] = np.mean(ssim_loss); del ssim_img\n",
    "        elif loss == 'MSE Loss':\n",
    "            worst_loss[i] = nn.MSELoss(reduction = 'mean')(worst_info['X_gt'], worst_info['X_fake'].cpu().numpy())\n",
    "        else: return 0\n",
    "    worst_idx = torch.argmin(worst_loss)\n",
    "\n",
    "    # Set Example Original & Best Loss Reconstructed Image Subplots\n",
    "    plt.subplot(2, 2, 1, title =    f\"Best | Target Parameter #{best_info['idxh_target'][best_idx]}\" +\\\n",
    "                                    f\" | Target Slice #{best_info['idxv_slice'][best_idx]}\")\n",
    "    plt.imshow(best_info['X_gt'][   best_idx, 0, :, :], cmap = plt.cm.binary)\n",
    "    plt.subplot(2, 2, 2, title =    f\"Best | Reconstruction | {loss}: {np.round(best_loss[best_idx], 5)}\")\n",
    "    plt.imshow(best_info['X_fake'][ best_idx, 0, :, :], cmap = plt.cm.binary)\n",
    "\n",
    "    # Set Example Original & Worst Loss Reconstructed Image Subplots\n",
    "    plt.subplot(2, 2, 3, title =    f\"Worst | Target Parameter #{worst_info['idxh_target'][worst_idx]}\" +\\\n",
    "                                    f\" | Target Slice #{worst_info['idxv_slice'][worst_idx]}\")\n",
    "    plt.imshow(worst_info['X_gt'][  worst_idx, 0, :, :], cmap = plt.cm.binary)\n",
    "    plt.subplot(2, 2, 4, title =    f\"Worst | Reconstruction | {loss}: {np.round(worst_loss[worst_idx], 5)}\")\n",
    "    plt.imshow(worst_info['X_fake'][worst_idx, 0, :, :], cmap = plt.cm.binary)\n",
    "\n",
    "    # Tensorboard Reconstruction Callback\n",
    "    logger.experiment.add_figure(f\"Image Results\", plot, epoch)\n",
    "    logger.experiment.add_scalar(\"Best Loss\", best_loss[best_idx], epoch)\n",
    "    logger.experiment.add_scalar(\"Worst Loss\", worst_loss[worst_idx], epoch)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D fcgCVAE Model Training Script (V0)\n",
    "def fcgCVAE_train(\n",
    "    settings,\n",
    "):\n",
    "\n",
    "    ##############################################################################################\n",
    "    # ------------------------------------ Setup | DataLoader ------------------------------------\n",
    "    ##############################################################################################\n",
    "\n",
    "    # Seed Random State for Reproducibility\n",
    "    torch.manual_seed(settings.seed)\n",
    "    np.random.seed(settings.seed)\n",
    "    random.seed(settings.seed)\n",
    "\n",
    "    # Experiment Logs Directories Initialization\n",
    "    checkpoint_folderpath = os.path.join(f'{settings.modelsave_folderpath}/V{settings.model_version}', 'logs')\n",
    "    train_mse_logger = TensorBoardLogger(checkpoint_folderpath, 'train/mse')\n",
    "    train_kld_logger = TensorBoardLogger(checkpoint_folderpath, 'train/kld')\n",
    "    train_ssim_logger = TensorBoardLogger(checkpoint_folderpath, 'train/ssim')\n",
    "    val_mse_logger = TensorBoardLogger(checkpoint_folderpath, 'val/mse')\n",
    "    val_kld_logger = TensorBoardLogger(checkpoint_folderpath, 'val/kld')\n",
    "    val_ssim_logger = TensorBoardLogger(checkpoint_folderpath, 'val/ssim')\n",
    "\n",
    "    # Training & Validation DataLoaders Initialization\n",
    "    train_set = []; val_set = []; train_loader = []; val_loader = []\n",
    "    for p, patient_id in enumerate(settings.patient_list):\n",
    "\n",
    "        # Patient Set & DataLoader Initialization\n",
    "        if patient_id in settings.train_patient_list:\n",
    "            print(f\"Patient #{patient_id} | Training Set:\")\n",
    "            train_set.append(   MUDI_fcgCVAE(   settings, subject = [patient_id], random = True,\n",
    "                                                target_param = settings.train_target_param,\n",
    "                                                target_slice = settings.train_target_slice,\n",
    "                                                target_combo = settings.train_param_loop))\n",
    "            train_loader.append(DataLoader(     dataset = train_set[-1], pin_memory = True,\n",
    "                                                shuffle = settings.train_sample_shuffle,\n",
    "                                                num_workers = settings.num_workers,\n",
    "                                                batch_size = settings.batch_size))\n",
    "            \n",
    "        elif patient_id in settings.val_patient_list:\n",
    "            print(f\"Patient #{patient_id} | Validation Set:\")\n",
    "            val_set.append(     MUDI_fcgCVAE(   settings, subject = [patient_id], random = False,\n",
    "                                                target_param = settings.val_target_param,\n",
    "                                                target_slice = settings.val_target_slice,\n",
    "                                                target_combo = settings.val_param_loop))\n",
    "            val_loader.append(  DataLoader(     dataset = val_set[-1], pin_memory = True,\n",
    "                                                shuffle = settings.val_sample_shuffle,\n",
    "                                                num_workers = settings.num_workers, batch_size = 1))\n",
    "                                                #batch_size = settings.batch_size))\n",
    "            \n",
    "        else: print(f\"Patient #{patient_id} | Test Set:     > Not Included\")\n",
    "    \n",
    "    ##############################################################################################\n",
    "    # -------------------------------- Setup | Models & Optimizers -------------------------------\n",
    "    ##############################################################################################\n",
    "\n",
    "    # Model & Optimizer Initialization\n",
    "    print(f\"Running\\n     > Training 2D fcgCVAE Model with {torch.cuda.device_count()} GPUs!\")\n",
    "    model = nn.DataParallel(fcgCVAE(settings), device_ids = settings.device_ids).to(settings.device)\n",
    "    optimizer = torch.optim.AdamW(  model.parameters(), lr = settings.base_lr,\n",
    "                                    weight_decay = settings.weight_decay)\n",
    "\n",
    "    # Criterion & Early Stopping Setup\n",
    "    mse_criterion = nn.MSELoss(reduction = 'mean')\n",
    "    lr_schedule = ExponentialLR(optimizer, gamma = settings.lr_decay)\n",
    "    earlyStopping = EarlyStopping(settings); train_iter = 0; val_iter = 0\n",
    "\n",
    "    # Model Checkpoint Loading\n",
    "    model_filepath = Path(f\"{settings.modelsave_folderpath}/V{settings.model_version}/Best 2D fcgCVAE.pt\")\n",
    "    if model_filepath.exists():\n",
    "        checkpoint = torch.load(model_filepath, map_location = settings.device)\n",
    "        model.load_state_dict(checkpoint['Model'])\n",
    "        optimizer.load_state_dict(checkpoint['Optimizer'])\n",
    "        train_iter = checkpoint['Current Training Iteration']\n",
    "        val_iter = checkpoint['Current Validation Iteration']\n",
    "        save_epoch = checkpoint['Current Epoch']\n",
    "        torch.set_rng_state(checkpoint['RNG State']); del checkpoint\n",
    "        print(f\"     > Loading 2D fcgCVAE Model for {settings.model_version}: {save_epoch} Past Epochs\")\n",
    "    else: save_epoch = -1\n",
    "    \n",
    "    # Epoch Iteration Loop\n",
    "    for epoch in range(save_epoch + 1, settings.num_epochs):\n",
    "\n",
    "        ##############################################################################################\n",
    "        # ----------------------------------- Training | Iteration -----------------------------------\n",
    "        ##############################################################################################\n",
    "\n",
    "        # Result Value Initialization\n",
    "        train_mse = []; train_kld = []; train_ssim = []\n",
    "        best_train_mse = 1000; worst_train_mse = 0\n",
    "        best_train_ssim = 0; worst_train_ssim = 1000\n",
    "\n",
    "        # Training Patient Loop\n",
    "        print(f\"Training Epoch #{epoch}:\")\n",
    "        for p, patient_id in enumerate(settings.train_patient_list):\n",
    "\n",
    "            # Training Iteration Loop\n",
    "            train_bar = tqdm(   enumerate(train_loader[p]), total = len(train_loader[p]),\n",
    "                desc = f'Epoch #{epoch} | Training Patient {patient_id}', unit = 'Batches')\n",
    "            for batch_idx, batch in train_bar:\n",
    "                \n",
    "                # --------------------------------------------------------------------------------------------\n",
    "\n",
    "                # Forward Propagation\n",
    "                model.train(); model.zero_grad(); optimizer.zero_grad()\n",
    "                X_target, kld_loss = model( batch['X_train'].to(settings.device),                       # Model Application\n",
    "                                            batch['y_target'].to(settings.device))                      # Kullback-Leibler Divergence\n",
    "                gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "                # Loss Computation\n",
    "                mse_loss = mse_criterion(X_target, batch['X_target'].to(settings.device))               # Mean Squared Error Loss\n",
    "                ssim_loss, ssim_img = ssim( X_target.detach().cpu().numpy().astype(np.float32),         # Structural Similarity Index\n",
    "                                    batch['X_target'].detach().cpu().numpy().astype(np.float32), full = True,\n",
    "                    data_range = (torch.max(batch['X_target']) - torch.min(batch['X_target'])).cpu().numpy())\n",
    "                ssim_loss = np.mean(ssim_loss); del ssim_img\n",
    "\n",
    "                # Backward Propagation\n",
    "                mse_loss.backward(); optimizer.step()\n",
    "                train_mse_logger.experiment.add_scalar(\"Batch Loss\", mse_loss.item(), train_iter)\n",
    "                train_kld_logger.experiment.add_scalar(\"Batch Loss\", kld_loss.item(), train_iter)\n",
    "                train_ssim_logger.experiment.add_scalar(\"Batch Loss\", ssim_loss, train_iter); train_iter += 1\n",
    "                train_mse.append(mse_loss.item()); train_kld.append(kld_loss.item())\n",
    "                train_ssim.append(ssim_loss); gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "                # --------------------------------------------------------------------------------------------\n",
    "\n",
    "                # Result Saving (MSE Loss)\n",
    "                if mse_loss.item() < best_train_mse:\n",
    "                    best_train_mse = mse_loss.item()\n",
    "                    best_train_mse_info = { 'loss': mse_loss.item(), 'patient_id': patient_id,\n",
    "                                            'X_gt': batch['X_target'].detach().cpu(),\n",
    "                                            'X_fake': X_target.detach().cpu(),\n",
    "                                            'idxv_slice': batch['slice_target'],\n",
    "                                            'idxh_target': batch['param_target']}\n",
    "                if mse_loss.item() > worst_train_mse:\n",
    "                    worst_train_mse = mse_loss.item()\n",
    "                    worst_train_mse_info = {'loss': mse_loss.item(), 'patient_id': patient_id,\n",
    "                                            'X_gt': batch['X_target'].detach().cpu(),\n",
    "                                            'X_fake': X_target.detach().cpu(),\n",
    "                                            'idxv_slice': batch['slice_target'],\n",
    "                                            'idxh_target': batch['param_target']}\n",
    "                \n",
    "                # Result Saving (SSIM Index)\n",
    "                if ssim_loss > best_train_ssim:\n",
    "                    best_train_ssim = ssim_loss\n",
    "                    best_train_ssim_info = {'loss': ssim_loss, 'patient_id': patient_id,\n",
    "                                            'X_gt': batch['X_target'].detach().cpu(),\n",
    "                                            'X_fake': X_target.detach().cpu(),\n",
    "                                            'idxv_slice': batch['slice_target'],\n",
    "                                            'idxh_target': batch['param_target']}\n",
    "                if ssim_loss < worst_train_ssim:\n",
    "                    worst_train_ssim = ssim_loss\n",
    "                    worst_train_ssim_info = {'loss': ssim_loss, 'patient_id': patient_id,\n",
    "                                            'X_gt': batch['X_target'].detach().cpu(),\n",
    "                                            'X_fake': X_target.detach().cpu(),\n",
    "                                            'idxv_slice': batch['slice_target'],\n",
    "                                            'idxh_target': batch['param_target']}\n",
    "                gc.collect(); torch.cuda.empty_cache()\n",
    "                del batch, X_target, mse_loss, kld_loss, ssim_loss\n",
    "\n",
    "        ##############################################################################################\n",
    "        # ------------------------------------ Training | Results ------------------------------------\n",
    "        ##############################################################################################\n",
    "\n",
    "            # Inter-Patient Reconstruction Parameter Sharing Functionality\n",
    "            if settings.interpatient_sharing:\n",
    "                if p == 0:\n",
    "                    train_set[p].shuffle()\n",
    "                    train_idxh_target = train_set[p].idxh_target\n",
    "                    train_idxv_slice = train_set[p].idxv_slice\n",
    "                    train_idx_combo = train_set[p].idx_combo\n",
    "                else:\n",
    "                    train_set[p].shuffle(idxh_target = train_idxh_target)\n",
    "                    train_set[p].shuffle(idxv_slice = train_idxv_slice)\n",
    "                    train_set[p].shuffle(idx_combo = train_idx_combo)\n",
    "            else: train_set[p].shuffle()\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # End of Training Epoch Mean & STD Loss Writing\n",
    "        train_kld_logger.experiment.add_scalar(\"Learning Rate\", lr_schedule.get_last_lr()[0], epoch); lr_schedule.step()\n",
    "        train_mse_logger.experiment.add_scalar(\"Mean Loss\", np.mean(np.array(train_mse)), epoch)\n",
    "        train_mse_logger.experiment.add_scalar(\"Loss STD\", np.std(np.array(train_mse)), epoch)\n",
    "        train_kld_logger.experiment.add_scalar(\"Mean Loss\", np.mean(np.array(train_kld)), epoch)\n",
    "        train_kld_logger.experiment.add_scalar(\"Loss STD\", np.std(np.array(train_kld)), epoch)\n",
    "        train_ssim_logger.experiment.add_scalar(\"Mean Loss\", np.mean(np.array(train_ssim)), epoch)\n",
    "        train_ssim_logger.experiment.add_scalar(\"Loss STD\", np.std(np.array(train_ssim)), epoch)\n",
    "        del train_mse, train_kld, train_ssim\n",
    "\n",
    "        # End of Training Epoch Image Result Writing\n",
    "        train_mse_logger = ResultCallback(  settings, mode = 'Train',\n",
    "                                            logger = train_mse_logger,\n",
    "                                            epoch = epoch, loss = 'MSE Loss',\n",
    "                                            best_info = best_train_mse_info,\n",
    "                                            worst_info = worst_train_mse_info)\n",
    "        train_ssim_logger = ResultCallback( settings, mode = 'Train',\n",
    "                                            logger = train_ssim_logger,\n",
    "                                            epoch = epoch, loss = 'SSIM Index',\n",
    "                                            best_info = best_train_ssim_info,\n",
    "                                            worst_info = worst_train_ssim_info)\n",
    "        del best_train_mse_info, worst_train_mse_info, best_train_ssim_info, worst_train_ssim_info\n",
    "\n",
    "        ##############################################################################################\n",
    "        # ---------------------------------- Validation | Iteration ----------------------------------\n",
    "        ##############################################################################################\n",
    "\n",
    "        # Result Value Initialization\n",
    "        val_mse = []; val_kld = []; val_ssim = []\n",
    "        best_val_mse = 1000; worst_val_mse = 0\n",
    "        best_val_ssim = 0; worst_val_ssim = 1000\n",
    "\n",
    "        # Validation Patient Loop\n",
    "        with torch.no_grad():\n",
    "            model.eval(); print(f\"Validation Epoch #{epoch}:\")\n",
    "            for p, patient_id in enumerate(settings.val_patient_list):\n",
    "\n",
    "                # Validation Iteration Loop\n",
    "                val_bar = tqdm(   enumerate(val_loader[p]), total = len(val_loader[p]),\n",
    "                    desc = f'Epoch #{epoch} | Validation Patient {patient_id}', unit = 'Batches')\n",
    "                for batch_idx, batch in val_bar:\n",
    "                    \n",
    "                    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "                    # Forward Propagation\n",
    "                    X_target, kld_loss = model( batch['X_train'].to(settings.device),                       # Model Application\n",
    "                                                batch['y_target'].to(settings.device))                      # Kullback-Leibler Divergence\n",
    "                    gc.collect(); torch.cuda.empty_cache()\n",
    "                    \n",
    "                    # Loss Computation\n",
    "                    mse_loss = mse_criterion(X_target, batch['X_target'].to(settings.device))               # Mean Squared Error Loss\n",
    "                    ssim_loss, ssim_img = ssim( X_target.detach().cpu().numpy().astype(np.float32),         # Structural Similarity Index\n",
    "                                                batch['X_target'].detach().cpu().astype(np.float32), full = True,\n",
    "                        data_range = (torch.max(batch['X_target']) - torch.min(batch['X_target'])).cpu().numpy())\n",
    "                    ssim_loss = np.mean(ssim_loss); del ssim_img\n",
    "                    \n",
    "                    # Loss Appending\n",
    "                    val_mse_logger.experiment.add_scalar(\"Batch Loss\", mse_loss.item(), val_iter)\n",
    "                    val_kld_logger.experiment.add_scalar(\"Batch Loss\", kld_loss.item(), val_iter)\n",
    "                    val_ssim_logger.experiment.add_scalar(\"Batch Loss\", ssim_loss, val_iter); val_iter += 1\n",
    "                    val_mse.append(mse_loss.item()); val_kld.append(kld_loss.item())\n",
    "                    val_ssim.append(ssim_loss); gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "                    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "                    # Result Saving (MSE Loss)\n",
    "                    if mse_loss.item() < best_val_mse:\n",
    "                        best_val_mse = mse_loss.item()\n",
    "                        best_val_mse_info = {   'loss': mse_loss.item(), 'patient_id': patient_id,\n",
    "                                                'X_gt': batch['X_target'].detach().cpu(),\n",
    "                                                'X_fake': X_target.detach().cpu(),\n",
    "                                                'idxv_slice': batch['slice_target'],\n",
    "                                                'idxh_target': batch['param_target']}\n",
    "                    if mse_loss.item() > worst_val_mse:\n",
    "                        worst_val_mse = mse_loss.item()\n",
    "                        worst_val_mse_info = {  'loss': mse_loss.item(), 'patient_id': patient_id,\n",
    "                                                'X_gt': batch['X_target'].detach().cpu(),\n",
    "                                                'X_fake': X_target.detach().cpu(),\n",
    "                                                'idxv_slice': batch['slice_target'],\n",
    "                                                'idxh_target': batch['param_target']}\n",
    "                    \n",
    "                    # Result Saving (SSIM Index)\n",
    "                    if ssim_loss > best_val_ssim:\n",
    "                        best_val_ssim = ssim_loss\n",
    "                        best_val_ssim_info = {  'loss': ssim_loss, 'patient_id': patient_id,\n",
    "                                                'X_gt': batch['X_target'].detach().cpu(),\n",
    "                                                'X_fake': X_target.detach().cpu(),\n",
    "                                                'idxv_slice': batch['slice_target'],\n",
    "                                                'idxh_target': batch['param_target']}\n",
    "                    if ssim_loss < worst_val_ssim:\n",
    "                        worst_val_ssim = ssim_loss\n",
    "                        worst_val_ssim_info = { 'loss': ssim_loss, 'patient_id': patient_id,\n",
    "                                                'X_gt': batch['X_target'].detach().cpu(),\n",
    "                                                'X_fake': X_target.detach().cpu(),\n",
    "                                                'idxv_slice': batch['slice_target'],\n",
    "                                                'idxh_target': batch['param_target']}\n",
    "                    gc.collect(); torch.cuda.empty_cache()\n",
    "                    del batch, X_target, mse_loss, kld_loss, ssim_loss\n",
    "\n",
    "            ##############################################################################################\n",
    "            # ------------------------------------ Validation | Results ------------------------------------\n",
    "            ##############################################################################################\n",
    "\n",
    "                # Inter-Patient Reconstruction Parameter Sharing Functionality\n",
    "                if settings.interpatient_sharing:\n",
    "                    if p == 0:\n",
    "                        val_set[p].shuffle()\n",
    "                        val_idxh_target = val_set[p].idxh_target\n",
    "                        val_idxv_slice = val_set[p].idxv_slice\n",
    "                        val_idx_combo = val_set[p].idx_combo\n",
    "                    else:\n",
    "                        val_set[p].shuffle(idxh_target = val_idxh_target)\n",
    "                        val_set[p].shuffle(idxv_slice = val_idxv_slice)\n",
    "                        val_set[p].shuffle(idx_combo = val_idx_combo)\n",
    "                else: val_set[p].shuffle()\n",
    "\n",
    "            # --------------------------------------------------------------------------------------------\n",
    "            \n",
    "        # End of Training Epoch Mean & STD Loss Writing\n",
    "        val_mse_logger.experiment.add_scalar(\"Mean Loss\", np.mean(np.array(val_mse)), epoch)\n",
    "        val_mse_logger.experiment.add_scalar(\"Loss STD\", np.std(np.array(val_mse)), epoch)\n",
    "        val_kld_logger.experiment.add_scalar(\"Mean Loss\", np.mean(np.array(val_kld)), epoch)\n",
    "        val_kld_logger.experiment.add_scalar(\"Loss STD\", np.std(np.array(val_kld)), epoch)\n",
    "        val_ssim_logger.experiment.add_scalar(\"Mean Loss\", np.mean(np.array(val_ssim)), epoch)\n",
    "        val_ssim_logger.experiment.add_scalar(\"Loss STD\", np.std(np.array(val_ssim)), epoch)\n",
    "        del val_mse, val_kld, val_ssim\n",
    "\n",
    "        # End of Training Epoch Image Result Writing\n",
    "        val_mse_logger = ResultCallback(    settings, mode = 'Validation',\n",
    "                                            logger = val_mse_logger,\n",
    "                                            epoch = epoch, loss = 'MSE Loss',\n",
    "                                            best_info = best_val_mse_info,\n",
    "                                            worst_info = worst_val_mse_info)\n",
    "        val_ssim_logger = ResultCallback(   settings, mode = 'Validation',\n",
    "                                            logger = val_ssim_logger,\n",
    "                                            epoch = epoch, loss = 'SSIM Index',\n",
    "                                            best_info = best_val_ssim_info,\n",
    "                                            worst_info = worst_val_ssim_info)\n",
    "        del best_val_mse_info, worst_val_mse_info, best_val_ssim_info, worst_val_ssim_info\n",
    "\n",
    "        # Early Stopping Callback Application\n",
    "        early_stop = earlyStopping( loss = np.mean(np.array(val_mse)), epoch = epoch,\n",
    "                                    model = model, optimizer = optimizer)\n",
    "        val_kld_logger.experiment.add_scalar(\"Early Stopping Counter\", earlyStopping.counter, epoch)\n",
    "        if early_stop: print(f'     > Training Finished at Epoch #{epoch}'); return\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3629, 0.9330, 0.3346, 0.2452, 0.7000, 0.2600, 0.1754, 0.8885, 0.7616,\n",
       "        0.3074, 0.4657, 0.0090, 0.6760, 0.2030, 0.4818, 0.5181, 0.0074, 0.0609,\n",
       "        0.5422, 0.7226, 0.7758, 0.5545, 0.3803, 0.6194, 0.2501, 0.4425, 0.8280,\n",
       "        0.6303, 0.3459, 0.3713, 0.2772, 0.0370, 0.5292, 0.8969, 0.6580, 0.9944,\n",
       "        0.6421, 0.6794, 0.8211, 0.7355, 0.7163, 0.4077, 0.3542, 0.6867, 0.5817,\n",
       "        0.3580, 0.7400, 0.5989, 0.6106, 0.8616, 0.8197, 0.5715, 0.4865, 0.7445,\n",
       "        0.7486, 0.0762, 0.8225, 0.5071, 0.0311, 0.5887, 0.6230, 0.4759, 0.8119,\n",
       "        0.0749, 0.6054, 0.1161, 0.4330, 0.6626, 0.2553, 0.3366, 0.8575, 0.2139,\n",
       "        0.8075, 0.1432, 0.8114, 0.3410, 0.5106, 0.2882, 0.7115, 0.6115])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[25, 30, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(data=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, --, 0.0,\n",
       "                   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                   0.0, 0.0, 0.0],\n",
       "             mask=[False, False, False, False, False, False, False, False,\n",
       "                   False, False, False, False, False, False, False, False,\n",
       "                   False, False, False, False, False, False, False, False,\n",
       "                   False, False, False, False, False, False, False, False,\n",
       "                   False, False, False, False, False, False, False, False,\n",
       "                   False, False, False, False, False, False, False, False,\n",
       "                   False, False, False, False, False, False, False, False,\n",
       "                   False, False, False, False, False, False, False, False,\n",
       "                    True, False, False, False, False, False, False, False,\n",
       "                   False, False, False, False, False, False, False, False],\n",
       "       fill_value=1e+20,\n",
       "            dtype=float32)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_final[25, 25, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2bec49002e0>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img[25, :, :], 'gray', interpolation = 'none')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2bec588fe80>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = torch.rand((56, 92, 80))\n",
    "\n",
    "img_final = np.multiply(np.array(img).astype(np.float32), mask_wm)\n",
    "plt.imshow(img_final[25, :, :], 'gray', interpolation = 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2bec7399810>"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 4000x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask_wm_ = np.array(nib.load(os.path.join(settings.mask_folderpath, f'p14_csf.nii.gz')).dataobj).T.astype(int)\n",
    "img = torch.rand((56, 92, 80))\n",
    "\n",
    "plt.figure(figsize = (40, 10))\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(mask_wm_[25, :, :], 'gray', interpolation = 'none')\n",
    "mask_wm = np.ma.masked_array(mask_wm == 1, mask_wm)\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(img[25, :, :], 'gray', interpolation = 'none')\n",
    "plt.imshow(mask_wm[25, :, :], 'gray', interpolation = 'none')\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(img[25, :, :], 'gray', interpolation = 'none')\n",
    "plt.subplot(1,4,4)\n",
    "img_final = np.multiply(mask_wm_, np.array(img))\n",
    "plt.imshow(img_final[25, :, :], 'gray', interpolation = 'none')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
