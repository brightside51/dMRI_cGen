{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "# *Initial* **Setup**\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Library** *Settings*\n",
    "\n",
    "The Real Package Name must be found in https://pypi.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Import\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import psutil\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchsummary\n",
    "import torchvision\n",
    "import pytorch_lightning as pl\n",
    "import tensorboard\n",
    "import sklearn\n",
    "import fvcore\n",
    "import matplotlib.pyplot as plt\n",
    "import itk\n",
    "import itkwidgets\n",
    "import time\n",
    "import timeit\n",
    "import warnings\n",
    "import alive_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functionality Import\n",
    "from pathlib import Path\n",
    "from typing import List, Literal, Optional, Callable, Dict, Literal, Optional, Union, Tuple\n",
    "from collections import OrderedDict\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.utils import spectral_norm\n",
    "from torchsummary import summary\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from PIL import Image\n",
    "from ipywidgets import interactive, IntSlider\n",
    "from tabulate import tabulate\n",
    "from alive_progress import alive_bar\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Control** *Station*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Parametrizations Parser Initialization\n",
    "data_parser = argparse.ArgumentParser(\n",
    "description = \"2/3D MUDI Dataset Settings\")\n",
    "data_parser.add_argument(                               # Dataset Version Variable\n",
    "        '--version', type = int,                        # Default: 0\n",
    "        default = 2,\n",
    "        help = \"Dataset Save Version\")\n",
    "data_parser.add_argument(                               # Dataset Dimensionality\n",
    "        '--dim', type = int,                            # Default: 3\n",
    "        default = 2,\n",
    "        help = \"Dataset Dimensionality\")\n",
    "data_parser.add_argument(                               # Dataset Batch Size Value\n",
    "        '--batch_size', type = int,                     # Default: 500\n",
    "        default = 500,\n",
    "        help = \"Dataset Batch Size Value\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Dataset Label Parametrization Arguments\n",
    "data_parser.add_argument(                       # Control Variable for the Inclusion of Patient ID in Labels\n",
    "        '--patient_id', type = bool,            # Default: True\n",
    "        default = False,\n",
    "        help = \"Control Variable for the Inclusion of Patient ID in Labels\")\n",
    "data_parser.add_argument(                       # Control Variable for the Conversion of 3 Gradient Directions\n",
    "        '--gradient_coord', type = bool,        # Coordinates into 2 Gradient Direction Angles (suggested by prof. Chantal)\n",
    "        default = False,                        # Default: True (3 Coordinate Gradient Values)\n",
    "        help = \"Control Variable for the Conversion of Gradient Direction Mode\")\n",
    "data_parser.add_argument(                       # Control Variable for the Rescaling & Normalization of Labels\n",
    "        '--label_norm', type = bool,            # Default: True\n",
    "        default = True,\n",
    "        help = \"Control Variable for the Rescaling & Normalization of Labels\")\n",
    "data_settings = data_parser.parse_args(\"\")\n",
    "num_labels = 7\n",
    "if not(data_settings.patient_id): num_labels -= 1       # Exclusion of Patiend ID\n",
    "if not(data_settings.gradient_coord): num_labels -= 1   # Conversion of Gradient Coordinates to Angles\n",
    "data_parser.add_argument(                               # Dataset Number of Labels\n",
    "        '--num_labels', type = int,             # Default: 7\n",
    "        default = num_labels,\n",
    "        help = \"MUDI Dataset Number of Labels\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Addition of File & Folderpath Arguments\n",
    "data_parser.add_argument(                               # Path for Main Dataset Folder\n",
    "        '--main_folderpath', type = str,\n",
    "        default = '../../../Datasets/MUDI Dataset',\n",
    "        help = 'Main Folderpath for Root Dataset')\n",
    "data_settings = data_parser.parse_args(\"\")\n",
    "data_parser.add_argument(                               # Path for Folder Containing Patient Data Files\n",
    "        '--patient_folderpath', type = Path,\n",
    "        default = Path(f'{data_settings.main_folderpath}/Patient Data'),\n",
    "        help = 'Input Folderpath for Segregated Patient Data')\n",
    "data_parser.add_argument(                               # Path for Folder Containing Mask Data Files\n",
    "        '--mask_folderpath', type = Path,\n",
    "        default = Path(f'{data_settings.main_folderpath}/Patient Mask'),\n",
    "        help = 'Input Folderpath for Segregated Patient Mask Data')\n",
    "data_parser.add_argument(                               # Path for Parameter Value File\n",
    "        '--param_filepath', type = Path,\n",
    "        default = Path(f'{data_settings.main_folderpath}/Raw Data/parameters_new.xlsx'),\n",
    "        help = 'Input Filepath for Parameter Value Table')\n",
    "data_parser.add_argument(                               # Path for Patient Information File\n",
    "        '--info_filepath', type = Path,\n",
    "        default = Path(f'{data_settings.main_folderpath}/Raw Data/header1_.csv'),\n",
    "        help = 'Input Filepath for Patient Information Table')\n",
    "data_parser.add_argument(                               # Path for Dataset Saved Files\n",
    "        '--save_folderpath', type = Path,\n",
    "        default = Path(f'{data_settings.main_folderpath}/Saved Data/V{data_settings.version}'),\n",
    "        help = 'Output Folderpath for MUDI Dataset Saved Versions')\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Dataset Splitting  Arguments\n",
    "data_parser.add_argument(                       # Number of Patients to be used in the Test Set\n",
    "        '--test_patients', type = int,          # Default: 1\n",
    "        default = 1,\n",
    "        help = \"Number of Patients in Test Set\")\n",
    "data_parser.add_argument(                       # Number / Percentage of Parameters for Training Set's Training\n",
    "        '--train_params', type = int,           # Default: 500\n",
    "        default = 500,\n",
    "        help = \"Number / Percentage of Patients in the Training of the Training Set\")\n",
    "data_parser.add_argument(                       # Number / Percentage of Parameters for Training Set's Training\n",
    "        '--test_params', type = int,            # Default: 20\n",
    "        default = 20,\n",
    "        help = \"Number / Percentage of Patients in the Training of the Test Set\")\n",
    "\n",
    "# Boolean Control Input & Shuffling Arguments\n",
    "data_parser.add_argument(                       # Control Variable for the Usage of Percentage Values in Parameters\n",
    "        '--percentage', type = bool,            # Default: False\n",
    "        default = False,\n",
    "        help = \"Control Variable for the Usage of Percentage Values in Parameters\")\n",
    "data_parser.add_argument(                       # Ability to Shuffle the Patients that compose both Training and Test Sets\n",
    "        '--patient_shuffle', type = bool,       # Default: False\n",
    "        default = False,\n",
    "        help = \"Ability to Shuffle the Patients that compose both Training and Test Sets\")\n",
    "data_parser.add_argument(                       # Ability to Shuffle the Samples inside both Training and Validation Sets\n",
    "        '--sample_shuffle', type = bool,        # Default: False\n",
    "        default = False,\n",
    "        help = \"Ability to Shuffle the Samples inside both Training and Validation Sets\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Dataset Pre-Processing Arguments\n",
    "data_parser.add_argument(                       # Data Pre-Processing Method\n",
    "        '--pre_processing', type = str,         # Default: Zero Padding\n",
    "        default = 'Zero Padding',\n",
    "        choices = ['Interpolation', 'Zero Padding', 'CNN'],\n",
    "        help = \"Data Pre-Processing Method\")\n",
    "data_parser.add_argument(                       # Final 3D Image Shape for Pre-Processing Output\n",
    "        '--img_shape', type = np.array,         # Default: [85, 128, 128]\n",
    "        default = np.array((85, 128, 128)),\n",
    "        help = \"Final 3D Image Shape for Pre-Processing Output\")\n",
    "data_parser.add_argument(                       # Number of Selected Slices in 2D Conversion\n",
    "        '--num_slices', type = int,             # Default: 35\n",
    "        default = 35,\n",
    "        help = \"Number of Selected Slices in 2D Conversion\")\n",
    "data_settings = data_parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D CVAE-mCcGAN Model Parametrizations Parser Initialization\n",
    "model_parser = argparse.ArgumentParser(\n",
    "description = \"2D CcGAN Settings\")\n",
    "model_parser.add_argument(              # Model Version Variable\n",
    "        '--model_version', type = int,        # Default: 0\n",
    "        default = 0,\n",
    "        help = \"Experiment Version\")\n",
    "model_parser.add_argument(              # Dataset Version Variable\n",
    "        '--data_version', type = int,   # Default: 0\n",
    "        default = 2,\n",
    "        help = \"MUDI Dataset Version\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Addition of Filepath Arguments\n",
    "model_parser.add_argument(\n",
    "        '--reader_folderpath', type = Path,\n",
    "        default = Path(f'{data_settings.main_folderpath}/Dataset Reader'),\n",
    "        help = 'Input Folderpath for MUDI Dataset Reader')\n",
    "model_parser.add_argument(\n",
    "        '--data_folderpath', type = Path,\n",
    "        default = Path(f'{data_settings.main_folderpath}/Saved Data/V{data_settings.version}'),\n",
    "        help = 'Input Folderpath for MUDI Dataset Saved Versions')\n",
    "model_parser.add_argument(\n",
    "        '--model_folderpath', type = str,\n",
    "        default = 'Model Builds',\n",
    "        help = 'Input Folderpath for Model Build & Architecture')\n",
    "model_parser.add_argument(\n",
    "        '--script_folderpath', type = str,\n",
    "        default = 'Training Scripts',\n",
    "        help = 'Input Folderpath for Training & Testing Script Functions')\n",
    "model_parser.add_argument(\n",
    "        '--save_folderpath', type = str,\n",
    "        default = 'Saved Models',\n",
    "        help = 'Output Folderpath for Saved & Saving Models')\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Addition of Label Embedding Models Training Requirement Arguments\n",
    "model_parser.add_argument(              # Number of Epochs\n",
    "        '--num_epochs', type = int,     # Default: 1\n",
    "        default = 50,\n",
    "        help = \"Number of Epochs in Training Mode\")\n",
    "model_parser.add_argument(              # Base Learning Rate Value for Label Embedding\n",
    "        '--base_lr', type = float,      # Default: 0.01\n",
    "        default = 0.01,\n",
    "        help = \"Base Learning Rate Value in Training Mode\")\n",
    "model_parser.add_argument(              # Weight Decay Value\n",
    "        '--weight_decay', type = float, # Default: 0.0001\n",
    "        default = 1e-4,\n",
    "        help = \"Weight Decay Value in Training Mode\")\n",
    "model_parser.add_argument(              # Learning Rate Decay Ratio\n",
    "        '--lr_decay', type = float,     # Default: 0.9\n",
    "        default = 0.9,\n",
    "        help = \"Learning Rate Decay Value in Training Mode\")\n",
    "model_parser.add_argument(              # Control Variable for the Inclusion of Label Gamma Noise\n",
    "        '--noise', type = bool,         # Default: True\n",
    "        default = True,\n",
    "        help = \"Control Variable for the Inclusion of Label Gamma Noise\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Addition of Model Architecture Arguments\n",
    "model_parser.add_argument(              # Embedding Space Dimensionality\n",
    "        '--dim_embedding', type = int,  # Default: 128\n",
    "        default = 128,\n",
    "        help = \"Embedding Space Dimensionality Value\")\n",
    "model_parser.add_argument(              # Z Space Dimensionality\n",
    "        '--dim_z', type = int,          # Default: 256\n",
    "        default = 256,\n",
    "        help = \"Z Space Dimensionality Value\")\n",
    "model_parser.add_argument(              # Generator & Discriminator No. Intermediate Channels\n",
    "        '--num_channels', type = int,   # Default: 64\n",
    "        default = 64,\n",
    "        help = \"Generator & Discriminator No. Intermediate Channels\")\n",
    "model_parser.add_argument(              # T1 & T2 Model Expansion\n",
    "        '--expansion', type = int,      # Default: 1\n",
    "        default = 1,\n",
    "        help = \"T1 & T2 Model Expansion Value\")\n",
    "model_parser.add_argument(              # Batch Size Value\n",
    "        '--batch_size', type = int,     # Default: 500\n",
    "        default = data_settings.batch_size,\n",
    "        help = \"Batch Size Value\")\n",
    "model_parser.add_argument(              # Dataset Number of Labels\n",
    "        '--num_labels', type = int,     # Default: 7\n",
    "        default = data_settings.num_labels,\n",
    "        help = \"MUDI Dataset Number of Labels\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Addition of CcGAN Training Requirement Arguments\n",
    "model_parser.add_argument(              # Base Learning Rate Value\n",
    "        '--lr_ccgan', type = float,     # Default: 0.0001\n",
    "        default = 1e-4,\n",
    "        help = \"Base Learning Rate Value in Training Mode\")\n",
    "model_parser.add_argument(              # Sigma Kernel Size in Gaussian Noise Added\n",
    "        '--kernel_eps', type = np.array,# Default: -1.0\n",
    "        default = 1.0,\n",
    "        help = \"Sigma Kernel Size in Gaussian Noise Added\")\n",
    "model_parser.add_argument(              # Discriminator's Number of Updates per Iteration\n",
    "        '--dis_update', type = int,     # Default: 4\n",
    "        default = 4,\n",
    "        help = \"Number of Updates / Iteration for Discriminator\")\n",
    "model_parser.add_argument(              # Generator's Number of Updates per Iteration\n",
    "        '--gen_update', type = int,     # Default: 4\n",
    "        default = 4,\n",
    "        help = \"Number of Updates / Iteration for Generator\")\n",
    "model_parser.add_argument(              # GAN Loss Function\n",
    "        '--loss', type = str,           # Default: Hinge Loss\n",
    "        choices = ['vanilla', 'hinge'],\n",
    "        default = 'hinge',\n",
    "        help = 'GAN Loss Function')\n",
    "\n",
    "model_settings = model_parser.parse_args(\"\")\n",
    "model_settings.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **Data** *Access*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Access Requirements\n",
    "sys.path.append(f'{main_folderpath}Dataset Reader')\n",
    "from v3DMUDI import v3DMUDI\n",
    "\n",
    "# Dataset Initialization & Saving Example\n",
    "#mudi = v3DMUDI(data_settings)\n",
    "#mudi.split(); mudi.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D Interactive Plotting Function\n",
    "def plot(\n",
    "    sample_number,\n",
    "    slice_number,\n",
    "):\n",
    "\n",
    "    # Patient Sample & Slice for Visualization\n",
    "    img = X[sample_number]\n",
    "    img = img[slice_number]\n",
    "    #img = data[slice_number, :, :, sample_number].T\n",
    "    plt.figure(figsize = (10, 20)); plt.imshow(img, cmap = 'gray'); plt.axis('off')\n",
    "    plt.title(f\"Patient #11 to 14 | Sample #{sample_number} | Slice #{slice_number}\")\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Patient Data Visualization Function\n",
    "#patient_number = 0; data = mudi.get_patient(patient_number)\n",
    "#X = data.train_set['X_train']\n",
    "sample_slider = IntSlider(value = 0, min = 0, max = X.shape[0], description = 'Sample', continuous_update = False)\n",
    "slice_slider = IntSlider(value = 0, min = 0, max = X.shape[1], description = 'Slice', continuous_update = False)\n",
    "interactive(plot, sample_number = sample_slider, slice_number = slice_slider)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# *Model* **Building**\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CVAE** *Model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "# --------------------------------------- Encoder Build --------------------------------------\n",
    "##############################################################################################\n",
    "\n",
    "# Encoder Model Class\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser    # Model Settings & Parametrizations\n",
    "        #num_labels: int = 5,                # Number of Labels contained in Dataset\n",
    "        #num_channel: int = 64,              # Number of Output Channels for Encoder\n",
    "        #num_layers: int = 3,                # Number of Main Convolutional Layers\n",
    "        #latent_dim: int = 64                # Latent Space Dimensionality\n",
    "    ):\n",
    "\n",
    "        # Class Variable Logging\n",
    "        super(Encoder, self).__init__()\n",
    "        self.settings = settings\n",
    "\n",
    "        # Encoder Downsampling Architecture Definition\n",
    "        net = []; in_channel = 1 + settings.num_labels\n",
    "        for i in reversed(range(settings.num_layers)):\n",
    "            out_channel = int(settings.num_channel / (2 ** i))      # Current Main Layer's Output Channels\n",
    "            #k = 2 * (i + 1)                                        # Kernel Size Value (6 is too high for Voxel-Wise CVAE)\n",
    "            #print(f\"{in_channel} -> {out_channel}\")\n",
    "            net.append(nn.Sequential(                               # Main Layer Block Repeatable Architecture\n",
    "                nn.Conv1d(      in_channels = in_channel,\n",
    "                                out_channels = out_channel,\n",
    "                                kernel_size = 1, stride = 2, padding = 0),\n",
    "                nn.LeakyReLU(   inplace = True)))\n",
    "            in_channel = out_channel                                # Next Main Layer's Input Channels\n",
    "        self.net = nn.Sequential(*net)\n",
    "        \n",
    "        # Mean and LogVariance Computation Linear Layers\n",
    "        self.mean_layer = nn.Linear(    in_features = settings.num_channel,\n",
    "                                        out_features = settings.latent_dim)\n",
    "        self.logvar_layer = nn.Linear(  in_features = settings.num_channel,\n",
    "                                        out_features = settings.latent_dim)\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Encoder Application Function\n",
    "    def forward(\n",
    "        self,\n",
    "        X: np.ndarray or torch.Tensor,      # 1D Image Input\n",
    "        y: np.ndarray or torch.Tensor       # Image Labels Input\n",
    "    ):\n",
    "\n",
    "        # Net Input Handling\n",
    "        X = torch.Tensor(X).view(-1, 1, 1).to(self.settings.device)                             # Input Features | [batch_size, 1,              1]\n",
    "        y = torch.Tensor(y).view(-1, self.settings.num_labels, 1).to(self.settings.device)      # Input Labels   | [batch_size, num_labels,     1]\n",
    "        input = torch.cat((X, y), dim = 1)                                                      # Encoder Output | [batch_size, 1+num_channel,  1]\n",
    "        \n",
    "        # Forward Propagation in Encoder Architecture\n",
    "        output = self.net(input)                                                                # Encoder Output | [batch_size, num_channel,    1]\n",
    "        z_mean = self.mean_layer(output.view(-1, self.settings.num_channel))                    # Latent Mean    | [batch_size, latent_dim]\n",
    "        z_logvar = self.logvar_layer(output.view(-1, self.settings.num_channel))                # Latent LogVar  | [batch_size, latent_dim]\n",
    "\n",
    "        # Display Settings for Experimental Model Version\n",
    "        if self.settings.model_version == 0:\n",
    "            print(f\"Encoder Input  | {list(input.shape)}\")\n",
    "            print(f\"Encoder Output | {list(output.shape)}\")\n",
    "            print(f\"Latent Mean    | {list(z_mean.shape)}\")\n",
    "            print(f\"Latent LogVar  | {list(z_logvar.shape)}\\n\")\n",
    "        return z_mean, z_logvar\n",
    "\n",
    "import tensorboard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **GAN** *Model*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Image* **Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Image* **Discriminator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# *Model* **Building**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Label** *Embedding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main / Repeatable ResNet Block Construction Class\n",
    "class SimpleBlock(nn.Module):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channel:int,\n",
    "        out_channel: int,\n",
    "        stride: int = 1,\n",
    "        expansion: int = 1\n",
    "    ):\n",
    "\n",
    "        # Main Block's Common Section Architecture\n",
    "        super(SimpleBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(  in_channel, out_channel, kernel_size = 3,\n",
    "                        stride = stride, padding = 1, bias = False),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.ReLU(),          # WARNING: They use torch.functional's ReLU for some reason here!\n",
    "            nn.Conv2d(  out_channel, out_channel, kernel_size = 3,\n",
    "                        stride = 1, padding = 1, bias = False),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.ReLU(),          # WARNING: They use torch.functional's ReLU for some reason here!\n",
    "            nn.Conv2d(  out_channel, expansion * out_channel,\n",
    "                        kernel_size = 1, bias = False),\n",
    "            nn.BatchNorm2d(expansion * out_channel)\n",
    "        )\n",
    "\n",
    "        # Main Block's Shortcut Section Architecture\n",
    "        if stride != 1 or in_channel != expansion * out_channel:\n",
    "             self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(  in_channel, expansion * out_channel, kernel_size = 1,\n",
    "                            stride = stride, bias = False),\n",
    "                nn.BatchNorm2d(expansion * out_channel)\n",
    "             )\n",
    "        else: self.shortcut = nn.Sequential()\n",
    "\n",
    "    # Main Block Application Function\n",
    "    def forward(self, X):\n",
    "\n",
    "        # Main Block Architecture Walkthrough\n",
    "        out = self.block(X)\n",
    "        out += self.shortcut(X)\n",
    "        return F.relu(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Embedding CNN Class (X -> h -> y)\n",
    "class LabelEmbedding(nn.Module):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_blocks: list = [3, 4, 6, 3],    # Number of Blocks in ResNet Main Block Intermediate Layers\n",
    "        in_channel: int = 64,               # Number of Input Channels in ResNet Main Block Intermediate Layers' Blocks\n",
    "        expansion: int = 1,                 # Expansion Factor for Stride Value in ResNet Main Block Intermediate Layers\n",
    "        dim_embedding: int = 128,           # Embedding Space Dimensionality (WIP)\n",
    "    ):\n",
    "\n",
    "        # Class Variable Logging\n",
    "        super(LabelEmbedding, self).__init__()\n",
    "        assert(len(num_blocks) == 4), \"Number of Blocks provided Not Supported!\"\n",
    "        self.num_blocks = num_blocks\n",
    "        self.in_channel = in_channel\n",
    "        self.expansion = expansion\n",
    "        self.dim_embedding = dim_embedding\n",
    "\n",
    "        # Main ResNet50 Architecture Construction\n",
    "        self.mainNet = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            self.main_layer(64, self.num_blocks[0]),\n",
    "            self.main_layer(128, self.num_blocks[1]),\n",
    "            self.main_layer(256, self.num_blocks[2]),\n",
    "            self.main_layer(512, self.num_blocks[3]),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "        # 1st SubNetwork for Label Embedding (X -> h)\n",
    "        self.t1Net = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, self.dim_embedding),\n",
    "            nn.BatchNorm1d(self.dim_embedding),\n",
    "            nn.ReLU())\n",
    "\n",
    "        # 2nd SubNetwork for Label Embedding (h -> y)\n",
    "        self.t2Net = nn.Sequential(\n",
    "            nn.Linear(self.dim_embedding, 7),\n",
    "            nn.ReLU())\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # ResNet Repeatable Layer Definition Function\n",
    "    def main_layer(\n",
    "        self,\n",
    "        out_channel: int,\n",
    "        num_blocks: int,\n",
    "        stride: int = 2\n",
    "    ):\n",
    "\n",
    "        # Layer Architecture Creation\n",
    "        stride = [stride] + [1] * (num_blocks - 1); layer = []\n",
    "        for s in stride:\n",
    "            layer.append(SimpleBlock(self.in_channel, out_channel, s, expansion = self.expansion))\n",
    "            self.in_channel = out_channel * self.expansion\n",
    "        return nn.Sequential(*layer)\n",
    "            \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Label Embedding Application Function\n",
    "    def forward(self,\n",
    "        X: np.ndarray or torch.Tensor       # 3D Image Input\n",
    "    ):\n",
    "\n",
    "        # Forwad Propagation in CNN Architecture\n",
    "        X = torch.Tensor(X)                 # Numpy Array to Tensor Conversion\n",
    "        h = self.mainNet(X)                 # Main ResNet Application\n",
    "        h = h.view(h.size(0), -1)           # Linearization of ResNet Features\n",
    "        h = self.t1Net(h)                   # 1st SubNewtork Application (X -> h)\n",
    "        y = self.t2Net(h)                   # 2nd SubNewtork Application (h -> y)\n",
    "        return h, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Embedding SubNetwork Class (y -> h)\n",
    "class t3Net(nn.Module):\n",
    "    \n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(self,\n",
    "        dim_embedding: int = 128,           # Embedding Space Dimensionality\n",
    "        num_blocks: int = 4,                # Number of Blocks in T3 SubNewtork\n",
    "        num_labels: int = 7                 # Number of Labels in Dataset provided\n",
    "    ):\n",
    "\n",
    "        # Class Variable Logging\n",
    "        super(t3Net, self).__init__()\n",
    "        self.dim_embedding = dim_embedding      # h Variable Dimension\n",
    "        self.num_blocks = num_blocks            # Number of Blocks in Embedding MLP\n",
    "        self.num_labels = num_labels            # Number of Labels in Dataset provided\n",
    "        self.mlp = nn.Sequential()              # Empty Embedding MLP Variable\n",
    "        norm = True                             # Default Block Group Normalization\n",
    "\n",
    "        # MLP Architecture Definition\n",
    "        for i in range(num_blocks + 1):\n",
    "            if i == 0: in_channel = self.num_labels         # 1st Block Entry Features\n",
    "            else: in_channel = self.dim_embedding           # Intermediate Block Input Features\n",
    "            if i == num_blocks - 1: norm = False            # No Group Normalization on Last Block\n",
    "            self.mlp.add_module(f'Block #{i + 1}',\n",
    "                                self.main_block(in_channel,\n",
    "                                self.dim_embedding, norm = norm))\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # MLP Repeatable Main Block Definition\n",
    "    def main_block(self,\n",
    "        in_channel: int,            # Input Features for Linear Layer\n",
    "        out_channel: int,           # Output Features for Linear Layer\n",
    "        norm: bool = True,          # Group Normalization Boolean Control Variable\n",
    "    ):\n",
    "\n",
    "        # Main Block Architecture Definition\n",
    "        if norm:\n",
    "            block = nn.Sequential(\n",
    "                nn.Linear(in_channel, out_channel),\n",
    "                nn.GroupNorm(8, out_channel), nn.ReLU())\n",
    "        else:\n",
    "            block = nn.Sequential(\n",
    "                nn.Linear(in_channel, out_channel),\n",
    "                nn.ReLU())\n",
    "        return block\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Label Embedding Application Function\n",
    "    def forward(self,\n",
    "        y: pd.DataFrame       # 3D Image Input Labels\n",
    "    ):\n",
    "\n",
    "        # Label Embedding using MLP\n",
    "        assert(y.ndim == 2), f\"ERROR: Input Labels not Correctly Dimensioned!\"\n",
    "        return self.mlp(torch.Tensor(np.array(y)))          # h Embedded Labels Variable \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Test MUDI Data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# 2D Data Sample Creation\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTest MUDI Data\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m      3\u001b[0m y \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTest MUDI Labels\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m      4\u001b[0m X \u001b[39m=\u001b[39m X[\u001b[39m0\u001b[39m:\u001b[39m35\u001b[39m,:]; y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m:\u001b[39m35\u001b[39m]; y[\u001b[39m'\u001b[39m\u001b[39mPatient\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m11\u001b[39m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Test MUDI Data'"
     ]
    }
   ],
   "source": [
    "# 2D Data Sample Creation\n",
    "X = pickle.load(open(f'Test MUDI Data', 'rb'))\n",
    "y = pickle.load(open(f'Test MUDI Labels', 'rb'))\n",
    "X = X[0:35,:]; y = y.iloc[0:35]; y['Patient'] = 11\n",
    "plt.imshow(X[0, 0, :, :], cmap = 'gray')\n",
    "\n",
    "# Label Embedding Network Testing (X -> h -> y)\n",
    "embedNet = LabelEmbedding()                 # T1 & T2 Model Creation\n",
    "h1, y2 = embedNet(X)                        # T1 (X -> h) & T2 (h -> y) Models Application\n",
    "y2h_model = t3Net()                            # T3 Model Creation\n",
    "h3 = y2h_model(y)                           # T3 (y -> h) Model Application\n",
    "print(tabulate([[\"X\", X.shape, \"->\", \"h\", list(h1.shape)],\n",
    "                [\"h\", list(h1.shape), \"->\", \"y\", list(y2.shape)],\n",
    "                [\"y\", y.shape, \"->\", \"h\", list(h3.shape)]],\n",
    "                headers = [\"Input\", \"Input Shape\", \"->\", \"Output\", \"Output Shape\"],\n",
    "                showindex = [\"T1\", \"T2\", \"T3\"], tablefmt = 'fancy_grid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Image* **Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Spectral Normalization Layer Class\n",
    "class LinearSpectralNorm(nn.Module):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channel: int,\n",
    "        out_channel: int,\n",
    "        num_channels: int = 64,\n",
    "        bias: bool = True\n",
    "    ):\n",
    "\n",
    "        # Layer Architecture Construction\n",
    "        super().__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.layer = spectral_norm(nn.Linear(in_channel, out_channel, bias))\n",
    "\n",
    "    # Layer Application Function\n",
    "    def forward(\n",
    "        self,\n",
    "        z: torch.Tensor\n",
    "    ):\n",
    "\n",
    "        # Layer Walkthrough\n",
    "        out = self.layer(z)\n",
    "        out = out.view(-1, self.num_channels * 16, 4, 4)\n",
    "        return out\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# 2D Convolutional Spectral Normalization Layer Class\n",
    "class Conv2DSpectralNorm(nn.Module):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channel: int,\n",
    "        out_channel: int,\n",
    "        kernel_size: int = 3,\n",
    "        stride: int = 1,\n",
    "        padding: int = 0,\n",
    "        dilation: int = 1,\n",
    "        groups: int = 1,\n",
    "        bias: bool = True\n",
    "    ):\n",
    "\n",
    "        # Layer Architecture Construction\n",
    "        super().__init__()\n",
    "        self.layer = spectral_norm( nn.Conv2d(in_channel, out_channel, kernel_size,\n",
    "                                    stride, padding, dilation, groups, bias))\n",
    "\n",
    "    # Layer Application Function\n",
    "    def forward(\n",
    "        self,\n",
    "        z: torch.Tensor\n",
    "    ):\n",
    "\n",
    "        # Layer Walkthrough\n",
    "        out = self.layer(z)\n",
    "        return out\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Self Attention Layer Class\n",
    "class SelfAttention(nn.Module):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channel: int\n",
    "    ):\n",
    "\n",
    "        # Block Architecture Construction\n",
    "        super().__init__()\n",
    "        self.in_channel = in_channel\n",
    "        self.conv2DSN_theta = Conv2DSpectralNorm(   in_channel, in_channel // 8,\n",
    "                                                    kernel_size = 1, stride = 1, padding = 0)\n",
    "        self.conv2DSN_phi = Conv2DSpectralNorm(     in_channel, in_channel // 8,\n",
    "                                                    kernel_size = 1, stride = 1, padding = 0)\n",
    "        self.conv2DSN_gamma = Conv2DSpectralNorm(   in_channel, in_channel // 2,\n",
    "                                                    kernel_size = 1, stride = 1, padding = 0)\n",
    "        self.conv2DSN_attent = Conv2DSpectralNorm(  in_channel // 2, in_channel,\n",
    "                                                    kernel_size = 1, stride = 1, padding = 0)\n",
    "        self.MaxPool2D = nn.MaxPool2d(2, stride = 2, padding = 0)\n",
    "        self.SoftMax = nn.Softmax(dim = -1)\n",
    "    \n",
    "    # Layer Application Function\n",
    "    def forward(\n",
    "        self,\n",
    "        X: torch.Tensor                 # Tensor containing Data\n",
    "    ):\n",
    "\n",
    "        # Theta Path\n",
    "        theta = self.conv2DSN_theta(X)\n",
    "        theta = theta.view(-1, X.shape[1] // 8, X.shape[2] * X.shape[3])\n",
    "\n",
    "        # Phi Path\n",
    "        phi = self.conv2DSN_phi(X)\n",
    "        phi = self.MaxPool2D(phi)\n",
    "        phi = phi.view(-1, X.shape[1] // 8, (X.shape[2] * X.shape[3]) // 4)\n",
    "\n",
    "        # Gamma Path\n",
    "        gamma = self.conv2DSN_gamma(X)\n",
    "        gamma = self.MaxPool2D(gamma)\n",
    "        gamma = gamma.view(-1, X.shape[1] // 2, (X.shape[2] * X.shape[3]) // 4)\n",
    "\n",
    "        # Attention Map\n",
    "        attent = torch.bmm(theta.permute(0, 2, 1), phi)\n",
    "        attent = self.SoftMax(attent)\n",
    "        attent = torch.bmm(gamma, attent.permute(0, 2, 1))\n",
    "        attent = attent.view(-1, X.shape[1] // 2, X.shape[2], X.shape[3])\n",
    "        attent = self.conv2DSN_attent(attent)\n",
    "\n",
    "        return X + (nn.Parameter(torch.zeros(1)) * attent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D Conditional Batch Normalization Layer Class\n",
    "class c2DBatchNorm(nn.Module):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_feats: int,                 #\n",
    "        dim_embedding: int = 128,       #\n",
    "        momentum: float = 0.001         #\n",
    "    ):\n",
    "\n",
    "        # Layer Architecture Construction\n",
    "        super().__init__()\n",
    "        self.num_feats = num_feats\n",
    "        self.layer = nn.BatchNorm2d(num_feats, momentum = momentum, affine = False)\n",
    "        self.embedding = nn.Linear(dim_embedding, num_feats, bias = False)\n",
    "\n",
    "    # Layer Application Function\n",
    "    def forward(\n",
    "        self,\n",
    "        X: torch.Tensor,                # Tensor containing Data\n",
    "        y: torch.Tensor                 # Tensor containing Labels\n",
    "    ):\n",
    "\n",
    "        # Layer Walkthrough\n",
    "        out = self.layer(X)\n",
    "        gamma = beta = self.embedding(y).view(-1, self.num_feats, 1, 1)\n",
    "        out = out + (gamma * out) + beta\n",
    "        return out\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Main / Repeatable Generator Block Construction Class\n",
    "class GeneratorBlock(nn.Module):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channel: int,\n",
    "        out_channel: int,\n",
    "        dim_embedding: int = 128\n",
    "    ):\n",
    "\n",
    "        # Block Architecture Construction\n",
    "        super().__init__()\n",
    "        self.c2DBN_1 = c2DBatchNorm(            in_channel, dim_embedding)\n",
    "        self.conv2DSN_1 = Conv2DSpectralNorm(   in_channel, out_channel,\n",
    "                                                kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.c2DBN_2 = c2DBatchNorm(            out_channel, dim_embedding)\n",
    "        self.conv2DSN_2 = Conv2DSpectralNorm(   out_channel, out_channel,\n",
    "                                                kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv2DSN_X = Conv2DSpectralNorm(   in_channel, out_channel,\n",
    "                                                kernel_size = 1, stride = 1, padding = 0)\n",
    "\n",
    "    # Layer Application Function\n",
    "    def forward(\n",
    "        self,\n",
    "        X: torch.Tensor,                # Tensor containing Data\n",
    "        y: torch.Tensor                 # Tensor containing Labels\n",
    "    ):\n",
    "\n",
    "        # Block Walkthrough (Data Processing)\n",
    "        X_0 = X                              # Copy of Original Data\n",
    "        X_0 = F.interpolate(X_0, scale_factor = 2, mode = 'nearest')\n",
    "        X_0 = self.conv2DSN_X(X_0)\n",
    "\n",
    "        # Block Walkthrough\n",
    "        X = self.c2DBN_1(X, y)\n",
    "        X = nn.ReLU(inplace = True)(X)\n",
    "        X = F.interpolate(X, scale_factor = 2, mode = 'nearest')\n",
    "        X = self.conv2DSN_1(X)\n",
    "        X = self.c2DBN_2(X, y)\n",
    "        X = nn.ReLU(inplace = True)(X)\n",
    "        X = self.conv2DSN_2(X)\n",
    "\n",
    "        out = X + X_0\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight Initialization Function\n",
    "def weightInit(module):\n",
    "    if type(module) == nn.Linear or type(module) == nn.Conv2d:\n",
    "        nn.init.xavier_uniform_(module.weight)\n",
    "        if module.bias is not None: module.bias.data.fill_(0.)\n",
    "\n",
    "# Generator Model Class\n",
    "class Generator(nn.Module):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim_z: int = 256,               # Z Space Dimensionality\n",
    "        dim_embedding: int = 128,       # Embedding Space Dimensionality\n",
    "        num_channels: int = 64,         #\n",
    "        momentum: float = 0.0001,       #\n",
    "        eps: float = 1e-5,              #\n",
    "    ):\n",
    "\n",
    "        # Class Variable Logging\n",
    "        super().__init__()\n",
    "        self.dim_z = dim_z\n",
    "        self.num_channels = num_channels\n",
    "\n",
    "        # Generator Architecture\n",
    "        #self.gen = nn.Sequential(); genList = dict()\n",
    "        self.linearSN = LinearSpectralNorm( self.dim_z,  self.num_channels * 16 * 4 * 4,\n",
    "                                            self.num_channels)                  # (4 x 4) Image\n",
    "        self.genBlock1 = GeneratorBlock(    num_channels * 16,                  #    |\n",
    "                                            num_channels * 16, dim_embedding)   # (8 x 8) Image\n",
    "        self.genBlock2 = GeneratorBlock(    num_channels * 16,                  #    |\n",
    "                                            num_channels * 8, dim_embedding)    # (16 x 16) Image\n",
    "        self.genBlock3 = GeneratorBlock(    num_channels * 8,                   #     |\n",
    "                                            num_channels * 4, dim_embedding)    # (32 x 32) Image\n",
    "        self.selfAttention = SelfAttention( num_channels * 4)                   # (32 x 32) Image\n",
    "        self.genBlock4 = GeneratorBlock(    num_channels * 4,                   #     |\n",
    "                                            num_channels * 2, dim_embedding)    # (64 x 64) Image\n",
    "        self.genBlock5 = GeneratorBlock(    num_channels * 2,                   #      |\n",
    "                                            num_channels * 1, dim_embedding)    # (128 x 128) Image\n",
    "        self.genPost = nn.Sequential(                                           # Image Post-Processing\n",
    "            nn.BatchNorm2d(     num_channels, eps = eps,\n",
    "                                momentum = momentum, affine = True),\n",
    "            nn.ReLU(            inplace = True),\n",
    "            Conv2DSpectralNorm( num_channels, 1,\n",
    "                                kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.Tanh())\n",
    "        \n",
    "        # Weight & Parameter Initialization\n",
    "        self.visualizer()               # Parameter Numbers Visualization\n",
    "        self.apply(weightInit)          # Weight Initialization Function     \n",
    "\n",
    "    # Model Visualizer Function\n",
    "    def visualizer(self):\n",
    "        \n",
    "        # Number of Total & Trainable Parameters\n",
    "        num_total = sum(p.numel()   for p in self.parameters())     # Number of Total Parameters\n",
    "        num_train = sum(p.numel()   for p in self.parameters()      # Number of Trainable Parameters \n",
    "                                    if p.requires_grad)             # (those that Require Autograd)\n",
    "        print(f\"Generator | Total Parameters: {num_total}\\n          | Trainable Parameters: {num_train}\")\n",
    "\n",
    "    # Layer Application Function\n",
    "    def forward(\n",
    "        self,\n",
    "        z: torch.Tensor,                # Tensor containing Z Space Data\n",
    "        y: torch.Tensor                 # Tensor containing Labels\n",
    "    ):\n",
    "\n",
    "        # Block Walkthrough\n",
    "        out = self.linearSN(z)                              # (4 x 4) Image\n",
    "        out = out.view(-1, self.num_channels * 16, 4, 4)    # (4 x 4) Image\n",
    "        out = self.genBlock1(out, y)                        # (8 x 8) Image\n",
    "        out = self.genBlock2(out, y)                        # (16 x 16) Image\n",
    "        out = self.genBlock3(out, y)                        # (32 x 32) Image\n",
    "        out = self.selfAttention(out)                       # (32 x 32) Image\n",
    "        out = self.genBlock4(out, y)                        # (64 x 64) Image\n",
    "        out = self.genBlock5(out, y)                        # (128 x 128) Image\n",
    "        out = self.genPost(out)                             # Image Post-Processing\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D Data Sample Creation\n",
    "X = pickle.load(open(f'Test MUDI Data', 'rb'))\n",
    "y = pickle.load(open(f'Test MUDI Labels', 'rb'))\n",
    "X = X[0:35,:]; y = y.iloc[0:35]; y['Patient'] = 11\n",
    "h = y2h_model(y); h = torch.Tensor(h)\n",
    "X = torch.Tensor(X); y = torch.Tensor(y.values)\n",
    "\n",
    "# Generator Model Testing Example\n",
    "gen = Generator()\n",
    "z = torch.randn(X.shape[0], 256, dtype = torch.float)   # Random Noise Generation\n",
    "genX = gen(z, y = h)\n",
    "trueFig = plt.figure(1); genFig = plt.figure(2)\n",
    "for i in range(genX.shape[0]):\n",
    "    trueAxis = trueFig.add_subplot(5, 7, i + 1); trueAxis.axis('off')\n",
    "    genAxis = genFig.add_subplot(5, 7, i + 1); genAxis.axis('off')\n",
    "    trueAxis.imshow(X.detach().numpy()[i, 0, :, :], cmap = 'gray')\n",
    "    genAxis.imshow(genX.detach().numpy()[i, 0, :, :], cmap = 'gray')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Image* **Discriminator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main / Repeatable Discriminator Block Construction Class\n",
    "class DiscriminatorBlock(nn.Module):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channel: int,\n",
    "        out_channel: int,\n",
    "        downsample: bool = True         # Boolean Control Variable for Downsampling\n",
    "    ):\n",
    "\n",
    "        # Block Architecture Construction\n",
    "        super().__init__()\n",
    "        if in_channel != out_channel: self.mismatch = True\n",
    "        else: self.mismatch = False\n",
    "        self.downsample = downsample\n",
    "        self.conv2DSN_1 = Conv2DSpectralNorm(   in_channel, out_channel,\n",
    "                                                kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv2DSN_2 = Conv2DSpectralNorm(   out_channel, out_channel,\n",
    "                                                kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.downsampleLayer = nn.AvgPool2d(2)\n",
    "        self.conv2DSN_X = Conv2DSpectralNorm(   in_channel, out_channel,\n",
    "                                                kernel_size = 1, stride = 1, padding = 0)\n",
    "        \n",
    "    # Block Application Function\n",
    "    def forward(\n",
    "        self,\n",
    "        X: torch.Tensor                 # Tensor containing Data\n",
    "    ):\n",
    "\n",
    "        # Block Walkthrough (Data Processing)\n",
    "        X_0 = X.detach().clone()        # Copy of Original Data\n",
    "        if self.downsample or self.mismatch:\n",
    "            X_0 = self.conv2DSN_X(X_0)\n",
    "            if self.downsample: X_0 = self.downsampleLayer(X_0)\n",
    "\n",
    "        # Block Walkthrough\n",
    "        X = nn.ReLU(inplace = True)(X)\n",
    "        X = self.conv2DSN_1(X)\n",
    "        X = nn.ReLU(inplace = True)(X)\n",
    "        X = self.conv2DSN_2(X)\n",
    "        if self.downsample: X = self.downsampleLayer(X)\n",
    "\n",
    "        out = (X + X_0)\n",
    "        return out\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Optimal Discriminator Block Construction Class\n",
    "class OptimalBlock(nn.Module):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channel: int,\n",
    "        out_channel: int,\n",
    "    ):\n",
    "\n",
    "        # Block Architecture Construction\n",
    "        super().__init__()\n",
    "        self.X0Block = nn.Sequential(\n",
    "            nn.AvgPool2d(2),\n",
    "            Conv2DSpectralNorm( in_channel, out_channel,\n",
    "                                kernel_size = 1, stride = 1, padding = 0))\n",
    "        self.XBlock = nn.Sequential(\n",
    "            Conv2DSpectralNorm( in_channel, out_channel,\n",
    "                                kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(inplace = True),\n",
    "            Conv2DSpectralNorm( out_channel, out_channel,\n",
    "                                kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.AvgPool2d(2))\n",
    "\n",
    "    # Block Application Function\n",
    "    def forward(\n",
    "        self,\n",
    "        X: torch.Tensor                 # Tensor containing Data\n",
    "    ):\n",
    "\n",
    "        # Block Walkthrough\n",
    "        X_0 = self.X0Block(X)\n",
    "        X = self.XBlock(X)\n",
    "        out = X + X_0\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator Model Class\n",
    "class Discriminator(nn.Module):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        #num_labels: int = 7,           # Number of Labels provided in y\n",
    "        dim_embedding: int = 128,       # Embedding Space Dimensionality\n",
    "        num_channels: int = 64,         # Number of Neural Net Channels\n",
    "    ):\n",
    "\n",
    "        # Class Variable Logging\n",
    "        super().__init__()\n",
    "        self.num_channels = num_channels\n",
    "\n",
    "        # Discriminator Architecture\n",
    "        self.main = nn.Sequential(\n",
    "            OptimalBlock(       1,                  num_channels),          # (128 x 128) Image\n",
    "            DiscriminatorBlock( num_channels,       num_channels * 2),      # (64 x 64) Image\n",
    "            SelfAttention(      num_channels * 2),                          # (64 x 64) Image\n",
    "            DiscriminatorBlock( num_channels * 2,   num_channels * 4),      # (32 x 32) Image\n",
    "            DiscriminatorBlock( num_channels * 4,   num_channels * 8),      # (16 x 16) Image\n",
    "            DiscriminatorBlock( num_channels * 8,   num_channels * 16),     # (8 x 8) Image\n",
    "            DiscriminatorBlock( num_channels * 16,   num_channels * 16,     # (4 x 4) Image\n",
    "                                downsample = False),\n",
    "            nn.ReLU(inplace = True))                                        # (4 x 4) Image\n",
    "        self.linearSN = self.LinearSpectralNorm(num_channels * 16 * 4 * 4, 1)\n",
    "        self.embedding = self.LinearSpectralNorm(dim_embedding, num_channels * 16 * 4 * 4, bias = False)\n",
    "\n",
    "        # Weight & Parameter Initialization\n",
    "        self.visualizer()               # Parameter Numbers Visualization\n",
    "        self.apply(weightInit)          # Weight Initialization Function    \n",
    "        nn.init.xavier_uniform_(self.embedding.weight) \n",
    "\n",
    "    # Model Visualizer Function\n",
    "    def visualizer(self):\n",
    "        \n",
    "        # Number of Total & Trainable Parameters\n",
    "        num_total = sum(p.numel()   for p in self.parameters())     # Number of Total Parameters\n",
    "        num_train = sum(p.numel()   for p in self.parameters()      # Number of Trainable Parameters \n",
    "                                    if p.requires_grad)             # (those that Require Autograd)\n",
    "        print(f\"Discriminator | Total Parameters: {num_total}\\n              | Trainable Parameters: {num_train}\")\n",
    "\n",
    "    # Linear Spectral Normalization Layer Function\n",
    "    def LinearSpectralNorm(\n",
    "        self,\n",
    "        in_channel: int,\n",
    "        out_channel: int,\n",
    "        bias: bool = True\n",
    "    ):\n",
    "        return spectral_norm(nn.Linear(in_channel, out_channel, bias = bias))\n",
    "\n",
    "    # Layer Application Function\n",
    "    def forward(\n",
    "        self,\n",
    "        X: torch.Tensor,                # Tensor containing Data\n",
    "        h: torch.Tensor                 # Tensor containing Embedded Labels\n",
    "    ):\n",
    "\n",
    "        # Block Walkthrough\n",
    "        out = self.main(X)                              # (128 x 128) -> (4 x 4) Image\n",
    "        out = out.view(-1, self.num_channels * 16 * 4 * 4)\n",
    "        out1 = torch.squeeze(self.linearSN(out))        # 1st Output Section (Linear)\n",
    "        h = self.embedding(h)                           # Embedded Labels\n",
    "        out2 = torch.sum(torch.mul(out, h), dim = [1])  # 2nd Output Section (Projection)\n",
    "        return (out1 + out2).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D Data Sample Creation\n",
    "X = pickle.load(open(f'Test MUDI Data', 'rb'))\n",
    "y = pickle.load(open(f'Test MUDI Labels', 'rb'))\n",
    "X = X[0:35,:]; y = y.iloc[0:35]; y['Patient'] = 11\n",
    "h = y2h_model(y); h = torch.Tensor(h)\n",
    "X = torch.Tensor(X); y = torch.Tensor(y.values)\n",
    "\n",
    "# Discriminator Model Testing Example\n",
    "testX = torch.randn(X.shape[0], 1, 128, 128)\n",
    "dis = Discriminator()\n",
    "out = dis(testX, y)\n",
    "#summary(dis, [testX.shape, y.shape])\n",
    "\n",
    "\"\"\"\n",
    "h = torch.Tensor(t3Net(y_train[0:500,:]))\n",
    "dis = Discriminator()\n",
    "out = dis(X_train[0:500,:], h)\n",
    "print(out.shape)\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **Running** *Scripts*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Embedding Models Training, Validation & Testing Script Class\n",
    "class LitT12Net(pl.LightningModule):\n",
    "\n",
    "    ##############################################################################################\n",
    "    # --------------------------------------- Initial Setup --------------------------------------\n",
    "    ##############################################################################################\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,              # Model Settings & Parametrizations\n",
    "    ):\n",
    "\n",
    "        # Class Variable Logging\n",
    "        super().__init__()\n",
    "        self.settings = settings\n",
    "        self.lr_decay_epochs = [80, 140]                # Epochs for Learning Rate Decay\n",
    "\n",
    "        # Model Initialization\n",
    "        self.model = LabelEmbedding(in_channel = 64,\n",
    "                                    expansion= settings.expansion,\n",
    "                                    dim_embedding = settings.dim_embedding,\n",
    "                                    num_labels = settings.num_labels)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        \n",
    "        # Existing Model Checkpoint Loading\n",
    "        self.model_filepath = Path(f\"{self.settings.save_folderpath}/V{self.settings.model_version}/Embedding Net (V{self.settings.model_version}).pth\")\n",
    "        if self.settings.model_version != 0 and self.model_filepath.exists():\n",
    "\n",
    "            # Checkpoint Fixing (due to the use of nn.DataParallel)\n",
    "            checkpoint = torch.load(self.model_filepath); self.checkpoint_fix = dict()\n",
    "            for sd, sd_value in checkpoint.items():\n",
    "                if sd == 'ModelSD' or sd == 'OptimizerSD':\n",
    "                    self.checkpoint_fix[sd] = OrderedDict()\n",
    "                    for key, value in checkpoint[sd].items():\n",
    "                        if key[0:7] == 'module.':\n",
    "                            self.checkpoint_fix[sd][key[7:]] = value\n",
    "                        else: self.checkpoint_fix[sd][key] = value\n",
    "                else: self.checkpoint_fix[sd] = sd_value\n",
    "            \n",
    "            # Application of Checkpoint's State Dictionary\n",
    "            self.model.load_state_dict(self.checkpoint_fix['ModelSD'])\n",
    "            torch.set_rng_state(self.checkpoint_fix['RNG State'])\n",
    "            del checkpoint#, checkpoint_fix\n",
    "        self.model = nn.DataParallel(self.model.to(self.settings.device))\n",
    "\n",
    "    # Optimizer Initialization Function\n",
    "    def configure_optimizers(self):\n",
    "        self.optimizer = torch.optim.SGD(   self.model.parameters(),                # T3 Model Optimizer\n",
    "                                            lr = self.settings.base_lr,             # using T2's Parameters\n",
    "                                            momentum = 0.9,\n",
    "                                            weight_decay = self.settings.weight_decay)\n",
    "        if self.settings.model_version != 0 and self.model_filepath.exists():       # T3 Model Optimizer\n",
    "            self.optimizer.load_state_dict(self.checkpoint_fix['OptimizerSD'])      # Checkpoint Loading\n",
    "        self.lr_schedule = torch.optim.lr_scheduler.ExponentialLR(  self.optimizer, # Learning Rate Decay\n",
    "                                                    gamma = self.settings.lr_decay) # in Chosen Epochs\n",
    "        return self.optimizer\n",
    "\n",
    "    # Foward Functionality\n",
    "    def forward(self, X): return self.model(X)\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Train Set DataLoader Download\n",
    "    def train_dataloader(self):\n",
    "        TrainTrainLoader = v3DMUDI.loader(  Path(f\"{self.settings.data_folderpath}\"),\n",
    "                                            dim = 2, version = self.settings.data_version,\n",
    "                                            set_ = 'Train', mode_ = 'Train')\n",
    "        self.train_batches = len(TrainTrainLoader)\n",
    "        return TrainTrainLoader\n",
    "    \n",
    "    # Validation Set DataLoader Download\n",
    "    def val_dataloader(self):\n",
    "        TrainValLoader = v3DMUDI.loader(Path(f\"{self.settings.data_folderpath}\"),\n",
    "                                        dim = 2, version = self.settings.data_version,\n",
    "                                        set_ = 'Train', mode_ = 'Val')\n",
    "        self.val_batches = len(TrainValLoader)\n",
    "        return TrainValLoader\n",
    "\n",
    "    # Test Set DataLoader Download\n",
    "    def test_dataloader(self):\n",
    "        TestValLoader = v3DMUDI.loader( Path(f\"{self.settings.data_folderpath}\"),\n",
    "                                        dim = 2, version = self.settings.data_version,\n",
    "                                        set_ = 'Test', mode_ = 'Val')\n",
    "        self.test_batches = len(TestValLoader)\n",
    "        return TestValLoader\n",
    "\n",
    "    ##############################################################################################\n",
    "    # ------------------------------------- Training Script --------------------------------------\n",
    "    ##############################################################################################\n",
    "\n",
    "    # Functionality called upon the Start of Training\n",
    "    def on_train_start(self):\n",
    "        \n",
    "        # Model Training Mode Setup\n",
    "        self.model.train()\n",
    "        if self.settings.model_version == 0:\n",
    "            self.current_epoch = self.settings.num_epochs - 1\n",
    "\n",
    "        # TensorBoard Loggers Initialization\n",
    "        self.train_loss_logger = TensorBoardLogger(f'{self.settings.save_folderpath}/V{self.settings.model_version}/T12 Net', 'Training Performance')\n",
    "        self.val_loss_logger = TensorBoardLogger(f'{self.settings.save_folderpath}/V{self.settings.model_version}/T12 Net', 'Validation Performance')\n",
    "\n",
    "    # Functionality called upon the Start of Training Epoch\n",
    "    def on_train_epoch_start(self): self.train_loss = 0\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Training Step / Batch Loop \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        # Label Handling + Noise Addition\n",
    "        X_batch, ygt_batch = batch\n",
    "        X_batch = X_batch.type(torch.float).to(self.settings.device)\n",
    "        ygt_batch = ygt_batch.type(torch.float).to(self.settings.device)\n",
    "\n",
    "        # Forward Pass\n",
    "        h_batch, y_batch = self.model(X_batch)                  # T12 Model (X -> h -> y)\n",
    "        loss = self.criterion(y_batch, ygt_batch)               # Loss Computation\n",
    "        del X_batch, ygt_batch, h_batch\n",
    "        return loss\n",
    "\n",
    "    # Functionality called upon the End of a Batch Training Step\n",
    "    def on_train_batch_end(self, loss): self.train_loss = self.train_loss + loss.cpu().item()\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Functionality called upon the End of a Training Epoch\n",
    "    def on_train_epoch_end(self):\n",
    "\n",
    "        # Learning Rate Decay\n",
    "        if (self.trainer.current_epoch + 1) in self.lr_decay_epochs:\n",
    "            self.lr_schedule.step()\n",
    "\n",
    "        # TensorBoard Logger Update\n",
    "        self.train_loss = self.train_loss / self.train_batches\n",
    "        self.train_loss_logger.experiment.add_scalar(\"Training Loss\", self.train_loss, self.current_epoch)\n",
    "        \n",
    "        # Model Checkpoint Saving\n",
    "        torch.save({'ModelSD': self.model.state_dict(),\n",
    "                    'OptimizerSD': self.optimizer.state_dict(),\n",
    "                    'Training Epochs': self.current_epoch,\n",
    "                    'RNG State': torch.get_rng_state()},\n",
    "                    self.model_filepath)\n",
    "\n",
    "    ##############################################################################################\n",
    "    # ------------------------------------ Validation Script -------------------------------------\n",
    "    ##############################################################################################\n",
    "\n",
    "    # Functionality called upon the Start of Validation\n",
    "    def on_validation_start(self): self.model.eval()\n",
    "\n",
    "    # Functionality called upon the Start of Training Epoch\n",
    "    def on_validation_epoch_start(self): self.val_loss = 0\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Training Step / Batch Loop \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \n",
    "        # Label Handling + Noise Addition\n",
    "        X_batch, ygt_batch = batch\n",
    "        X_batch = X_batch.type(torch.float).to(self.settings.device)\n",
    "        ygt_batch = ygt_batch.type(torch.float).to(self.settings.device)\n",
    "\n",
    "        # Forward Pass\n",
    "        h_batch, y_batch = self.model(X_batch)                  # T12 Model (X -> h -> y)\n",
    "        loss = self.criterion(y_batch, ygt_batch)               # Loss Computation\n",
    "        self.val_loss = self.val_loss + loss.cpu().item()\n",
    "        del X_batch, ygt_batch, h_batch\n",
    "        return loss\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Functionality called upon the End of a Training Epoch\n",
    "    def on_train_epoch_end(self):\n",
    "        \n",
    "        # TensorBoard Logger Update\n",
    "        self.val_loss = self.val_loss / self.val_batches\n",
    "        self.val_loss_logger.experiment.add_scalar(\"Training Loss\", self.val_loss, self.current_epoch)\n",
    "    \n",
    "    ##############################################################################################\n",
    "    # ------------------------------------- Testing Script ---------------------------------------\n",
    "    ##############################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T3 Embedding Model Training, Validation & Testing Script Class\n",
    "class LitT3Net(pl.LightningModule):\n",
    "\n",
    "    ##############################################################################################\n",
    "    # --------------------------------------- Initial Setup --------------------------------------\n",
    "    ##############################################################################################\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,              # Model Settings & Parametrizations\n",
    "        embedNet: LabelEmbedding,                       # Trained T1 & T2 Conjoint Model\n",
    "    ):\n",
    "\n",
    "        # Class Variable Logging\n",
    "        super().__init__()\n",
    "        self.settings = settings\n",
    "        #self.embedNet = embedNet                        # Label Embedding Variable\n",
    "        self.t2Net = embedNet.module.t2Net              # T2 Model Contained in Label Embedding Variable\n",
    "        self.lr_decay_epochs = [150, 250, 350]          # Epochs for Learning Rate Decay\n",
    "\n",
    "        # Model Initialization\n",
    "        self.model = t3Net( dim_embedding = self.settings.dim_embedding,\n",
    "                            num_labels = self.settings.num_labels)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        \n",
    "        # Existing Model Checkpoint Loading\n",
    "        self.model_filepath = Path(f\"{self.settings.save_folderpath}/V{self.settings.model_version}/T3 Net (V{self.settings.model_version}).pth\")\n",
    "        if self.settings.model_version != 0 and self.model_filepath.exists():\n",
    "\n",
    "            # Checkpoint Fixing (due to the use of nn.DataParallel)\n",
    "            checkpoint = torch.load(self.model_filepath); self.checkpoint_fix = dict()\n",
    "            for sd, sd_value in checkpoint.items():\n",
    "                if sd == 'ModelSD' or sd == 'OptimizerSD':\n",
    "                    self.checkpoint_fix[sd] = OrderedDict()\n",
    "                    for key, value in checkpoint[sd].items():\n",
    "                        if key[0:7] == 'module.':\n",
    "                            self.checkpoint_fix[sd][key[7:]] = value\n",
    "                        else: self.checkpoint_fix[sd][key] = value\n",
    "                else: self.checkpoint_fix[sd] = sd_value\n",
    "            \n",
    "            # Application of Checkpoint's State Dictionary\n",
    "            self.model.load_state_dict(self.checkpoint_fix['ModelSD'])\n",
    "            #self.optimizer.load_state_dict(self.checkpoint_fix['OptimizerSD'])\n",
    "            #current_epoch = self.checkpoint_fix['Training Epochs']\n",
    "            torch.set_rng_state(self.checkpoint_fix['RNG State'])\n",
    "            del checkpoint#, checkpoint_fix\n",
    "        self.model = nn.DataParallel(self.model.to(self.settings.device))\n",
    "\n",
    "    # Optimizer Initialization Function\n",
    "    def configure_optimizers(self):\n",
    "        self.optimizer = torch.optim.SGD(   self.t2Net.parameters(),                # T3 Model Optimizer\n",
    "                                            lr = self.settings.base_lr,             # using T2's Parameters\n",
    "                                            momentum = 0.9,\n",
    "                                            weight_decay = self.settings.weight_decay)\n",
    "        if self.settings.model_version != 0 and self.model_filepath.exists():       # T3 Model Optimizer\n",
    "            self.optimizer.load_state_dict(self.checkpoint_fix['OptimizerSD'])      # Checkpoint Loading\n",
    "        self.lr_schedule = torch.optim.lr_scheduler.ExponentialLR(  self.optimizer, # Learning Rate Decay\n",
    "                                                    gamma = self.settings.lr_decay) # in Chosen Epochs\n",
    "        return self.optimizer\n",
    "\n",
    "    # Foward Functionality\n",
    "    def forward(self, y): return self.model(y)\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Train Set DataLoader Download\n",
    "    def train_dataloader(self):\n",
    "        TrainTrainLoader = v3DMUDI.loader(  Path(f\"{self.settings.data_folderpath}\"),\n",
    "                                            dim = 2, version = self.settings.data_version,\n",
    "                                            set_ = 'Train', mode_ = 'Train')\n",
    "        self.train_batches = len(TrainTrainLoader)\n",
    "        return TrainTrainLoader\n",
    "    \n",
    "    # Validation Set DataLoader Download\n",
    "    def val_dataloader(self):\n",
    "        TrainValLoader = v3DMUDI.loader(Path(f\"{self.settings.data_folderpath}\"),\n",
    "                                        dim = 2, version = self.settings.data_version,\n",
    "                                        set_ = 'Train', mode_ = 'Val')\n",
    "        self.val_batches = len(TrainValLoader)\n",
    "        return TrainValLoader\n",
    "\n",
    "    # Test Set DataLoader Download\n",
    "    def test_dataloader(self):\n",
    "        TestValLoader = v3DMUDI.loader( Path(f\"{self.settings.data_folderpath}\"),\n",
    "                                        dim = 2, version = self.settings.data_version,\n",
    "                                        set_ = 'Test', mode_ = 'Val')\n",
    "        self.test_batches = len(TestValLoader)\n",
    "        return TestValLoader\n",
    "\n",
    "    ##############################################################################################\n",
    "    # ------------------------------------- Training Script --------------------------------------\n",
    "    ##############################################################################################\n",
    "\n",
    "    # Functionality called upon the Start of Training\n",
    "    def on_train_start(self):\n",
    "        \n",
    "        # Model Training Mode Setup\n",
    "        self.model.train()\n",
    "        if self.settings.model_version == 0:\n",
    "            self.current_epoch = self.settings.num_epochs - 1\n",
    "\n",
    "        # TensorBoard Loggers Initialization\n",
    "        self.train_loss_logger = TensorBoardLogger(f'{self.settings.save_folderpath}/V{self.settings.model_version}/T3 Net', 'Training Performance')\n",
    "\n",
    "    # Functionality called upon the Start of Training Epoch\n",
    "    def on_train_epoch_start(self): self.train_loss = 0\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Training Step / Batch Loop \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        # Label Handling + Noise Addition\n",
    "        X_batch, ygt_batch = batch\n",
    "        ygt_batch = ygt_batch.type(torch.float).to(self.settings.device)\n",
    "        gamma_batch = np.random.normal(0, 0.2, ygt_batch.shape)\n",
    "        gamma_batch = torch.from_numpy(gamma_batch).type(torch.float).to(self.settings.device)\n",
    "        ygt_noise_batch = torch.clamp(ygt_batch + gamma_batch, 0.0, 1.0)\n",
    "\n",
    "        # Forward Pass\n",
    "        h_noise_batch = self.model(ygt_noise_batch)              # T3 Model (y -> h)\n",
    "        y_noise_batch = self.t2Net(h_noise_batch)                # T2 Model (h -> y)\n",
    "        loss = self.criterion(y_noise_batch, ygt_noise_batch)    # Loss Computation\n",
    "        del X_batch, ygt_batch, gamma_batch, ygt_noise_batch, y_noise_batch, h_noise_batch\n",
    "        return loss\n",
    "\n",
    "    # Functionality called upon the End of a Batch Training Step\n",
    "    def on_train_batch_end(self, loss):\n",
    "        \n",
    "        # Backward Pass\n",
    "        #self.optimizer.zero_grad()\n",
    "        #loss.backward(retain_graph = True)\n",
    "        #self.optimizer.step()\n",
    "        self.train_loss = self.train_loss + loss.cpu().item()\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Functionality called upon the End of a Training Epoch\n",
    "    def on_train_epoch_end(self):\n",
    "\n",
    "        # Learning Rate Decay\n",
    "        if (self.trainer.current_epoch + 1) in self.lr_decay_epochs:\n",
    "            self.lr_schedule.step()\n",
    "\n",
    "        # TensorBoard Logger Update\n",
    "        self.train_loss = self.train_loss / self.train_batches\n",
    "        self.train_loss_logger.experiment.add_scalar(\"Training Loss\", self.train_loss, self.current_epoch)\n",
    "        \n",
    "        # Model Checkpoint Saving\n",
    "        torch.save({'ModelSD': self.model.state_dict(),\n",
    "                    'OptimizerSD': self.optimizer.state_dict(),\n",
    "                    'Training Epochs': self.current_epoch,\n",
    "                    'RNG State': torch.get_rng_state()},\n",
    "                    self.model_filepath)\n",
    "\n",
    "    ##############################################################################################\n",
    "    # ------------------------------------ Validation Script -------------------------------------\n",
    "    ##############################################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator & Discriminator Models Training\n",
    "def train_gan(\n",
    "    t3Net: t3Net,                                   # Trained T3 Model\n",
    "    train_set: DataLoader,                          # Training Set's Train DataLoader\n",
    "    settings: argparse.ArgumentParser,              # Model Settings & Parametrizations\n",
    "    train: bool = True,                             # Boolean Control Variable: False if the purpose...\n",
    "):                                                  # is to just Load the Selected Model model_version\n",
    "\n",
    "    # Models Architecture & Optimizer Initialization\n",
    "    gen = Generator(dim_z = settings.dim_z, dim_embedding = settings.dim_embedding)\n",
    "    dis = Discriminator(); current_epoch = 0\n",
    "    gen_optimizer = torch.optim.Adam(gen.parameters(), lr = settings.lr_ccgan, betas = (0.5, 0.999))\n",
    "    dis_optimizer = torch.optim.Adam(dis.parameters(), lr = settings.lr_ccgan, betas = (0.5, 0.999))\n",
    "\n",
    "    # Existing Model Checkpoint Loading\n",
    "    gen_filepath = Path(f\"{settings.save_folderpath}/V{settings.model_version}/Generator (V{settings.model_version}).pth\")\n",
    "    dis_filepath = Path(f\"{settings.save_folderpath}/V{settings.model_version}/Discriminator (V{settings.model_version}).pth\")\n",
    "    if settings.model_version != 0 and gen_filepath.exists() and dis_filepath.exists():\n",
    "\n",
    "        # Generator Checkpoint Fixing (due to the use of nn.DataParallel)\n",
    "        gen_checkpoint = torch.load(gen_filepath); gen_checkpoint_fix = dict()\n",
    "        for sd, sd_value in gen_checkpoint.items():\n",
    "            if sd == 'ModelSD' or sd == 'OptimizerSD':\n",
    "                gen_checkpoint_fix[sd] = OrderedDict()\n",
    "                for key, value in gen_checkpoint[sd].items():\n",
    "                    if key[0:7] == 'module.':\n",
    "                        gen_checkpoint_fix[sd][key[7:]] = value\n",
    "                    else: gen_checkpoint_fix[sd][key] = value\n",
    "            else: gen_checkpoint_fix[sd] = sd_value\n",
    "\n",
    "        # Discriminator Checkpoint Fixing (due to the use of nn.DataParallel)\n",
    "        dis_checkpoint = torch.load(dis_filepath); dis_checkpoint_fix = dict()\n",
    "        for sd, sd_value in dis_checkpoint.items():\n",
    "            if sd == 'ModelSD' or sd == 'OptimizerSD':\n",
    "                dis_checkpoint_fix[sd] = OrderedDict()\n",
    "                for key, value in dis_checkpoint[sd].items():\n",
    "                    if key[0:7] == 'module.':\n",
    "                        dis_checkpoint_fix[sd][key[7:]] = value\n",
    "                    else: dis_checkpoint_fix[sd][key] = value\n",
    "            else: dis_checkpoint_fix[sd] = sd_value\n",
    "\n",
    "        # Generator Checkpoint Loading\n",
    "        gen.load_state_dict(gen_checkpoint_fix['ModelSD'])\n",
    "        gen_optimizer.load_state_dict(gen_checkpoint_fix['OptimizerSD'])\n",
    "        current_epoch = gen_checkpoint_fix['Training Epochs']\n",
    "\n",
    "        # Discriminator Checkpoint Loading\n",
    "        dis.load_state_dict(dis_checkpoint_fix['ModelSD'])\n",
    "        dis_optimizer.load_state_dict(dis_checkpoint_fix['OptimizerSD'])\n",
    "        torch.set_rng_state(dis_checkpoint_fix['RNG State'])\n",
    "        del gen_checkpoint, dis_checkpoint, gen_checkpoint_fix, dis_checkpoint_fix\n",
    "    \n",
    "    # Model Transfer to CUDA Device\n",
    "    t3Net = t3Net.to(settings.device); t3Net.eval()\n",
    "    gen = nn.DataParallel(gen).to(settings.device)\n",
    "    dis = nn.DataParallel(dis).to(settings.device)\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "    if not(train):\n",
    "        print(f\"DOWNLOAD: Generator Model (V{settings.model_version})\")\n",
    "        print(f\"DOWNLOAD: Discriminator Model (V{settings.model_version})\")\n",
    "    else:\n",
    "\n",
    "        # Data Accessing Betterment\n",
    "        nRow= nCol = 10\n",
    "        X_train, y_train = train_set.dataset[:]\n",
    "        nSamples, nLabels = y_train.shape\n",
    "        if settings.model_version != 0: assert(settings.batch_size == train_set.batch_size\n",
    "        ), \"ERROR: Batch Size Value not Corresponding\"\n",
    "\n",
    "        # Training Image Selection between the 5th & 95th Label Percentile\n",
    "        sel_label = np.empty((nRow, nLabels))\n",
    "        start_label = np.quantile(y_train, 0.05, axis = 0)      # 5th Percentile Label Value\n",
    "        end_label = np.quantile(y_train, 0.95, axis = 0)        # 95th Percentile Label Value\n",
    "        for l in range(nLabels): sel_label[:, l] = np.linspace(start_label[l], end_label[l], num = nRow)\n",
    "        del start_label, end_label\n",
    "\n",
    "        # Automated Label-Specific Kappa Difference Computation & Gaussian Noise Generation Function\n",
    "        kappa_list = np.empty(nLabels)\n",
    "        for l in range(nLabels): kappa_list[l] = np.mean(np.diff(np.sort(np.unique(y_train[:, l].numpy()))))\n",
    "        if nLabels >= 6: kappa_list[-1] = 0.0\n",
    "        def eps(samples):\n",
    "            eps_pos = np.random.normal(0, settings.kernel_eps, (samples, nLabels))\n",
    "            eps_neg = np.random.normal(0, settings.kernel_eps, (samples, nLabels))\n",
    "            return (eps_pos - eps_neg) * (kappa_list / 2)\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # Epoch Loop\n",
    "        if settings.model_version == 0: settings.num_epochs = 1; settings.batch_size = 1\n",
    "        dis_loss_table = np.empty(0, dtype = np.float)\n",
    "        gen_loss_table = np.empty(0, dtype = np.float)\n",
    "        for epoch in range(current_epoch, current_epoch + settings.num_epochs):\n",
    "\n",
    "            # Discriminator Training Process / Step Loop\n",
    "            with alive_bar( settings.dis_update, bar = 'blocks',\n",
    "                        title = f'Epoch #{epoch} | Discriminator ',\n",
    "                        force_tty = True) as dis_bar:\n",
    "                for up in range(settings.dis_update):\n",
    "\n",
    "                    # Random Draw of Batch of Target Labels (w/ Added Gaussian Noise)\n",
    "                    \"\"\"[Bug] Since the Target Labels are chosen from the Overall Dataset\n",
    "                    and not from a List of Unique Labels, there might be some Repeats,\n",
    "                    though it is also a fact there aren't that many Unique Values\"\"\"\n",
    "                    y_target = y_train[np.random.choice(nSamples, size = settings.batch_size, replace = False), :]   # Random Batch of Target Labels\n",
    "                    y_vic = y_target + eps(settings.batch_size)                                                      # Initial Addition of Gaussian Noise\n",
    "                    index_target = np.empty(settings.batch_size, dtype = int)                       # Vicinity-Labelled Real Image Indexes\n",
    "                    y_fake = np.empty((settings.batch_size, nLabels))                               # Fake Vicinity Labels for Image Generation\n",
    "                \n",
    "                    # Batch Loop\n",
    "                    for i in range(settings.batch_size):\n",
    "                        \n",
    "                        # Hard Vicinity-Labelled Real Image Searching\n",
    "                        index_vic = np.where(np.all(np.abs(y_train - y_vic[i, :]).numpy()           # Index of Real in-Vicinity Training Sample Labels\n",
    "                                                        <= (kappa_list * 2.0), axis = 1))[0]\n",
    "                        while len(index_vic) < nLabels:                                             # Redoing of the Vicinity Area Loop...\n",
    "                            y_vic[i, :] = y_target[i, :] + eps(1)                                   # using different Gaussian Noise values...\n",
    "                            index_vic = np.where(np.all(np.abs(y_train - y_vic[i, :]).numpy()       # to Ensure that at least 'nlabels' Neighbour...\n",
    "                                                        <= (kappa_list * 2.0), axis = 1))[0]        # for each Target in the Random Batch is found!\n",
    "                        index_target[i] = np.random.choice(index_vic, size = 1)                     # Choosing of 1 in-Vicinity Sample per Target\n",
    "\n",
    "                        # Fake Image Label Generation\n",
    "                        inf_bound = y_vic[i, :] - kappa_list\n",
    "                        sup_bound = y_vic[i, :] + kappa_list\n",
    "                        assert(np.all((inf_bound <= sup_bound).numpy())), \"ERROR: Kappa Paremeter wrongly Set!\"\n",
    "                        y_fake[i, :] = np.random.uniform(inf_bound, sup_bound, size = nLabels)      # Random Creation of a Fake Label Sample...\n",
    "                        assert(np.all(np.abs(y_fake[i, :] - y_vic[i, :].numpy())                    # that must remain within Vicinity...\n",
    "                                    <= kappa_list)), \"ERROR: Kappa Paremeter wrongly Set!\"          # of the used batch Target Label \n",
    "\n",
    "                    # Hard Vicinity-Labelled Real Image Drawing\n",
    "                    X_vic = torch.Tensor(X_train[index_target]).type(torch.float).to(settings.device)\n",
    "                    y_vic = torch.Tensor(y_train[index_target]).type(torch.float).to(settings.device)\n",
    "                    del index_target, index_vic, inf_bound, sup_bound\n",
    "\n",
    "                    # Fake Image Generation\n",
    "                    y_fake = torch.from_numpy(y_fake).type(torch.float).to(settings.device)\n",
    "                    z_fake = torch.randn(settings.batch_size, settings.dim_z, dtype = torch.float).to(settings.device)\n",
    "                    X_fake = gen(z_fake, t3Net(y_fake))\n",
    "\n",
    "                    # Forward Pass\n",
    "                    w_target = w_fake = torch.ones(settings.batch_size, dtype = torch.float).to(settings.device)\n",
    "                    out_target = dis(X_vic, t3Net(y_target))\t\t    # Real Sample Discriminator Output\n",
    "                    out_fake = dis(X_fake, t3Net(y_fake))\t\t        # Fake Sample Discriminator Output\n",
    "\n",
    "                    # Vanilla Loss Function Computation Switch Case\n",
    "                    assert(settings.loss == 'vanilla' or settings.loss == 'hinge'\n",
    "                    ), f\"ERROR: Loss Function not Supported!\"\n",
    "                    if settings.loss == 'vanilla':\n",
    "                        loss_target = torch.nn.Sigmoid()(out_target)\n",
    "                        loss_fake = torch.nn.Sigmoid()(out_fake)\n",
    "                        loss_target = torch.log(loss_target + 1e-20)        # Real Sample Loss Value\n",
    "                        loss_fake = torch.log(loss_fake + 1e-20)            # Fake Sample Loss Value\n",
    "\n",
    "                    # Hinge Loss Function Computation Switch Case\n",
    "                    elif settings.loss == 'hinge':                          \n",
    "                        loss_target = torch.nn.ReLU()(1.0 - out_target)\t\t# Real Sample Loss Value\n",
    "                        loss_fake = torch.nn.ReLU()(1.0 + out_fake)\t\t    # Fake Sample Loss Value\n",
    "                    del X_vic, y_vic, z_fake, X_fake, out_target, out_fake, y_fake, y_target\n",
    "\n",
    "                    # Backward Pass & Step Update\n",
    "                    w_target = w_target.unsqueeze(-1); loss_target = loss_target.unsqueeze(-1)\n",
    "                    w_fake = w_fake.unsqueeze(-1); loss_fake = loss_fake.unsqueeze(-1)\n",
    "                    dis_loss =  torch.mean(w_target.view(-1) * loss_target.view(-1)) + torch.mean(w_fake.view(-1) * loss_fake.view(-1))\n",
    "                    dis_optimizer.zero_grad()\n",
    "                    dis_loss.backward()\n",
    "                    dis_optimizer.step()\n",
    "                    dis_loss_table = np.append(dis_loss_table, dis_loss.detach().numpy())\n",
    "                    time.sleep(1); dis_bar()\n",
    "\n",
    "            # --------------------------------------------------------------------------------------------\n",
    "\n",
    "            # Generator Training Process / Step Loop\n",
    "            gen.train()\n",
    "            with alive_bar( settings.gen_update, bar = 'blocks',\n",
    "                    title = f'Epoch #{epoch} | Generator     ',\n",
    "                    force_tty = True) as gen_bar:\n",
    "                for up in range(settings.gen_update):\n",
    "\n",
    "                    # Random Draw of Batch of Target Labels (w/ Added Gaussian Noise)\n",
    "                    \"\"\"[Bug] Since the Target Labels are chosen from the Overall Dataset\n",
    "                    and not from a List of Unique Labels, there might be some Repeats,\n",
    "                    though it is also a fact there aren't that many Unique Values\"\"\"\n",
    "                    y_target = y_train[np.random.choice(nSamples, size = settings.batch_size, replace = False), :]  # Random Batch of Target Labels\n",
    "                    y_fake = (y_target + eps(settings.batch_size)).type(torch.float).to(settings.device)            # Initial Addition of Gaussian Noise\n",
    "\n",
    "                    # Fake Image Generation & Forward Pass\n",
    "                    z_fake = torch.randn(settings.batch_size, settings.dim_z, dtype = torch.float).to(settings.device)\n",
    "                    X_fake = gen(z_fake, t3Net(y_fake))\n",
    "                    out_fake = dis(X_fake, t3Net(y_fake))\t\t        # Fake Sample Discriminator Output\n",
    "\n",
    "                    # Loss Function Computation Switch Case\n",
    "                    assert(settings.loss == 'vanilla' or settings.loss == 'hinge'\n",
    "                    ), f\"ERROR: Loss Function not Supported!\"\n",
    "                    if settings.loss == 'vanilla':\n",
    "                        gen_loss = torch.nn.Sigmoid()(out_fake)\n",
    "                        gen_loss = torch.log(gen_loss + 1e-20)      # Fake Sample Loss Value\n",
    "                    elif settings.loss == 'hinge':                          \n",
    "                        gen_loss = - out_fake.mean()\t\t        # Fake Sample Loss Value\n",
    "                    del z_fake, X_fake, out_fake, y_fake, y_target\n",
    "\n",
    "                    # Backward Pass & Step Update\n",
    "                    gen_optimizer.zero_grad()\n",
    "                    gen_loss.backward()\n",
    "                    gen_optimizer.step()\n",
    "                    gen_loss_table = np.append(gen_loss_table, gen_loss.detach().numpy())\n",
    "                    time.sleep(1); gen_bar()\n",
    "\n",
    "            # --------------------------------------------------------------------------------------------\n",
    "\n",
    "            # Model Progress & State Dictionary Saving\n",
    "            print(f\"Epoch #{epoch} | Discriminator Train Loss: {np.round(dis_loss.detach().numpy(), 3)}\")\n",
    "            print(f\"Epoch #{epoch} | Generator Train Loss: {np.round(gen_loss.detach().numpy(), 3)}\")\n",
    "            torch.save({'ModelSD': dis.state_dict(),\n",
    "                        'OptimizerSD': dis_optimizer.state_dict(),\n",
    "                        'Training Epochs': epoch,\n",
    "                        'RNG State': torch.get_rng_state()},\n",
    "                        dis_filepath)\n",
    "            torch.save({'ModelSD': gen.state_dict(),\n",
    "                        'OptimizerSD': gen_optimizer.state_dict(),\n",
    "                        'Training Epochs': epoch,\n",
    "                        'RNG State': torch.get_rng_state()},\n",
    "                        gen_filepath)\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Training Performance Evaluation - Example Images Visualization\n",
    "        z_fix = torch.randn(nRow * nCol, settings.dim_z, dtype = torch.float).to(settings.device)\n",
    "        gen.eval(); y_fix = np.empty((nRow * nCol, nLabels))\n",
    "        for i in range(nRow):\n",
    "            current_label = sel_label[i, :]\n",
    "            for j in range(nCol):\n",
    "                y_fix[(i * nCol) + j, :] = current_label\n",
    "        y_fix = torch.from_numpy(y_fix).type(torch.float).to(settings.device)\n",
    "        with torch.no_grad(): X_fix = gen(z_fix, t3Net(y_fix)).detach().cpu()\n",
    "        fig, axs = plt.subplots(int(np.ceil(nRow/2)), int(np.ceil(nCol/2)), figsize=(15, 15)); fig.tight_layout()\n",
    "        for i in range(int(np.ceil(nRow/2))):\n",
    "            for j in range(int(np.ceil(nCol/2))):\n",
    "                axs[i, j].imshow(X_fix[int((i * np.ceil(nRow/2)) + j), 0, :, :], cmap = 'gray')\n",
    "                plt.axis('off'), axs[i, j].xaxis.set_visible(False); axs[i, j].yaxis.set_visible(False)\n",
    "        plt.savefig(Path(f\"{settings.save_folderpath}/V{settings.model_version}/Example Images (V{settings.model_version}).png\"))\n",
    "        del z_fix, X_fix, y_fix\n",
    "        \n",
    "        # Training Performance Evaluation - Loss Analysis\n",
    "        fig, ax = plt.subplots(figsize = (10, 10))\n",
    "        ax.plot(dis_loss_table, 'g', label = 'Discriminator')\n",
    "        ax.plot(gen_loss_table, 'r', label = 'Generator')\n",
    "        ax.legend(loc = 'upper right'); ax.set_title('GAN Loss'); ax.set_xticks([])\n",
    "        plt.savefig(Path(f\"{settings.save_folderpath}/V{settings.model_version}/GAN Loss (V{settings.model_version}).png\"))\n",
    "        \n",
    "        # Training Performance Evaluation - Other Analytics\n",
    "        #\n",
    "\n",
    "    return dis, gen\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **Main** *Scripts*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Dataset Version Creation\n",
    "sys.path.append(data_settings.main_folderpath + \"/Dataset Reader\")\n",
    "from v3DMUDI import v3DMUDI\n",
    "data = v3DMUDI(data_settings)\n",
    "data.split(data_settings)\n",
    "data.save()\n",
    "\"\"\"\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Dataset Access\n",
    "sys.path.append(f\"{data_settings.main_folderpath}/Dataset Reader\")\n",
    "from v3DMUDI import v3DMUDI\n",
    "\n",
    "# Dataset Version Creation\n",
    "#data = v3DMUDI(data_settings)\n",
    "#data.split(data_settings)\n",
    "#data.save()\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Full 2D CcGAN Model Class Importing\n",
    "sys.path.append(model_settings.model_folderpath)\n",
    "from LabelEmbedding import LabelEmbedding, t3Net\n",
    "from Generator import Generator\n",
    "from Discriminator import Discriminator\n",
    "\n",
    "# Full 2D CcGAN Model Training Importing\n",
    "sys.path.append(model_settings.script_folderpath)\n",
    "from train_embedNet import LitT12Net\n",
    "from train_t3Net import LitT3Net\n",
    "#from train_gan import Lit2DCcGAN\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Model Initialization & Training | T12 Net\n",
    "\"\"\"\n",
    "t12Net = LitT12Net(model_settings)\n",
    "t12_trainer = pl.Trainer(       max_epochs = 3,#model_settings.num_epochs,\n",
    "                                devices = 1 if torch.cuda.is_available() else None,\n",
    "                                enable_progress_bar = True,\n",
    "                                callbacks = [pl.callbacks.TQDMProgressBar(refresh_rate = 1)])\n",
    "t12_trainer.fit(t12Net)\n",
    "\"\"\"\n",
    "\n",
    "# Model Initialization & Training | T3 Net\n",
    "\"\"\"\n",
    "t3Net = LitT3Net(model_settings, t12Net)\n",
    "t3_trainer = pl.Trainer(max_epochs = model_settings.num_epochs,\n",
    "                        devices = 1 if torch.cuda.is_available() else None,\n",
    "                        enable_progress_bar = True,\n",
    "                        callbacks = [pl.callbacks.TQDMProgressBar(refresh_rate = 1)])\n",
    "t3_trainer.fit(t3Net)\n",
    "\"\"\"\n",
    "\n",
    "# Model Initialization & Training | 2D CcGAN\n",
    "\n",
    "%load_ext tensorboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7e2413ca9464f5b18ee008ec75e3890212b75ca17b4a3699f34f03bf3acaeea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
